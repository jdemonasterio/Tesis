{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ipynb to \n",
    "\n",
    "graph and try out different \n",
    "\n",
    "ML concepts with a sample datasize.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A partir de las 3 tablas ya procesdas : \n",
    "* homeantennas\n",
    "* sumlinks\n",
    "* groundtruth\n",
    "\n",
    "armames un datset para explorar conceptos de ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(180000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 180 seconds\n"
     ]
    }
   ],
   "source": [
    "## seteamos los parametros del notebook\n",
    "%autosave 180\n",
    "import pandas as pd; \n",
    "import os;\n",
    "import random;\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np; import os;import random;\n",
    "# import graphlab as gl\n",
    "from IPython.display import display # para pretty-print con estetica ipython si es que estamos dentro de  un loop, if, etc\n",
    "#esto es para dibujar directo a la notebook\n",
    "# gl.canvas.set_target('ipynb')\n",
    "\n",
    "# for nice graphics and plots\n",
    "import seaborn as sns\n",
    "palette = sns.color_palette()\n",
    "\n",
    "# for nice long graphic titles\n",
    "from textwrap import wrap\n",
    "\n",
    "#seteamos el lugar de trabajo\n",
    "HOMEDIR=os.path.expanduser('~')\n",
    "\n",
    "PROJECTDIR = os.getcwd().split(os.sep)\n",
    "PROJECTDIR =  os.sep.join(PROJECTDIR[:PROJECTDIR.index('mexico-scripts-ver2') + 1])\n",
    "\n",
    "DATADIR = os.path.join(PROJECTDIR,'datasets')\n",
    "\n",
    "DATADIR2 = os.path.join(PROJECTDIR,'data')\n",
    "# os.chdir(DATADIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_balanced_sample.csv  gtruth_0215_0715  sl\r\n",
      "gtruth_0114_0715\t  homeant\t    sl.csv.gz\r\n"
     ]
    }
   ],
   "source": [
    "!ls $DATADIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "graphlab_frame = False\n",
    "# graphlab_frame = 'juan' in HOMEDIR\n",
    "\n",
    "def get_input_sframe(ds,graphlab_frame=graphlab_frame):\n",
    "    if graphlab_frame:\n",
    "        if ds == 'home_antenna': url = DATADIR +\"/homeant\"\n",
    "        elif ds == 'sum_links': url  = DATADIR +\"/sl\"\n",
    "        elif ds == 'gtruth_02': url  = DATADIR +\"/gtruth_0215_0715\" # can be near ground truth (previous to july 2015)\n",
    "        elif ds == 'gtruth_01': url  =  DATADIR +\"/gtruth_0114_0715\" # or can be old GT\n",
    "        else: print('type chosen is %s, type should be home_antenna, sum_links, gtruth_02 or gtruth_01' % ds)\n",
    "    else:\n",
    "        url = DATADIR + '/data_balanced_sample.csv'\n",
    "    return url "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#from unbalanced_dataset import UnderSampler, NearMiss, CondensedNearestNeighbour, OneSidedSelection,\\\n",
    "#NeighbourhoodCleaningRule, TomekLinks, ClusterCentroids, OverSampler, SMOTE,\\\n",
    "#SMOTETomek, SMOTEENN, EasyEnsemble, BalanceCascade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## decide if load a reduced size dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set what is the resulting sample we want of the global dataset\n",
    "global_split = 0.25\n",
    "global_split = None\n",
    "\n",
    "# since we have 2 datets that will be later joined and which are going to be previously sampled, in the end this \n",
    "# independent sampling will result in that, after the join, the dataset will have a size of fraction given by \n",
    "# the `global_split` variable\n",
    "if global_split:\n",
    "    \n",
    "    seed = 2015\n",
    "    sample = pd.np.sqrt(global_split)\n",
    "    print(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.9 s, sys: 212 ms, total: 4.12 s\n",
      "Wall time: 4.68 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "if graphlab_frame:\n",
    "    sf_table, _ = gl.load_sframe(get_input_sframe('home_antenna',graphlab_frame))\n",
    "    sl_table, _ = gl.load_sframe(get_input_sframe('sum_links',graphlab_frame))\n",
    "    # no need to sample the gt table since it is very small in memory\n",
    "    gt_table = gl.load_sframe(get_input_sframe('gtruth_01',graphlab_frame))\n",
    "\n",
    "    if global_split:\n",
    "\n",
    "        sf_table, _ = sf_table.random_split(sample,seed=seed)\n",
    "        sl_table, _ = sl_table.random_split(sample,seed=seed)\n",
    "\n",
    "\n",
    "    rename_gt = (dict([(col,col+\"_gt\") for col in gt_table.column_names() if col != 'USER']))\n",
    "\n",
    "    #agrego la etiqueta \"_gt\" a las columnas del ground_truth\n",
    "    gt_table.rename(rename_gt) \n",
    "else:\n",
    "    data = pd.read_csv(get_input_sframe('sum_links',graphlab_frame))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(153010, 176)\n"
     ]
    }
   ],
   "source": [
    "if graphlab_frame:\n",
    "    print(sf_table.shape, sl_table.shape, gt_table.shape)\n",
    "else:\n",
    "    print(data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## simple format description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aca miramos las top 10 antenas que utilizo un usuario, ordeandas de 0 a 10 segun el uso, en numero de llamados, que el user le daba a c. antenna. _0_ Seria la antenna mas utilizada y _10_ la menos utilizada. El count es la cantidad de veces que utilizo esa antenna. \n",
    "\n",
    "Cuando aparece _WEEKNIGHT_ en el nombre de la columna, es porque cumple la condicion de que los llamados fueron hechos de noche fuera del horario [8,20] y dentro de la semana laboral.\n",
    "\n",
    "Siguiendo las definiciones del trabajo de Caro, un user es _EPIDEMIC_ siii su ANTENNA_WEEKNIGHT_0 (esta es la home_antenna) pertence a la zona epidemica.\n",
    "\n",
    "El mobility_diameter es el radio de las antennas (0 si uso una sola, etc.) utilizadas por este user. Nuevamente el modificador _WEEKNIGHT_ solo aplica para antennas utilizadas en esos horarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([u'USER', u'COUNT_0', u'COUNT_1', u'COUNT_2', u'COUNT_3', u'COUNT_4',\n",
      "       u'COUNT_5', u'COUNT_6', u'COUNT_7', u'COUNT_8',\n",
      "       ...\n",
      "       u'TimeWeekDay_IN_11', u'CallsWeekEnd_IN_11', u'TimeWeekNight_IN_11',\n",
      "       u'TimeWeekEnd_IN_VUL_11', u'CallsWeekDay_IN_VUL_11',\n",
      "       u'CallsWeekNight_IN_VUL_11', u'TimeWeekDay_IN_VUL_11',\n",
      "       u'CallsWeekEnd_IN_VUL_11', u'TimeWeekNight_IN_VUL_11',\n",
      "       u'VULNERABLE_IN_11'],\n",
      "      dtype='object', length=176)\n"
     ]
    }
   ],
   "source": [
    "# column names\n",
    "if graphlab_frame:\n",
    "    print(sf_table.column_names())\n",
    "else:\n",
    "    print(data.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sum links description\n",
    "\n",
    "La tabla sum_links tiene mas atributos y con data mas rica en informacion:\n",
    "    \n",
    "Esencialmente para c/ user miramos la cantidad de llamados y el tiempo que duraron esos llamados pero segmentando con distintos modificadores. `Time` representa la duracion del llamado y Calls el conteo de llamados.\n",
    "\n",
    "Los modficadores/ segmentaciones son:\n",
    "\n",
    "* mes en el cual estamos parados (12 == diciembre, ..., 08 == agosto)\n",
    "* OUT/IN, separa por la direccion de los llamados si salientes u entrantes.\n",
    "* _VULN_ : separa los llamados que fueron realizados hacia/desde un target_user (en una llamada hay 2 usuarios, el origin o el target) viviendo en una zona epidemica. Donde la home antena de un target_user determina su vulnerabilidad segun si es zona epidemica o no.\n",
    "* Weekend, WeekDay y WeekNight son lo que suenan. Weekend el finde, Weeknight la semana pero fuera de horario laboral y Weekday en horario laboral y de lunes a viernes.\n",
    "\n",
    "Hay solo una columna que no entra enteramente en este esquema que es VULNERABLE. Esta columna hace un conteo p/c/ usuario d cuantos target_users viven en una zona epidemica. Tambien se segmenta esta columna con los modficiadores anteriores (el mes y el out/in)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# column names\n",
    "if graphlab_frame:\n",
    "    print(sl_table.column_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Para la\n",
    "tabla gt (ground_truth) es mas simple la explicacion. Solo se busco el antenna_ID_0 (nuevamente la antenna mas utilizada) por un user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if graphlab_frame:\n",
    "    print(gt_table.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We need antennas metadata\n",
    "to get the epidemicity of each antenna and add that info to the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/juan/mobility-study/mexico-scripts-ver2/data'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATADIR2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/juan/mobility-study/mexico-scripts-ver2/datasets'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATADIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#agregamos al gt su info de epidemicidad\n",
    "antennas_file = DATADIR2+'/celdas_limpio.csv'\n",
    "\n",
    "if graphlab_frame:\n",
    "    antennas = gl.SFrame.read_csv(antennas_file, \n",
    "                              delimiter= \"|\", \n",
    "                usecols=['LATITUDE','LONGITUDE','CEL_ID','STATE','EPIDEMIC'],\n",
    "                column_type_hints=[float, float, str,str, bool]\n",
    "                            )\n",
    "else:\n",
    "    antennas = pd.read_csv(antennas_file,sep='|')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 5.01 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# enriquecemos la data de gt con info de epidemicidad\n",
    "if graphlab_frame:\n",
    "    # agrego tambien data de epidemicidad al simpleformat table\n",
    "    sf_table = sf_table.join(antennas['CEL_ID','EPIDEMIC','STATE'], \n",
    "                             on = {'ANTENNA_ID_WEEKNIGHT_0':'CEL_ID'},\n",
    "                             how = 'left')\n",
    "    gt_table = gt_table.join(antennas['CEL_ID','EPIDEMIC','STATE'], \n",
    "                             on = {'ANTENNA_ID_WEEKNIGHT_0_gt':'CEL_ID'},\n",
    "                             how = 'left')\n",
    "\n",
    "    gt_table.rename({'EPIDEMIC':'EPIDEMIC_gt'});"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# create data matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(153010, 176)\n",
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 558 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if graphlab_frame:\n",
    "    data = sl_table.join(gt_table['USER','EPIDEMIC_gt'], on = 'USER', how = 'inner')\n",
    "    data = data.join(sf_table, on = 'USER', how = 'inner')\n",
    "    #no podemos tener nulls en el target asi que dropeamos\n",
    "    data = data.dropna(columns = ['EPIDEMIC_gt'], how='any')\n",
    "    del sl_table, sf_table, gt_table\n",
    "\n",
    "print(data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51709, 47344)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['EPIDEMIC_gt'].sum(),data['EPIDEMIC'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# data.query('EPIDEMIC==0  ').STATE.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## preparamos los datasets que no pueden tomar valores negativos o categorical vars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train test split as \n",
    "p% of set as validation and the resulting  as train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "split_perc = 0.9\n",
    "mask = pd.np.random.rand(data.shape[0])< split_perc\n",
    "\n",
    "val_set = data[mask==0]\n",
    "data = data[mask==1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define our real X variable and Y vars\n",
    "\n",
    "exclude/include features. Decide our problem (multi-target, single_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## in our  X features..\n",
    "\n",
    "determine which columns have no meaning.\n",
    "\n",
    "we are going to try different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['USER',\n",
       " 'ANTENNA_ID_0',\n",
       " 'ANTENNA_ID_1',\n",
       " 'ANTENNA_ID_2',\n",
       " 'ANTENNA_ID_3',\n",
       " 'ANTENNA_ID_4',\n",
       " 'ANTENNA_ID_5',\n",
       " 'ANTENNA_ID_6',\n",
       " 'ANTENNA_ID_7',\n",
       " 'ANTENNA_ID_8',\n",
       " 'ANTENNA_ID_9',\n",
       " 'ANTENNA_ID_WEEKNIGHT_0',\n",
       " 'ANTENNA_ID_WEEKNIGHT_1',\n",
       " 'ANTENNA_ID_WEEKNIGHT_2',\n",
       " 'ANTENNA_ID_WEEKNIGHT_3',\n",
       " 'ANTENNA_ID_WEEKNIGHT_4',\n",
       " 'ANTENNA_ID_WEEKNIGHT_5',\n",
       " 'ANTENNA_ID_WEEKNIGHT_6',\n",
       " 'ANTENNA_ID_WEEKNIGHT_7',\n",
       " 'ANTENNA_ID_WEEKNIGHT_8',\n",
       " 'ANTENNA_ID_WEEKNIGHT_9']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if graphlab_frame: iterable=data.column_names()\n",
    "else: iterable=data.columns\n",
    "\n",
    "# this param will *force* the exclusion of these columns in the final X, no matter what.\n",
    "\n",
    "manual_exclude_cols = [     \n",
    "#     'EPIDEMIC',\n",
    "#      'EPIDEMIC_gt',\n",
    "#       'STATE',\n",
    "                ]\n",
    "\n",
    "comprehensive_exclude_cols = [col for col in iterable if col == 'USER' \n",
    "          or ('ANTENNA' in col) ]   \n",
    "                                \n",
    "exclude_cols = manual_exclude_cols + comprehensive_exclude_cols\n",
    "exclude_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## first our Y vars\n",
    "\n",
    "define them with a set of different possible cases/problems to solve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "case = 2\n",
    "\n",
    "## people that used to live in the endemic area\n",
    "if case ==0:\n",
    "    case_text = \"people that used to live in the endemic area\"\n",
    "    Y = data['EPIDEMIC_gt'] == 1\n",
    "    Y_val = val_set['EPIDEMIC_gt'] == 1\n",
    "    add_exclusion_cols =[     \n",
    "            #     'EPIDEMIC',\n",
    "                 'EPIDEMIC_gt',\n",
    "                  'STATE',\n",
    "                ]\n",
    "\n",
    "## people that used to live in the endemic area *and* migrated\n",
    "if case ==1:\n",
    "    case_text = \"people that used to live in the endemic area *and* migrated\"\n",
    "    Y = (data['EPIDEMIC_gt'] ==1) & (data['EPIDEMIC'] ==0)\n",
    "    Y_val = (val_set['EPIDEMIC_gt'] ==1) & (val_set['EPIDEMIC'] ==0)\n",
    "    add_exclusion_cols = [\n",
    "                        'EPIDEMIC',\n",
    "                          'STATE',\n",
    "                         'EPIDEMIC_gt',\n",
    "                    ]\n",
    "\n",
    "##  people that migrated in any direction\n",
    "if case ==2:\n",
    "    case_text = \"people that migrated in any direction\"\n",
    "    Y = data['EPIDEMIC_gt'] != data['EPIDEMIC']\n",
    "    Y_val = val_set['EPIDEMIC_gt'] != val_set['EPIDEMIC']\n",
    "    \n",
    "    add_exclusion_cols = [           \n",
    "            #     'EPIDEMIC',\n",
    "#                  'EPIDEMIC_gt',\n",
    "            #       'STATE',\n",
    "]\n",
    "\n",
    "    \n",
    "##  people that migrated in any direction, but are currently non-endemic\n",
    "if case ==3:\n",
    "    case_text = \"currently non_endemic, that used to live in the endemic area\"\n",
    "    \n",
    "    data = data[data['EPIDEMIC'] ==0]\n",
    "    val_set = val_set[val_set['EPIDEMIC'] ==0]\n",
    "\n",
    "    Y = (data['EPIDEMIC_gt'] ==1)\n",
    "    Y_val = (val_set['EPIDEMIC_gt'] ==1) \n",
    "    \n",
    "    add_exclusion_cols = [\n",
    "                'EPIDEMIC'\n",
    "                'EPIDEMIC_gt',\n",
    "            #     'STATE',\n",
    "         \n",
    "                         ]    \n",
    "    \n",
    "## people from the Mexico or DF states\n",
    "if case == 4:\n",
    "    case_text = \"people from the Mexico or DF states\"\n",
    "    Y = (data['STATE'] == 'Distrito_Federal') | (data['STATE'] == 'Mexico')\n",
    "    Y_val = (val_set['STATE'] == 'Distrito_Federal') | (val_set['STATE'] == 'Mexico')\n",
    "    \n",
    "    add_exclusion_cols = [\n",
    "                'EPIDEMIC',\n",
    "                'STATE',\n",
    "                ]\n",
    "                        \n",
    "## people with a HIGH present mobility (>1000 after looking at percentiles of the MOBILITY_DIAMTER)\n",
    "if case == 5:\n",
    "    val = 1000\n",
    "    case_text = \"people with a high mobility during present time (values > {} )\".format(val)\n",
    "    Y = (data['MOBILITY_DIAMETER'] > val) \n",
    "    Y_val = (val_set['MOBILITY_DIAMETER'] > val) \n",
    "    \n",
    "    add_exclusion_cols = [\n",
    "        \n",
    "        'MOBILITY_DIAMETER_WEEKNIGHT',\n",
    "        'MOBILITY_DIAMETER',\n",
    "    ]\n",
    "\n",
    "for col in add_exclusion_cols:\n",
    "    if not col in exclude_cols:\n",
    "        exclude_cols+=[col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if graphlab_frame: iterable=data.column_names()\n",
    "else: iterable=data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'COUNT_WEEKNIGHT_9', u'ANTENNA_ID_WEEKNIGHT_0',\n",
       "       u'ANTENNA_ID_WEEKNIGHT_1', u'ANTENNA_ID_WEEKNIGHT_2',\n",
       "       u'ANTENNA_ID_WEEKNIGHT_3', u'ANTENNA_ID_WEEKNIGHT_4',\n",
       "       u'ANTENNA_ID_WEEKNIGHT_5', u'ANTENNA_ID_WEEKNIGHT_6',\n",
       "       u'ANTENNA_ID_WEEKNIGHT_7', u'ANTENNA_ID_WEEKNIGHT_8',\n",
       "       u'ANTENNA_ID_WEEKNIGHT_9', u'MOBILITY_DIAMETER',\n",
       "       u'MOBILITY_DIAMETER_WEEKNIGHT', u'EPIDEMIC', u'STATE', u'EPIDEMIC_gt',\n",
       "       u'TimeWeekEnd_OUT_12', u'CallsWeekDay_OUT_12', u'CallsWeekNight_OUT_12',\n",
       "       u'TimeWeekDay_OUT_12', u'CallsWeekEnd_OUT_12', u'TimeWeekNight_OUT_12',\n",
       "       u'TimeWeekEnd_OUT_VUL_12', u'CallsWeekDay_OUT_VUL_12',\n",
       "       u'CallsWeekNight_OUT_VUL_12', u'TimeWeekDay_OUT_VUL_12',\n",
       "       u'CallsWeekEnd_OUT_VUL_12', u'TimeWeekNight_OUT_VUL_12',\n",
       "       u'VULNERABLE_OUT_12', u'TimeWeekEnd_IN_12'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "width = 30\n",
    "N= pd.np.random.randint(1,int(iterable.shape[0]*1.0/width))\n",
    "data.columns[(N)*width: (N+1)*width]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/juan/mfixman/venv/lib/python2.7/site-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/home/juan/mfixman/venv/lib/python2.7/site-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.46 s, sys: 88 ms, total: 3.55 s\n",
      "Wall time: 3.77 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "X = data[[col for col in iterable if col not in exclude_cols]]\n",
    "\n",
    "X_val = val_set[[col for col in iterable if col not in exclude_cols]]\n",
    "\n",
    "if graphlab_frame: iterable=X.column_names()\n",
    "else: iterable=X.columns\n",
    "    \n",
    "# clean negative/Null vals in count cols \n",
    "for col in [col for col in iterable if 'COUNT' in col]:\n",
    "    X[col]= X[col].apply(lambda x :  x if x>=0 else 0)\n",
    "    X_val[col]= X_val[col].apply(lambda x :  x if x>=0 else 0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((137978, 155), (137978,))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dummy-ize categorical cols\n",
    "if necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if graphlab_frame: iterable=X.column_names()\n",
    "else: iterable=X.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# X.columns\n",
    "# [col for col in X.columns if 'STATE' in col]\n",
    "# [col for col in X_val.columns if 'STATE' in col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "categorical_cols = [\n",
    "    'STATE'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we are categorizing col STATE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/juan/mfixman/venv/lib/python2.7/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n",
      "/home/juan/mfixman/venv/lib/python2.7/site-packages/ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "for col in categorical_cols:\n",
    "    if col not in exclude_cols:\n",
    "        print('we are categorizing col %s' %col)\n",
    "        X[col] = X[col].astype('category')\n",
    "    #     if X[col].dtype != 'category':\n",
    "    #         continue \n",
    "        X = pd.concat([X,pd.get_dummies(X[col], \n",
    "                                          prefix= col, \n",
    "                                          prefix_sep='_', \n",
    "                                          #sparse = True,\n",
    "                                          dummy_na=False).astype(pd.np.int8)],\\\n",
    "                  axis=1 ,join = 'inner')\n",
    "        X.drop(col, axis =1 , inplace=True)\n",
    "\n",
    "        # now onto test_table\n",
    "        X_val[col] = X_val[col].astype('category')\n",
    "        X_val = pd.concat([X_val,pd.get_dummies(X_val[col], \n",
    "                                          prefix= col, \n",
    "                                          prefix_sep='_', \n",
    "                                          #sparse = True,\n",
    "                                          dummy_na=False).astype(pd.np.int8)],\\\n",
    "                  axis=1 ,join = 'inner')\n",
    "\n",
    "        X_val.drop(col, axis =1 , inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## explore correlations to target var\n",
    "\n",
    "with current column configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(187, 187)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr = pd.DataFrame(X).copy()\n",
    "target_col = 'target'\n",
    "corr[target_col] = Y\n",
    "corr = corr.corr()\n",
    "corr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MOBILITY_DIAMETER</th>\n",
       "      <th>MOBILITY_DIAMETER_WEEKNIGHT</th>\n",
       "      <th>EPIDEMIC</th>\n",
       "      <th>EPIDEMIC_gt</th>\n",
       "      <th>VULNERABLE_OUT_12</th>\n",
       "      <th>VULNERABLE_IN_12</th>\n",
       "      <th>VULNERABLE_OUT_08</th>\n",
       "      <th>VULNERABLE_IN_08</th>\n",
       "      <th>VULNERABLE_OUT_09</th>\n",
       "      <th>VULNERABLE_IN_09</th>\n",
       "      <th>VULNERABLE_OUT_10</th>\n",
       "      <th>VULNERABLE_IN_10</th>\n",
       "      <th>VULNERABLE_OUT_11</th>\n",
       "      <th>VULNERABLE_IN_11</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MOBILITY_DIAMETER</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.715785</td>\n",
       "      <td>-0.003945</td>\n",
       "      <td>0.014296</td>\n",
       "      <td>0.037268</td>\n",
       "      <td>0.038297</td>\n",
       "      <td>0.009403</td>\n",
       "      <td>0.011983</td>\n",
       "      <td>0.012433</td>\n",
       "      <td>0.015307</td>\n",
       "      <td>0.023347</td>\n",
       "      <td>0.025225</td>\n",
       "      <td>0.026690</td>\n",
       "      <td>0.029336</td>\n",
       "      <td>0.154510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MOBILITY_DIAMETER_WEEKNIGHT</th>\n",
       "      <td>0.715785</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.004830</td>\n",
       "      <td>0.015718</td>\n",
       "      <td>0.066160</td>\n",
       "      <td>0.064305</td>\n",
       "      <td>0.037523</td>\n",
       "      <td>0.039123</td>\n",
       "      <td>0.042406</td>\n",
       "      <td>0.043005</td>\n",
       "      <td>0.055744</td>\n",
       "      <td>0.054169</td>\n",
       "      <td>0.058903</td>\n",
       "      <td>0.059001</td>\n",
       "      <td>0.141488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EPIDEMIC</th>\n",
       "      <td>-0.003945</td>\n",
       "      <td>-0.004830</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.439833</td>\n",
       "      <td>0.497319</td>\n",
       "      <td>0.494694</td>\n",
       "      <td>0.536371</td>\n",
       "      <td>0.538411</td>\n",
       "      <td>0.529397</td>\n",
       "      <td>0.527918</td>\n",
       "      <td>0.521953</td>\n",
       "      <td>0.516863</td>\n",
       "      <td>0.517026</td>\n",
       "      <td>0.517551</td>\n",
       "      <td>0.164076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EPIDEMIC_gt</th>\n",
       "      <td>0.014296</td>\n",
       "      <td>0.015718</td>\n",
       "      <td>0.439833</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.503275</td>\n",
       "      <td>0.501030</td>\n",
       "      <td>0.553516</td>\n",
       "      <td>0.556578</td>\n",
       "      <td>0.535707</td>\n",
       "      <td>0.538601</td>\n",
       "      <td>0.520675</td>\n",
       "      <td>0.519689</td>\n",
       "      <td>0.514406</td>\n",
       "      <td>0.518411</td>\n",
       "      <td>0.265702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VULNERABLE_OUT_12</th>\n",
       "      <td>0.037268</td>\n",
       "      <td>0.066160</td>\n",
       "      <td>0.497319</td>\n",
       "      <td>0.503275</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.850494</td>\n",
       "      <td>0.675247</td>\n",
       "      <td>0.668012</td>\n",
       "      <td>0.705926</td>\n",
       "      <td>0.695814</td>\n",
       "      <td>0.746994</td>\n",
       "      <td>0.734306</td>\n",
       "      <td>0.782372</td>\n",
       "      <td>0.770537</td>\n",
       "      <td>0.195114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VULNERABLE_IN_12</th>\n",
       "      <td>0.038297</td>\n",
       "      <td>0.064305</td>\n",
       "      <td>0.494694</td>\n",
       "      <td>0.501030</td>\n",
       "      <td>0.850494</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.667544</td>\n",
       "      <td>0.673078</td>\n",
       "      <td>0.697240</td>\n",
       "      <td>0.704027</td>\n",
       "      <td>0.736680</td>\n",
       "      <td>0.745467</td>\n",
       "      <td>0.769155</td>\n",
       "      <td>0.780544</td>\n",
       "      <td>0.192320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VULNERABLE_OUT_08</th>\n",
       "      <td>0.009403</td>\n",
       "      <td>0.037523</td>\n",
       "      <td>0.536371</td>\n",
       "      <td>0.553516</td>\n",
       "      <td>0.675247</td>\n",
       "      <td>0.667544</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.852876</td>\n",
       "      <td>0.782459</td>\n",
       "      <td>0.766317</td>\n",
       "      <td>0.732880</td>\n",
       "      <td>0.720692</td>\n",
       "      <td>0.707799</td>\n",
       "      <td>0.697568</td>\n",
       "      <td>0.188274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VULNERABLE_IN_08</th>\n",
       "      <td>0.011983</td>\n",
       "      <td>0.039123</td>\n",
       "      <td>0.538411</td>\n",
       "      <td>0.556578</td>\n",
       "      <td>0.668012</td>\n",
       "      <td>0.673078</td>\n",
       "      <td>0.852876</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.765804</td>\n",
       "      <td>0.776070</td>\n",
       "      <td>0.716975</td>\n",
       "      <td>0.726505</td>\n",
       "      <td>0.695999</td>\n",
       "      <td>0.704907</td>\n",
       "      <td>0.189714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VULNERABLE_OUT_09</th>\n",
       "      <td>0.012433</td>\n",
       "      <td>0.042406</td>\n",
       "      <td>0.529397</td>\n",
       "      <td>0.535707</td>\n",
       "      <td>0.705926</td>\n",
       "      <td>0.697240</td>\n",
       "      <td>0.782459</td>\n",
       "      <td>0.765804</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.852478</td>\n",
       "      <td>0.780843</td>\n",
       "      <td>0.766148</td>\n",
       "      <td>0.745492</td>\n",
       "      <td>0.732956</td>\n",
       "      <td>0.180650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VULNERABLE_IN_09</th>\n",
       "      <td>0.015307</td>\n",
       "      <td>0.043005</td>\n",
       "      <td>0.527918</td>\n",
       "      <td>0.538601</td>\n",
       "      <td>0.695814</td>\n",
       "      <td>0.704027</td>\n",
       "      <td>0.766317</td>\n",
       "      <td>0.776070</td>\n",
       "      <td>0.852478</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.763148</td>\n",
       "      <td>0.775414</td>\n",
       "      <td>0.732281</td>\n",
       "      <td>0.741032</td>\n",
       "      <td>0.181837</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             MOBILITY_DIAMETER  MOBILITY_DIAMETER_WEEKNIGHT  \\\n",
       "MOBILITY_DIAMETER                     1.000000                     0.715785   \n",
       "MOBILITY_DIAMETER_WEEKNIGHT           0.715785                     1.000000   \n",
       "EPIDEMIC                             -0.003945                    -0.004830   \n",
       "EPIDEMIC_gt                           0.014296                     0.015718   \n",
       "VULNERABLE_OUT_12                     0.037268                     0.066160   \n",
       "VULNERABLE_IN_12                      0.038297                     0.064305   \n",
       "VULNERABLE_OUT_08                     0.009403                     0.037523   \n",
       "VULNERABLE_IN_08                      0.011983                     0.039123   \n",
       "VULNERABLE_OUT_09                     0.012433                     0.042406   \n",
       "VULNERABLE_IN_09                      0.015307                     0.043005   \n",
       "\n",
       "                             EPIDEMIC  EPIDEMIC_gt  VULNERABLE_OUT_12  \\\n",
       "MOBILITY_DIAMETER           -0.003945     0.014296           0.037268   \n",
       "MOBILITY_DIAMETER_WEEKNIGHT -0.004830     0.015718           0.066160   \n",
       "EPIDEMIC                     1.000000     0.439833           0.497319   \n",
       "EPIDEMIC_gt                  0.439833     1.000000           0.503275   \n",
       "VULNERABLE_OUT_12            0.497319     0.503275           1.000000   \n",
       "VULNERABLE_IN_12             0.494694     0.501030           0.850494   \n",
       "VULNERABLE_OUT_08            0.536371     0.553516           0.675247   \n",
       "VULNERABLE_IN_08             0.538411     0.556578           0.668012   \n",
       "VULNERABLE_OUT_09            0.529397     0.535707           0.705926   \n",
       "VULNERABLE_IN_09             0.527918     0.538601           0.695814   \n",
       "\n",
       "                             VULNERABLE_IN_12  VULNERABLE_OUT_08  \\\n",
       "MOBILITY_DIAMETER                    0.038297           0.009403   \n",
       "MOBILITY_DIAMETER_WEEKNIGHT          0.064305           0.037523   \n",
       "EPIDEMIC                             0.494694           0.536371   \n",
       "EPIDEMIC_gt                          0.501030           0.553516   \n",
       "VULNERABLE_OUT_12                    0.850494           0.675247   \n",
       "VULNERABLE_IN_12                     1.000000           0.667544   \n",
       "VULNERABLE_OUT_08                    0.667544           1.000000   \n",
       "VULNERABLE_IN_08                     0.673078           0.852876   \n",
       "VULNERABLE_OUT_09                    0.697240           0.782459   \n",
       "VULNERABLE_IN_09                     0.704027           0.766317   \n",
       "\n",
       "                             VULNERABLE_IN_08  VULNERABLE_OUT_09  \\\n",
       "MOBILITY_DIAMETER                    0.011983           0.012433   \n",
       "MOBILITY_DIAMETER_WEEKNIGHT          0.039123           0.042406   \n",
       "EPIDEMIC                             0.538411           0.529397   \n",
       "EPIDEMIC_gt                          0.556578           0.535707   \n",
       "VULNERABLE_OUT_12                    0.668012           0.705926   \n",
       "VULNERABLE_IN_12                     0.673078           0.697240   \n",
       "VULNERABLE_OUT_08                    0.852876           0.782459   \n",
       "VULNERABLE_IN_08                     1.000000           0.765804   \n",
       "VULNERABLE_OUT_09                    0.765804           1.000000   \n",
       "VULNERABLE_IN_09                     0.776070           0.852478   \n",
       "\n",
       "                             VULNERABLE_IN_09  VULNERABLE_OUT_10  \\\n",
       "MOBILITY_DIAMETER                    0.015307           0.023347   \n",
       "MOBILITY_DIAMETER_WEEKNIGHT          0.043005           0.055744   \n",
       "EPIDEMIC                             0.527918           0.521953   \n",
       "EPIDEMIC_gt                          0.538601           0.520675   \n",
       "VULNERABLE_OUT_12                    0.695814           0.746994   \n",
       "VULNERABLE_IN_12                     0.704027           0.736680   \n",
       "VULNERABLE_OUT_08                    0.766317           0.732880   \n",
       "VULNERABLE_IN_08                     0.776070           0.716975   \n",
       "VULNERABLE_OUT_09                    0.852478           0.780843   \n",
       "VULNERABLE_IN_09                     1.000000           0.763148   \n",
       "\n",
       "                             VULNERABLE_IN_10  VULNERABLE_OUT_11  \\\n",
       "MOBILITY_DIAMETER                    0.025225           0.026690   \n",
       "MOBILITY_DIAMETER_WEEKNIGHT          0.054169           0.058903   \n",
       "EPIDEMIC                             0.516863           0.517026   \n",
       "EPIDEMIC_gt                          0.519689           0.514406   \n",
       "VULNERABLE_OUT_12                    0.734306           0.782372   \n",
       "VULNERABLE_IN_12                     0.745467           0.769155   \n",
       "VULNERABLE_OUT_08                    0.720692           0.707799   \n",
       "VULNERABLE_IN_08                     0.726505           0.695999   \n",
       "VULNERABLE_OUT_09                    0.766148           0.745492   \n",
       "VULNERABLE_IN_09                     0.775414           0.732281   \n",
       "\n",
       "                             VULNERABLE_IN_11    target  \n",
       "MOBILITY_DIAMETER                    0.029336  0.154510  \n",
       "MOBILITY_DIAMETER_WEEKNIGHT          0.059001  0.141488  \n",
       "EPIDEMIC                             0.517551  0.164076  \n",
       "EPIDEMIC_gt                          0.518411  0.265702  \n",
       "VULNERABLE_OUT_12                    0.770537  0.195114  \n",
       "VULNERABLE_IN_12                     0.780544  0.192320  \n",
       "VULNERABLE_OUT_08                    0.697568  0.188274  \n",
       "VULNERABLE_IN_08                     0.704907  0.189714  \n",
       "VULNERABLE_OUT_09                    0.732956  0.180650  \n",
       "VULNERABLE_IN_09                     0.741032  0.181837  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "view = corr.query('target>0.1')\n",
    "# show only those columns which \n",
    "corr_columns = view.index.values\n",
    "\n",
    "view[corr_columns].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATE_Aguascalientes</th>\n",
       "      <th>STATE_Baja_California</th>\n",
       "      <th>STATE_Baja_California_Sur</th>\n",
       "      <th>STATE_Campeche</th>\n",
       "      <th>STATE_Chiapas</th>\n",
       "      <th>STATE_Chihuahua</th>\n",
       "      <th>STATE_Coahuila_de_Zaragoza</th>\n",
       "      <th>STATE_Colima</th>\n",
       "      <th>STATE_Distrito_Federal</th>\n",
       "      <th>STATE_Durango</th>\n",
       "      <th>...</th>\n",
       "      <th>STATE_San_Luis_Potosi</th>\n",
       "      <th>STATE_Sinaloa</th>\n",
       "      <th>STATE_Sonora</th>\n",
       "      <th>STATE_Tabasco</th>\n",
       "      <th>STATE_Tamaulipas</th>\n",
       "      <th>STATE_Tlaxcala</th>\n",
       "      <th>STATE_Veracruz</th>\n",
       "      <th>STATE_Yucatan</th>\n",
       "      <th>STATE_Zacatecas</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>COUNT_WEEKNIGHT_2</th>\n",
       "      <td>0.001858</td>\n",
       "      <td>0.017464</td>\n",
       "      <td>0.010462</td>\n",
       "      <td>0.010913</td>\n",
       "      <td>0.002828</td>\n",
       "      <td>0.010746</td>\n",
       "      <td>0.000414</td>\n",
       "      <td>0.023018</td>\n",
       "      <td>0.021149</td>\n",
       "      <td>-0.000483</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011250</td>\n",
       "      <td>0.016204</td>\n",
       "      <td>0.008146</td>\n",
       "      <td>-0.005059</td>\n",
       "      <td>-0.008536</td>\n",
       "      <td>-0.022472</td>\n",
       "      <td>-0.007995</td>\n",
       "      <td>0.000920</td>\n",
       "      <td>0.002465</td>\n",
       "      <td>0.013574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>COUNT_WEEKNIGHT_3</th>\n",
       "      <td>0.001989</td>\n",
       "      <td>0.010829</td>\n",
       "      <td>0.010054</td>\n",
       "      <td>0.010218</td>\n",
       "      <td>-0.000853</td>\n",
       "      <td>0.008956</td>\n",
       "      <td>-0.000462</td>\n",
       "      <td>0.020948</td>\n",
       "      <td>0.036144</td>\n",
       "      <td>-0.001415</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015895</td>\n",
       "      <td>0.017738</td>\n",
       "      <td>0.009910</td>\n",
       "      <td>-0.006288</td>\n",
       "      <td>-0.008762</td>\n",
       "      <td>-0.026701</td>\n",
       "      <td>-0.011268</td>\n",
       "      <td>0.004046</td>\n",
       "      <td>-0.003612</td>\n",
       "      <td>0.020339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>COUNT_WEEKNIGHT_4</th>\n",
       "      <td>0.002362</td>\n",
       "      <td>0.009248</td>\n",
       "      <td>0.010038</td>\n",
       "      <td>0.006389</td>\n",
       "      <td>-0.001716</td>\n",
       "      <td>0.006701</td>\n",
       "      <td>-0.004008</td>\n",
       "      <td>0.015477</td>\n",
       "      <td>0.053368</td>\n",
       "      <td>-0.003196</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016725</td>\n",
       "      <td>0.017207</td>\n",
       "      <td>0.010034</td>\n",
       "      <td>-0.009539</td>\n",
       "      <td>-0.009958</td>\n",
       "      <td>-0.031832</td>\n",
       "      <td>-0.015481</td>\n",
       "      <td>0.006283</td>\n",
       "      <td>-0.006494</td>\n",
       "      <td>0.023249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>COUNT_WEEKNIGHT_5</th>\n",
       "      <td>0.002514</td>\n",
       "      <td>0.009140</td>\n",
       "      <td>0.007257</td>\n",
       "      <td>0.001450</td>\n",
       "      <td>-0.003555</td>\n",
       "      <td>0.005085</td>\n",
       "      <td>-0.005752</td>\n",
       "      <td>0.011588</td>\n",
       "      <td>0.067628</td>\n",
       "      <td>-0.003591</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017598</td>\n",
       "      <td>0.013512</td>\n",
       "      <td>0.009724</td>\n",
       "      <td>-0.009275</td>\n",
       "      <td>-0.010257</td>\n",
       "      <td>-0.036685</td>\n",
       "      <td>-0.020784</td>\n",
       "      <td>0.007593</td>\n",
       "      <td>-0.011132</td>\n",
       "      <td>0.024684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>COUNT_WEEKNIGHT_6</th>\n",
       "      <td>0.000630</td>\n",
       "      <td>0.005390</td>\n",
       "      <td>0.005871</td>\n",
       "      <td>-0.002301</td>\n",
       "      <td>-0.006009</td>\n",
       "      <td>0.004453</td>\n",
       "      <td>-0.007847</td>\n",
       "      <td>0.008485</td>\n",
       "      <td>0.079762</td>\n",
       "      <td>-0.004916</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017243</td>\n",
       "      <td>0.012980</td>\n",
       "      <td>0.010150</td>\n",
       "      <td>-0.008714</td>\n",
       "      <td>-0.011598</td>\n",
       "      <td>-0.040544</td>\n",
       "      <td>-0.024538</td>\n",
       "      <td>0.007912</td>\n",
       "      <td>-0.014315</td>\n",
       "      <td>0.026258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>COUNT_WEEKNIGHT_7</th>\n",
       "      <td>-0.001530</td>\n",
       "      <td>0.004680</td>\n",
       "      <td>0.003499</td>\n",
       "      <td>-0.008053</td>\n",
       "      <td>-0.008596</td>\n",
       "      <td>0.002837</td>\n",
       "      <td>-0.008421</td>\n",
       "      <td>0.003400</td>\n",
       "      <td>0.091035</td>\n",
       "      <td>-0.006330</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016603</td>\n",
       "      <td>0.010894</td>\n",
       "      <td>0.010091</td>\n",
       "      <td>-0.011306</td>\n",
       "      <td>-0.015316</td>\n",
       "      <td>-0.043402</td>\n",
       "      <td>-0.029444</td>\n",
       "      <td>0.008145</td>\n",
       "      <td>-0.017771</td>\n",
       "      <td>0.027846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>COUNT_WEEKNIGHT_8</th>\n",
       "      <td>-0.003100</td>\n",
       "      <td>0.004055</td>\n",
       "      <td>0.002260</td>\n",
       "      <td>-0.011266</td>\n",
       "      <td>-0.011632</td>\n",
       "      <td>0.002160</td>\n",
       "      <td>-0.010742</td>\n",
       "      <td>0.001750</td>\n",
       "      <td>0.100469</td>\n",
       "      <td>-0.007947</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014271</td>\n",
       "      <td>0.008808</td>\n",
       "      <td>0.009519</td>\n",
       "      <td>-0.012101</td>\n",
       "      <td>-0.016915</td>\n",
       "      <td>-0.045340</td>\n",
       "      <td>-0.033115</td>\n",
       "      <td>0.008182</td>\n",
       "      <td>-0.019009</td>\n",
       "      <td>0.028464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>COUNT_WEEKNIGHT_9</th>\n",
       "      <td>-0.006229</td>\n",
       "      <td>0.003036</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>-0.015504</td>\n",
       "      <td>-0.014553</td>\n",
       "      <td>0.000584</td>\n",
       "      <td>-0.013024</td>\n",
       "      <td>0.000132</td>\n",
       "      <td>0.109838</td>\n",
       "      <td>-0.008881</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011430</td>\n",
       "      <td>0.007838</td>\n",
       "      <td>0.009845</td>\n",
       "      <td>-0.013021</td>\n",
       "      <td>-0.018124</td>\n",
       "      <td>-0.046815</td>\n",
       "      <td>-0.037587</td>\n",
       "      <td>0.007833</td>\n",
       "      <td>-0.020115</td>\n",
       "      <td>0.029678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MOBILITY_DIAMETER</th>\n",
       "      <td>0.047697</td>\n",
       "      <td>0.144126</td>\n",
       "      <td>0.029463</td>\n",
       "      <td>0.006546</td>\n",
       "      <td>-0.014228</td>\n",
       "      <td>0.022625</td>\n",
       "      <td>-0.002491</td>\n",
       "      <td>-0.007132</td>\n",
       "      <td>-0.137678</td>\n",
       "      <td>-0.009237</td>\n",
       "      <td>...</td>\n",
       "      <td>0.061433</td>\n",
       "      <td>0.050950</td>\n",
       "      <td>0.078405</td>\n",
       "      <td>0.003528</td>\n",
       "      <td>0.005187</td>\n",
       "      <td>-0.020111</td>\n",
       "      <td>0.055373</td>\n",
       "      <td>-0.029631</td>\n",
       "      <td>-0.000281</td>\n",
       "      <td>0.154510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MOBILITY_DIAMETER_WEEKNIGHT</th>\n",
       "      <td>0.046818</td>\n",
       "      <td>0.143429</td>\n",
       "      <td>0.029630</td>\n",
       "      <td>0.005464</td>\n",
       "      <td>-0.010217</td>\n",
       "      <td>0.023249</td>\n",
       "      <td>-0.001705</td>\n",
       "      <td>-0.005473</td>\n",
       "      <td>-0.118547</td>\n",
       "      <td>-0.009302</td>\n",
       "      <td>...</td>\n",
       "      <td>0.063474</td>\n",
       "      <td>0.054681</td>\n",
       "      <td>0.079987</td>\n",
       "      <td>0.007015</td>\n",
       "      <td>0.006280</td>\n",
       "      <td>-0.026489</td>\n",
       "      <td>0.045077</td>\n",
       "      <td>-0.021358</td>\n",
       "      <td>-0.006317</td>\n",
       "      <td>0.141488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EPIDEMIC</th>\n",
       "      <td>-0.070369</td>\n",
       "      <td>-0.064011</td>\n",
       "      <td>-0.024981</td>\n",
       "      <td>-0.057637</td>\n",
       "      <td>-0.086685</td>\n",
       "      <td>-0.041358</td>\n",
       "      <td>-0.046465</td>\n",
       "      <td>-0.045250</td>\n",
       "      <td>-0.346650</td>\n",
       "      <td>-0.034179</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.078990</td>\n",
       "      <td>-0.052967</td>\n",
       "      <td>-0.038237</td>\n",
       "      <td>0.223952</td>\n",
       "      <td>-0.052248</td>\n",
       "      <td>-0.088677</td>\n",
       "      <td>0.299250</td>\n",
       "      <td>-0.109611</td>\n",
       "      <td>-0.034794</td>\n",
       "      <td>0.164076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EPIDEMIC_gt</th>\n",
       "      <td>-0.042092</td>\n",
       "      <td>-0.018679</td>\n",
       "      <td>0.026783</td>\n",
       "      <td>-0.009529</td>\n",
       "      <td>-0.036335</td>\n",
       "      <td>-0.002569</td>\n",
       "      <td>-0.030514</td>\n",
       "      <td>0.015001</td>\n",
       "      <td>-0.138996</td>\n",
       "      <td>-0.021735</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.058760</td>\n",
       "      <td>0.035432</td>\n",
       "      <td>0.033727</td>\n",
       "      <td>0.097361</td>\n",
       "      <td>0.000915</td>\n",
       "      <td>0.018569</td>\n",
       "      <td>0.158318</td>\n",
       "      <td>-0.077202</td>\n",
       "      <td>-0.018218</td>\n",
       "      <td>0.265702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TimeWeekEnd_OUT_VUL_12</th>\n",
       "      <td>-0.013903</td>\n",
       "      <td>-0.006271</td>\n",
       "      <td>0.008033</td>\n",
       "      <td>-0.000488</td>\n",
       "      <td>-0.011647</td>\n",
       "      <td>-0.006696</td>\n",
       "      <td>-0.012125</td>\n",
       "      <td>0.007212</td>\n",
       "      <td>-0.059115</td>\n",
       "      <td>-0.009559</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.015696</td>\n",
       "      <td>0.009864</td>\n",
       "      <td>0.011210</td>\n",
       "      <td>0.059930</td>\n",
       "      <td>-0.000395</td>\n",
       "      <td>-0.013076</td>\n",
       "      <td>0.026118</td>\n",
       "      <td>-0.024898</td>\n",
       "      <td>-0.004787</td>\n",
       "      <td>0.066856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CallsWeekDay_OUT_VUL_12</th>\n",
       "      <td>-0.022729</td>\n",
       "      <td>-0.016582</td>\n",
       "      <td>-0.000007</td>\n",
       "      <td>-0.012801</td>\n",
       "      <td>-0.023496</td>\n",
       "      <td>-0.008627</td>\n",
       "      <td>-0.017978</td>\n",
       "      <td>0.007904</td>\n",
       "      <td>-0.095289</td>\n",
       "      <td>-0.013486</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.029212</td>\n",
       "      <td>0.004131</td>\n",
       "      <td>0.007377</td>\n",
       "      <td>0.088268</td>\n",
       "      <td>-0.009238</td>\n",
       "      <td>-0.021836</td>\n",
       "      <td>0.045091</td>\n",
       "      <td>-0.040722</td>\n",
       "      <td>-0.011748</td>\n",
       "      <td>0.056102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CallsWeekNight_OUT_VUL_12</th>\n",
       "      <td>-0.018719</td>\n",
       "      <td>-0.010042</td>\n",
       "      <td>0.006258</td>\n",
       "      <td>-0.003309</td>\n",
       "      <td>-0.017347</td>\n",
       "      <td>-0.005301</td>\n",
       "      <td>-0.012895</td>\n",
       "      <td>0.006902</td>\n",
       "      <td>-0.065913</td>\n",
       "      <td>-0.010075</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018689</td>\n",
       "      <td>0.008055</td>\n",
       "      <td>0.009917</td>\n",
       "      <td>0.073576</td>\n",
       "      <td>-0.000378</td>\n",
       "      <td>-0.014012</td>\n",
       "      <td>0.037924</td>\n",
       "      <td>-0.030445</td>\n",
       "      <td>-0.008211</td>\n",
       "      <td>0.064372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TimeWeekDay_OUT_VUL_12</th>\n",
       "      <td>-0.017553</td>\n",
       "      <td>-0.010648</td>\n",
       "      <td>0.003875</td>\n",
       "      <td>-0.004778</td>\n",
       "      <td>-0.016128</td>\n",
       "      <td>-0.005995</td>\n",
       "      <td>-0.014900</td>\n",
       "      <td>0.013330</td>\n",
       "      <td>-0.071550</td>\n",
       "      <td>-0.011761</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.024868</td>\n",
       "      <td>0.009684</td>\n",
       "      <td>0.012461</td>\n",
       "      <td>0.071719</td>\n",
       "      <td>-0.005967</td>\n",
       "      <td>-0.017661</td>\n",
       "      <td>0.033545</td>\n",
       "      <td>-0.033829</td>\n",
       "      <td>-0.009765</td>\n",
       "      <td>0.071430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CallsWeekEnd_OUT_VUL_12</th>\n",
       "      <td>-0.020718</td>\n",
       "      <td>-0.014418</td>\n",
       "      <td>0.002557</td>\n",
       "      <td>-0.009829</td>\n",
       "      <td>-0.021284</td>\n",
       "      <td>-0.009290</td>\n",
       "      <td>-0.016709</td>\n",
       "      <td>0.004856</td>\n",
       "      <td>-0.087687</td>\n",
       "      <td>-0.012906</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.025552</td>\n",
       "      <td>0.003966</td>\n",
       "      <td>0.008507</td>\n",
       "      <td>0.083876</td>\n",
       "      <td>-0.007315</td>\n",
       "      <td>-0.018611</td>\n",
       "      <td>0.043837</td>\n",
       "      <td>-0.036358</td>\n",
       "      <td>-0.010151</td>\n",
       "      <td>0.057492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TimeWeekNight_OUT_VUL_12</th>\n",
       "      <td>-0.011195</td>\n",
       "      <td>-0.002831</td>\n",
       "      <td>0.010893</td>\n",
       "      <td>0.007069</td>\n",
       "      <td>-0.006941</td>\n",
       "      <td>0.000307</td>\n",
       "      <td>-0.006621</td>\n",
       "      <td>0.005087</td>\n",
       "      <td>-0.033505</td>\n",
       "      <td>-0.006106</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.008468</td>\n",
       "      <td>0.013700</td>\n",
       "      <td>0.012363</td>\n",
       "      <td>0.043720</td>\n",
       "      <td>0.003380</td>\n",
       "      <td>-0.006625</td>\n",
       "      <td>0.019073</td>\n",
       "      <td>-0.017836</td>\n",
       "      <td>-0.003488</td>\n",
       "      <td>0.066613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VULNERABLE_OUT_12</th>\n",
       "      <td>-0.040959</td>\n",
       "      <td>-0.028321</td>\n",
       "      <td>0.008961</td>\n",
       "      <td>-0.016654</td>\n",
       "      <td>-0.039564</td>\n",
       "      <td>-0.016982</td>\n",
       "      <td>-0.033939</td>\n",
       "      <td>0.010742</td>\n",
       "      <td>-0.147497</td>\n",
       "      <td>-0.025169</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.050379</td>\n",
       "      <td>0.016702</td>\n",
       "      <td>0.017947</td>\n",
       "      <td>0.117970</td>\n",
       "      <td>-0.014838</td>\n",
       "      <td>-0.027587</td>\n",
       "      <td>0.134135</td>\n",
       "      <td>-0.074787</td>\n",
       "      <td>-0.018914</td>\n",
       "      <td>0.195114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TimeWeekEnd_IN_VUL_12</th>\n",
       "      <td>-0.012815</td>\n",
       "      <td>-0.007574</td>\n",
       "      <td>0.006726</td>\n",
       "      <td>-0.000521</td>\n",
       "      <td>-0.008049</td>\n",
       "      <td>-0.002762</td>\n",
       "      <td>-0.011186</td>\n",
       "      <td>0.009232</td>\n",
       "      <td>-0.055550</td>\n",
       "      <td>-0.008656</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.015693</td>\n",
       "      <td>0.008701</td>\n",
       "      <td>0.006479</td>\n",
       "      <td>0.060691</td>\n",
       "      <td>-0.002376</td>\n",
       "      <td>-0.009871</td>\n",
       "      <td>0.027561</td>\n",
       "      <td>-0.020505</td>\n",
       "      <td>-0.005930</td>\n",
       "      <td>0.059171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CallsWeekDay_IN_VUL_12</th>\n",
       "      <td>-0.022457</td>\n",
       "      <td>-0.017972</td>\n",
       "      <td>-0.000865</td>\n",
       "      <td>-0.014889</td>\n",
       "      <td>-0.024665</td>\n",
       "      <td>-0.007189</td>\n",
       "      <td>-0.018177</td>\n",
       "      <td>0.005136</td>\n",
       "      <td>-0.096553</td>\n",
       "      <td>-0.012183</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.028464</td>\n",
       "      <td>0.003156</td>\n",
       "      <td>0.006578</td>\n",
       "      <td>0.087977</td>\n",
       "      <td>-0.010368</td>\n",
       "      <td>-0.020877</td>\n",
       "      <td>0.045334</td>\n",
       "      <td>-0.040102</td>\n",
       "      <td>-0.011300</td>\n",
       "      <td>0.045735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CallsWeekNight_IN_VUL_12</th>\n",
       "      <td>-0.018331</td>\n",
       "      <td>-0.012598</td>\n",
       "      <td>0.003360</td>\n",
       "      <td>-0.010111</td>\n",
       "      <td>-0.017924</td>\n",
       "      <td>-0.005440</td>\n",
       "      <td>-0.014144</td>\n",
       "      <td>0.006850</td>\n",
       "      <td>-0.070318</td>\n",
       "      <td>-0.010760</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.021479</td>\n",
       "      <td>0.003239</td>\n",
       "      <td>0.008987</td>\n",
       "      <td>0.079932</td>\n",
       "      <td>-0.006294</td>\n",
       "      <td>-0.012031</td>\n",
       "      <td>0.038929</td>\n",
       "      <td>-0.029646</td>\n",
       "      <td>-0.008444</td>\n",
       "      <td>0.056618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TimeWeekDay_IN_VUL_12</th>\n",
       "      <td>-0.016058</td>\n",
       "      <td>-0.013013</td>\n",
       "      <td>0.003278</td>\n",
       "      <td>-0.006267</td>\n",
       "      <td>-0.016078</td>\n",
       "      <td>-0.004116</td>\n",
       "      <td>-0.014973</td>\n",
       "      <td>0.010036</td>\n",
       "      <td>-0.071406</td>\n",
       "      <td>-0.009973</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.021959</td>\n",
       "      <td>0.005298</td>\n",
       "      <td>0.011615</td>\n",
       "      <td>0.067899</td>\n",
       "      <td>-0.004141</td>\n",
       "      <td>-0.012841</td>\n",
       "      <td>0.031678</td>\n",
       "      <td>-0.030825</td>\n",
       "      <td>-0.007694</td>\n",
       "      <td>0.056979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CallsWeekEnd_IN_VUL_12</th>\n",
       "      <td>-0.020846</td>\n",
       "      <td>-0.016506</td>\n",
       "      <td>0.000786</td>\n",
       "      <td>-0.010897</td>\n",
       "      <td>-0.021659</td>\n",
       "      <td>-0.006442</td>\n",
       "      <td>-0.016915</td>\n",
       "      <td>0.004794</td>\n",
       "      <td>-0.089347</td>\n",
       "      <td>-0.012235</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.026426</td>\n",
       "      <td>0.004382</td>\n",
       "      <td>0.004749</td>\n",
       "      <td>0.086885</td>\n",
       "      <td>-0.009541</td>\n",
       "      <td>-0.018201</td>\n",
       "      <td>0.044469</td>\n",
       "      <td>-0.035791</td>\n",
       "      <td>-0.010668</td>\n",
       "      <td>0.051813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TimeWeekNight_IN_VUL_12</th>\n",
       "      <td>-0.008296</td>\n",
       "      <td>-0.005321</td>\n",
       "      <td>0.007753</td>\n",
       "      <td>-0.001753</td>\n",
       "      <td>-0.005488</td>\n",
       "      <td>-0.003227</td>\n",
       "      <td>-0.007575</td>\n",
       "      <td>0.007875</td>\n",
       "      <td>-0.035170</td>\n",
       "      <td>-0.006676</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009615</td>\n",
       "      <td>0.003860</td>\n",
       "      <td>0.012613</td>\n",
       "      <td>0.045118</td>\n",
       "      <td>0.000895</td>\n",
       "      <td>-0.003455</td>\n",
       "      <td>0.018321</td>\n",
       "      <td>-0.013248</td>\n",
       "      <td>-0.005159</td>\n",
       "      <td>0.053752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VULNERABLE_IN_12</th>\n",
       "      <td>-0.041107</td>\n",
       "      <td>-0.027672</td>\n",
       "      <td>0.009459</td>\n",
       "      <td>-0.015403</td>\n",
       "      <td>-0.039487</td>\n",
       "      <td>-0.015858</td>\n",
       "      <td>-0.033841</td>\n",
       "      <td>0.012749</td>\n",
       "      <td>-0.148157</td>\n",
       "      <td>-0.023546</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.048578</td>\n",
       "      <td>0.016454</td>\n",
       "      <td>0.015843</td>\n",
       "      <td>0.122644</td>\n",
       "      <td>-0.015729</td>\n",
       "      <td>-0.025308</td>\n",
       "      <td>0.133612</td>\n",
       "      <td>-0.073859</td>\n",
       "      <td>-0.019445</td>\n",
       "      <td>0.192320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TimeWeekEnd_OUT_VUL_08</th>\n",
       "      <td>-0.014957</td>\n",
       "      <td>-0.004448</td>\n",
       "      <td>0.013896</td>\n",
       "      <td>-0.001363</td>\n",
       "      <td>-0.009795</td>\n",
       "      <td>-0.004073</td>\n",
       "      <td>-0.009357</td>\n",
       "      <td>0.009206</td>\n",
       "      <td>-0.067427</td>\n",
       "      <td>-0.010476</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.017209</td>\n",
       "      <td>0.008612</td>\n",
       "      <td>0.007103</td>\n",
       "      <td>0.043694</td>\n",
       "      <td>-0.007526</td>\n",
       "      <td>-0.014896</td>\n",
       "      <td>0.027939</td>\n",
       "      <td>-0.028002</td>\n",
       "      <td>-0.009473</td>\n",
       "      <td>0.056637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CallsWeekDay_OUT_VUL_08</th>\n",
       "      <td>-0.022913</td>\n",
       "      <td>-0.015308</td>\n",
       "      <td>0.000393</td>\n",
       "      <td>-0.013446</td>\n",
       "      <td>-0.024191</td>\n",
       "      <td>-0.009933</td>\n",
       "      <td>-0.017416</td>\n",
       "      <td>0.007667</td>\n",
       "      <td>-0.101383</td>\n",
       "      <td>-0.012788</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.028131</td>\n",
       "      <td>-0.000279</td>\n",
       "      <td>0.001112</td>\n",
       "      <td>0.057443</td>\n",
       "      <td>-0.011762</td>\n",
       "      <td>-0.023200</td>\n",
       "      <td>0.032872</td>\n",
       "      <td>-0.040636</td>\n",
       "      <td>-0.011769</td>\n",
       "      <td>0.040469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CallsWeekNight_OUT_VUL_08</th>\n",
       "      <td>-0.018699</td>\n",
       "      <td>-0.011335</td>\n",
       "      <td>0.006758</td>\n",
       "      <td>-0.006365</td>\n",
       "      <td>-0.016954</td>\n",
       "      <td>-0.008103</td>\n",
       "      <td>-0.012660</td>\n",
       "      <td>0.011083</td>\n",
       "      <td>-0.077978</td>\n",
       "      <td>-0.012024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018589</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.000376</td>\n",
       "      <td>0.058175</td>\n",
       "      <td>-0.005336</td>\n",
       "      <td>-0.016747</td>\n",
       "      <td>0.038519</td>\n",
       "      <td>-0.034933</td>\n",
       "      <td>-0.008624</td>\n",
       "      <td>0.047088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TimeWeekDay_OUT_VUL_08</th>\n",
       "      <td>-0.017566</td>\n",
       "      <td>-0.011165</td>\n",
       "      <td>0.003923</td>\n",
       "      <td>-0.004893</td>\n",
       "      <td>-0.016604</td>\n",
       "      <td>-0.006313</td>\n",
       "      <td>-0.014123</td>\n",
       "      <td>0.009930</td>\n",
       "      <td>-0.080102</td>\n",
       "      <td>-0.011457</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.022973</td>\n",
       "      <td>0.002646</td>\n",
       "      <td>0.001732</td>\n",
       "      <td>0.049214</td>\n",
       "      <td>-0.008458</td>\n",
       "      <td>-0.018948</td>\n",
       "      <td>0.027646</td>\n",
       "      <td>-0.033421</td>\n",
       "      <td>-0.009883</td>\n",
       "      <td>0.058122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CallsWeekNight_OUT_VUL_11</th>\n",
       "      <td>-0.019018</td>\n",
       "      <td>-0.007404</td>\n",
       "      <td>0.000639</td>\n",
       "      <td>-0.005551</td>\n",
       "      <td>-0.015065</td>\n",
       "      <td>-0.008255</td>\n",
       "      <td>-0.013050</td>\n",
       "      <td>0.008629</td>\n",
       "      <td>-0.066810</td>\n",
       "      <td>-0.010967</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018093</td>\n",
       "      <td>0.002800</td>\n",
       "      <td>0.005746</td>\n",
       "      <td>0.059549</td>\n",
       "      <td>-0.005530</td>\n",
       "      <td>-0.015929</td>\n",
       "      <td>0.038877</td>\n",
       "      <td>-0.032002</td>\n",
       "      <td>-0.007708</td>\n",
       "      <td>0.057425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TimeWeekDay_OUT_VUL_11</th>\n",
       "      <td>-0.017407</td>\n",
       "      <td>-0.009035</td>\n",
       "      <td>0.003391</td>\n",
       "      <td>-0.006930</td>\n",
       "      <td>-0.015829</td>\n",
       "      <td>-0.005967</td>\n",
       "      <td>-0.013458</td>\n",
       "      <td>0.008591</td>\n",
       "      <td>-0.075553</td>\n",
       "      <td>-0.011472</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.022519</td>\n",
       "      <td>0.005454</td>\n",
       "      <td>0.008967</td>\n",
       "      <td>0.055378</td>\n",
       "      <td>-0.006377</td>\n",
       "      <td>-0.020304</td>\n",
       "      <td>0.029912</td>\n",
       "      <td>-0.032809</td>\n",
       "      <td>-0.010183</td>\n",
       "      <td>0.066649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CallsWeekEnd_OUT_VUL_11</th>\n",
       "      <td>-0.022730</td>\n",
       "      <td>-0.014366</td>\n",
       "      <td>0.002723</td>\n",
       "      <td>-0.010726</td>\n",
       "      <td>-0.021539</td>\n",
       "      <td>-0.009630</td>\n",
       "      <td>-0.015850</td>\n",
       "      <td>0.006855</td>\n",
       "      <td>-0.096621</td>\n",
       "      <td>-0.013394</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.026945</td>\n",
       "      <td>-0.000820</td>\n",
       "      <td>0.008018</td>\n",
       "      <td>0.073993</td>\n",
       "      <td>-0.008903</td>\n",
       "      <td>-0.022092</td>\n",
       "      <td>0.046996</td>\n",
       "      <td>-0.040295</td>\n",
       "      <td>-0.012146</td>\n",
       "      <td>0.049032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TimeWeekNight_OUT_VUL_11</th>\n",
       "      <td>-0.010750</td>\n",
       "      <td>0.001692</td>\n",
       "      <td>0.003391</td>\n",
       "      <td>0.004872</td>\n",
       "      <td>-0.004256</td>\n",
       "      <td>-0.005000</td>\n",
       "      <td>-0.006942</td>\n",
       "      <td>0.008321</td>\n",
       "      <td>-0.030047</td>\n",
       "      <td>-0.007340</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.008341</td>\n",
       "      <td>0.007259</td>\n",
       "      <td>0.007891</td>\n",
       "      <td>0.037977</td>\n",
       "      <td>-0.002081</td>\n",
       "      <td>-0.009624</td>\n",
       "      <td>0.021812</td>\n",
       "      <td>-0.018638</td>\n",
       "      <td>-0.004129</td>\n",
       "      <td>0.066150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VULNERABLE_OUT_11</th>\n",
       "      <td>-0.040210</td>\n",
       "      <td>-0.028672</td>\n",
       "      <td>0.005511</td>\n",
       "      <td>-0.020553</td>\n",
       "      <td>-0.042658</td>\n",
       "      <td>-0.017134</td>\n",
       "      <td>-0.034379</td>\n",
       "      <td>0.011267</td>\n",
       "      <td>-0.155290</td>\n",
       "      <td>-0.025967</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.052225</td>\n",
       "      <td>0.013658</td>\n",
       "      <td>0.016058</td>\n",
       "      <td>0.115650</td>\n",
       "      <td>-0.018341</td>\n",
       "      <td>-0.027724</td>\n",
       "      <td>0.141215</td>\n",
       "      <td>-0.079442</td>\n",
       "      <td>-0.023083</td>\n",
       "      <td>0.188275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TimeWeekEnd_IN_VUL_11</th>\n",
       "      <td>-0.015421</td>\n",
       "      <td>-0.006159</td>\n",
       "      <td>0.009940</td>\n",
       "      <td>-0.001356</td>\n",
       "      <td>-0.010575</td>\n",
       "      <td>-0.001549</td>\n",
       "      <td>-0.010403</td>\n",
       "      <td>0.003722</td>\n",
       "      <td>-0.058554</td>\n",
       "      <td>-0.008938</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.014515</td>\n",
       "      <td>0.003848</td>\n",
       "      <td>0.004136</td>\n",
       "      <td>0.050647</td>\n",
       "      <td>-0.007397</td>\n",
       "      <td>-0.010055</td>\n",
       "      <td>0.035241</td>\n",
       "      <td>-0.019520</td>\n",
       "      <td>-0.007869</td>\n",
       "      <td>0.051886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CallsWeekDay_IN_VUL_11</th>\n",
       "      <td>-0.021256</td>\n",
       "      <td>-0.018500</td>\n",
       "      <td>-0.000636</td>\n",
       "      <td>-0.015335</td>\n",
       "      <td>-0.023914</td>\n",
       "      <td>-0.008257</td>\n",
       "      <td>-0.017190</td>\n",
       "      <td>0.002792</td>\n",
       "      <td>-0.098893</td>\n",
       "      <td>-0.012572</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.027309</td>\n",
       "      <td>-0.001533</td>\n",
       "      <td>0.002638</td>\n",
       "      <td>0.067169</td>\n",
       "      <td>-0.012263</td>\n",
       "      <td>-0.023150</td>\n",
       "      <td>0.038400</td>\n",
       "      <td>-0.038855</td>\n",
       "      <td>-0.011680</td>\n",
       "      <td>0.033627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CallsWeekNight_IN_VUL_11</th>\n",
       "      <td>-0.018859</td>\n",
       "      <td>-0.010808</td>\n",
       "      <td>0.001258</td>\n",
       "      <td>-0.009396</td>\n",
       "      <td>-0.017210</td>\n",
       "      <td>-0.006741</td>\n",
       "      <td>-0.012355</td>\n",
       "      <td>0.004662</td>\n",
       "      <td>-0.069934</td>\n",
       "      <td>-0.010903</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.019439</td>\n",
       "      <td>0.000220</td>\n",
       "      <td>0.003768</td>\n",
       "      <td>0.065352</td>\n",
       "      <td>-0.008574</td>\n",
       "      <td>-0.014008</td>\n",
       "      <td>0.038536</td>\n",
       "      <td>-0.029306</td>\n",
       "      <td>-0.008704</td>\n",
       "      <td>0.047442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TimeWeekDay_IN_VUL_11</th>\n",
       "      <td>-0.014360</td>\n",
       "      <td>-0.012172</td>\n",
       "      <td>0.001558</td>\n",
       "      <td>-0.008221</td>\n",
       "      <td>-0.013160</td>\n",
       "      <td>-0.005113</td>\n",
       "      <td>-0.013512</td>\n",
       "      <td>0.005018</td>\n",
       "      <td>-0.070976</td>\n",
       "      <td>-0.010378</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.020598</td>\n",
       "      <td>0.001846</td>\n",
       "      <td>0.003013</td>\n",
       "      <td>0.054572</td>\n",
       "      <td>-0.007039</td>\n",
       "      <td>-0.017137</td>\n",
       "      <td>0.029210</td>\n",
       "      <td>-0.027677</td>\n",
       "      <td>-0.009016</td>\n",
       "      <td>0.048307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CallsWeekEnd_IN_VUL_11</th>\n",
       "      <td>-0.022765</td>\n",
       "      <td>-0.016996</td>\n",
       "      <td>0.000584</td>\n",
       "      <td>-0.012439</td>\n",
       "      <td>-0.024323</td>\n",
       "      <td>-0.007011</td>\n",
       "      <td>-0.016907</td>\n",
       "      <td>0.000881</td>\n",
       "      <td>-0.097204</td>\n",
       "      <td>-0.013275</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.026949</td>\n",
       "      <td>-0.000607</td>\n",
       "      <td>0.003648</td>\n",
       "      <td>0.074553</td>\n",
       "      <td>-0.013582</td>\n",
       "      <td>-0.020866</td>\n",
       "      <td>0.046481</td>\n",
       "      <td>-0.038301</td>\n",
       "      <td>-0.012095</td>\n",
       "      <td>0.039627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TimeWeekNight_IN_VUL_11</th>\n",
       "      <td>-0.009674</td>\n",
       "      <td>-0.002396</td>\n",
       "      <td>0.004088</td>\n",
       "      <td>-0.000596</td>\n",
       "      <td>-0.004479</td>\n",
       "      <td>-0.002574</td>\n",
       "      <td>-0.004920</td>\n",
       "      <td>0.003574</td>\n",
       "      <td>-0.029386</td>\n",
       "      <td>-0.006394</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.007047</td>\n",
       "      <td>0.004442</td>\n",
       "      <td>0.005233</td>\n",
       "      <td>0.037523</td>\n",
       "      <td>-0.003595</td>\n",
       "      <td>-0.005174</td>\n",
       "      <td>0.019848</td>\n",
       "      <td>-0.011918</td>\n",
       "      <td>-0.003494</td>\n",
       "      <td>0.047939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VULNERABLE_IN_11</th>\n",
       "      <td>-0.040535</td>\n",
       "      <td>-0.030162</td>\n",
       "      <td>0.008381</td>\n",
       "      <td>-0.019054</td>\n",
       "      <td>-0.043372</td>\n",
       "      <td>-0.016477</td>\n",
       "      <td>-0.032897</td>\n",
       "      <td>0.010190</td>\n",
       "      <td>-0.154610</td>\n",
       "      <td>-0.025122</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.052281</td>\n",
       "      <td>0.014488</td>\n",
       "      <td>0.014553</td>\n",
       "      <td>0.119650</td>\n",
       "      <td>-0.019492</td>\n",
       "      <td>-0.028566</td>\n",
       "      <td>0.141110</td>\n",
       "      <td>-0.078814</td>\n",
       "      <td>-0.019534</td>\n",
       "      <td>0.188558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STATE_Baja_California_Sur</th>\n",
       "      <td>-0.003925</td>\n",
       "      <td>-0.003571</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.003215</td>\n",
       "      <td>-0.004835</td>\n",
       "      <td>-0.002307</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>-0.002524</td>\n",
       "      <td>-0.019337</td>\n",
       "      <td>-0.001907</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.004406</td>\n",
       "      <td>-0.002955</td>\n",
       "      <td>-0.002133</td>\n",
       "      <td>-0.005594</td>\n",
       "      <td>-0.002915</td>\n",
       "      <td>-0.004947</td>\n",
       "      <td>-0.007475</td>\n",
       "      <td>-0.006114</td>\n",
       "      <td>-0.001941</td>\n",
       "      <td>0.037388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STATE_Chihuahua</th>\n",
       "      <td>-0.006499</td>\n",
       "      <td>-0.005912</td>\n",
       "      <td>-0.002307</td>\n",
       "      <td>-0.005323</td>\n",
       "      <td>-0.008006</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.004291</td>\n",
       "      <td>-0.004179</td>\n",
       "      <td>-0.032014</td>\n",
       "      <td>-0.003157</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.007295</td>\n",
       "      <td>-0.004892</td>\n",
       "      <td>-0.003531</td>\n",
       "      <td>-0.009262</td>\n",
       "      <td>-0.004825</td>\n",
       "      <td>-0.008189</td>\n",
       "      <td>-0.012376</td>\n",
       "      <td>-0.010123</td>\n",
       "      <td>-0.003213</td>\n",
       "      <td>0.010373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STATE_Colima</th>\n",
       "      <td>-0.007110</td>\n",
       "      <td>-0.006468</td>\n",
       "      <td>-0.002524</td>\n",
       "      <td>-0.005824</td>\n",
       "      <td>-0.008759</td>\n",
       "      <td>-0.004179</td>\n",
       "      <td>-0.004695</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.035027</td>\n",
       "      <td>-0.003454</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.007981</td>\n",
       "      <td>-0.005352</td>\n",
       "      <td>-0.003864</td>\n",
       "      <td>-0.010134</td>\n",
       "      <td>-0.005279</td>\n",
       "      <td>-0.008960</td>\n",
       "      <td>-0.013541</td>\n",
       "      <td>-0.011075</td>\n",
       "      <td>-0.003516</td>\n",
       "      <td>0.030913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STATE_Guerrero</th>\n",
       "      <td>-0.014047</td>\n",
       "      <td>-0.012778</td>\n",
       "      <td>-0.004987</td>\n",
       "      <td>-0.011505</td>\n",
       "      <td>-0.017304</td>\n",
       "      <td>-0.008256</td>\n",
       "      <td>-0.009275</td>\n",
       "      <td>-0.009033</td>\n",
       "      <td>-0.069197</td>\n",
       "      <td>-0.006823</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.015768</td>\n",
       "      <td>-0.010573</td>\n",
       "      <td>-0.007633</td>\n",
       "      <td>-0.020020</td>\n",
       "      <td>-0.010430</td>\n",
       "      <td>-0.017701</td>\n",
       "      <td>-0.026751</td>\n",
       "      <td>-0.021880</td>\n",
       "      <td>-0.006946</td>\n",
       "      <td>0.069300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STATE_Hidalgo</th>\n",
       "      <td>-0.023208</td>\n",
       "      <td>-0.021112</td>\n",
       "      <td>-0.008239</td>\n",
       "      <td>-0.019009</td>\n",
       "      <td>-0.028590</td>\n",
       "      <td>-0.013640</td>\n",
       "      <td>-0.015325</td>\n",
       "      <td>-0.014924</td>\n",
       "      <td>-0.114328</td>\n",
       "      <td>-0.011273</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.026052</td>\n",
       "      <td>-0.017469</td>\n",
       "      <td>-0.012611</td>\n",
       "      <td>-0.033077</td>\n",
       "      <td>-0.017232</td>\n",
       "      <td>-0.029246</td>\n",
       "      <td>-0.044198</td>\n",
       "      <td>-0.036151</td>\n",
       "      <td>-0.011475</td>\n",
       "      <td>0.096493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STATE_Jalisco</th>\n",
       "      <td>-0.034357</td>\n",
       "      <td>-0.031253</td>\n",
       "      <td>-0.012197</td>\n",
       "      <td>-0.028141</td>\n",
       "      <td>-0.042324</td>\n",
       "      <td>-0.020193</td>\n",
       "      <td>-0.022686</td>\n",
       "      <td>-0.022093</td>\n",
       "      <td>-0.169250</td>\n",
       "      <td>-0.016688</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.038567</td>\n",
       "      <td>-0.025861</td>\n",
       "      <td>-0.018669</td>\n",
       "      <td>-0.048967</td>\n",
       "      <td>-0.025510</td>\n",
       "      <td>-0.043296</td>\n",
       "      <td>-0.065431</td>\n",
       "      <td>-0.053517</td>\n",
       "      <td>-0.016988</td>\n",
       "      <td>0.032628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STATE_Morelos</th>\n",
       "      <td>-0.018556</td>\n",
       "      <td>-0.016880</td>\n",
       "      <td>-0.006587</td>\n",
       "      <td>-0.015199</td>\n",
       "      <td>-0.022859</td>\n",
       "      <td>-0.010906</td>\n",
       "      <td>-0.012253</td>\n",
       "      <td>-0.011932</td>\n",
       "      <td>-0.091412</td>\n",
       "      <td>-0.009013</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.020830</td>\n",
       "      <td>-0.013967</td>\n",
       "      <td>-0.010083</td>\n",
       "      <td>-0.026447</td>\n",
       "      <td>-0.013778</td>\n",
       "      <td>-0.023384</td>\n",
       "      <td>-0.035339</td>\n",
       "      <td>-0.028904</td>\n",
       "      <td>-0.009175</td>\n",
       "      <td>0.057009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STATE_Nayarit</th>\n",
       "      <td>-0.009555</td>\n",
       "      <td>-0.008692</td>\n",
       "      <td>-0.003392</td>\n",
       "      <td>-0.007826</td>\n",
       "      <td>-0.011771</td>\n",
       "      <td>-0.005616</td>\n",
       "      <td>-0.006309</td>\n",
       "      <td>-0.006144</td>\n",
       "      <td>-0.047071</td>\n",
       "      <td>-0.004641</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.010726</td>\n",
       "      <td>-0.007192</td>\n",
       "      <td>-0.005192</td>\n",
       "      <td>-0.013619</td>\n",
       "      <td>-0.007095</td>\n",
       "      <td>-0.012041</td>\n",
       "      <td>-0.018197</td>\n",
       "      <td>-0.014884</td>\n",
       "      <td>-0.004725</td>\n",
       "      <td>0.032723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STATE_Oaxaca</th>\n",
       "      <td>-0.011146</td>\n",
       "      <td>-0.010139</td>\n",
       "      <td>-0.003957</td>\n",
       "      <td>-0.009129</td>\n",
       "      <td>-0.013730</td>\n",
       "      <td>-0.006551</td>\n",
       "      <td>-0.007360</td>\n",
       "      <td>-0.007167</td>\n",
       "      <td>-0.054907</td>\n",
       "      <td>-0.005414</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.012512</td>\n",
       "      <td>-0.008390</td>\n",
       "      <td>-0.006056</td>\n",
       "      <td>-0.015886</td>\n",
       "      <td>-0.008276</td>\n",
       "      <td>-0.014046</td>\n",
       "      <td>-0.021227</td>\n",
       "      <td>-0.017362</td>\n",
       "      <td>-0.005511</td>\n",
       "      <td>0.044986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STATE_Puebla</th>\n",
       "      <td>-0.023362</td>\n",
       "      <td>-0.021251</td>\n",
       "      <td>-0.008293</td>\n",
       "      <td>-0.019135</td>\n",
       "      <td>-0.028779</td>\n",
       "      <td>-0.013730</td>\n",
       "      <td>-0.015426</td>\n",
       "      <td>-0.015023</td>\n",
       "      <td>-0.115084</td>\n",
       "      <td>-0.011347</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.026224</td>\n",
       "      <td>-0.017584</td>\n",
       "      <td>-0.012694</td>\n",
       "      <td>-0.033296</td>\n",
       "      <td>-0.017346</td>\n",
       "      <td>-0.029440</td>\n",
       "      <td>-0.044491</td>\n",
       "      <td>-0.036389</td>\n",
       "      <td>-0.011551</td>\n",
       "      <td>0.061183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STATE_Quintana_Roo</th>\n",
       "      <td>-0.012629</td>\n",
       "      <td>-0.011488</td>\n",
       "      <td>-0.004483</td>\n",
       "      <td>-0.010344</td>\n",
       "      <td>-0.015558</td>\n",
       "      <td>-0.007423</td>\n",
       "      <td>-0.008339</td>\n",
       "      <td>-0.008121</td>\n",
       "      <td>-0.062214</td>\n",
       "      <td>-0.006134</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.014177</td>\n",
       "      <td>-0.009506</td>\n",
       "      <td>-0.006862</td>\n",
       "      <td>-0.018000</td>\n",
       "      <td>-0.009377</td>\n",
       "      <td>-0.015915</td>\n",
       "      <td>-0.024052</td>\n",
       "      <td>-0.019672</td>\n",
       "      <td>-0.006245</td>\n",
       "      <td>0.024692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STATE_Sinaloa</th>\n",
       "      <td>-0.008323</td>\n",
       "      <td>-0.007571</td>\n",
       "      <td>-0.002955</td>\n",
       "      <td>-0.006817</td>\n",
       "      <td>-0.010253</td>\n",
       "      <td>-0.004892</td>\n",
       "      <td>-0.005496</td>\n",
       "      <td>-0.005352</td>\n",
       "      <td>-0.041000</td>\n",
       "      <td>-0.004043</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009343</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.004522</td>\n",
       "      <td>-0.011862</td>\n",
       "      <td>-0.006180</td>\n",
       "      <td>-0.010488</td>\n",
       "      <td>-0.015850</td>\n",
       "      <td>-0.012964</td>\n",
       "      <td>-0.004115</td>\n",
       "      <td>0.055817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STATE_Sonora</th>\n",
       "      <td>-0.006008</td>\n",
       "      <td>-0.005465</td>\n",
       "      <td>-0.002133</td>\n",
       "      <td>-0.004921</td>\n",
       "      <td>-0.007401</td>\n",
       "      <td>-0.003531</td>\n",
       "      <td>-0.003967</td>\n",
       "      <td>-0.003864</td>\n",
       "      <td>-0.029598</td>\n",
       "      <td>-0.002918</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.006744</td>\n",
       "      <td>-0.004522</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.008563</td>\n",
       "      <td>-0.004461</td>\n",
       "      <td>-0.007571</td>\n",
       "      <td>-0.011442</td>\n",
       "      <td>-0.009359</td>\n",
       "      <td>-0.002971</td>\n",
       "      <td>0.049245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STATE_Tabasco</th>\n",
       "      <td>-0.015759</td>\n",
       "      <td>-0.014336</td>\n",
       "      <td>-0.005594</td>\n",
       "      <td>-0.012908</td>\n",
       "      <td>-0.019413</td>\n",
       "      <td>-0.009262</td>\n",
       "      <td>-0.010406</td>\n",
       "      <td>-0.010134</td>\n",
       "      <td>-0.077633</td>\n",
       "      <td>-0.007655</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.017690</td>\n",
       "      <td>-0.011862</td>\n",
       "      <td>-0.008563</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.011701</td>\n",
       "      <td>-0.019859</td>\n",
       "      <td>-0.030012</td>\n",
       "      <td>-0.024548</td>\n",
       "      <td>-0.007792</td>\n",
       "      <td>0.037998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STATE_Tamaulipas</th>\n",
       "      <td>-0.008210</td>\n",
       "      <td>-0.007468</td>\n",
       "      <td>-0.002915</td>\n",
       "      <td>-0.006725</td>\n",
       "      <td>-0.010114</td>\n",
       "      <td>-0.004825</td>\n",
       "      <td>-0.005421</td>\n",
       "      <td>-0.005279</td>\n",
       "      <td>-0.040444</td>\n",
       "      <td>-0.003988</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009216</td>\n",
       "      <td>-0.006180</td>\n",
       "      <td>-0.004461</td>\n",
       "      <td>-0.011701</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.010346</td>\n",
       "      <td>-0.015635</td>\n",
       "      <td>-0.012788</td>\n",
       "      <td>-0.004059</td>\n",
       "      <td>0.017675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STATE_Tlaxcala</th>\n",
       "      <td>-0.013934</td>\n",
       "      <td>-0.012675</td>\n",
       "      <td>-0.004947</td>\n",
       "      <td>-0.011413</td>\n",
       "      <td>-0.017165</td>\n",
       "      <td>-0.008189</td>\n",
       "      <td>-0.009201</td>\n",
       "      <td>-0.008960</td>\n",
       "      <td>-0.068642</td>\n",
       "      <td>-0.006768</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.015641</td>\n",
       "      <td>-0.010488</td>\n",
       "      <td>-0.007571</td>\n",
       "      <td>-0.019859</td>\n",
       "      <td>-0.010346</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.026537</td>\n",
       "      <td>-0.021705</td>\n",
       "      <td>-0.006890</td>\n",
       "      <td>0.048688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STATE_Veracruz</th>\n",
       "      <td>-0.021058</td>\n",
       "      <td>-0.019155</td>\n",
       "      <td>-0.007475</td>\n",
       "      <td>-0.017248</td>\n",
       "      <td>-0.025941</td>\n",
       "      <td>-0.012376</td>\n",
       "      <td>-0.013905</td>\n",
       "      <td>-0.013541</td>\n",
       "      <td>-0.103735</td>\n",
       "      <td>-0.010228</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.023638</td>\n",
       "      <td>-0.015850</td>\n",
       "      <td>-0.011442</td>\n",
       "      <td>-0.030012</td>\n",
       "      <td>-0.015635</td>\n",
       "      <td>-0.026537</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.032801</td>\n",
       "      <td>-0.010412</td>\n",
       "      <td>0.019774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>target</th>\n",
       "      <td>-0.023783</td>\n",
       "      <td>-0.000094</td>\n",
       "      <td>0.037388</td>\n",
       "      <td>0.007922</td>\n",
       "      <td>-0.012255</td>\n",
       "      <td>0.010373</td>\n",
       "      <td>-0.018693</td>\n",
       "      <td>0.030913</td>\n",
       "      <td>-0.042078</td>\n",
       "      <td>-0.012970</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.039341</td>\n",
       "      <td>0.055817</td>\n",
       "      <td>0.049245</td>\n",
       "      <td>0.037998</td>\n",
       "      <td>0.017675</td>\n",
       "      <td>0.048688</td>\n",
       "      <td>0.019774</td>\n",
       "      <td>-0.049829</td>\n",
       "      <td>-0.008910</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             STATE_Aguascalientes  STATE_Baja_California  \\\n",
       "COUNT_WEEKNIGHT_2                        0.001858               0.017464   \n",
       "COUNT_WEEKNIGHT_3                        0.001989               0.010829   \n",
       "COUNT_WEEKNIGHT_4                        0.002362               0.009248   \n",
       "COUNT_WEEKNIGHT_5                        0.002514               0.009140   \n",
       "COUNT_WEEKNIGHT_6                        0.000630               0.005390   \n",
       "COUNT_WEEKNIGHT_7                       -0.001530               0.004680   \n",
       "COUNT_WEEKNIGHT_8                       -0.003100               0.004055   \n",
       "COUNT_WEEKNIGHT_9                       -0.006229               0.003036   \n",
       "MOBILITY_DIAMETER                        0.047697               0.144126   \n",
       "MOBILITY_DIAMETER_WEEKNIGHT              0.046818               0.143429   \n",
       "EPIDEMIC                                -0.070369              -0.064011   \n",
       "EPIDEMIC_gt                             -0.042092              -0.018679   \n",
       "TimeWeekEnd_OUT_VUL_12                  -0.013903              -0.006271   \n",
       "CallsWeekDay_OUT_VUL_12                 -0.022729              -0.016582   \n",
       "CallsWeekNight_OUT_VUL_12               -0.018719              -0.010042   \n",
       "TimeWeekDay_OUT_VUL_12                  -0.017553              -0.010648   \n",
       "CallsWeekEnd_OUT_VUL_12                 -0.020718              -0.014418   \n",
       "TimeWeekNight_OUT_VUL_12                -0.011195              -0.002831   \n",
       "VULNERABLE_OUT_12                       -0.040959              -0.028321   \n",
       "TimeWeekEnd_IN_VUL_12                   -0.012815              -0.007574   \n",
       "CallsWeekDay_IN_VUL_12                  -0.022457              -0.017972   \n",
       "CallsWeekNight_IN_VUL_12                -0.018331              -0.012598   \n",
       "TimeWeekDay_IN_VUL_12                   -0.016058              -0.013013   \n",
       "CallsWeekEnd_IN_VUL_12                  -0.020846              -0.016506   \n",
       "TimeWeekNight_IN_VUL_12                 -0.008296              -0.005321   \n",
       "VULNERABLE_IN_12                        -0.041107              -0.027672   \n",
       "TimeWeekEnd_OUT_VUL_08                  -0.014957              -0.004448   \n",
       "CallsWeekDay_OUT_VUL_08                 -0.022913              -0.015308   \n",
       "CallsWeekNight_OUT_VUL_08               -0.018699              -0.011335   \n",
       "TimeWeekDay_OUT_VUL_08                  -0.017566              -0.011165   \n",
       "...                                           ...                    ...   \n",
       "CallsWeekNight_OUT_VUL_11               -0.019018              -0.007404   \n",
       "TimeWeekDay_OUT_VUL_11                  -0.017407              -0.009035   \n",
       "CallsWeekEnd_OUT_VUL_11                 -0.022730              -0.014366   \n",
       "TimeWeekNight_OUT_VUL_11                -0.010750               0.001692   \n",
       "VULNERABLE_OUT_11                       -0.040210              -0.028672   \n",
       "TimeWeekEnd_IN_VUL_11                   -0.015421              -0.006159   \n",
       "CallsWeekDay_IN_VUL_11                  -0.021256              -0.018500   \n",
       "CallsWeekNight_IN_VUL_11                -0.018859              -0.010808   \n",
       "TimeWeekDay_IN_VUL_11                   -0.014360              -0.012172   \n",
       "CallsWeekEnd_IN_VUL_11                  -0.022765              -0.016996   \n",
       "TimeWeekNight_IN_VUL_11                 -0.009674              -0.002396   \n",
       "VULNERABLE_IN_11                        -0.040535              -0.030162   \n",
       "STATE_Baja_California_Sur               -0.003925              -0.003571   \n",
       "STATE_Chihuahua                         -0.006499              -0.005912   \n",
       "STATE_Colima                            -0.007110              -0.006468   \n",
       "STATE_Guerrero                          -0.014047              -0.012778   \n",
       "STATE_Hidalgo                           -0.023208              -0.021112   \n",
       "STATE_Jalisco                           -0.034357              -0.031253   \n",
       "STATE_Morelos                           -0.018556              -0.016880   \n",
       "STATE_Nayarit                           -0.009555              -0.008692   \n",
       "STATE_Oaxaca                            -0.011146              -0.010139   \n",
       "STATE_Puebla                            -0.023362              -0.021251   \n",
       "STATE_Quintana_Roo                      -0.012629              -0.011488   \n",
       "STATE_Sinaloa                           -0.008323              -0.007571   \n",
       "STATE_Sonora                            -0.006008              -0.005465   \n",
       "STATE_Tabasco                           -0.015759              -0.014336   \n",
       "STATE_Tamaulipas                        -0.008210              -0.007468   \n",
       "STATE_Tlaxcala                          -0.013934              -0.012675   \n",
       "STATE_Veracruz                          -0.021058              -0.019155   \n",
       "target                                  -0.023783              -0.000094   \n",
       "\n",
       "                             STATE_Baja_California_Sur  STATE_Campeche  \\\n",
       "COUNT_WEEKNIGHT_2                             0.010462        0.010913   \n",
       "COUNT_WEEKNIGHT_3                             0.010054        0.010218   \n",
       "COUNT_WEEKNIGHT_4                             0.010038        0.006389   \n",
       "COUNT_WEEKNIGHT_5                             0.007257        0.001450   \n",
       "COUNT_WEEKNIGHT_6                             0.005871       -0.002301   \n",
       "COUNT_WEEKNIGHT_7                             0.003499       -0.008053   \n",
       "COUNT_WEEKNIGHT_8                             0.002260       -0.011266   \n",
       "COUNT_WEEKNIGHT_9                             0.000089       -0.015504   \n",
       "MOBILITY_DIAMETER                             0.029463        0.006546   \n",
       "MOBILITY_DIAMETER_WEEKNIGHT                   0.029630        0.005464   \n",
       "EPIDEMIC                                     -0.024981       -0.057637   \n",
       "EPIDEMIC_gt                                   0.026783       -0.009529   \n",
       "TimeWeekEnd_OUT_VUL_12                        0.008033       -0.000488   \n",
       "CallsWeekDay_OUT_VUL_12                      -0.000007       -0.012801   \n",
       "CallsWeekNight_OUT_VUL_12                     0.006258       -0.003309   \n",
       "TimeWeekDay_OUT_VUL_12                        0.003875       -0.004778   \n",
       "CallsWeekEnd_OUT_VUL_12                       0.002557       -0.009829   \n",
       "TimeWeekNight_OUT_VUL_12                      0.010893        0.007069   \n",
       "VULNERABLE_OUT_12                             0.008961       -0.016654   \n",
       "TimeWeekEnd_IN_VUL_12                         0.006726       -0.000521   \n",
       "CallsWeekDay_IN_VUL_12                       -0.000865       -0.014889   \n",
       "CallsWeekNight_IN_VUL_12                      0.003360       -0.010111   \n",
       "TimeWeekDay_IN_VUL_12                         0.003278       -0.006267   \n",
       "CallsWeekEnd_IN_VUL_12                        0.000786       -0.010897   \n",
       "TimeWeekNight_IN_VUL_12                       0.007753       -0.001753   \n",
       "VULNERABLE_IN_12                              0.009459       -0.015403   \n",
       "TimeWeekEnd_OUT_VUL_08                        0.013896       -0.001363   \n",
       "CallsWeekDay_OUT_VUL_08                       0.000393       -0.013446   \n",
       "CallsWeekNight_OUT_VUL_08                     0.006758       -0.006365   \n",
       "TimeWeekDay_OUT_VUL_08                        0.003923       -0.004893   \n",
       "...                                                ...             ...   \n",
       "CallsWeekNight_OUT_VUL_11                     0.000639       -0.005551   \n",
       "TimeWeekDay_OUT_VUL_11                        0.003391       -0.006930   \n",
       "CallsWeekEnd_OUT_VUL_11                       0.002723       -0.010726   \n",
       "TimeWeekNight_OUT_VUL_11                      0.003391        0.004872   \n",
       "VULNERABLE_OUT_11                             0.005511       -0.020553   \n",
       "TimeWeekEnd_IN_VUL_11                         0.009940       -0.001356   \n",
       "CallsWeekDay_IN_VUL_11                       -0.000636       -0.015335   \n",
       "CallsWeekNight_IN_VUL_11                      0.001258       -0.009396   \n",
       "TimeWeekDay_IN_VUL_11                         0.001558       -0.008221   \n",
       "CallsWeekEnd_IN_VUL_11                        0.000584       -0.012439   \n",
       "TimeWeekNight_IN_VUL_11                       0.004088       -0.000596   \n",
       "VULNERABLE_IN_11                              0.008381       -0.019054   \n",
       "STATE_Baja_California_Sur                     1.000000       -0.003215   \n",
       "STATE_Chihuahua                              -0.002307       -0.005323   \n",
       "STATE_Colima                                 -0.002524       -0.005824   \n",
       "STATE_Guerrero                               -0.004987       -0.011505   \n",
       "STATE_Hidalgo                                -0.008239       -0.019009   \n",
       "STATE_Jalisco                                -0.012197       -0.028141   \n",
       "STATE_Morelos                                -0.006587       -0.015199   \n",
       "STATE_Nayarit                                -0.003392       -0.007826   \n",
       "STATE_Oaxaca                                 -0.003957       -0.009129   \n",
       "STATE_Puebla                                 -0.008293       -0.019135   \n",
       "STATE_Quintana_Roo                           -0.004483       -0.010344   \n",
       "STATE_Sinaloa                                -0.002955       -0.006817   \n",
       "STATE_Sonora                                 -0.002133       -0.004921   \n",
       "STATE_Tabasco                                -0.005594       -0.012908   \n",
       "STATE_Tamaulipas                             -0.002915       -0.006725   \n",
       "STATE_Tlaxcala                               -0.004947       -0.011413   \n",
       "STATE_Veracruz                               -0.007475       -0.017248   \n",
       "target                                        0.037388        0.007922   \n",
       "\n",
       "                             STATE_Chiapas  STATE_Chihuahua  \\\n",
       "COUNT_WEEKNIGHT_2                 0.002828         0.010746   \n",
       "COUNT_WEEKNIGHT_3                -0.000853         0.008956   \n",
       "COUNT_WEEKNIGHT_4                -0.001716         0.006701   \n",
       "COUNT_WEEKNIGHT_5                -0.003555         0.005085   \n",
       "COUNT_WEEKNIGHT_6                -0.006009         0.004453   \n",
       "COUNT_WEEKNIGHT_7                -0.008596         0.002837   \n",
       "COUNT_WEEKNIGHT_8                -0.011632         0.002160   \n",
       "COUNT_WEEKNIGHT_9                -0.014553         0.000584   \n",
       "MOBILITY_DIAMETER                -0.014228         0.022625   \n",
       "MOBILITY_DIAMETER_WEEKNIGHT      -0.010217         0.023249   \n",
       "EPIDEMIC                         -0.086685        -0.041358   \n",
       "EPIDEMIC_gt                      -0.036335        -0.002569   \n",
       "TimeWeekEnd_OUT_VUL_12           -0.011647        -0.006696   \n",
       "CallsWeekDay_OUT_VUL_12          -0.023496        -0.008627   \n",
       "CallsWeekNight_OUT_VUL_12        -0.017347        -0.005301   \n",
       "TimeWeekDay_OUT_VUL_12           -0.016128        -0.005995   \n",
       "CallsWeekEnd_OUT_VUL_12          -0.021284        -0.009290   \n",
       "TimeWeekNight_OUT_VUL_12         -0.006941         0.000307   \n",
       "VULNERABLE_OUT_12                -0.039564        -0.016982   \n",
       "TimeWeekEnd_IN_VUL_12            -0.008049        -0.002762   \n",
       "CallsWeekDay_IN_VUL_12           -0.024665        -0.007189   \n",
       "CallsWeekNight_IN_VUL_12         -0.017924        -0.005440   \n",
       "TimeWeekDay_IN_VUL_12            -0.016078        -0.004116   \n",
       "CallsWeekEnd_IN_VUL_12           -0.021659        -0.006442   \n",
       "TimeWeekNight_IN_VUL_12          -0.005488        -0.003227   \n",
       "VULNERABLE_IN_12                 -0.039487        -0.015858   \n",
       "TimeWeekEnd_OUT_VUL_08           -0.009795        -0.004073   \n",
       "CallsWeekDay_OUT_VUL_08          -0.024191        -0.009933   \n",
       "CallsWeekNight_OUT_VUL_08        -0.016954        -0.008103   \n",
       "TimeWeekDay_OUT_VUL_08           -0.016604        -0.006313   \n",
       "...                                    ...              ...   \n",
       "CallsWeekNight_OUT_VUL_11        -0.015065        -0.008255   \n",
       "TimeWeekDay_OUT_VUL_11           -0.015829        -0.005967   \n",
       "CallsWeekEnd_OUT_VUL_11          -0.021539        -0.009630   \n",
       "TimeWeekNight_OUT_VUL_11         -0.004256        -0.005000   \n",
       "VULNERABLE_OUT_11                -0.042658        -0.017134   \n",
       "TimeWeekEnd_IN_VUL_11            -0.010575        -0.001549   \n",
       "CallsWeekDay_IN_VUL_11           -0.023914        -0.008257   \n",
       "CallsWeekNight_IN_VUL_11         -0.017210        -0.006741   \n",
       "TimeWeekDay_IN_VUL_11            -0.013160        -0.005113   \n",
       "CallsWeekEnd_IN_VUL_11           -0.024323        -0.007011   \n",
       "TimeWeekNight_IN_VUL_11          -0.004479        -0.002574   \n",
       "VULNERABLE_IN_11                 -0.043372        -0.016477   \n",
       "STATE_Baja_California_Sur        -0.004835        -0.002307   \n",
       "STATE_Chihuahua                  -0.008006         1.000000   \n",
       "STATE_Colima                     -0.008759        -0.004179   \n",
       "STATE_Guerrero                   -0.017304        -0.008256   \n",
       "STATE_Hidalgo                    -0.028590        -0.013640   \n",
       "STATE_Jalisco                    -0.042324        -0.020193   \n",
       "STATE_Morelos                    -0.022859        -0.010906   \n",
       "STATE_Nayarit                    -0.011771        -0.005616   \n",
       "STATE_Oaxaca                     -0.013730        -0.006551   \n",
       "STATE_Puebla                     -0.028779        -0.013730   \n",
       "STATE_Quintana_Roo               -0.015558        -0.007423   \n",
       "STATE_Sinaloa                    -0.010253        -0.004892   \n",
       "STATE_Sonora                     -0.007401        -0.003531   \n",
       "STATE_Tabasco                    -0.019413        -0.009262   \n",
       "STATE_Tamaulipas                 -0.010114        -0.004825   \n",
       "STATE_Tlaxcala                   -0.017165        -0.008189   \n",
       "STATE_Veracruz                   -0.025941        -0.012376   \n",
       "target                           -0.012255         0.010373   \n",
       "\n",
       "                             STATE_Coahuila_de_Zaragoza  STATE_Colima  \\\n",
       "COUNT_WEEKNIGHT_2                              0.000414      0.023018   \n",
       "COUNT_WEEKNIGHT_3                             -0.000462      0.020948   \n",
       "COUNT_WEEKNIGHT_4                             -0.004008      0.015477   \n",
       "COUNT_WEEKNIGHT_5                             -0.005752      0.011588   \n",
       "COUNT_WEEKNIGHT_6                             -0.007847      0.008485   \n",
       "COUNT_WEEKNIGHT_7                             -0.008421      0.003400   \n",
       "COUNT_WEEKNIGHT_8                             -0.010742      0.001750   \n",
       "COUNT_WEEKNIGHT_9                             -0.013024      0.000132   \n",
       "MOBILITY_DIAMETER                             -0.002491     -0.007132   \n",
       "MOBILITY_DIAMETER_WEEKNIGHT                   -0.001705     -0.005473   \n",
       "EPIDEMIC                                      -0.046465     -0.045250   \n",
       "EPIDEMIC_gt                                   -0.030514      0.015001   \n",
       "TimeWeekEnd_OUT_VUL_12                        -0.012125      0.007212   \n",
       "CallsWeekDay_OUT_VUL_12                       -0.017978      0.007904   \n",
       "CallsWeekNight_OUT_VUL_12                     -0.012895      0.006902   \n",
       "TimeWeekDay_OUT_VUL_12                        -0.014900      0.013330   \n",
       "CallsWeekEnd_OUT_VUL_12                       -0.016709      0.004856   \n",
       "TimeWeekNight_OUT_VUL_12                      -0.006621      0.005087   \n",
       "VULNERABLE_OUT_12                             -0.033939      0.010742   \n",
       "TimeWeekEnd_IN_VUL_12                         -0.011186      0.009232   \n",
       "CallsWeekDay_IN_VUL_12                        -0.018177      0.005136   \n",
       "CallsWeekNight_IN_VUL_12                      -0.014144      0.006850   \n",
       "TimeWeekDay_IN_VUL_12                         -0.014973      0.010036   \n",
       "CallsWeekEnd_IN_VUL_12                        -0.016915      0.004794   \n",
       "TimeWeekNight_IN_VUL_12                       -0.007575      0.007875   \n",
       "VULNERABLE_IN_12                              -0.033841      0.012749   \n",
       "TimeWeekEnd_OUT_VUL_08                        -0.009357      0.009206   \n",
       "CallsWeekDay_OUT_VUL_08                       -0.017416      0.007667   \n",
       "CallsWeekNight_OUT_VUL_08                     -0.012660      0.011083   \n",
       "TimeWeekDay_OUT_VUL_08                        -0.014123      0.009930   \n",
       "...                                                 ...           ...   \n",
       "CallsWeekNight_OUT_VUL_11                     -0.013050      0.008629   \n",
       "TimeWeekDay_OUT_VUL_11                        -0.013458      0.008591   \n",
       "CallsWeekEnd_OUT_VUL_11                       -0.015850      0.006855   \n",
       "TimeWeekNight_OUT_VUL_11                      -0.006942      0.008321   \n",
       "VULNERABLE_OUT_11                             -0.034379      0.011267   \n",
       "TimeWeekEnd_IN_VUL_11                         -0.010403      0.003722   \n",
       "CallsWeekDay_IN_VUL_11                        -0.017190      0.002792   \n",
       "CallsWeekNight_IN_VUL_11                      -0.012355      0.004662   \n",
       "TimeWeekDay_IN_VUL_11                         -0.013512      0.005018   \n",
       "CallsWeekEnd_IN_VUL_11                        -0.016907      0.000881   \n",
       "TimeWeekNight_IN_VUL_11                       -0.004920      0.003574   \n",
       "VULNERABLE_IN_11                              -0.032897      0.010190   \n",
       "STATE_Baja_California_Sur                     -0.002592     -0.002524   \n",
       "STATE_Chihuahua                               -0.004291     -0.004179   \n",
       "STATE_Colima                                  -0.004695      1.000000   \n",
       "STATE_Guerrero                                -0.009275     -0.009033   \n",
       "STATE_Hidalgo                                 -0.015325     -0.014924   \n",
       "STATE_Jalisco                                 -0.022686     -0.022093   \n",
       "STATE_Morelos                                 -0.012253     -0.011932   \n",
       "STATE_Nayarit                                 -0.006309     -0.006144   \n",
       "STATE_Oaxaca                                  -0.007360     -0.007167   \n",
       "STATE_Puebla                                  -0.015426     -0.015023   \n",
       "STATE_Quintana_Roo                            -0.008339     -0.008121   \n",
       "STATE_Sinaloa                                 -0.005496     -0.005352   \n",
       "STATE_Sonora                                  -0.003967     -0.003864   \n",
       "STATE_Tabasco                                 -0.010406     -0.010134   \n",
       "STATE_Tamaulipas                              -0.005421     -0.005279   \n",
       "STATE_Tlaxcala                                -0.009201     -0.008960   \n",
       "STATE_Veracruz                                -0.013905     -0.013541   \n",
       "target                                        -0.018693      0.030913   \n",
       "\n",
       "                             STATE_Distrito_Federal  STATE_Durango    ...     \\\n",
       "COUNT_WEEKNIGHT_2                          0.021149      -0.000483    ...      \n",
       "COUNT_WEEKNIGHT_3                          0.036144      -0.001415    ...      \n",
       "COUNT_WEEKNIGHT_4                          0.053368      -0.003196    ...      \n",
       "COUNT_WEEKNIGHT_5                          0.067628      -0.003591    ...      \n",
       "COUNT_WEEKNIGHT_6                          0.079762      -0.004916    ...      \n",
       "COUNT_WEEKNIGHT_7                          0.091035      -0.006330    ...      \n",
       "COUNT_WEEKNIGHT_8                          0.100469      -0.007947    ...      \n",
       "COUNT_WEEKNIGHT_9                          0.109838      -0.008881    ...      \n",
       "MOBILITY_DIAMETER                         -0.137678      -0.009237    ...      \n",
       "MOBILITY_DIAMETER_WEEKNIGHT               -0.118547      -0.009302    ...      \n",
       "EPIDEMIC                                  -0.346650      -0.034179    ...      \n",
       "EPIDEMIC_gt                               -0.138996      -0.021735    ...      \n",
       "TimeWeekEnd_OUT_VUL_12                    -0.059115      -0.009559    ...      \n",
       "CallsWeekDay_OUT_VUL_12                   -0.095289      -0.013486    ...      \n",
       "CallsWeekNight_OUT_VUL_12                 -0.065913      -0.010075    ...      \n",
       "TimeWeekDay_OUT_VUL_12                    -0.071550      -0.011761    ...      \n",
       "CallsWeekEnd_OUT_VUL_12                   -0.087687      -0.012906    ...      \n",
       "TimeWeekNight_OUT_VUL_12                  -0.033505      -0.006106    ...      \n",
       "VULNERABLE_OUT_12                         -0.147497      -0.025169    ...      \n",
       "TimeWeekEnd_IN_VUL_12                     -0.055550      -0.008656    ...      \n",
       "CallsWeekDay_IN_VUL_12                    -0.096553      -0.012183    ...      \n",
       "CallsWeekNight_IN_VUL_12                  -0.070318      -0.010760    ...      \n",
       "TimeWeekDay_IN_VUL_12                     -0.071406      -0.009973    ...      \n",
       "CallsWeekEnd_IN_VUL_12                    -0.089347      -0.012235    ...      \n",
       "TimeWeekNight_IN_VUL_12                   -0.035170      -0.006676    ...      \n",
       "VULNERABLE_IN_12                          -0.148157      -0.023546    ...      \n",
       "TimeWeekEnd_OUT_VUL_08                    -0.067427      -0.010476    ...      \n",
       "CallsWeekDay_OUT_VUL_08                   -0.101383      -0.012788    ...      \n",
       "CallsWeekNight_OUT_VUL_08                 -0.077978      -0.012024    ...      \n",
       "TimeWeekDay_OUT_VUL_08                    -0.080102      -0.011457    ...      \n",
       "...                                             ...            ...    ...      \n",
       "CallsWeekNight_OUT_VUL_11                 -0.066810      -0.010967    ...      \n",
       "TimeWeekDay_OUT_VUL_11                    -0.075553      -0.011472    ...      \n",
       "CallsWeekEnd_OUT_VUL_11                   -0.096621      -0.013394    ...      \n",
       "TimeWeekNight_OUT_VUL_11                  -0.030047      -0.007340    ...      \n",
       "VULNERABLE_OUT_11                         -0.155290      -0.025967    ...      \n",
       "TimeWeekEnd_IN_VUL_11                     -0.058554      -0.008938    ...      \n",
       "CallsWeekDay_IN_VUL_11                    -0.098893      -0.012572    ...      \n",
       "CallsWeekNight_IN_VUL_11                  -0.069934      -0.010903    ...      \n",
       "TimeWeekDay_IN_VUL_11                     -0.070976      -0.010378    ...      \n",
       "CallsWeekEnd_IN_VUL_11                    -0.097204      -0.013275    ...      \n",
       "TimeWeekNight_IN_VUL_11                   -0.029386      -0.006394    ...      \n",
       "VULNERABLE_IN_11                          -0.154610      -0.025122    ...      \n",
       "STATE_Baja_California_Sur                 -0.019337      -0.001907    ...      \n",
       "STATE_Chihuahua                           -0.032014      -0.003157    ...      \n",
       "STATE_Colima                              -0.035027      -0.003454    ...      \n",
       "STATE_Guerrero                            -0.069197      -0.006823    ...      \n",
       "STATE_Hidalgo                             -0.114328      -0.011273    ...      \n",
       "STATE_Jalisco                             -0.169250      -0.016688    ...      \n",
       "STATE_Morelos                             -0.091412      -0.009013    ...      \n",
       "STATE_Nayarit                             -0.047071      -0.004641    ...      \n",
       "STATE_Oaxaca                              -0.054907      -0.005414    ...      \n",
       "STATE_Puebla                              -0.115084      -0.011347    ...      \n",
       "STATE_Quintana_Roo                        -0.062214      -0.006134    ...      \n",
       "STATE_Sinaloa                             -0.041000      -0.004043    ...      \n",
       "STATE_Sonora                              -0.029598      -0.002918    ...      \n",
       "STATE_Tabasco                             -0.077633      -0.007655    ...      \n",
       "STATE_Tamaulipas                          -0.040444      -0.003988    ...      \n",
       "STATE_Tlaxcala                            -0.068642      -0.006768    ...      \n",
       "STATE_Veracruz                            -0.103735      -0.010228    ...      \n",
       "target                                    -0.042078      -0.012970    ...      \n",
       "\n",
       "                             STATE_San_Luis_Potosi  STATE_Sinaloa  \\\n",
       "COUNT_WEEKNIGHT_2                         0.011250       0.016204   \n",
       "COUNT_WEEKNIGHT_3                         0.015895       0.017738   \n",
       "COUNT_WEEKNIGHT_4                         0.016725       0.017207   \n",
       "COUNT_WEEKNIGHT_5                         0.017598       0.013512   \n",
       "COUNT_WEEKNIGHT_6                         0.017243       0.012980   \n",
       "COUNT_WEEKNIGHT_7                         0.016603       0.010894   \n",
       "COUNT_WEEKNIGHT_8                         0.014271       0.008808   \n",
       "COUNT_WEEKNIGHT_9                         0.011430       0.007838   \n",
       "MOBILITY_DIAMETER                         0.061433       0.050950   \n",
       "MOBILITY_DIAMETER_WEEKNIGHT               0.063474       0.054681   \n",
       "EPIDEMIC                                 -0.078990      -0.052967   \n",
       "EPIDEMIC_gt                              -0.058760       0.035432   \n",
       "TimeWeekEnd_OUT_VUL_12                   -0.015696       0.009864   \n",
       "CallsWeekDay_OUT_VUL_12                  -0.029212       0.004131   \n",
       "CallsWeekNight_OUT_VUL_12                -0.018689       0.008055   \n",
       "TimeWeekDay_OUT_VUL_12                   -0.024868       0.009684   \n",
       "CallsWeekEnd_OUT_VUL_12                  -0.025552       0.003966   \n",
       "TimeWeekNight_OUT_VUL_12                 -0.008468       0.013700   \n",
       "VULNERABLE_OUT_12                        -0.050379       0.016702   \n",
       "TimeWeekEnd_IN_VUL_12                    -0.015693       0.008701   \n",
       "CallsWeekDay_IN_VUL_12                   -0.028464       0.003156   \n",
       "CallsWeekNight_IN_VUL_12                 -0.021479       0.003239   \n",
       "TimeWeekDay_IN_VUL_12                    -0.021959       0.005298   \n",
       "CallsWeekEnd_IN_VUL_12                   -0.026426       0.004382   \n",
       "TimeWeekNight_IN_VUL_12                  -0.009615       0.003860   \n",
       "VULNERABLE_IN_12                         -0.048578       0.016454   \n",
       "TimeWeekEnd_OUT_VUL_08                   -0.017209       0.008612   \n",
       "CallsWeekDay_OUT_VUL_08                  -0.028131      -0.000279   \n",
       "CallsWeekNight_OUT_VUL_08                -0.018589       0.002400   \n",
       "TimeWeekDay_OUT_VUL_08                   -0.022973       0.002646   \n",
       "...                                            ...            ...   \n",
       "CallsWeekNight_OUT_VUL_11                -0.018093       0.002800   \n",
       "TimeWeekDay_OUT_VUL_11                   -0.022519       0.005454   \n",
       "CallsWeekEnd_OUT_VUL_11                  -0.026945      -0.000820   \n",
       "TimeWeekNight_OUT_VUL_11                 -0.008341       0.007259   \n",
       "VULNERABLE_OUT_11                        -0.052225       0.013658   \n",
       "TimeWeekEnd_IN_VUL_11                    -0.014515       0.003848   \n",
       "CallsWeekDay_IN_VUL_11                   -0.027309      -0.001533   \n",
       "CallsWeekNight_IN_VUL_11                 -0.019439       0.000220   \n",
       "TimeWeekDay_IN_VUL_11                    -0.020598       0.001846   \n",
       "CallsWeekEnd_IN_VUL_11                   -0.026949      -0.000607   \n",
       "TimeWeekNight_IN_VUL_11                  -0.007047       0.004442   \n",
       "VULNERABLE_IN_11                         -0.052281       0.014488   \n",
       "STATE_Baja_California_Sur                -0.004406      -0.002955   \n",
       "STATE_Chihuahua                          -0.007295      -0.004892   \n",
       "STATE_Colima                             -0.007981      -0.005352   \n",
       "STATE_Guerrero                           -0.015768      -0.010573   \n",
       "STATE_Hidalgo                            -0.026052      -0.017469   \n",
       "STATE_Jalisco                            -0.038567      -0.025861   \n",
       "STATE_Morelos                            -0.020830      -0.013967   \n",
       "STATE_Nayarit                            -0.010726      -0.007192   \n",
       "STATE_Oaxaca                             -0.012512      -0.008390   \n",
       "STATE_Puebla                             -0.026224      -0.017584   \n",
       "STATE_Quintana_Roo                       -0.014177      -0.009506   \n",
       "STATE_Sinaloa                            -0.009343       1.000000   \n",
       "STATE_Sonora                             -0.006744      -0.004522   \n",
       "STATE_Tabasco                            -0.017690      -0.011862   \n",
       "STATE_Tamaulipas                         -0.009216      -0.006180   \n",
       "STATE_Tlaxcala                           -0.015641      -0.010488   \n",
       "STATE_Veracruz                           -0.023638      -0.015850   \n",
       "target                                   -0.039341       0.055817   \n",
       "\n",
       "                             STATE_Sonora  STATE_Tabasco  STATE_Tamaulipas  \\\n",
       "COUNT_WEEKNIGHT_2                0.008146      -0.005059         -0.008536   \n",
       "COUNT_WEEKNIGHT_3                0.009910      -0.006288         -0.008762   \n",
       "COUNT_WEEKNIGHT_4                0.010034      -0.009539         -0.009958   \n",
       "COUNT_WEEKNIGHT_5                0.009724      -0.009275         -0.010257   \n",
       "COUNT_WEEKNIGHT_6                0.010150      -0.008714         -0.011598   \n",
       "COUNT_WEEKNIGHT_7                0.010091      -0.011306         -0.015316   \n",
       "COUNT_WEEKNIGHT_8                0.009519      -0.012101         -0.016915   \n",
       "COUNT_WEEKNIGHT_9                0.009845      -0.013021         -0.018124   \n",
       "MOBILITY_DIAMETER                0.078405       0.003528          0.005187   \n",
       "MOBILITY_DIAMETER_WEEKNIGHT      0.079987       0.007015          0.006280   \n",
       "EPIDEMIC                        -0.038237       0.223952         -0.052248   \n",
       "EPIDEMIC_gt                      0.033727       0.097361          0.000915   \n",
       "TimeWeekEnd_OUT_VUL_12           0.011210       0.059930         -0.000395   \n",
       "CallsWeekDay_OUT_VUL_12          0.007377       0.088268         -0.009238   \n",
       "CallsWeekNight_OUT_VUL_12        0.009917       0.073576         -0.000378   \n",
       "TimeWeekDay_OUT_VUL_12           0.012461       0.071719         -0.005967   \n",
       "CallsWeekEnd_OUT_VUL_12          0.008507       0.083876         -0.007315   \n",
       "TimeWeekNight_OUT_VUL_12         0.012363       0.043720          0.003380   \n",
       "VULNERABLE_OUT_12                0.017947       0.117970         -0.014838   \n",
       "TimeWeekEnd_IN_VUL_12            0.006479       0.060691         -0.002376   \n",
       "CallsWeekDay_IN_VUL_12           0.006578       0.087977         -0.010368   \n",
       "CallsWeekNight_IN_VUL_12         0.008987       0.079932         -0.006294   \n",
       "TimeWeekDay_IN_VUL_12            0.011615       0.067899         -0.004141   \n",
       "CallsWeekEnd_IN_VUL_12           0.004749       0.086885         -0.009541   \n",
       "TimeWeekNight_IN_VUL_12          0.012613       0.045118          0.000895   \n",
       "VULNERABLE_IN_12                 0.015843       0.122644         -0.015729   \n",
       "TimeWeekEnd_OUT_VUL_08           0.007103       0.043694         -0.007526   \n",
       "CallsWeekDay_OUT_VUL_08          0.001112       0.057443         -0.011762   \n",
       "CallsWeekNight_OUT_VUL_08        0.000376       0.058175         -0.005336   \n",
       "TimeWeekDay_OUT_VUL_08           0.001732       0.049214         -0.008458   \n",
       "...                                   ...            ...               ...   \n",
       "CallsWeekNight_OUT_VUL_11        0.005746       0.059549         -0.005530   \n",
       "TimeWeekDay_OUT_VUL_11           0.008967       0.055378         -0.006377   \n",
       "CallsWeekEnd_OUT_VUL_11          0.008018       0.073993         -0.008903   \n",
       "TimeWeekNight_OUT_VUL_11         0.007891       0.037977         -0.002081   \n",
       "VULNERABLE_OUT_11                0.016058       0.115650         -0.018341   \n",
       "TimeWeekEnd_IN_VUL_11            0.004136       0.050647         -0.007397   \n",
       "CallsWeekDay_IN_VUL_11           0.002638       0.067169         -0.012263   \n",
       "CallsWeekNight_IN_VUL_11         0.003768       0.065352         -0.008574   \n",
       "TimeWeekDay_IN_VUL_11            0.003013       0.054572         -0.007039   \n",
       "CallsWeekEnd_IN_VUL_11           0.003648       0.074553         -0.013582   \n",
       "TimeWeekNight_IN_VUL_11          0.005233       0.037523         -0.003595   \n",
       "VULNERABLE_IN_11                 0.014553       0.119650         -0.019492   \n",
       "STATE_Baja_California_Sur       -0.002133      -0.005594         -0.002915   \n",
       "STATE_Chihuahua                 -0.003531      -0.009262         -0.004825   \n",
       "STATE_Colima                    -0.003864      -0.010134         -0.005279   \n",
       "STATE_Guerrero                  -0.007633      -0.020020         -0.010430   \n",
       "STATE_Hidalgo                   -0.012611      -0.033077         -0.017232   \n",
       "STATE_Jalisco                   -0.018669      -0.048967         -0.025510   \n",
       "STATE_Morelos                   -0.010083      -0.026447         -0.013778   \n",
       "STATE_Nayarit                   -0.005192      -0.013619         -0.007095   \n",
       "STATE_Oaxaca                    -0.006056      -0.015886         -0.008276   \n",
       "STATE_Puebla                    -0.012694      -0.033296         -0.017346   \n",
       "STATE_Quintana_Roo              -0.006862      -0.018000         -0.009377   \n",
       "STATE_Sinaloa                   -0.004522      -0.011862         -0.006180   \n",
       "STATE_Sonora                     1.000000      -0.008563         -0.004461   \n",
       "STATE_Tabasco                   -0.008563       1.000000         -0.011701   \n",
       "STATE_Tamaulipas                -0.004461      -0.011701          1.000000   \n",
       "STATE_Tlaxcala                  -0.007571      -0.019859         -0.010346   \n",
       "STATE_Veracruz                  -0.011442      -0.030012         -0.015635   \n",
       "target                           0.049245       0.037998          0.017675   \n",
       "\n",
       "                             STATE_Tlaxcala  STATE_Veracruz  STATE_Yucatan  \\\n",
       "COUNT_WEEKNIGHT_2                 -0.022472       -0.007995       0.000920   \n",
       "COUNT_WEEKNIGHT_3                 -0.026701       -0.011268       0.004046   \n",
       "COUNT_WEEKNIGHT_4                 -0.031832       -0.015481       0.006283   \n",
       "COUNT_WEEKNIGHT_5                 -0.036685       -0.020784       0.007593   \n",
       "COUNT_WEEKNIGHT_6                 -0.040544       -0.024538       0.007912   \n",
       "COUNT_WEEKNIGHT_7                 -0.043402       -0.029444       0.008145   \n",
       "COUNT_WEEKNIGHT_8                 -0.045340       -0.033115       0.008182   \n",
       "COUNT_WEEKNIGHT_9                 -0.046815       -0.037587       0.007833   \n",
       "MOBILITY_DIAMETER                 -0.020111        0.055373      -0.029631   \n",
       "MOBILITY_DIAMETER_WEEKNIGHT       -0.026489        0.045077      -0.021358   \n",
       "EPIDEMIC                          -0.088677        0.299250      -0.109611   \n",
       "EPIDEMIC_gt                        0.018569        0.158318      -0.077202   \n",
       "TimeWeekEnd_OUT_VUL_12            -0.013076        0.026118      -0.024898   \n",
       "CallsWeekDay_OUT_VUL_12           -0.021836        0.045091      -0.040722   \n",
       "CallsWeekNight_OUT_VUL_12         -0.014012        0.037924      -0.030445   \n",
       "TimeWeekDay_OUT_VUL_12            -0.017661        0.033545      -0.033829   \n",
       "CallsWeekEnd_OUT_VUL_12           -0.018611        0.043837      -0.036358   \n",
       "TimeWeekNight_OUT_VUL_12          -0.006625        0.019073      -0.017836   \n",
       "VULNERABLE_OUT_12                 -0.027587        0.134135      -0.074787   \n",
       "TimeWeekEnd_IN_VUL_12             -0.009871        0.027561      -0.020505   \n",
       "CallsWeekDay_IN_VUL_12            -0.020877        0.045334      -0.040102   \n",
       "CallsWeekNight_IN_VUL_12          -0.012031        0.038929      -0.029646   \n",
       "TimeWeekDay_IN_VUL_12             -0.012841        0.031678      -0.030825   \n",
       "CallsWeekEnd_IN_VUL_12            -0.018201        0.044469      -0.035791   \n",
       "TimeWeekNight_IN_VUL_12           -0.003455        0.018321      -0.013248   \n",
       "VULNERABLE_IN_12                  -0.025308        0.133612      -0.073859   \n",
       "TimeWeekEnd_OUT_VUL_08            -0.014896        0.027939      -0.028002   \n",
       "CallsWeekDay_OUT_VUL_08           -0.023200        0.032872      -0.040636   \n",
       "CallsWeekNight_OUT_VUL_08         -0.016747        0.038519      -0.034933   \n",
       "TimeWeekDay_OUT_VUL_08            -0.018948        0.027646      -0.033421   \n",
       "...                                     ...             ...            ...   \n",
       "CallsWeekNight_OUT_VUL_11         -0.015929        0.038877      -0.032002   \n",
       "TimeWeekDay_OUT_VUL_11            -0.020304        0.029912      -0.032809   \n",
       "CallsWeekEnd_OUT_VUL_11           -0.022092        0.046996      -0.040295   \n",
       "TimeWeekNight_OUT_VUL_11          -0.009624        0.021812      -0.018638   \n",
       "VULNERABLE_OUT_11                 -0.027724        0.141215      -0.079442   \n",
       "TimeWeekEnd_IN_VUL_11             -0.010055        0.035241      -0.019520   \n",
       "CallsWeekDay_IN_VUL_11            -0.023150        0.038400      -0.038855   \n",
       "CallsWeekNight_IN_VUL_11          -0.014008        0.038536      -0.029306   \n",
       "TimeWeekDay_IN_VUL_11             -0.017137        0.029210      -0.027677   \n",
       "CallsWeekEnd_IN_VUL_11            -0.020866        0.046481      -0.038301   \n",
       "TimeWeekNight_IN_VUL_11           -0.005174        0.019848      -0.011918   \n",
       "VULNERABLE_IN_11                  -0.028566        0.141110      -0.078814   \n",
       "STATE_Baja_California_Sur         -0.004947       -0.007475      -0.006114   \n",
       "STATE_Chihuahua                   -0.008189       -0.012376      -0.010123   \n",
       "STATE_Colima                      -0.008960       -0.013541      -0.011075   \n",
       "STATE_Guerrero                    -0.017701       -0.026751      -0.021880   \n",
       "STATE_Hidalgo                     -0.029246       -0.044198      -0.036151   \n",
       "STATE_Jalisco                     -0.043296       -0.065431      -0.053517   \n",
       "STATE_Morelos                     -0.023384       -0.035339      -0.028904   \n",
       "STATE_Nayarit                     -0.012041       -0.018197      -0.014884   \n",
       "STATE_Oaxaca                      -0.014046       -0.021227      -0.017362   \n",
       "STATE_Puebla                      -0.029440       -0.044491      -0.036389   \n",
       "STATE_Quintana_Roo                -0.015915       -0.024052      -0.019672   \n",
       "STATE_Sinaloa                     -0.010488       -0.015850      -0.012964   \n",
       "STATE_Sonora                      -0.007571       -0.011442      -0.009359   \n",
       "STATE_Tabasco                     -0.019859       -0.030012      -0.024548   \n",
       "STATE_Tamaulipas                  -0.010346       -0.015635      -0.012788   \n",
       "STATE_Tlaxcala                     1.000000       -0.026537      -0.021705   \n",
       "STATE_Veracruz                    -0.026537        1.000000      -0.032801   \n",
       "target                             0.048688        0.019774      -0.049829   \n",
       "\n",
       "                             STATE_Zacatecas    target  \n",
       "COUNT_WEEKNIGHT_2                   0.002465  0.013574  \n",
       "COUNT_WEEKNIGHT_3                  -0.003612  0.020339  \n",
       "COUNT_WEEKNIGHT_4                  -0.006494  0.023249  \n",
       "COUNT_WEEKNIGHT_5                  -0.011132  0.024684  \n",
       "COUNT_WEEKNIGHT_6                  -0.014315  0.026258  \n",
       "COUNT_WEEKNIGHT_7                  -0.017771  0.027846  \n",
       "COUNT_WEEKNIGHT_8                  -0.019009  0.028464  \n",
       "COUNT_WEEKNIGHT_9                  -0.020115  0.029678  \n",
       "MOBILITY_DIAMETER                  -0.000281  0.154510  \n",
       "MOBILITY_DIAMETER_WEEKNIGHT        -0.006317  0.141488  \n",
       "EPIDEMIC                           -0.034794  0.164076  \n",
       "EPIDEMIC_gt                        -0.018218  0.265702  \n",
       "TimeWeekEnd_OUT_VUL_12             -0.004787  0.066856  \n",
       "CallsWeekDay_OUT_VUL_12            -0.011748  0.056102  \n",
       "CallsWeekNight_OUT_VUL_12          -0.008211  0.064372  \n",
       "TimeWeekDay_OUT_VUL_12             -0.009765  0.071430  \n",
       "CallsWeekEnd_OUT_VUL_12            -0.010151  0.057492  \n",
       "TimeWeekNight_OUT_VUL_12           -0.003488  0.066613  \n",
       "VULNERABLE_OUT_12                  -0.018914  0.195114  \n",
       "TimeWeekEnd_IN_VUL_12              -0.005930  0.059171  \n",
       "CallsWeekDay_IN_VUL_12             -0.011300  0.045735  \n",
       "CallsWeekNight_IN_VUL_12           -0.008444  0.056618  \n",
       "TimeWeekDay_IN_VUL_12              -0.007694  0.056979  \n",
       "CallsWeekEnd_IN_VUL_12             -0.010668  0.051813  \n",
       "TimeWeekNight_IN_VUL_12            -0.005159  0.053752  \n",
       "VULNERABLE_IN_12                   -0.019445  0.192320  \n",
       "TimeWeekEnd_OUT_VUL_08             -0.009473  0.056637  \n",
       "CallsWeekDay_OUT_VUL_08            -0.011769  0.040469  \n",
       "CallsWeekNight_OUT_VUL_08          -0.008624  0.047088  \n",
       "TimeWeekDay_OUT_VUL_08             -0.009883  0.058122  \n",
       "...                                      ...       ...  \n",
       "CallsWeekNight_OUT_VUL_11          -0.007708  0.057425  \n",
       "TimeWeekDay_OUT_VUL_11             -0.010183  0.066649  \n",
       "CallsWeekEnd_OUT_VUL_11            -0.012146  0.049032  \n",
       "TimeWeekNight_OUT_VUL_11           -0.004129  0.066150  \n",
       "VULNERABLE_OUT_11                  -0.023083  0.188275  \n",
       "TimeWeekEnd_IN_VUL_11              -0.007869  0.051886  \n",
       "CallsWeekDay_IN_VUL_11             -0.011680  0.033627  \n",
       "CallsWeekNight_IN_VUL_11           -0.008704  0.047442  \n",
       "TimeWeekDay_IN_VUL_11              -0.009016  0.048307  \n",
       "CallsWeekEnd_IN_VUL_11             -0.012095  0.039627  \n",
       "TimeWeekNight_IN_VUL_11            -0.003494  0.047939  \n",
       "VULNERABLE_IN_11                   -0.019534  0.188558  \n",
       "STATE_Baja_California_Sur          -0.001941  0.037388  \n",
       "STATE_Chihuahua                    -0.003213  0.010373  \n",
       "STATE_Colima                       -0.003516  0.030913  \n",
       "STATE_Guerrero                     -0.006946  0.069300  \n",
       "STATE_Hidalgo                      -0.011475  0.096493  \n",
       "STATE_Jalisco                      -0.016988  0.032628  \n",
       "STATE_Morelos                      -0.009175  0.057009  \n",
       "STATE_Nayarit                      -0.004725  0.032723  \n",
       "STATE_Oaxaca                       -0.005511  0.044986  \n",
       "STATE_Puebla                       -0.011551  0.061183  \n",
       "STATE_Quintana_Roo                 -0.006245  0.024692  \n",
       "STATE_Sinaloa                      -0.004115  0.055817  \n",
       "STATE_Sonora                       -0.002971  0.049245  \n",
       "STATE_Tabasco                      -0.007792  0.037998  \n",
       "STATE_Tamaulipas                   -0.004059  0.017675  \n",
       "STATE_Tlaxcala                     -0.006890  0.048688  \n",
       "STATE_Veracruz                     -0.010412  0.019774  \n",
       "target                             -0.008910  1.000000  \n",
       "\n",
       "[100 rows x 33 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## show correlation between state and target\n",
    "\n",
    "if not 'STATE' in exclude_cols:    \n",
    "    state_cols = [col for col in corr if 'STATE' in col]\n",
    "    view = corr[state_cols + [target_col]]\n",
    "    display(view.query('target > 0.01'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.33775674382872634"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=data['EPIDEMIC_gt'].sum();b= data.shape[0]\n",
    "a*1.0/b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.31040447046301223"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=val_set['EPIDEMIC'].sum();b= val_set.shape[0]\n",
    "a*1.0/b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get metric functions and sklearn model selectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import *\n",
    "# from sklearn.cross_validation import *\n",
    "from sklearn.model_selection import (GridSearchCV, RandomizedSearchCV, \n",
    "                                     train_test_split, KFold, cross_val_predict, \n",
    "                                     cross_val_score, learning_curve, validation_curve\n",
    "                                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instance 1st fast model with MNB\n",
    "this is a benchmarking-only process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "from sklearn.naive_bayes import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remember that the Multinomail NB assumes no negative values\n",
    "are present in the dataset as this must be `count` data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n",
      "[CV] alpha=0.001, fit_prior=True .....................................\n",
      "[CV] alpha=0.001, fit_prior=True .....................................\n",
      "[CV] alpha=0.001, fit_prior=True .....................................\n",
      "[CV] ...... alpha=0.001, fit_prior=True, score=0.704388, total=   0.4s\n",
      "[CV] alpha=0.001, fit_prior=False ....................................\n",
      "[CV] ...... alpha=0.001, fit_prior=True, score=0.768092, total=   0.4s\n",
      "[CV] alpha=0.001, fit_prior=False ....................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 out of  24 | elapsed:    1.2s remaining:   13.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ...... alpha=0.001, fit_prior=True, score=0.768343, total=   0.4s\n",
      "[CV] alpha=0.001, fit_prior=False ....................................\n",
      "[CV] ..... alpha=0.001, fit_prior=False, score=0.700921, total=   0.4s\n",
      "[CV] alpha=0.1, fit_prior=True .......................................\n",
      "[CV] ..... alpha=0.001, fit_prior=False, score=0.768012, total=   0.4s\n",
      "[CV] alpha=0.1, fit_prior=True .......................................\n",
      "[CV] ..... alpha=0.001, fit_prior=False, score=0.768308, total=   0.4s\n",
      "[CV] alpha=0.1, fit_prior=True .......................................\n",
      "[CV] ........ alpha=0.1, fit_prior=True, score=0.704388, total=   0.4s\n",
      "[CV] alpha=0.1, fit_prior=False ......................................\n",
      "[CV] ........ alpha=0.1, fit_prior=True, score=0.768092, total=   0.4s\n",
      "[CV] alpha=0.1, fit_prior=False ......................................\n",
      "[CV] ........ alpha=0.1, fit_prior=True, score=0.768343, total=   0.5s\n",
      "[CV] alpha=0.1, fit_prior=False ......................................\n",
      "[CV] ....... alpha=0.1, fit_prior=False, score=0.700921, total=   0.4s\n",
      "[CV] alpha=10.0, fit_prior=True ......................................\n",
      "[CV] ....... alpha=0.1, fit_prior=False, score=0.768012, total=   0.4s\n",
      "[CV] alpha=10.0, fit_prior=True ......................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  11 out of  24 | elapsed:    3.4s remaining:    4.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ....... alpha=0.1, fit_prior=False, score=0.768308, total=   0.4s\n",
      "[CV] alpha=10.0, fit_prior=True ......................................\n",
      "[CV] ....... alpha=10.0, fit_prior=True, score=0.704269, total=   0.4s\n",
      "[CV] alpha=10.0, fit_prior=False .....................................\n",
      "[CV] ....... alpha=10.0, fit_prior=True, score=0.768092, total=   0.4s\n",
      "[CV] alpha=10.0, fit_prior=False .....................................\n",
      "[CV] ....... alpha=10.0, fit_prior=True, score=0.768323, total=   0.4s\n",
      "[CV] alpha=10.0, fit_prior=False .....................................\n",
      "[CV] ...... alpha=10.0, fit_prior=False, score=0.700681, total=   0.4s\n",
      "[CV] alpha=1.0, fit_prior=True .......................................\n",
      "[CV] ...... alpha=10.0, fit_prior=False, score=0.768012, total=   0.4s\n",
      "[CV] alpha=1.0, fit_prior=True .......................................\n",
      "[CV] ...... alpha=10.0, fit_prior=False, score=0.768308, total=   0.4s\n",
      "[CV] alpha=1.0, fit_prior=True .......................................\n",
      "[CV] ........ alpha=1.0, fit_prior=True, score=0.704412, total=   0.4s\n",
      "[CV] alpha=1.0, fit_prior=False ......................................\n",
      "[CV] ........ alpha=1.0, fit_prior=True, score=0.768092, total=   0.4s\n",
      "[CV] alpha=1.0, fit_prior=False ......................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  20 out of  24 | elapsed:    5.6s remaining:    1.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ........ alpha=1.0, fit_prior=True, score=0.768343, total=   0.4s\n",
      "[CV] alpha=1.0, fit_prior=False ......................................\n",
      "[CV] ....... alpha=1.0, fit_prior=False, score=0.700873, total=   0.4s\n",
      "[CV] ....... alpha=1.0, fit_prior=False, score=0.768012, total=   0.4s\n",
      "[CV] ....... alpha=1.0, fit_prior=False, score=0.768308, total=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  24 out of  24 | elapsed:    6.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid Search took 7.40813994408 seconds to run\n",
      "\n",
      " Best estimator was MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True) \n",
      "\n",
      "\n",
      " Best estimator was 0.746948151621 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/juan/mfixman/venv/local/lib/python2.7/site-packages/sklearn/model_selection/_search.py:667: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n",
      "/home/juan/mfixman/venv/local/lib/python2.7/site-packages/sklearn/model_selection/_search.py:667: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n",
      "/home/juan/mfixman/venv/local/lib/python2.7/site-packages/sklearn/model_selection/_search.py:667: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n",
      "/home/juan/mfixman/venv/local/lib/python2.7/site-packages/sklearn/model_selection/_search.py:667: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n",
      "/home/juan/mfixman/venv/local/lib/python2.7/site-packages/sklearn/model_selection/_search.py:667: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n",
      "/home/juan/mfixman/venv/local/lib/python2.7/site-packages/sklearn/model_selection/_search.py:667: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n",
      "/home/juan/mfixman/venv/local/lib/python2.7/site-packages/sklearn/model_selection/_search.py:667: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n",
      "/home/juan/mfixman/venv/local/lib/python2.7/site-packages/sklearn/model_selection/_search.py:667: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n",
      "/home/juan/mfixman/venv/local/lib/python2.7/site-packages/sklearn/model_selection/_search.py:667: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n",
      "/home/juan/mfixman/venv/local/lib/python2.7/site-packages/sklearn/model_selection/_search.py:667: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n",
      "/home/juan/mfixman/venv/local/lib/python2.7/site-packages/sklearn/model_selection/_search.py:667: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n",
      "/home/juan/mfixman/venv/local/lib/python2.7/site-packages/sklearn/model_selection/_search.py:667: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n",
      "/home/juan/mfixman/venv/local/lib/python2.7/site-packages/sklearn/model_selection/_search.py:667: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n",
      "/home/juan/mfixman/venv/local/lib/python2.7/site-packages/sklearn/model_selection/_search.py:667: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n",
      "/home/juan/mfixman/venv/local/lib/python2.7/site-packages/sklearn/model_selection/_search.py:667: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n",
      "/home/juan/mfixman/venv/local/lib/python2.7/site-packages/sklearn/model_selection/_search.py:667: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n",
      "/home/juan/mfixman/venv/local/lib/python2.7/site-packages/sklearn/model_selection/_search.py:667: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n",
      "/home/juan/mfixman/venv/local/lib/python2.7/site-packages/sklearn/model_selection/_search.py:667: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.86      0.85      0.86      9114\n",
      "       True       0.21      0.22      0.21      1644\n",
      "\n",
      "avg / total       0.76      0.76      0.76     10758\n",
      "\n",
      "CPU times: user 6.43 s, sys: 628 ms, total: 7.06 s\n",
      "Wall time: 7.73 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "start_time = time.time()\n",
    "param_grid = {\n",
    "    'alpha':[\n",
    "        1e-3,\n",
    "        1e-1,\n",
    "        1e1,\n",
    "        1e0\n",
    "            ], \n",
    "    'fit_prior': [\n",
    "        True,\n",
    "        False\n",
    "                ],\n",
    "             }\n",
    "\n",
    "mnb  = MultinomialNB( )\n",
    "\n",
    "clf = GridSearchCV(mnb, param_grid, scoring='f1_weighted', fit_params=None, n_jobs=-1, iid=True, refit=True, \n",
    "verbose=3, pre_dispatch='2*n_jobs', error_score='raise')\n",
    "\n",
    "clf2 = MultinomialNB( )\n",
    "#how many parameters to randomly search for\n",
    "#n_iter_search = 45\n",
    "\n",
    "#random_search = RandomizedSearchCV(rforest, param_distributions=param_grid,\n",
    "                                 #  n_iter=n_iter_search, n_jobs =8, verbose=3)\n",
    "\n",
    "elapsed_time =  time.time() - start_time\n",
    "\n",
    "#Y = categorical(train_table_target.values, drop=True).astype(int)\n",
    "\n",
    "clf.fit(X,Y)\n",
    "\n",
    "elapsed_time =   time.time() - start_time \n",
    "\n",
    "print('Grid Search took %s seconds to run' % (elapsed_time))\n",
    "\n",
    "cv_result = pd.DataFrame(columns=['mean_score' ] + [key for key, value in clf.grid_scores_[0].parameters.items() ] )\n",
    "i=0\n",
    "for setup in clf.grid_scores_:\n",
    "    row = [clf.grid_scores_[i].mean_validation_score ] + [value for key, value in clf.grid_scores_[i].parameters.items() ]\n",
    "    cv_result.loc[i] = row\n",
    "    i+=1\n",
    "\n",
    "\n",
    "#este flag es basicamente para chequear que hayamos terminado nomas\n",
    "finished = True\n",
    "\n",
    "print('\\n Best estimator was %s \\n' % str(clf.best_estimator_))\n",
    "print('\\n Best estimator was %s \\n' % str(clf.best_score_))\n",
    "\n",
    "clf2.set_params(**clf.best_params_)\n",
    "\n",
    "clf2.fit(X,Y)\n",
    "\n",
    "\n",
    "#converted_dict = evaluation_print(clf, X_val, test_table_target.values, test_table.index.values, \n",
    "#                              test_table_target[test_table_target>0].index.values,start_date,future)\n",
    "\n",
    "print(classification_report(Y_val,clf2.predict(X_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.53569666623418843"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(Y_val,clf2.predict(X_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((94908,), 14294, {'alpha': 1.0, 'fit_prior': True})"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape, Y.sum(), clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15281650864472951"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_val.sum()*1.0/Y_val.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.53569666623418843"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(Y_val,clf2.predict(X_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.001</th>\n",
       "      <td>0.746343</td>\n",
       "      <td>0.000844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.100</th>\n",
       "      <td>0.746343</td>\n",
       "      <td>0.000844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.000</th>\n",
       "      <td>0.746339</td>\n",
       "      <td>0.000861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10.000</th>\n",
       "      <td>0.746280</td>\n",
       "      <td>0.000868</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            mean       std\n",
       "alpha                     \n",
       "0.001   0.746343  0.000844\n",
       "0.100   0.746343  0.000844\n",
       "1.000   0.746339  0.000861\n",
       "10.000  0.746280  0.000868"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fit_prior</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>0.745722</td>\n",
       "      <td>0.000038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>0.746931</td>\n",
       "      <td>0.000025</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               mean       std\n",
       "fit_prior                    \n",
       "False      0.745722  0.000038\n",
       "True       0.746931  0.000025"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for col in cv_result.columns:\n",
    "    if col != 'mean_score':\n",
    "        df = cv_result.groupby(col)['mean_score'].mean().to_frame().copy()\n",
    "        df.columns = ['mean']\n",
    "        df['std'] = cv_result.groupby(col)['mean_score'].std()\n",
    "\n",
    "        display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " 'EPIDEMIC' in X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## now graphlab models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from graphlab import random_forest_classifier, boosted_trees_classifier, logistic_classifier, decision_tree_classifier\n",
    "from graphlab.toolkits import cross_validation, model_parameter_search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get kfolds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.18 s, sys: 460 ms, total: 6.64 s\n",
      "Wall time: 4.64 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "num_folds = 10\n",
    "\n",
    "target_col = 'target'\n",
    "if graphlab_frame:   \n",
    "    X[target_col] = Y\n",
    "    X_val[target_col] = Y_val\n",
    "    kfold = cross_validation.KFold(\n",
    "    X,num_folds=num_folds)\n",
    "else:\n",
    "    X_gl= gl.SFrame(X)\n",
    "    Y_gl = gl.SArray(Y)\n",
    "    X_val_gl= gl.SFrame(X_val)\n",
    "    Y_val_gl = gl.SArray(Y_val)\n",
    "    X_gl[target_col] = Y_gl\n",
    "    X_val_gl[target_col] = Y_val_gl\n",
    "    \n",
    "    kfold = cross_validation.KFold(\n",
    "    X_gl,num_folds=num_folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'target' in X_gl.column_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandomForest \n",
    "HyperParams Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "param_grid = {\n",
    "    \"target\":target_col,\n",
    "    \n",
    "    'metric': [\n",
    "                'auc',\n",
    "#                 'log_loss',\n",
    "                 ], \n",
    "    \n",
    "    'max_iterations': [\n",
    "#                     50,\n",
    "                    100,\n",
    "                    150,\n",
    "                    200,\n",
    "                    ],\n",
    "    \n",
    "  'column_subsample': [\n",
    "                  pd.np.sqrt(X_gl.shape[1])/X_gl.shape[1],\n",
    "                  pd.np.log2(X_gl.shape[1])/X_gl.shape[1],\n",
    "                  0.5,\n",
    "#                   0.1,\n",
    "                  ], \n",
    "#     \"bootstrap\": [ \n",
    "#                 False,\n",
    "#                 True,\n",
    "#                     ],\n",
    "#     \"min_child_weight\": pd.np.append(pd.np.random.randint(3,15,3),[3]),\n",
    "    'max_depth':[\n",
    "#                  3,\n",
    "                 6,\n",
    "                 9,\n",
    "                 12,\n",
    "                ], \n",
    "   \"class_weights\": [\n",
    "#                    'balanced',\n",
    "                   None,\n",
    "                   ],\n",
    "#     \"validation_set\": X_val_gl,\n",
    "              }\n",
    "\n",
    "model_factory = random_forest_classifier.create"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] graphlab.deploy.job: Validating job.\n",
      "[INFO] graphlab.deploy.job: Creating a LocalAsync environment called 'async'.\n",
      "[INFO] graphlab.deploy.map_job: Validation complete. Job: 'Model-Parameter-Search-May-28-2017-04-13-5100000' ready for execution\n",
      "[INFO] graphlab.deploy.map_job: Job: 'Model-Parameter-Search-May-28-2017-04-13-5100000' scheduled.\n",
      "[INFO] graphlab.deploy.job: Validating job.\n",
      "[INFO] graphlab.deploy.map_job: A job with name 'Model-Parameter-Search-May-28-2017-04-13-5100000' already exists. Renaming the job to 'Model-Parameter-Search-May-28-2017-04-13-5100000-62725'.\n",
      "[INFO] graphlab.deploy.map_job: Validation complete. Job: 'Model-Parameter-Search-May-28-2017-04-13-5100000-62725' ready for execution\n",
      "[INFO] graphlab.deploy.map_job: Job: 'Model-Parameter-Search-May-28-2017-04-13-5100000-62725' scheduled.\n",
      "[INFO] graphlab.deploy.job: Validating job.\n",
      "[INFO] graphlab.deploy.map_job: Validation complete. Job: 'Model-Parameter-Search-May-28-2017-04-13-5100001' ready for execution\n",
      "[INFO] graphlab.deploy.map_job: Job: 'Model-Parameter-Search-May-28-2017-04-13-5100001' scheduled.\n",
      "[INFO] graphlab.deploy.job: Validating job.\n",
      "[INFO] graphlab.deploy.map_job: Validation complete. Job: 'Model-Parameter-Search-May-28-2017-04-13-5100002' ready for execution\n",
      "[INFO] graphlab.deploy.map_job: Job: 'Model-Parameter-Search-May-28-2017-04-13-5100002' scheduled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 36s, sys: 8.24 s, total: 1min 44s\n",
      "Wall time: 1h 7min 3s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "start_time = time.time()\n",
    "model_search = model_parameter_search.create( datasets = kfold, \n",
    "                                             #[data, val_set],\n",
    "                                             model_factory = model_factory,\n",
    "                                            model_parameters = param_grid, \n",
    "                                             perform_trial_run = True,\n",
    "                                            )\n",
    "\n",
    "search_results = model_search.get_results()\n",
    "\n",
    "all_time = time.time() - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 7.054373967647551)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(abs(all_time)/3600) ,(abs(all_time)/3600 %1)*60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\"><table frame=\"box\" rules=\"cols\">\n",
       "    <tr>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">task_name</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">status</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">start_time</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">run_time</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">exception</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">exception_message</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">exception_traceback</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">_train_test_model-0-0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Completed</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2017-05-28 04:15:38</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">142.217834949</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">_train_test_model-0-1</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Completed</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2017-05-28 04:18:00</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">147.120588064</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">_train_test_model-0-2</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Completed</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2017-05-28 04:20:28</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">143.171838999</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">_train_test_model-0-3</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Completed</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2017-05-28 04:22:51</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">142.518718958</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">_train_test_model-0-4</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Completed</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2017-05-28 04:25:13</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">144.32323885</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">_train_test_model-0-5</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Completed</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2017-05-28 04:27:38</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">143.988962889</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">_train_test_model-0-6</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Completed</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2017-05-28 04:30:02</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">148.018715143</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">_train_test_model-0-7</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Completed</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2017-05-28 04:32:30</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">145.34139204</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">_train_test_model-0-8</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Completed</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2017-05-28 04:34:55</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">143.07583499</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">_train_test_model-0-9</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Completed</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2017-05-28 04:37:19</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">138.991053104</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "    </tr>\n",
       "</table>\n",
       "<table frame=\"box\" rules=\"cols\">\n",
       "    <tr>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">job_name</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Model-Parameter-Search-Ma<br>y-28-2017-04-13-51000 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Model-Parameter-Search-Ma<br>y-28-2017-04-13-51000 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Model-Parameter-Search-Ma<br>y-28-2017-04-13-51000 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Model-Parameter-Search-Ma<br>y-28-2017-04-13-51000 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Model-Parameter-Search-Ma<br>y-28-2017-04-13-51000 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Model-Parameter-Search-Ma<br>y-28-2017-04-13-51000 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Model-Parameter-Search-Ma<br>y-28-2017-04-13-51000 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Model-Parameter-Search-Ma<br>y-28-2017-04-13-51000 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Model-Parameter-Search-Ma<br>y-28-2017-04-13-51000 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Model-Parameter-Search-Ma<br>y-28-2017-04-13-51000 ...</td>\n",
       "    </tr>\n",
       "</table>\n",
       "[35 rows x 8 columns]<br/>Note: Only the head of the SFrame is printed.<br/>You can use print_rows(num_rows=m, num_columns=n) to print more rows and columns.\n",
       "</div>"
      ],
      "text/plain": [
       "Columns:\n",
       "\ttask_name\tstr\n",
       "\tstatus\tstr\n",
       "\tstart_time\tstr\n",
       "\trun_time\tfloat\n",
       "\texception\tfloat\n",
       "\texception_message\tfloat\n",
       "\texception_traceback\tfloat\n",
       "\tjob_name\tstr\n",
       "\n",
       "Rows: 35\n",
       "\n",
       "Data:\n",
       "+-----------------------+-----------+---------------------+---------------+-----------+\n",
       "|       task_name       |   status  |      start_time     |    run_time   | exception |\n",
       "+-----------------------+-----------+---------------------+---------------+-----------+\n",
       "| _train_test_model-0-0 | Completed | 2017-05-28 04:15:38 | 142.217834949 |    None   |\n",
       "| _train_test_model-0-1 | Completed | 2017-05-28 04:18:00 | 147.120588064 |    None   |\n",
       "| _train_test_model-0-2 | Completed | 2017-05-28 04:20:28 | 143.171838999 |    None   |\n",
       "| _train_test_model-0-3 | Completed | 2017-05-28 04:22:51 | 142.518718958 |    None   |\n",
       "| _train_test_model-0-4 | Completed | 2017-05-28 04:25:13 |  144.32323885 |    None   |\n",
       "| _train_test_model-0-5 | Completed | 2017-05-28 04:27:38 | 143.988962889 |    None   |\n",
       "| _train_test_model-0-6 | Completed | 2017-05-28 04:30:02 | 148.018715143 |    None   |\n",
       "| _train_test_model-0-7 | Completed | 2017-05-28 04:32:30 |  145.34139204 |    None   |\n",
       "| _train_test_model-0-8 | Completed | 2017-05-28 04:34:55 |  143.07583499 |    None   |\n",
       "| _train_test_model-0-9 | Completed | 2017-05-28 04:37:19 | 138.991053104 |    None   |\n",
       "+-----------------------+-----------+---------------------+---------------+-----------+\n",
       "+-------------------+---------------------+-------------------------------+\n",
       "| exception_message | exception_traceback |            job_name           |\n",
       "+-------------------+---------------------+-------------------------------+\n",
       "|        None       |         None        | Model-Parameter-Search-May... |\n",
       "|        None       |         None        | Model-Parameter-Search-May... |\n",
       "|        None       |         None        | Model-Parameter-Search-May... |\n",
       "|        None       |         None        | Model-Parameter-Search-May... |\n",
       "|        None       |         None        | Model-Parameter-Search-May... |\n",
       "|        None       |         None        | Model-Parameter-Search-May... |\n",
       "|        None       |         None        | Model-Parameter-Search-May... |\n",
       "|        None       |         None        | Model-Parameter-Search-May... |\n",
       "|        None       |         None        | Model-Parameter-Search-May... |\n",
       "|        None       |         None        | Model-Parameter-Search-May... |\n",
       "+-------------------+---------------------+-------------------------------+\n",
       "[35 rows x 8 columns]\n",
       "Note: Only the head of the SFrame is printed.\n",
       "You can use print_rows(num_rows=m, num_columns=n) to print more rows and columns."
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = model_search.get_metrics()\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 14)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_results.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-----------------+----------------+\n",
      "| class_weights |       std       |      mean      |\n",
      "+---------------+-----------------+----------------+\n",
      "|      None     | 0.0159401641879 | 0.889271322173 |\n",
      "+---------------+-----------------+----------------+\n",
      "[1 rows x 3 columns]\n",
      "\n",
      "+------------------+------------------+----------------+\n",
      "| column_subsample |       std        |      mean      |\n",
      "+------------------+------------------+----------------+\n",
      "| 0.0421898618649  |       0.0        | 0.862865681399 |\n",
      "|       0.5        | 0.0127577258664  | 0.900803623544 |\n",
      "| 0.0751646028003  | 0.00549159509322 | 0.881457355654 |\n",
      "+------------------+------------------+----------------+\n",
      "[3 rows x 3 columns]\n",
      "\n",
      "+-----------+----------------+----------------+\n",
      "| max_depth |      std       |      mean      |\n",
      "+-----------+----------------+----------------+\n",
      "|     6     |      0.0       | 0.884267236348 |\n",
      "|     12    | 0.016513145653 | 0.896034414326 |\n",
      "|     9     | 0.013381018859 | 0.882068478439 |\n",
      "+-----------+----------------+----------------+\n",
      "[3 rows x 3 columns]\n",
      "\n",
      "+----------------+------------------+----------------+\n",
      "| max_iterations |       std        |      mean      |\n",
      "+----------------+------------------+----------------+\n",
      "|      200       | 0.0139737979744  | 0.89786836637  |\n",
      "|      150       | 0.00240040371231 | 0.880879114037 |\n",
      "|      100       |       0.0        | 0.862865681399 |\n",
      "+----------------+------------------+----------------+\n",
      "[3 rows x 3 columns]\n",
      "\n",
      "+--------+-----------------+----------------+\n",
      "| metric |       std       |      mean      |\n",
      "+--------+-----------------+----------------+\n",
      "|  auc   | 0.0159401641879 | 0.889271322173 |\n",
      "+--------+-----------------+----------------+\n",
      "[1 rows x 3 columns]\n",
      "\n",
      "+------------------+------------------+----------------+\n",
      "| min_child_weight |       std        |      mean      |\n",
      "+------------------+------------------+----------------+\n",
      "|        2         |       0.0        | 0.913250916392 |\n",
      "|        16        |       0.0        | 0.862865681399 |\n",
      "|        8         | 0.00119880686648 | 0.87834395648  |\n",
      "|        1         | 0.0128187286724  | 0.896103873363 |\n",
      "|        4         |       0.0        | 0.897149261049 |\n",
      "+------------------+------------------+----------------+\n",
      "[5 rows x 3 columns]\n",
      "\n",
      "+--------------------+------------------+----------------+\n",
      "| min_loss_reduction |       std        |      mean      |\n",
      "+--------------------+------------------+----------------+\n",
      "|         10         | 0.0143657631155  | 0.877231444514 |\n",
      "|         0          | 0.00834433680765 | 0.88599408139  |\n",
      "|         1          | 0.0171099202572  | 0.898568501786 |\n",
      "+--------------------+------------------+----------------+\n",
      "[3 rows x 3 columns]\n",
      "\n",
      "+---------------+------------------+----------------+\n",
      "| row_subsample |       std        |      mean      |\n",
      "+---------------+------------------+----------------+\n",
      "|      0.9      | 0.0209762076874  | 0.892265882188 |\n",
      "|      1.0      | 0.00708813094983 | 0.886276762158 |\n",
      "+---------------+------------------+----------------+\n",
      "[2 rows x 3 columns]\n",
      "\n",
      "+--------+-----------------+----------------+\n",
      "| target |       std       |      mean      |\n",
      "+--------+-----------------+----------------+\n",
      "| target | 0.0159401641879 | 0.889271322173 |\n",
      "+--------+-----------------+----------------+\n",
      "[1 rows x 3 columns]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for col in [col for col in search_results.column_names() if \\\n",
    "            not('accuracy' in col) and col!= 'model_id' and col!= 'random_seed' and col!= 'fold_id' \\\n",
    "                               and col!= 'num_folds']:\n",
    "    print(search_results.groupby(col,\n",
    "                             {'mean':gl.aggregate.MEAN('mean_training_accuracy'),\n",
    "                                'std':gl.aggregate.STD('mean_training_accuracy')}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Refit best model for feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 'currently non_endemic, that used to live in the endemic area')"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "case, case_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = model_search.get_best_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'class_weights': None,\n",
       " 'column_subsample': 0.5,\n",
       " 'max_depth': 12,\n",
       " 'max_iterations': 200,\n",
       " 'metric': 'auc',\n",
       " 'min_child_weight': 1,\n",
       " 'min_loss_reduction': 1,\n",
       " 'row_subsample': 0.9,\n",
       " 'target': 'target'}"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ## manually insert params if needed\n",
    "params = {'class_weights': None,\n",
    " 'column_subsample': 0.5,\n",
    " 'max_depth': 12,\n",
    " 'max_iterations': 200,\n",
    " 'metric': 'auc',\n",
    " 'min_child_weight': 1,\n",
    " 'min_loss_reduction': 1,\n",
    " 'row_subsample': 0.9,\n",
    " 'target': 'target'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre>Random forest classifier:</pre>"
      ],
      "text/plain": [
       "Random forest classifier:"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>--------------------------------------------------------</pre>"
      ],
      "text/plain": [
       "--------------------------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of examples          : 95180</pre>"
      ],
      "text/plain": [
       "Number of examples          : 95180"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of classes           : 2</pre>"
      ],
      "text/plain": [
       "Number of classes           : 2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of feature columns   : 176</pre>"
      ],
      "text/plain": [
       "Number of feature columns   : 176"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of unpacked features : 176</pre>"
      ],
      "text/plain": [
       "Number of unpacked features : 176"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>+-----------+--------------+--------------+----------------+</pre>"
      ],
      "text/plain": [
       "+-----------+--------------+--------------+----------------+"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| Iteration | Elapsed Time | Training-auc | Validation-auc |</pre>"
      ],
      "text/plain": [
       "| Iteration | Elapsed Time | Training-auc | Validation-auc |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>+-----------+--------------+--------------+----------------+</pre>"
      ],
      "text/plain": [
       "+-----------+--------------+--------------+----------------+"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 1         | 0.652321     | 0.887324     | 0.857103       |</pre>"
      ],
      "text/plain": [
       "| 1         | 0.652321     | 0.887324     | 0.857103       |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 2         | 1.246490     | 0.901957     | 0.867521       |</pre>"
      ],
      "text/plain": [
       "| 2         | 1.246490     | 0.901957     | 0.867521       |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 3         | 1.806583     | 0.905375     | 0.872422       |</pre>"
      ],
      "text/plain": [
       "| 3         | 1.806583     | 0.905375     | 0.872422       |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 4         | 2.413643     | 0.907046     | 0.874334       |</pre>"
      ],
      "text/plain": [
       "| 4         | 2.413643     | 0.907046     | 0.874334       |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 5         | 2.997941     | 0.907899     | 0.877066       |</pre>"
      ],
      "text/plain": [
       "| 5         | 2.997941     | 0.907899     | 0.877066       |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 6         | 3.560141     | 0.909016     | 0.877600       |</pre>"
      ],
      "text/plain": [
       "| 6         | 3.560141     | 0.909016     | 0.877600       |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 10        | 5.866732     | 0.910702     | 0.878135       |</pre>"
      ],
      "text/plain": [
       "| 10        | 5.866732     | 0.910702     | 0.878135       |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 11        | 6.437765     | 0.911047     | 0.878510       |</pre>"
      ],
      "text/plain": [
       "| 11        | 6.437765     | 0.911047     | 0.878510       |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 15        | 8.785547     | 0.910084     | 0.878787       |</pre>"
      ],
      "text/plain": [
       "| 15        | 8.785547     | 0.910084     | 0.878787       |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 20        | 11.807212    | 0.909904     | 0.878865       |</pre>"
      ],
      "text/plain": [
       "| 20        | 11.807212    | 0.909904     | 0.878865       |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 25        | 14.744240    | 0.910098     | 0.879282       |</pre>"
      ],
      "text/plain": [
       "| 25        | 14.744240    | 0.910098     | 0.879282       |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 30        | 17.685828    | 0.910600     | 0.879573       |</pre>"
      ],
      "text/plain": [
       "| 30        | 17.685828    | 0.910600     | 0.879573       |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 35        | 20.626458    | 0.910753     | 0.879844       |</pre>"
      ],
      "text/plain": [
       "| 35        | 20.626458    | 0.910753     | 0.879844       |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 40        | 23.548323    | 0.911700     | 0.880033       |</pre>"
      ],
      "text/plain": [
       "| 40        | 23.548323    | 0.911700     | 0.880033       |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 45        | 26.465986    | 0.911888     | 0.880170       |</pre>"
      ],
      "text/plain": [
       "| 45        | 26.465986    | 0.911888     | 0.880170       |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 50        | 29.398379    | 0.911304     | 0.880063       |</pre>"
      ],
      "text/plain": [
       "| 50        | 29.398379    | 0.911304     | 0.880063       |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 51        | 29.978672    | 0.911127     | 0.879940       |</pre>"
      ],
      "text/plain": [
       "| 51        | 29.978672    | 0.911127     | 0.879940       |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 55        | 32.421343    | 0.911586     | 0.880214       |</pre>"
      ],
      "text/plain": [
       "| 55        | 32.421343    | 0.911586     | 0.880214       |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 60        | 35.351890    | 0.911719     | 0.880223       |</pre>"
      ],
      "text/plain": [
       "| 60        | 35.351890    | 0.911719     | 0.880223       |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 65        | 38.301109    | 0.911431     | 0.880264       |</pre>"
      ],
      "text/plain": [
       "| 65        | 38.301109    | 0.911431     | 0.880264       |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 70        | 41.233651    | 0.911672     | 0.880431       |</pre>"
      ],
      "text/plain": [
       "| 70        | 41.233651    | 0.911672     | 0.880431       |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 75        | 44.202491    | 0.911783     | 0.880531       |</pre>"
      ],
      "text/plain": [
       "| 75        | 44.202491    | 0.911783     | 0.880531       |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 80        | 47.131820    | 0.911876     | 0.880787       |</pre>"
      ],
      "text/plain": [
       "| 80        | 47.131820    | 0.911876     | 0.880787       |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 85        | 50.115690    | 0.911692     | 0.880654       |</pre>"
      ],
      "text/plain": [
       "| 85        | 50.115690    | 0.911692     | 0.880654       |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 90        | 53.037312    | 0.911642     | 0.880638       |</pre>"
      ],
      "text/plain": [
       "| 90        | 53.037312    | 0.911642     | 0.880638       |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 95        | 55.982949    | 0.911761     | 0.880594       |</pre>"
      ],
      "text/plain": [
       "| 95        | 55.982949    | 0.911761     | 0.880594       |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 100       | 58.942501    | 0.911896     | 0.880770       |</pre>"
      ],
      "text/plain": [
       "| 100       | 58.942501    | 0.911896     | 0.880770       |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 101       | 59.543678    | 0.911917     | 0.880809       |</pre>"
      ],
      "text/plain": [
       "| 101       | 59.543678    | 0.911917     | 0.880809       |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 105       | 61.956159    | 0.912024     | 0.880812       |</pre>"
      ],
      "text/plain": [
       "| 105       | 61.956159    | 0.912024     | 0.880812       |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 110       | 64.997207    | 0.912055     | 0.880836       |</pre>"
      ],
      "text/plain": [
       "| 110       | 64.997207    | 0.912055     | 0.880836       |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 115       | 68.007296    | 0.912050     | 0.880840       |</pre>"
      ],
      "text/plain": [
       "| 115       | 68.007296    | 0.912050     | 0.880840       |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 120       | 70.928535    | 0.912091     | 0.880870       |</pre>"
      ],
      "text/plain": [
       "| 120       | 70.928535    | 0.912091     | 0.880870       |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 125       | 73.922047    | 0.912097     | 0.880861       |</pre>"
      ],
      "text/plain": [
       "| 125       | 73.922047    | 0.912097     | 0.880861       |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 130       | 76.888999    | 0.912162     | 0.880940       |</pre>"
      ],
      "text/plain": [
       "| 130       | 76.888999    | 0.912162     | 0.880940       |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 135       | 79.867156    | 0.912198     | 0.880969       |</pre>"
      ],
      "text/plain": [
       "| 135       | 79.867156    | 0.912198     | 0.880969       |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 140       | 82.805333    | 0.912126     | 0.880958       |</pre>"
      ],
      "text/plain": [
       "| 140       | 82.805333    | 0.912126     | 0.880958       |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 145       | 85.773335    | 0.912173     | 0.880983       |</pre>"
      ],
      "text/plain": [
       "| 145       | 85.773335    | 0.912173     | 0.880983       |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 150       | 88.706009    | 0.912145     | 0.880899       |</pre>"
      ],
      "text/plain": [
       "| 150       | 88.706009    | 0.912145     | 0.880899       |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 155       | 91.627645    | 0.912177     | 0.880941       |</pre>"
      ],
      "text/plain": [
       "| 155       | 91.627645    | 0.912177     | 0.880941       |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 160       | 94.561862    | 0.912095     | 0.880943       |</pre>"
      ],
      "text/plain": [
       "| 160       | 94.561862    | 0.912095     | 0.880943       |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 165       | 97.539032    | 0.912132     | 0.880898       |</pre>"
      ],
      "text/plain": [
       "| 165       | 97.539032    | 0.912132     | 0.880898       |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 170       | 100.415218   | 0.912055     | 0.880924       |</pre>"
      ],
      "text/plain": [
       "| 170       | 100.415218   | 0.912055     | 0.880924       |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 175       | 103.342166   | 0.912047     | 0.881013       |</pre>"
      ],
      "text/plain": [
       "| 175       | 103.342166   | 0.912047     | 0.881013       |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 180       | 106.324004   | 0.912119     | 0.881047       |</pre>"
      ],
      "text/plain": [
       "| 180       | 106.324004   | 0.912119     | 0.881047       |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 185       | 109.276733   | 0.912126     | 0.881056       |</pre>"
      ],
      "text/plain": [
       "| 185       | 109.276733   | 0.912126     | 0.881056       |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 190       | 112.230811   | 0.912185     | 0.881136       |</pre>"
      ],
      "text/plain": [
       "| 190       | 112.230811   | 0.912185     | 0.881136       |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 195       | 115.117248   | 0.912165     | 0.881090       |</pre>"
      ],
      "text/plain": [
       "| 195       | 115.117248   | 0.912165     | 0.881090       |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 200       | 118.090183   | 0.912192     | 0.881041       |</pre>"
      ],
      "text/plain": [
       "| 200       | 118.090183   | 0.912192     | 0.881041       |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>+-----------+--------------+--------------+----------------+</pre>"
      ],
      "text/plain": [
       "+-----------+--------------+--------------+----------------+"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9min 30s, sys: 17.7 s, total: 9min 48s\n",
      "Wall time: 2min 9s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "best_model =  random_forest_classifier.create(dataset=X_gl,\n",
    "                                             validation_set = X_val_gl,\n",
    "                                             **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\"><table frame=\"box\" rules=\"cols\">\n",
       "    <tr>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">name</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">index</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">MOBILITY_DIAMETER</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">7950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">COUNT_0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">7009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">COUNT_WEEKNIGHT_0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">6912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">MOBILITY_DIAMETER_WEEKNIG<br>HT ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">6333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">COUNT_1</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">4335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">COUNT_2</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">3925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">COUNT_WEEKNIGHT_1</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">COUNT_3</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">TimeWeekDay_OUT_08</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">TimeWeekDay_OUT_12</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2482</td>\n",
       "    </tr>\n",
       "</table>\n",
       "[20 rows x 3 columns]<br/>Note: Only the head of the SFrame is printed.<br/>You can use print_rows(num_rows=m, num_columns=n) to print more rows and columns.\n",
       "</div>"
      ],
      "text/plain": [
       "Columns:\n",
       "\tname\tstr\n",
       "\tindex\tstr\n",
       "\tcount\tint\n",
       "\n",
       "Rows: 20\n",
       "\n",
       "Data:\n",
       "+-----------------------------+-------+-------+\n",
       "|             name            | index | count |\n",
       "+-----------------------------+-------+-------+\n",
       "|      MOBILITY_DIAMETER      |  None |  7950 |\n",
       "|           COUNT_0           |  None |  7009 |\n",
       "|      COUNT_WEEKNIGHT_0      |  None |  6912 |\n",
       "| MOBILITY_DIAMETER_WEEKNIGHT |  None |  6333 |\n",
       "|           COUNT_1           |  None |  4335 |\n",
       "|           COUNT_2           |  None |  3925 |\n",
       "|      COUNT_WEEKNIGHT_1      |  None |  2844 |\n",
       "|           COUNT_3           |  None |  2687 |\n",
       "|      TimeWeekDay_OUT_08     |  None |  2509 |\n",
       "|      TimeWeekDay_OUT_12     |  None |  2482 |\n",
       "+-----------------------------+-------+-------+\n",
       "[20 rows x 3 columns]\n",
       "Note: Only the head of the SFrame is printed.\n",
       "You can use print_rows(num_rows=m, num_columns=n) to print more rows and columns."
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_feat = best_model.get_feature_importance()\n",
    "best_feat.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# filter_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MOBILITY_DIAMETER',\n",
       " 'COUNT_0',\n",
       " 'COUNT_WEEKNIGHT_0',\n",
       " 'MOBILITY_DIAMETER_WEEKNIGHT',\n",
       " 'COUNT_1',\n",
       " 'COUNT_2',\n",
       " 'COUNT_WEEKNIGHT_1',\n",
       " 'COUNT_3',\n",
       " 'TimeWeekDay_OUT_08',\n",
       " 'TimeWeekDay_OUT_12',\n",
       " 'TimeWeekDay_IN_08',\n",
       " 'COUNT_4',\n",
       " 'COUNT_5',\n",
       " 'TimeWeekDay_IN_09',\n",
       " 'TimeWeekDay_IN_12',\n",
       " 'TimeWeekDay_OUT_09',\n",
       " 'TimeWeekEnd_IN_08',\n",
       " 'TimeWeekDay_OUT_VUL_08',\n",
       " 'CallsWeekDay_OUT_08',\n",
       " 'TimeWeekEnd_OUT_08',\n",
       " 'COUNT_WEEKNIGHT_2',\n",
       " 'COUNT_7',\n",
       " 'CallsWeekDay_OUT_12',\n",
       " 'TimeWeekDay_OUT_11',\n",
       " 'COUNT_6',\n",
       " 'CallsWeekDay_IN_12',\n",
       " 'TimeWeekDay_IN_10',\n",
       " 'TimeWeekDay_OUT_10',\n",
       " 'TimeWeekDay_IN_VUL_08',\n",
       " 'COUNT_8']"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(best_feat['name'].head(30))\n",
    "#print_rows(num_rows= 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "118.09162"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.training_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.8896624070188823,\n",
       " 'auc': 0.8810393712641603,\n",
       " 'confusion_matrix': Columns:\n",
       " \ttarget_label\tint\n",
       " \tpredicted_label\tint\n",
       " \tcount\tint\n",
       " \n",
       " Rows: 4\n",
       " \n",
       " Data:\n",
       " +--------------+-----------------+-------+\n",
       " | target_label | predicted_label | count |\n",
       " +--------------+-----------------+-------+\n",
       " |      0       |        1        |  258  |\n",
       " |      1       |        0        |  899  |\n",
       " |      1       |        1        |  1139 |\n",
       " |      0       |        0        |  8190 |\n",
       " +--------------+-----------------+-------+\n",
       " [4 rows x 3 columns],\n",
       " 'f1_score': 0.6631732168850072,\n",
       " 'log_loss': 0.337038657437402,\n",
       " 'precision': 0.8153185397279885,\n",
       " 'recall': 0.5588812561334642,\n",
       " 'roc_curve': Columns:\n",
       " \tthreshold\tfloat\n",
       " \tfpr\tfloat\n",
       " \ttpr\tfloat\n",
       " \tp\tint\n",
       " \tn\tint\n",
       " \n",
       " Rows: 100001\n",
       " \n",
       " Data:\n",
       " +-----------+-----+-----+------+------+\n",
       " | threshold | fpr | tpr |  p   |  n   |\n",
       " +-----------+-----+-----+------+------+\n",
       " |    0.0    | 1.0 | 1.0 | 2038 | 8448 |\n",
       " |   1e-05   | 1.0 | 1.0 | 2038 | 8448 |\n",
       " |   2e-05   | 1.0 | 1.0 | 2038 | 8448 |\n",
       " |   3e-05   | 1.0 | 1.0 | 2038 | 8448 |\n",
       " |   4e-05   | 1.0 | 1.0 | 2038 | 8448 |\n",
       " |   5e-05   | 1.0 | 1.0 | 2038 | 8448 |\n",
       " |   6e-05   | 1.0 | 1.0 | 2038 | 8448 |\n",
       " |   7e-05   | 1.0 | 1.0 | 2038 | 8448 |\n",
       " |   8e-05   | 1.0 | 1.0 | 2038 | 8448 |\n",
       " |   9e-05   | 1.0 | 1.0 | 2038 | 8448 |\n",
       " +-----------+-----+-----+------+------+\n",
       " [100001 rows x 5 columns]\n",
       " Note: Only the head of the SFrame is printed.\n",
       " You can use print_rows(num_rows=m, num_columns=n) to print more rows and columns.}"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_error = best_model.evaluate(X_val_gl)\n",
    "\n",
    "test_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method RandomForestClassifier.get_current_options of Class                          : RandomForestClassifier\n",
       "\n",
       "Schema\n",
       "------\n",
       "Number of examples             : 95180\n",
       "Number of feature columns      : 176\n",
       "Number of unpacked features    : 176\n",
       "Number of classes              : 2\n",
       "\n",
       "Settings\n",
       "--------\n",
       "Number of trees                : 200\n",
       "Max tree depth                 : 12\n",
       "Training time (sec)            : 118.0916\n",
       "Training auc                   : 0.9122\n",
       "Validation auc                 : 0.881\n",
       ">"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.get_current_options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boosted Classifier\n",
    "### HyperParams search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Boosted Trees HyperParams\n",
    "\n",
    "# target_col = 'Y'\n",
    "\n",
    "params = {\n",
    "    'target': target_col, ## the target column string name \n",
    "    'max_iterations': [\n",
    "                      200,\n",
    "                       250,\n",
    "#                        90,\n",
    "#                        120,\n",
    "                    300,\n",
    "                      ], #The maximum number of iterations for boosting. Each iteration == extra tree.\n",
    "    'class_weights': [\n",
    "                      None, \n",
    "#                       'auto',\n",
    "    ], #Weights the examples in the training data according to the given class weights.\n",
    "#     'class_weights': [None],\n",
    "    'max_depth': [\n",
    "#         2,\n",
    "#         3,\n",
    "        4,\n",
    "#         6,\n",
    "        9,\n",
    "        15,\n",
    "        20,\n",
    "    ], #Maximum depth of a tree. Must be at least 1.\n",
    "    'step_size': [\n",
    "        1e-1,\n",
    "        0.5,\n",
    "        1e-2,\n",
    "        1,\n",
    "    ], # Step size (shrinkage) used in update to prevents overfitting\n",
    "    'min_loss_reduction': [\n",
    "#         1e-2,\n",
    "        1,\n",
    "        10,\n",
    "    ], #Minimum loss reduction required to make a further partition/split a node during the tree learning\n",
    "    'min_child_weight': [\n",
    "#         1e-2,\n",
    "        2,\n",
    "        5,\n",
    "        10,\n",
    "    ], # Controls the minimum weight of each leaf node . larger values > less overfitting\n",
    "    'row_subsample': [\n",
    "        0.5,\n",
    "        0.75,\n",
    "    ], #Subsample the ratio of the training set in each iteration of tree construction\n",
    "    \n",
    "    'column_subsample': [\n",
    "#         0.01,\n",
    "        0.1,\n",
    "        0.05,\n",
    "        0.8,\n",
    "                        ], # Subsample the ratio of the columns in each iteration of tree construction\n",
    "    #'metric': ['accuracy', 'auc', 'f1_score','recall','precision'], # Performance metric(s) that are tracked during training     \n",
    "    'metric': ['auc'],\n",
    "    'random_seed' : int(abs(hash('im not joking...'))%1e6) \n",
    "}\n",
    "\n",
    "model_factory = boosted_trees_classifier.create"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose if we want to use random forest's top features result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_cols = 30\n",
    "\n",
    "top_rf_features = False\n",
    "# top_rf_features = None\n",
    "\n",
    "if top_rf_features:\n",
    "    filter_cols = list(best_feat['name'].head(n_cols).to_numpy()) + [target_col]\n",
    "\n",
    "    X_val_gl = X_val_gl[filter_cols]\n",
    "    X_gl = X_gl[filter_cols]\n",
    "    \n",
    "    kfold = cross_validation.KFold(\n",
    "    X_gl,num_folds=num_folds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search Boosted "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] graphlab.deploy.job: Validating job.\n",
      "[INFO] graphlab.deploy.map_job: Validation complete. Job: 'Model-Parameter-Search-May-28-2017-05-23-0800000' ready for execution\n",
      "[INFO] graphlab.deploy.map_job: Job: 'Model-Parameter-Search-May-28-2017-05-23-0800000' scheduled.\n",
      "[INFO] graphlab.deploy.job: Validating job.\n",
      "[INFO] graphlab.deploy.map_job: A job with name 'Model-Parameter-Search-May-28-2017-05-23-0800000' already exists. Renaming the job to 'Model-Parameter-Search-May-28-2017-05-23-0800000-804e5'.\n",
      "[INFO] graphlab.deploy.map_job: Validation complete. Job: 'Model-Parameter-Search-May-28-2017-05-23-0800000-804e5' ready for execution\n",
      "[INFO] graphlab.deploy.map_job: Job: 'Model-Parameter-Search-May-28-2017-05-23-0800000-804e5' scheduled.\n",
      "[INFO] graphlab.deploy.job: Validating job.\n",
      "[INFO] graphlab.deploy.map_job: Validation complete. Job: 'Model-Parameter-Search-May-28-2017-05-23-0800001' ready for execution\n",
      "[INFO] graphlab.deploy.map_job: Job: 'Model-Parameter-Search-May-28-2017-05-23-0800001' scheduled.\n",
      "[INFO] graphlab.deploy.job: Validating job.\n",
      "[INFO] graphlab.deploy.map_job: Validation complete. Job: 'Model-Parameter-Search-May-28-2017-05-23-0800002' ready for execution\n",
      "[INFO] graphlab.deploy.map_job: Job: 'Model-Parameter-Search-May-28-2017-05-23-0800002' scheduled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 41.5 s, sys: 9.14 s, total: 50.6 s\n",
      "Wall time: 19min 32s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "start_time = time.time()\n",
    "model_search = model_parameter_search.create( datasets = kfold, \n",
    "                                             #[data, val_set],\n",
    "                                             model_factory = model_factory,\n",
    "                                    model_parameters = params, \n",
    "                                    perform_trial_run = True  )\n",
    "\n",
    "search_results = model_search.get_results()\n",
    "\n",
    "all_time = time.time() - start_time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 19.53582328557968)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert duration in seconds to hours and minutes\n",
    "int(abs(all_time)/3600) ,(abs(all_time)/3600 %1)*60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\"><table frame=\"box\" rules=\"cols\">\n",
       "    <tr>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">task_name</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">status</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">start_time</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">run_time</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">exception</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">exception_message</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">exception_traceback</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">_train_test_model-0-0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Completed</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2017-05-28 05:24:26</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">84.0898089409</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">_train_test_model-0-1</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Completed</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2017-05-28 05:25:50</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">86.6875948906</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">_train_test_model-0-2</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Completed</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2017-05-28 05:27:17</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">59.9590389729</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">_train_test_model-0-3</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Completed</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2017-05-28 05:28:17</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">94.800579071</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">_train_test_model-0-4</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Completed</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2017-05-28 05:29:52</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">138.167016983</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">_train_test_model-0-5</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Completed</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2017-05-28 05:32:10</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">89.2651269436</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">_train_test_model-0-6</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Completed</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2017-05-28 05:33:40</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">101.135102987</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">_train_test_model-0-7</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Completed</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2017-05-28 05:35:21</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">48.8374538422</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">_train_test_model-0-8</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Completed</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2017-05-28 05:36:10</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">62.6350979805</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">_train_test_model-0-9</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Completed</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2017-05-28 05:37:13</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">44.2389678955</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "    </tr>\n",
       "</table>\n",
       "<table frame=\"box\" rules=\"cols\">\n",
       "    <tr>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">job_name</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Model-Parameter-Search-Ma<br>y-28-2017-05-23-08000 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Model-Parameter-Search-Ma<br>y-28-2017-05-23-08000 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Model-Parameter-Search-Ma<br>y-28-2017-05-23-08000 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Model-Parameter-Search-Ma<br>y-28-2017-05-23-08000 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Model-Parameter-Search-Ma<br>y-28-2017-05-23-08000 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Model-Parameter-Search-Ma<br>y-28-2017-05-23-08000 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Model-Parameter-Search-Ma<br>y-28-2017-05-23-08000 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Model-Parameter-Search-Ma<br>y-28-2017-05-23-08000 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Model-Parameter-Search-Ma<br>y-28-2017-05-23-08000 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Model-Parameter-Search-Ma<br>y-28-2017-05-23-08000 ...</td>\n",
       "    </tr>\n",
       "</table>\n",
       "[35 rows x 8 columns]<br/>Note: Only the head of the SFrame is printed.<br/>You can use print_rows(num_rows=m, num_columns=n) to print more rows and columns.\n",
       "</div>"
      ],
      "text/plain": [
       "Columns:\n",
       "\ttask_name\tstr\n",
       "\tstatus\tstr\n",
       "\tstart_time\tstr\n",
       "\trun_time\tfloat\n",
       "\texception\tfloat\n",
       "\texception_message\tfloat\n",
       "\texception_traceback\tfloat\n",
       "\tjob_name\tstr\n",
       "\n",
       "Rows: 35\n",
       "\n",
       "Data:\n",
       "+-----------------------+-----------+---------------------+---------------+-----------+\n",
       "|       task_name       |   status  |      start_time     |    run_time   | exception |\n",
       "+-----------------------+-----------+---------------------+---------------+-----------+\n",
       "| _train_test_model-0-0 | Completed | 2017-05-28 05:24:26 | 84.0898089409 |    None   |\n",
       "| _train_test_model-0-1 | Completed | 2017-05-28 05:25:50 | 86.6875948906 |    None   |\n",
       "| _train_test_model-0-2 | Completed | 2017-05-28 05:27:17 | 59.9590389729 |    None   |\n",
       "| _train_test_model-0-3 | Completed | 2017-05-28 05:28:17 |  94.800579071 |    None   |\n",
       "| _train_test_model-0-4 | Completed | 2017-05-28 05:29:52 | 138.167016983 |    None   |\n",
       "| _train_test_model-0-5 | Completed | 2017-05-28 05:32:10 | 89.2651269436 |    None   |\n",
       "| _train_test_model-0-6 | Completed | 2017-05-28 05:33:40 | 101.135102987 |    None   |\n",
       "| _train_test_model-0-7 | Completed | 2017-05-28 05:35:21 | 48.8374538422 |    None   |\n",
       "| _train_test_model-0-8 | Completed | 2017-05-28 05:36:10 | 62.6350979805 |    None   |\n",
       "| _train_test_model-0-9 | Completed | 2017-05-28 05:37:13 | 44.2389678955 |    None   |\n",
       "+-----------------------+-----------+---------------------+---------------+-----------+\n",
       "+-------------------+---------------------+-------------------------------+\n",
       "| exception_message | exception_traceback |            job_name           |\n",
       "+-------------------+---------------------+-------------------------------+\n",
       "|        None       |         None        | Model-Parameter-Search-May... |\n",
       "|        None       |         None        | Model-Parameter-Search-May... |\n",
       "|        None       |         None        | Model-Parameter-Search-May... |\n",
       "|        None       |         None        | Model-Parameter-Search-May... |\n",
       "|        None       |         None        | Model-Parameter-Search-May... |\n",
       "|        None       |         None        | Model-Parameter-Search-May... |\n",
       "|        None       |         None        | Model-Parameter-Search-May... |\n",
       "|        None       |         None        | Model-Parameter-Search-May... |\n",
       "|        None       |         None        | Model-Parameter-Search-May... |\n",
       "|        None       |         None        | Model-Parameter-Search-May... |\n",
       "+-------------------+---------------------+-------------------------------+\n",
       "[35 rows x 8 columns]\n",
       "Note: Only the head of the SFrame is printed.\n",
       "You can use print_rows(num_rows=m, num_columns=n) to print more rows and columns."
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = model_search.get_metrics()\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# res['exception_message']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\"><table frame=\"box\" rules=\"cols\">\n",
       "    <tr>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">task_name</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">status</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">start_time</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">run_time</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">exception</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">exception_message</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">exception_traceback</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">_train_test_model-0-0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Completed</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2017-05-28 05:24:26</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">84.0898089409</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">_train_test_model-0-1</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Completed</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2017-05-28 05:25:50</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">86.6875948906</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">_train_test_model-0-2</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Completed</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2017-05-28 05:27:17</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">59.9590389729</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">_train_test_model-0-3</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Completed</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2017-05-28 05:28:17</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">94.800579071</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">_train_test_model-0-4</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Completed</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2017-05-28 05:29:52</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">138.167016983</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">_train_test_model-0-5</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Completed</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2017-05-28 05:32:10</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">89.2651269436</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">_train_test_model-0-6</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Completed</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2017-05-28 05:33:40</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">101.135102987</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">_train_test_model-0-7</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Completed</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2017-05-28 05:35:21</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">48.8374538422</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">_train_test_model-0-8</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Completed</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2017-05-28 05:36:10</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">62.6350979805</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">_train_test_model-0-9</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Completed</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2017-05-28 05:37:13</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">44.2389678955</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "    </tr>\n",
       "</table>\n",
       "<table frame=\"box\" rules=\"cols\">\n",
       "    <tr>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">job_name</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Model-Parameter-Search-Ma<br>y-28-2017-05-23-08000 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Model-Parameter-Search-Ma<br>y-28-2017-05-23-08000 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Model-Parameter-Search-Ma<br>y-28-2017-05-23-08000 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Model-Parameter-Search-Ma<br>y-28-2017-05-23-08000 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Model-Parameter-Search-Ma<br>y-28-2017-05-23-08000 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Model-Parameter-Search-Ma<br>y-28-2017-05-23-08000 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Model-Parameter-Search-Ma<br>y-28-2017-05-23-08000 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Model-Parameter-Search-Ma<br>y-28-2017-05-23-08000 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Model-Parameter-Search-Ma<br>y-28-2017-05-23-08000 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Model-Parameter-Search-Ma<br>y-28-2017-05-23-08000 ...</td>\n",
       "    </tr>\n",
       "</table>\n",
       "[35 rows x 8 columns]<br/>Note: Only the head of the SFrame is printed.<br/>You can use print_rows(num_rows=m, num_columns=n) to print more rows and columns.\n",
       "</div>"
      ],
      "text/plain": [
       "Columns:\n",
       "\ttask_name\tstr\n",
       "\tstatus\tstr\n",
       "\tstart_time\tstr\n",
       "\trun_time\tfloat\n",
       "\texception\tfloat\n",
       "\texception_message\tfloat\n",
       "\texception_traceback\tfloat\n",
       "\tjob_name\tstr\n",
       "\n",
       "Rows: 35\n",
       "\n",
       "Data:\n",
       "+-----------------------+-----------+---------------------+---------------+-----------+\n",
       "|       task_name       |   status  |      start_time     |    run_time   | exception |\n",
       "+-----------------------+-----------+---------------------+---------------+-----------+\n",
       "| _train_test_model-0-0 | Completed | 2017-05-28 05:24:26 | 84.0898089409 |    None   |\n",
       "| _train_test_model-0-1 | Completed | 2017-05-28 05:25:50 | 86.6875948906 |    None   |\n",
       "| _train_test_model-0-2 | Completed | 2017-05-28 05:27:17 | 59.9590389729 |    None   |\n",
       "| _train_test_model-0-3 | Completed | 2017-05-28 05:28:17 |  94.800579071 |    None   |\n",
       "| _train_test_model-0-4 | Completed | 2017-05-28 05:29:52 | 138.167016983 |    None   |\n",
       "| _train_test_model-0-5 | Completed | 2017-05-28 05:32:10 | 89.2651269436 |    None   |\n",
       "| _train_test_model-0-6 | Completed | 2017-05-28 05:33:40 | 101.135102987 |    None   |\n",
       "| _train_test_model-0-7 | Completed | 2017-05-28 05:35:21 | 48.8374538422 |    None   |\n",
       "| _train_test_model-0-8 | Completed | 2017-05-28 05:36:10 | 62.6350979805 |    None   |\n",
       "| _train_test_model-0-9 | Completed | 2017-05-28 05:37:13 | 44.2389678955 |    None   |\n",
       "+-----------------------+-----------+---------------------+---------------+-----------+\n",
       "+-------------------+---------------------+-------------------------------+\n",
       "| exception_message | exception_traceback |            job_name           |\n",
       "+-------------------+---------------------+-------------------------------+\n",
       "|        None       |         None        | Model-Parameter-Search-May... |\n",
       "|        None       |         None        | Model-Parameter-Search-May... |\n",
       "|        None       |         None        | Model-Parameter-Search-May... |\n",
       "|        None       |         None        | Model-Parameter-Search-May... |\n",
       "|        None       |         None        | Model-Parameter-Search-May... |\n",
       "|        None       |         None        | Model-Parameter-Search-May... |\n",
       "|        None       |         None        | Model-Parameter-Search-May... |\n",
       "|        None       |         None        | Model-Parameter-Search-May... |\n",
       "|        None       |         None        | Model-Parameter-Search-May... |\n",
       "|        None       |         None        | Model-Parameter-Search-May... |\n",
       "+-------------------+---------------------+-------------------------------+\n",
       "[35 rows x 8 columns]\n",
       "Note: Only the head of the SFrame is printed.\n",
       "You can use print_rows(num_rows=m, num_columns=n) to print more rows and columns."
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 17)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_results.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\"><table frame=\"box\" rules=\"cols\">\n",
       "    <tr>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">class_weights</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">column_subsample</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">early_stopping_rounds</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">max_depth</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">max_iterations</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">metric</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">min_child_weight</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">min_loss_reduction</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.1</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">5</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">9</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">250</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">auc</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.8</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">5</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">15</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">200</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">auc</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">5</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.8</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">5</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">15</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">200</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">auc</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">10</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.05</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">5</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">15</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">200</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">auc</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">5</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.05</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">5</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">9</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">200</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">auc</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">10</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.8</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">5</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">9</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">300</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">auc</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.1</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">5</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">15</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">300</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">auc</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.8</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">5</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">20</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">250</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">auc</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.05</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">5</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">9</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">200</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">auc</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.8</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">5</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">4</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">200</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">auc</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">10</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n",
       "    </tr>\n",
       "</table>\n",
       "<table frame=\"box\" rules=\"cols\">\n",
       "    <tr>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">random_seed</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">row_subsample</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">step_size</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">target</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">num_folds</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">fold_id</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">mean_training_accuracy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">415168</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.75</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1.0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">target</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">10</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">[8, 9, 4, 5, 6, 7, 0, 1,<br>2, 3] ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.888214143961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">415168</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.75</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.5</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">target</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">10</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">[9, 8, 1, 0, 3, 2, 5, 4,<br>7, 6] ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.916128505055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">415168</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.5</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1.0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">target</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">10</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">[1, 8, 9, 4, 5, 6, 7, 0,<br>3, 2] ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.886419882795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">415168</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.75</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1.0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">target</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">10</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">[0, 1, 5, 4, 7, 6, 2, 3,<br>9, 8] ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.886152553057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">415168</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.5</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.1</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">target</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">10</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">[1, 0, 3, 2, 5, 4, 7, 6,<br>9, 8] ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.874481100138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">415168</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.5</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1.0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">target</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">10</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">[8, 9, 1, 0, 3, 2, 5, 4,<br>7, 6] ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.888411430973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">415168</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.5</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.1</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">target</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">10</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">[3, 2, 1, 0, 5, 4, 7, 6,<br>9, 8] ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.882219653989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">415168</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.5</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.01</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">target</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">10</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">[8, 1, 0, 3, 2, 5, 4, 7,<br>9, 6] ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.91135859541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">415168</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.75</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.01</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">target</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">10</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">[3, 4, 5, 0, 1, 9, 8, 6,<br>7, 2] ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.869836100021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">415168</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.5</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.5</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">target</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">10</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">[7, 9, 8, 6, 1, 0, 3, 2,<br>5, 4] ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.889262450095</td>\n",
       "    </tr>\n",
       "</table>\n",
       "<table frame=\"box\" rules=\"cols\">\n",
       "    <tr>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">mean_validation_accuracy</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">model_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.87504727884</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">[28, 29, 24, 25, 26, 27,<br>20, 21, 22, 23] ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.878976675772</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">[19, 18, 11, 10, 13, 12,<br>15, 14, 17, 16] ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.877390208027</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">[51, 58, 59, 54, 55, 56,<br>57, 50, 53, 52] ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.876392099181</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">[60, 61, 65, 64, 67, 66,<br>62, 63, 69, 68] ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.870487497373</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">[31, 30, 33, 32, 35, 34,<br>37, 36, 39, 38] ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.877064509351</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">[88, 89, 81, 80, 83, 82,<br>85, 84, 87, 86] ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.878041605379</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">[43, 42, 41, 40, 45, 44,<br>47, 46, 49, 48] ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.883441899559</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">[8, 1, 0, 3, 2, 5, 4, 7,<br>9, 6] ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.866453036352</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">[93, 94, 95, 90, 91, 99,<br>98, 96, 97, 92] ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.882086572809</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">[77, 79, 78, 76, 71, 70,<br>73, 72, 75, 74] ...</td>\n",
       "    </tr>\n",
       "</table>\n",
       "[10 rows x 17 columns]<br/>\n",
       "</div>"
      ],
      "text/plain": [
       "Columns:\n",
       "\tclass_weights\tfloat\n",
       "\tcolumn_subsample\tfloat\n",
       "\tearly_stopping_rounds\tint\n",
       "\tmax_depth\tint\n",
       "\tmax_iterations\tint\n",
       "\tmetric\tstr\n",
       "\tmin_child_weight\tint\n",
       "\tmin_loss_reduction\tint\n",
       "\trandom_seed\tint\n",
       "\trow_subsample\tfloat\n",
       "\tstep_size\tfloat\n",
       "\ttarget\tstr\n",
       "\tnum_folds\tint\n",
       "\tfold_id\tlist\n",
       "\tmean_training_accuracy\tfloat\n",
       "\tmean_validation_accuracy\tfloat\n",
       "\tmodel_id\tlist\n",
       "\n",
       "Rows: 10\n",
       "\n",
       "Data:\n",
       "+---------------+------------------+-----------------------+-----------+----------------+\n",
       "| class_weights | column_subsample | early_stopping_rounds | max_depth | max_iterations |\n",
       "+---------------+------------------+-----------------------+-----------+----------------+\n",
       "|      None     |       0.1        |           5           |     9     |      250       |\n",
       "|      None     |       0.8        |           5           |     15    |      200       |\n",
       "|      None     |       0.8        |           5           |     15    |      200       |\n",
       "|      None     |       0.05       |           5           |     15    |      200       |\n",
       "|      None     |       0.05       |           5           |     9     |      200       |\n",
       "|      None     |       0.8        |           5           |     9     |      300       |\n",
       "|      None     |       0.1        |           5           |     15    |      300       |\n",
       "|      None     |       0.8        |           5           |     20    |      250       |\n",
       "|      None     |       0.05       |           5           |     9     |      200       |\n",
       "|      None     |       0.8        |           5           |     4     |      200       |\n",
       "+---------------+------------------+-----------------------+-----------+----------------+\n",
       "+--------+------------------+--------------------+-------------+---------------+\n",
       "| metric | min_child_weight | min_loss_reduction | random_seed | row_subsample |\n",
       "+--------+------------------+--------------------+-------------+---------------+\n",
       "|  auc   |        2         |         10         |    415168   |      0.75     |\n",
       "|  auc   |        5         |         1          |    415168   |      0.75     |\n",
       "|  auc   |        10        |         10         |    415168   |      0.5      |\n",
       "|  auc   |        5         |         10         |    415168   |      0.75     |\n",
       "|  auc   |        10        |         1          |    415168   |      0.5      |\n",
       "|  auc   |        2         |         10         |    415168   |      0.5      |\n",
       "|  auc   |        2         |         10         |    415168   |      0.5      |\n",
       "|  auc   |        2         |         1          |    415168   |      0.5      |\n",
       "|  auc   |        2         |         10         |    415168   |      0.75     |\n",
       "|  auc   |        10        |         1          |    415168   |      0.5      |\n",
       "+--------+------------------+--------------------+-------------+---------------+\n",
       "+-----------+--------+-----------+--------------------------------+\n",
       "| step_size | target | num_folds |            fold_id             |\n",
       "+-----------+--------+-----------+--------------------------------+\n",
       "|    1.0    | target |     10    | [8, 9, 4, 5, 6, 7, 0, 1, 2, 3] |\n",
       "|    0.5    | target |     10    | [9, 8, 1, 0, 3, 2, 5, 4, 7, 6] |\n",
       "|    1.0    | target |     10    | [1, 8, 9, 4, 5, 6, 7, 0, 3, 2] |\n",
       "|    1.0    | target |     10    | [0, 1, 5, 4, 7, 6, 2, 3, 9, 8] |\n",
       "|    0.1    | target |     10    | [1, 0, 3, 2, 5, 4, 7, 6, 9, 8] |\n",
       "|    1.0    | target |     10    | [8, 9, 1, 0, 3, 2, 5, 4, 7, 6] |\n",
       "|    0.1    | target |     10    | [3, 2, 1, 0, 5, 4, 7, 6, 9, 8] |\n",
       "|    0.01   | target |     10    | [8, 1, 0, 3, 2, 5, 4, 7, 9, 6] |\n",
       "|    0.01   | target |     10    | [3, 4, 5, 0, 1, 9, 8, 6, 7, 2] |\n",
       "|    0.5    | target |     10    | [7, 9, 8, 6, 1, 0, 3, 2, 5, 4] |\n",
       "+-----------+--------+-----------+--------------------------------+\n",
       "+------------------------+--------------------------+\n",
       "| mean_training_accuracy | mean_validation_accuracy |\n",
       "+------------------------+--------------------------+\n",
       "|     0.888214143961     |      0.87504727884       |\n",
       "|     0.916128505055     |      0.878976675772      |\n",
       "|     0.886419882795     |      0.877390208027      |\n",
       "|     0.886152553057     |      0.876392099181      |\n",
       "|     0.874481100138     |      0.870487497373      |\n",
       "|     0.888411430973     |      0.877064509351      |\n",
       "|     0.882219653989     |      0.878041605379      |\n",
       "|     0.91135859541      |      0.883441899559      |\n",
       "|     0.869836100021     |      0.866453036352      |\n",
       "|     0.889262450095     |      0.882086572809      |\n",
       "+------------------------+--------------------------+\n",
       "+--------------------------------+\n",
       "|            model_id            |\n",
       "+--------------------------------+\n",
       "| [28, 29, 24, 25, 26, 27, 2...  |\n",
       "| [19, 18, 11, 10, 13, 12, 1...  |\n",
       "| [51, 58, 59, 54, 55, 56, 5...  |\n",
       "| [60, 61, 65, 64, 67, 66, 6...  |\n",
       "| [31, 30, 33, 32, 35, 34, 3...  |\n",
       "| [88, 89, 81, 80, 83, 82, 8...  |\n",
       "| [43, 42, 41, 40, 45, 44, 4...  |\n",
       "| [8, 1, 0, 3, 2, 5, 4, 7, 9, 6] |\n",
       "| [93, 94, 95, 90, 91, 99, 9...  |\n",
       "| [77, 79, 78, 76, 71, 70, 7...  |\n",
       "+--------------------------------+\n",
       "[10 rows x 17 columns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-----------------+----------------+\n",
      "| class_weights |       std       |      mean      |\n",
      "+---------------+-----------------+----------------+\n",
      "|      None     | 0.0136933187101 | 0.889248441549 |\n",
      "+---------------+-----------------+----------------+\n",
      "[1 rows x 3 columns]\n",
      "\n",
      "+------------------+------------------+----------------+\n",
      "| column_subsample |       std        |      mean      |\n",
      "+------------------+------------------+----------------+\n",
      "|       0.05       | 0.00686395965271 | 0.876823251072 |\n",
      "|       0.8        | 0.0127199016447  | 0.898316172865 |\n",
      "|       0.1        | 0.00299724498611 | 0.885216898975 |\n",
      "+------------------+------------------+----------------+\n",
      "[3 rows x 3 columns]\n",
      "\n",
      "+-----------------------+-----------------+----------------+\n",
      "| early_stopping_rounds |       std       |      mean      |\n",
      "+-----------------------+-----------------+----------------+\n",
      "|           5           | 0.0136933187101 | 0.889248441549 |\n",
      "+-----------------------+-----------------+----------------+\n",
      "[1 rows x 3 columns]\n",
      "\n",
      "+-----------+-----------------+----------------+\n",
      "| max_depth |       std       |      mean      |\n",
      "+-----------+-----------------+----------------+\n",
      "|     15    | 0.0136110047333 | 0.892730148724 |\n",
      "|     20    |       0.0       | 0.91135859541  |\n",
      "|     4     |       0.0       | 0.889262450095 |\n",
      "|     9     |  0.008242651944 | 0.880235693773 |\n",
      "+-----------+-----------------+----------------+\n",
      "[4 rows x 3 columns]\n",
      "\n",
      "+----------------+------------------+----------------+\n",
      "| max_iterations |       std        |      mean      |\n",
      "+----------------+------------------+----------------+\n",
      "|      200       | 0.0147532616947  | 0.887046765193 |\n",
      "|      250       | 0.0115722257244  | 0.899786369686 |\n",
      "|      300       | 0.00309588849198 | 0.885315542481 |\n",
      "+----------------+------------------+----------------+\n",
      "[3 rows x 3 columns]\n",
      "\n",
      "+--------+-----------------+----------------+\n",
      "| metric |       std       |      mean      |\n",
      "+--------+-----------------+----------------+\n",
      "|  auc   | 0.0136933187101 | 0.889248441549 |\n",
      "+--------+-----------------+----------------+\n",
      "[1 rows x 3 columns]\n",
      "\n",
      "+------------------+------------------+----------------+\n",
      "| min_child_weight |       std        |      mean      |\n",
      "+------------------+------------------+----------------+\n",
      "|        2         | 0.0134846465009  | 0.888007984871 |\n",
      "|        10        | 0.00640401806801 | 0.883387811009 |\n",
      "|        5         | 0.0149879759987  | 0.901140529056 |\n",
      "+------------------+------------------+----------------+\n",
      "[3 rows x 3 columns]\n",
      "\n",
      "+--------------------+------------------+----------------+\n",
      "| min_loss_reduction |       std        |      mean      |\n",
      "+--------------------+------------------+----------------+\n",
      "|         10         | 0.00645804119592 | 0.883542294133 |\n",
      "|         1          | 0.0168554903617  | 0.897807662674 |\n",
      "+--------------------+------------------+----------------+\n",
      "[2 rows x 3 columns]\n",
      "\n",
      "+---------------+-----------------+----------------+\n",
      "| row_subsample |       std       |      mean      |\n",
      "+---------------+-----------------+----------------+\n",
      "|      0.5      | 0.0112781657339 | 0.888692185567 |\n",
      "|      0.75     | 0.0166376555459 | 0.890082825524 |\n",
      "+---------------+-----------------+----------------+\n",
      "[2 rows x 3 columns]\n",
      "\n",
      "+-----------+------------------+----------------+\n",
      "| step_size |       std        |      mean      |\n",
      "+-----------+------------------+----------------+\n",
      "|    0.5    | 0.0134330274801  | 0.902695477575 |\n",
      "|    0.01   | 0.0207612476944  | 0.890597347715 |\n",
      "|    0.1    | 0.00386927692559 | 0.878350377063 |\n",
      "|    1.0    | 0.00102007080396 | 0.887299502697 |\n",
      "+-----------+------------------+----------------+\n",
      "[4 rows x 3 columns]\n",
      "\n",
      "+--------+-----------------+----------------+\n",
      "| target |       std       |      mean      |\n",
      "+--------+-----------------+----------------+\n",
      "| target | 0.0136933187101 | 0.889248441549 |\n",
      "+--------+-----------------+----------------+\n",
      "[1 rows x 3 columns]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for col in [col for col in search_results.column_names() if \\\n",
    "            not('accuracy' in col) and col!= 'model_id' and col!= 'random_seed' and col!= 'fold_id' \\\n",
    "                               and col!= 'num_folds']:\n",
    "    print(search_results.groupby(col,\n",
    "                             {'mean':gl.aggregate.MEAN('mean_training_accuracy'),\n",
    "                                'std':gl.aggregate.STD('mean_training_accuracy')}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## hyperparameter results\n",
    "\n",
    "* class_weights: None, gana por afano\n",
    "* column_subsample : algo menor a 1 pero no queda claro si cuanto menos mejor\n",
    "* row_subsample : algo menor a 1 pero no queda claro si cuanto menos mejor, refinar\n",
    "* max_depth: varia mucho, refinar\n",
    "* max_iterations: tampoco queda claro si poquito o mucho es mejor, reprobar\n",
    "* metric: el f1_score es el unico que no parece variar mucho,los demas cambian demasiado\n",
    "* min_child_weight: varia mucho, reprobar con mas\n",
    "* min_loss_reduction: varia mucho, reprobar\n",
    "* step_size: mas grande parece ser mejor> 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Results\n",
    "\n",
    "* bootstrap  ???= False es 5% mejor\n",
    "* min_samples_leaf ????= mas chico es claramente mejor, pero tmb aumenta el overfitting lo cual me hace caer mucho el valor del recall en el test_set. Sin embargo es un parametro muy sensible en la precision. Resta evaluar asi el tradeoff entre la precision y el volumen de users al cual queremos llegar.\n",
    "* n_estimators ???= mas pareceria mejor, pero depende del app y hay que ver 'cuanto' mejora por app\n",
    "* citerion ???= entropy o gini no cambia. gini podria ser mejor entonces pues entropy usa logs de los valores lo cual es mas computacionalmente costoso\n",
    "* max_features ???= no afecta al score. con auto esta bien\n",
    "* max_depth ??=  mas es mejor. intentaria probar con >15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## boosted run with best params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = model_search.get_best_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'class_weights': None,\n",
       " 'column_subsample': 0.8,\n",
       " 'early_stopping_rounds': 5,\n",
       " 'max_depth': 20,\n",
       " 'max_iterations': 250,\n",
       " 'metric': 'auc',\n",
       " 'min_child_weight': 2,\n",
       " 'min_loss_reduction': 1,\n",
       " 'random_seed': 415168,\n",
       " 'row_subsample': 0.5,\n",
       " 'step_size': 0.01,\n",
       " 'target': 'target'}"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = {'class_weights': None,\n",
    " 'column_subsample': 0.8,\n",
    " 'early_stopping_rounds': 5,\n",
    " 'max_depth': 12,\n",
    " 'max_iterations': 250,\n",
    " 'metric': 'auc',\n",
    " 'min_child_weight': 2,\n",
    " 'min_loss_reduction': 1,\n",
    " 'random_seed': 415168,\n",
    " 'row_subsample': 0.5,\n",
    " 'step_size': 0.01,\n",
    " 'target': 'target'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre>Boosted trees classifier:</pre>"
      ],
      "text/plain": [
       "Boosted trees classifier:"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>--------------------------------------------------------</pre>"
      ],
      "text/plain": [
       "--------------------------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of examples          : 95180</pre>"
      ],
      "text/plain": [
       "Number of examples          : 95180"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of classes           : 2</pre>"
      ],
      "text/plain": [
       "Number of classes           : 2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of feature columns   : 176</pre>"
      ],
      "text/plain": [
       "Number of feature columns   : 176"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of unpacked features : 176</pre>"
      ],
      "text/plain": [
       "Number of unpacked features : 176"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>+-----------+--------------+--------------+----------------+</pre>"
      ],
      "text/plain": [
       "+-----------+--------------+--------------+----------------+"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| Iteration | Elapsed Time | Training-auc | Validation-auc |</pre>"
      ],
      "text/plain": [
       "| Iteration | Elapsed Time | Training-auc | Validation-auc |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>+-----------+--------------+--------------+----------------+</pre>"
      ],
      "text/plain": [
       "+-----------+--------------+--------------+----------------+"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 1         | 0.792755     | 0.870534     | 0.854229       |</pre>"
      ],
      "text/plain": [
       "| 1         | 0.792755     | 0.870534     | 0.854229       |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 2         | 1.599966     | 0.885401     | 0.866128       |</pre>"
      ],
      "text/plain": [
       "| 2         | 1.599966     | 0.885401     | 0.866128       |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 3         | 2.415011     | 0.891582     | 0.872199       |</pre>"
      ],
      "text/plain": [
       "| 3         | 2.415011     | 0.891582     | 0.872199       |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 4         | 3.172991     | 0.896710     | 0.875075       |</pre>"
      ],
      "text/plain": [
       "| 4         | 3.172991     | 0.896710     | 0.875075       |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 5         | 3.932190     | 0.898678     | 0.876098       |</pre>"
      ],
      "text/plain": [
       "| 5         | 3.932190     | 0.898678     | 0.876098       |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 6         | 4.718734     | 0.898829     | 0.875404       |</pre>"
      ],
      "text/plain": [
       "| 6         | 4.718734     | 0.898829     | 0.875404       |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 10        | 7.827187     | 0.901186     | 0.878331       |</pre>"
      ],
      "text/plain": [
       "| 10        | 7.827187     | 0.901186     | 0.878331       |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 11        | 8.619724     | 0.901667     | 0.878403       |</pre>"
      ],
      "text/plain": [
       "| 11        | 8.619724     | 0.901667     | 0.878403       |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 15        | 11.739438    | 0.904433     | 0.879636       |</pre>"
      ],
      "text/plain": [
       "| 15        | 11.739438    | 0.904433     | 0.879636       |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 20        | 15.623586    | 0.905729     | 0.880089       |</pre>"
      ],
      "text/plain": [
       "| 20        | 15.623586    | 0.905729     | 0.880089       |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 25        | 19.480804    | 0.907467     | 0.880335       |</pre>"
      ],
      "text/plain": [
       "| 25        | 19.480804    | 0.907467     | 0.880335       |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 30        | 23.432567    | 0.907983     | 0.880966       |</pre>"
      ],
      "text/plain": [
       "| 30        | 23.432567    | 0.907983     | 0.880966       |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 35        | 27.363924    | 0.908957     | 0.880943       |</pre>"
      ],
      "text/plain": [
       "| 35        | 27.363924    | 0.908957     | 0.880943       |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>+-----------+--------------+--------------+----------------+</pre>"
      ],
      "text/plain": [
       "+-----------+--------------+--------------+----------------+"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Early stop triggered. Returning the best model at iteration: 30</pre>"
      ],
      "text/plain": [
       "Early stop triggered. Returning the best model at iteration: 30"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 27s, sys: 4.76 s, total: 2min 32s\n",
      "Wall time: 30.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "best_model =  boosted_trees_classifier.create(dataset=X_gl,\n",
    "                                             validation_set = X_val_gl,\n",
    "                                             **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['COUNT_0',\n",
       " 'MOBILITY_DIAMETER_WEEKNIGHT',\n",
       " 'MOBILITY_DIAMETER',\n",
       " 'COUNT_WEEKNIGHT_0',\n",
       " 'COUNT_1',\n",
       " 'TimeWeekDay_IN_08',\n",
       " 'COUNT_2',\n",
       " 'TimeWeekDay_OUT_08',\n",
       " 'COUNT_WEEKNIGHT_1',\n",
       " 'TimeWeekDay_OUT_09',\n",
       " 'TimeWeekDay_OUT_12',\n",
       " 'TimeWeekDay_IN_09',\n",
       " 'TimeWeekDay_IN_12',\n",
       " 'TimeWeekDay_OUT_10',\n",
       " 'TimeWeekEnd_OUT_08',\n",
       " 'COUNT_3',\n",
       " 'COUNT_4',\n",
       " 'CallsWeekDay_IN_08',\n",
       " 'TimeWeekDay_OUT_11',\n",
       " 'TimeWeekDay_IN_10']"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_feat = best_model.get_feature_importance()\n",
    "best_feat = list(best_feat['name'].head(20))\n",
    "best_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>LATITUDE</th>\n",
       "      <th>LONGITUDE</th>\n",
       "      <th>CEL_ID</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STATE</th>\n",
       "      <th>EPIDEMIC</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Aguascalientes</th>\n",
       "      <th>0</th>\n",
       "      <td>21.856175</td>\n",
       "      <td>-102.352281</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Baja_California</th>\n",
       "      <th>0</th>\n",
       "      <td>32.642231</td>\n",
       "      <td>-115.408042</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Baja_California_Sur</th>\n",
       "      <th>0</th>\n",
       "      <td>24.142063</td>\n",
       "      <td>-110.294055</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Campeche</th>\n",
       "      <th>0</th>\n",
       "      <td>19.814033</td>\n",
       "      <td>-90.508705</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chiapas</th>\n",
       "      <th>0</th>\n",
       "      <td>16.620228</td>\n",
       "      <td>-93.097100</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chihuahua</th>\n",
       "      <th>0</th>\n",
       "      <td>28.694722</td>\n",
       "      <td>-106.108056</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Coahuila_de_Zaragoza</th>\n",
       "      <th>0</th>\n",
       "      <td>28.637778</td>\n",
       "      <td>-100.553056</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Colima</th>\n",
       "      <th>0</th>\n",
       "      <td>19.052920</td>\n",
       "      <td>-104.320394</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Distrito_Federal</th>\n",
       "      <th>0</th>\n",
       "      <td>19.317872</td>\n",
       "      <td>-99.137003</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Durango</th>\n",
       "      <th>0</th>\n",
       "      <td>25.553119</td>\n",
       "      <td>-103.489508</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Guanajuato</th>\n",
       "      <th>0</th>\n",
       "      <td>21.158572</td>\n",
       "      <td>-100.923861</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Guerrero</th>\n",
       "      <th>1</th>\n",
       "      <td>16.831714</td>\n",
       "      <td>-99.778656</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hidalgo</th>\n",
       "      <th>1</th>\n",
       "      <td>19.832881</td>\n",
       "      <td>-98.950172</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jalisco</th>\n",
       "      <th>1</th>\n",
       "      <td>20.581427</td>\n",
       "      <td>-103.432628</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mexico</th>\n",
       "      <th>0</th>\n",
       "      <td>19.490600</td>\n",
       "      <td>-99.271200</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Michoacan_de_Ocampo</th>\n",
       "      <th>0</th>\n",
       "      <td>19.699532</td>\n",
       "      <td>-101.211267</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Morelos</th>\n",
       "      <th>1</th>\n",
       "      <td>18.828056</td>\n",
       "      <td>-99.244444</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nayarit</th>\n",
       "      <th>0</th>\n",
       "      <td>21.055389</td>\n",
       "      <td>-105.127556</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nuevo_Leon</th>\n",
       "      <th>0</th>\n",
       "      <td>25.806569</td>\n",
       "      <td>-100.325653</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Oaxaca</th>\n",
       "      <th>1</th>\n",
       "      <td>17.071125</td>\n",
       "      <td>-96.676006</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Puebla</th>\n",
       "      <th>1</th>\n",
       "      <td>19.067444</td>\n",
       "      <td>-98.221000</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Queretaro</th>\n",
       "      <th>0</th>\n",
       "      <td>20.594503</td>\n",
       "      <td>-100.393656</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Quintana_Roo</th>\n",
       "      <th>0</th>\n",
       "      <td>21.140333</td>\n",
       "      <td>-86.864528</td>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>San_Luis_Potosi</th>\n",
       "      <th>0</th>\n",
       "      <td>22.186800</td>\n",
       "      <td>-100.945300</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sinaloa</th>\n",
       "      <th>0</th>\n",
       "      <td>23.278450</td>\n",
       "      <td>-106.448220</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sonora</th>\n",
       "      <th>0</th>\n",
       "      <td>32.444358</td>\n",
       "      <td>-114.771023</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tabasco</th>\n",
       "      <th>1</th>\n",
       "      <td>17.879241</td>\n",
       "      <td>-92.480478</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tamaulipas</th>\n",
       "      <th>0</th>\n",
       "      <td>22.415000</td>\n",
       "      <td>-97.938000</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tlaxcala</th>\n",
       "      <th>0</th>\n",
       "      <td>19.212956</td>\n",
       "      <td>-98.240853</td>\n",
       "      <td>162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Veracruz</th>\n",
       "      <th>1</th>\n",
       "      <td>17.994111</td>\n",
       "      <td>-94.566444</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Yucatan</th>\n",
       "      <th>0</th>\n",
       "      <td>21.016680</td>\n",
       "      <td>-89.607927</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Zacatecas</th>\n",
       "      <th>0</th>\n",
       "      <td>22.738691</td>\n",
       "      <td>-102.555193</td>\n",
       "      <td>131</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                LATITUDE   LONGITUDE  CEL_ID\n",
       "STATE                EPIDEMIC                               \n",
       "Aguascalientes       0         21.856175 -102.352281      37\n",
       "Baja_California      0         32.642231 -115.408042      67\n",
       "Baja_California_Sur  0         24.142063 -110.294055       1\n",
       "Campeche             0         19.814033  -90.508705      49\n",
       "Chiapas              0         16.620228  -93.097100      76\n",
       "Chihuahua            0         28.694722 -106.108056      55\n",
       "Coahuila_de_Zaragoza 0         28.637778 -100.553056     118\n",
       "Colima               0         19.052920 -104.320394      87\n",
       "Distrito_Federal     0         19.317872  -99.137003       2\n",
       "Durango              0         25.553119 -103.489508      35\n",
       "Guanajuato           0         21.158572 -100.923861      30\n",
       "Guerrero             1         16.831714  -99.778656      57\n",
       "Hidalgo              1         19.832881  -98.950172      60\n",
       "Jalisco              1         20.581427 -103.432628      10\n",
       "Mexico               0         19.490600  -99.271200       9\n",
       "Michoacan_de_Ocampo  0         19.699532 -101.211267     102\n",
       "Morelos              1         18.828056  -99.244444       6\n",
       "Nayarit              0         21.055389 -105.127556      56\n",
       "Nuevo_Leon           0         25.806569 -100.325653       8\n",
       "Oaxaca               1         17.071125  -96.676006      24\n",
       "Puebla               1         19.067444  -98.221000       5\n",
       "Queretaro            0         20.594503 -100.393656      17\n",
       "Quintana_Roo         0         21.140333  -86.864528     123\n",
       "San_Luis_Potosi      0         22.186800 -100.945300     105\n",
       "Sinaloa              0         23.278450 -106.448220      86\n",
       "Sonora               0         32.444358 -114.771023      38\n",
       "Tabasco              1         17.879241  -92.480478       3\n",
       "Tamaulipas           0         22.415000  -97.938000       4\n",
       "Tlaxcala             0         19.212956  -98.240853     162\n",
       "Veracruz             1         17.994111  -94.566444      13\n",
       "Yucatan              0         21.016680  -89.607927      12\n",
       "Zacatecas            0         22.738691 -102.555193     131"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if best feat states are epidemic or not\n",
    "antennas.groupby(['STATE','EPIDEMIC']).first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.8897577722677856,\n",
       " 'auc': 0.8809650552848158,\n",
       " 'confusion_matrix': Columns:\n",
       " \ttarget_label\tint\n",
       " \tpredicted_label\tint\n",
       " \tcount\tint\n",
       " \n",
       " Rows: 4\n",
       " \n",
       " Data:\n",
       " +--------------+-----------------+-------+\n",
       " | target_label | predicted_label | count |\n",
       " +--------------+-----------------+-------+\n",
       " |      0       |        1        |  281  |\n",
       " |      1       |        0        |  875  |\n",
       " |      1       |        1        |  1163 |\n",
       " |      0       |        0        |  8167 |\n",
       " +--------------+-----------------+-------+\n",
       " [4 rows x 3 columns],\n",
       " 'f1_score': 0.6680068925904652,\n",
       " 'log_loss': 0.5461287424860415,\n",
       " 'precision': 0.8054016620498615,\n",
       " 'recall': 0.570657507360157,\n",
       " 'roc_curve': Columns:\n",
       " \tthreshold\tfloat\n",
       " \tfpr\tfloat\n",
       " \ttpr\tfloat\n",
       " \tp\tint\n",
       " \tn\tint\n",
       " \n",
       " Rows: 100001\n",
       " \n",
       " Data:\n",
       " +-----------+-----+-----+------+------+\n",
       " | threshold | fpr | tpr |  p   |  n   |\n",
       " +-----------+-----+-----+------+------+\n",
       " |    0.0    | 1.0 | 1.0 | 2038 | 8448 |\n",
       " |   1e-05   | 1.0 | 1.0 | 2038 | 8448 |\n",
       " |   2e-05   | 1.0 | 1.0 | 2038 | 8448 |\n",
       " |   3e-05   | 1.0 | 1.0 | 2038 | 8448 |\n",
       " |   4e-05   | 1.0 | 1.0 | 2038 | 8448 |\n",
       " |   5e-05   | 1.0 | 1.0 | 2038 | 8448 |\n",
       " |   6e-05   | 1.0 | 1.0 | 2038 | 8448 |\n",
       " |   7e-05   | 1.0 | 1.0 | 2038 | 8448 |\n",
       " |   8e-05   | 1.0 | 1.0 | 2038 | 8448 |\n",
       " |   9e-05   | 1.0 | 1.0 | 2038 | 8448 |\n",
       " +-----------+-----+-----+------+------+\n",
       " [100001 rows x 5 columns]\n",
       " Note: Only the head of the SFrame is printed.\n",
       " You can use print_rows(num_rows=m, num_columns=n) to print more rows and columns.}"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_error = best_model.evaluate(X_val_gl)\n",
    "test_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method BoostedTreesClassifier.get_current_options of Class                          : BoostedTreesClassifier\n",
       "\n",
       "Schema\n",
       "------\n",
       "Number of examples             : 95180\n",
       "Number of feature columns      : 176\n",
       "Number of unpacked features    : 176\n",
       "Number of classes              : 2\n",
       "\n",
       "Settings\n",
       "--------\n",
       "Number of trees                : 30\n",
       "Max tree depth                 : 12\n",
       "Training time (sec)            : 27.3684\n",
       "Training auc                   : 0.908\n",
       "Validation auc                 : 0.881\n",
       ">"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.get_current_options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sklearn \n",
    "\n",
    "validation, bias variance, learning curves  and decision tree models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/juan/mfixman/venv/local/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/home/juan/mfixman/venv/local/lib/python2.7/site-packages/sklearn/grid_search.py:43: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import *\n",
    "from sklearn.ensemble import *\n",
    "\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import validation_curve\n",
    "\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "from sklearn.utils import *\n",
    "\n",
    "from sklearn.preprocessing import label_binarize, scale, StandardScaler, MinMaxScaler\n",
    "\n",
    "from sklearn.metrics import *\n",
    "\n",
    "from sklearn.tree import *\n",
    "\n",
    "from sklearn.grid_search import *\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# dimensionality reduction  with SVD might improve the fit\n",
    "from sklearn.decomposition import TruncatedSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## bias variance trade-off in the number of attributes\n",
    "we first used a random forest to get the best attributes in the model and now will try to overfit the validation set using too many features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# best_columns = best_feat['name'].to_numpy()\n",
    "# X[best_columns].columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## scale numerical features when necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scale_cols = None\n",
    "# scale_cols = True\n",
    "if scale_cols:\n",
    "\n",
    "    # by definition any column which is outside of [-1,1]\n",
    "    scaling_cols = (X.max()) >1 | (X.min()<-1)\n",
    "\n",
    "    scaling_cols = scaling_cols[scaling_cols==True].index\n",
    "\n",
    "    scale = MinMaxScaler(copy=True)\n",
    "    \n",
    "    X[scaling_cols] = scale.fit_transform(X[scaling_cols])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make validation curve\n",
    "with DecisionTreeClassifier to overfit and compare without cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can't have more binary splits in a tree than the data we train with\n",
    "max_tree_depth = int(pd.np.log2(X.shape[0]))\n",
    "max_tree_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define our tree_depth range to compare in cross validation\n",
    "\n",
    "param_range = pd.np.arange(2,17,)\n",
    "param_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/juan/mfixman/venv/local/lib/python2.7/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/juan/mfixman/venv/local/lib/python2.7/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 48.8 s, sys: 564 ms, total: 49.3 s\n",
      "Wall time: 1min 43s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_scores, test_scores = validation_curve(\n",
    "    DecisionTreeClassifier(\n",
    "                       # max_depth = 100,\n",
    "                      criterion='gini'\n",
    "    ),\n",
    "    X, Y, \n",
    "    param_name=\"max_depth\", \n",
    "        param_range=param_range,\n",
    "\n",
    "        cv=10, \n",
    "    scoring='f1_weighted', \n",
    "    n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### check results by standarizing scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reverse_scores_train = 1 - train_scores\n",
    "reverse_scores_test = 1 - test_scores\n",
    "\n",
    "train_scores_mean = pd.np.mean(reverse_scores_train, axis=1)\n",
    "train_scores_std = pd.np.std(reverse_scores_train, axis=1)\n",
    "test_scores_mean = pd.np.mean(reverse_scores_test, axis=1)\n",
    "test_scores_std = pd.np.std(reverse_scores_test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f7640032d10>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfYAAAGNCAYAAADjDlO+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkP8H++AyJY85aEgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7544fd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 6)) \n",
    "plt.title(\"Validation Curve with Decision Tree Classifier\")\n",
    "plt.xlabel(\"$Max Depth$ value\".format())\n",
    "plt.ylabel(\"1 - Score\")\n",
    "plt.ylim(0.0, 0.5)\n",
    "\n",
    "lw = 1\n",
    "\n",
    "plt.plot(param_range, train_scores_mean, label=\"Training score with std-dev band\",\n",
    "             color=\"navy\", lw=lw)\n",
    "\n",
    "plt.fill_between(param_range, train_scores_mean - train_scores_std,\n",
    "                 train_scores_mean + train_scores_std, alpha=0.2,\n",
    "                 color=\"blue\", lw=lw)\n",
    "\n",
    "plt.plot(param_range, test_scores_mean, label=\"Cross-validation score avg\",\n",
    "             color=\"darkorange\", lw=lw)\n",
    "\n",
    "plt.fill_between(param_range, test_scores_mean - test_scores_std,\n",
    "                 test_scores_mean + test_scores_std, alpha=0.2,\n",
    "                 color=\"red\", lw=lw)\n",
    "\n",
    "plt.legend(loc=\"best\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### now build decision tree \n",
    "and draw with graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "        'max_leaf_nodes': [\n",
    "                    15,\n",
    "                    20,\n",
    "                    ], # number of final count of leaf nodes\n",
    "    \n",
    "            'class_weight': [\n",
    "                        None,\n",
    "#                         'balanced',\n",
    "                        ], # with imbalanced taret classes\n",
    "            'criterion': [\n",
    "                        'gini',\n",
    "                        ], # the split criterion   \n",
    "            \"max_depth\": [ \n",
    "                        4,\n",
    "                6,\n",
    "                5,\n",
    "                            ],# max tree depth            \n",
    "              \"max_features\": [\n",
    "                               None,\n",
    "#                                 'auto',\n",
    "#                                20,\n",
    "#                                0.75,\n",
    "                           ],# number of features to consider at each split\n",
    "              }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define loss function\n",
    "\n",
    "# scoring = 'f1'\n",
    "scoring = 'roc_auc'\n",
    "# scoring = 'neg_log_loss'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HyperParam Search took 14.59469223022461 seconds to run\n",
      "CPU times: user 11.1 s, sys: 268 ms, total: 11.4 s\n",
      "Wall time: 17.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "start_time = time.time()\n",
    "\n",
    "num_jobs = -1\n",
    "\n",
    "dtree  = DecisionTreeClassifier( )\n",
    "clf =GridSearchCV( dtree, \n",
    "                  param_grid, \n",
    "                  scoring=scoring, \n",
    "                  fit_params=None,\n",
    "                  n_jobs=num_jobs, \n",
    "                  iid=True, \n",
    "                  refit=True, \n",
    "                verbose=0, \n",
    "                pre_dispatch='2*n_jobs', \n",
    "                  error_score='ignore')\n",
    "\n",
    "clf2 = DecisionTreeClassifier( )\n",
    "\n",
    "clf.fit(X, Y)\n",
    "\n",
    "elapsed_time =   time.time() - start_time \n",
    "print('HyperParam Search took %s seconds to run' % (elapsed_time))\n",
    "\n",
    "\n",
    "cv_result = pd.DataFrame(columns=['mean_score' ] + [key for key, \n",
    "                            value in clf.grid_scores_[0].parameters.items() ] )\n",
    "i=0\n",
    "for setup in clf.grid_scores_:\n",
    "    row = [clf.grid_scores_[i].mean_validation_score ] + [value for key,\n",
    "                                        value in clf.grid_scores_[i].parameters.items() ]\n",
    "    cv_result.loc[i] = row\n",
    "    i+=1\n",
    "\n",
    "elapsed_time =   time.time() - start_time\n",
    "\n",
    "clf2.set_params(**clf.best_params_)\n",
    "clf2.fit(X,Y)\n",
    "\n",
    "#este flag es basicamente para chequear que hayamos terminado nomas\n",
    "finished = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finished"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Best estimator was DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=4,\n",
      "            max_features=None, max_leaf_nodes=20, min_impurity_split=1e-07,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best') \n",
      "\n",
      "\n",
      " Best estimator was 0.823 in \"roc_auc\" metric \n",
      "\n",
      "\n",
      "Best estimator's performance with \"roc_auc\" metric on the test set is: 0.880\n",
      "\n",
      "Param exploration Search took 14.612095355987549 seconds to run\n",
      "Our problem type id is 0 which means \"People that used to live in the endemic area\"\n"
     ]
    }
   ],
   "source": [
    "print('\\n Best estimator was %s \\n' % str(clf.best_estimator_))\n",
    "\n",
    "print('\\n Best estimator was {:.3f} in \"{}\" metric \\n'.format( clf.best_score_,\n",
    "                                                    scoring\n",
    "                                                   )\n",
    "     )\n",
    "\n",
    "\n",
    "## get testing score with the score used inour function\n",
    "scoring_fun = SCORERS[scoring]\n",
    "test_score = scoring_fun(clf,X_val,Y_val)\n",
    "\n",
    "print('\\nBest estimator\\'s performance with \\\n",
    "\"{}\" metric on the test set is: {:.3f}\\n'.format( scoring,\n",
    "                                                 test_score,  \n",
    "                                            )\n",
    "     )\n",
    "\n",
    "\n",
    "\n",
    "print('Param exploration Search took %s seconds to run' % (elapsed_time))\n",
    "\n",
    "print('Our problem type id is {} which means \\\"{}\\\"'.format(case,case_text.capitalize()))\n",
    "\n",
    "#ojo que esta parte cuando poly ==True no funciona.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## now draw tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dot -Tps tree.dot -o tree.ps \n"
     ]
    }
   ],
   "source": [
    "file_tree = 'tree.dot'\n",
    "outf = os.path.join(DATADIR,file_tree)\n",
    "\n",
    "tree.export_graphviz(clf2,\n",
    "                    max_depth = 7,\n",
    "                        impurity = True,\n",
    "                        proportion = True,\n",
    "                     feature_names = X.columns,\n",
    "                    out_file=outf)\n",
    "\n",
    "sub_call = 'dot -Tps {} -o {} '.format(file_tree, file_tree.replace('.dot','.ps'))\n",
    "print(sub_call)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show the importance of cross validation and regularization using the logistic regression. \n",
    "\n",
    "try with different \n",
    "\n",
    "* cv values: (1, 3, 10 and 20)\n",
    "\n",
    "* C regularization values (L2): (1/10, 1, 10000,20000 ,etc. - high values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1.001,   2.112,   3.223,   4.334,   5.445,   6.556,   7.667,\n",
       "         8.778,   9.889,  11.   ])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  1.00000000e-05,   1.21348277e-05,   1.47254043e-05,\n",
       "          1.78690243e-05,   2.16837531e-05,   2.63128607e-05,\n",
       "          3.19302031e-05,   3.87467512e-05,   4.70185149e-05,\n",
       "          5.70561576e-05,   6.92366640e-05,   8.40174987e-05,\n",
       "          1.01953787e-04,   1.23719163e-04,   1.50131073e-04,\n",
       "          1.82181470e-04,   2.21074074e-04,   2.68269580e-04,\n",
       "          3.25540512e-04,   3.95037801e-04]),\n",
       " array([   2531.40331524,    3071.81430127,    3727.59372031,\n",
       "           4523.37074477,    5489.03245092,    6660.84629081,\n",
       "           8082.82219252,    9808.36544541,   11902.28244779,\n",
       "          14443.21464727,   17526.59208537,   21268.21747296,\n",
       "          25808.61540418,   31318.31005244,   38004.22956366,\n",
       "          46117.47767708,   55962.7644532 ,   67909.85029956,\n",
       "          82407.43309894,  100000.        ]))"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # define our c range to compare\n",
    "# inv_c_range = pd.np.logspace(-4, 100, 15)\n",
    "\n",
    "# # param_range = 1./inv_c_range\n",
    "# param_range = pd.np.linspace(-3,0.5,30)\n",
    "# # param_range = pd.np.ceil(param_range)\n",
    "# param_range = pd.np.exp((param_range)*pd.np.log(10))\n",
    "\n",
    "# low_values = pd.np.linspace(0.001,1,10) \n",
    "# high_values = pd.np.linspace(10000,20000,10)\n",
    "# param_range = pd.np.concatenate([low_values,high_values])\n",
    "\n",
    "param_range = pd.np.logspace(-5, 5, 120)\n",
    "\n",
    "param_range[:20],param_range[-20:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## with no cv, high and low regularization comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# make this algorithm nilpotent (copy the data from the original case's X)\n",
    "# in case we want to run this again without re-building the whole X\n",
    "X_lreg = X.copy()\n",
    "X_val_lreg = X_val.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### check if we want SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 16 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "svd_features = False\n",
    "num_features_limit = 30\n",
    "\n",
    "#note that some svd algorithms are non-deterministic and thus results will vary if random state is not specified\n",
    "svd = TruncatedSVD(\n",
    "    n_components=num_features_limit, \n",
    "    n_iter=100, \n",
    "    random_state=42 ,\n",
    "    \n",
    "                )\n",
    "if svd_features: # only for train and test\n",
    "    svd.fit(X_lreg) \n",
    "    X_lreg = pd.DataFrame(svd.transform(X_lreg), index = X_lreg.index.values)\n",
    "    X_val_lreg = pd.DataFrame(svd.transform(X_val_lreg), index = X_val_lreg.index.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((137978, 186), (137978, 186))"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_lreg.shape, X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define loss function\n",
    "\n",
    "scoring = 'f1'\n",
    "# scoring = 'roc_auc'\n",
    "# scoring = 'neg_log_loss'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NO CV\n",
    "LOGREG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 16s, sys: 3min 55s, total: 5min 12s\n",
      "Wall time: 14min 32s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "num_jobs = -1\n",
    "\n",
    "logreg  =  LogisticRegression(solver = 'lbfgs', \n",
    "                       max_iter = 250,\n",
    "                      warm_start=False,\n",
    "                              verbose = 0,\n",
    "                              n_jobs =-1,\n",
    "                        )\n",
    "# init fit over a range of parameters and load these into the\n",
    "# test and train scoring lists\n",
    "scores = []\n",
    "scores_val = []\n",
    "\n",
    "## get testing score fun with our defined str score\n",
    "scoring_fun = SCORERS[scoring]\n",
    "\n",
    "for param in param_range:\n",
    "\n",
    "    logreg.set_params(C=param)\n",
    "    logreg.fit(X_lreg, Y)\n",
    "    \n",
    "    # get train and \"test\" errors without CV\n",
    "    error = scoring_fun(logreg,X_lreg,Y)\n",
    "\n",
    "    scores.append(error)\n",
    "    error_val = scoring_fun(logreg,\n",
    "                            X_val_lreg,\n",
    "                            Y_val)\n",
    "    scores_val.append(error_val)\n",
    "\n",
    "# cast to numpy arrays type\n",
    "scores = pd.np.asarray(scores)\n",
    "scores_val = pd.np.asarray(scores_val)\n",
    "\n",
    "elapsed_time =   time.time() - start_time \n",
    "#este flag es basicamente para chequear que hayamos terminado nomas\n",
    "finished = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finished"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Param exploration Search took 872.792695045 seconds to run\n",
      "\n",
      " Best estimator had (-0.547,-0.535) error and error_val scorewith scoring metric neg_log_loss \n",
      "\n",
      "\n",
      " Best param found with this metric was (1.0000000000000001e-05, 0.0048873746316244271) \n",
      "\n",
      "Our problem type id is 0 which means \"People that used to live in the endemic area\"\n"
     ]
    }
   ],
   "source": [
    "print('Param exploration Search took %s seconds to run' % (elapsed_time))\n",
    "\n",
    "max_score_index = pd.np.nonzero(scores == scores.max())[0][0]\n",
    "\n",
    "max_val_score_index = pd.np.nonzero(scores_val == scores_val.max())[0][0]\n",
    "\n",
    "print('\\n Best estimator had ({:.3f},{:.3f}) error and error_val score\\\n",
    "with scoring metric {} \\n'.format(\n",
    "                                 scores[max_score_index] ,\n",
    "                                 scores_val[max_val_score_index],\n",
    "                                scoring,\n",
    "                               )\n",
    "    )\n",
    "\n",
    "print('\\n Best param found with this metric was {} \\n'.format( str( (param_range[max_score_index],\n",
    "                                           param_range[max_val_score_index])\n",
    "                                           )\n",
    "                                      )\n",
    "     )\n",
    "\n",
    "print('Our problem type id is {} which means \\\"{}\\\"'.format(case,case_text.capitalize()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.24244241529040866, True)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get elapsed time in hours\n",
    "elapsed_time/3600, finished"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# reverse_scores_train = 1 - train_scores\n",
    "# reverse_scores_test = 1 - test_scores\n",
    "\n",
    "train_scores_mean = scores\n",
    "train_scores_std = pd.np.std(scores)\n",
    "test_scores_mean = scores_val\n",
    "test_scores_std = pd.np.std(scores_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6.8053344896406231e-08, (120,), (120,), (120,), ())"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.np.std(scores), param_range.shape, train_scores_mean.shape, test_scores_mean.shape, train_scores_std.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.54674996288044209, -0.54675060857410918)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_scores_mean.max(), train_scores_mean.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size = param_range.shape[0]\n",
    "#i = 0.002\n",
    "#pd.np.linspace(1+i,1,size)\n",
    "size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7effb2a8e6d0>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgkAAAGUCAYAAAC/crH4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nERFpYpNAREREmtgkEBERkab/ATPpfzn1OECiAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xd505310>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax, fig = plt.subplots(figsize=(8,6))\n",
    "plt.title(\"Validation Curve with Logistic Regression Classifier\")\n",
    "plt.xlabel(\"Regularization $C$ Param\")\n",
    "plt.ylabel(\"{}\".format(scoring))\n",
    "# plt.ylim(0.0, 10.1)\n",
    "\n",
    "lw = 1\n",
    "\n",
    "plt.semilogx(param_range, -train_scores_mean,#\n",
    "                          label=\"Training score\",\n",
    "             color=\"navy\", lw=lw)\n",
    "\n",
    "# plt.fill_between(param_range, train_scores_mean - train_scores_std,\n",
    "#                  train_scores_mean + train_scores_std, alpha=0.2,\n",
    "#                  color=\"blue\", lw=lw)\n",
    "\n",
    "plt.semilogx(param_range, -test_scores_mean,#\n",
    "             label=\"score for test set\",\n",
    "             color=\"darkorange\", lw=lw)\n",
    "\n",
    "# plt.fill_between(param_range, test_scores_mean - test_scores_std,\n",
    "#                  test_scores_mean + test_scores_std, alpha=0.2,\n",
    "#                  color=\"red\", lw=lw)\n",
    "\n",
    "plt.legend(loc=\"best\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.007843137254901968"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a =0.51\n",
    "b= 0.506\n",
    "(a-b)/a\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## YES CV\n",
    "LOGREG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## now add cross validation to the problem\n",
    "\n",
    "show different instances of l1 and l2 regularization (low C) vs. non-regularizing (high C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-7.        , -6.86956522, -6.73913043, -6.60869565, -6.47826087,\n",
       "       -6.34782609, -6.2173913 , -6.08695652, -5.95652174, -5.82608696,\n",
       "       -5.69565217, -5.56521739, -5.43478261, -5.30434783, -5.17391304,\n",
       "       -5.04347826, -4.91304348, -4.7826087 , -4.65217391, -4.52173913,\n",
       "       -4.39130435, -4.26086957, -4.13043478, -4.        , -3.86956522,\n",
       "       -3.73913043, -3.60869565, -3.47826087, -3.34782609, -3.2173913 ,\n",
       "       -3.08695652, -2.95652174, -2.82608696, -2.69565217, -2.56521739,\n",
       "       -2.43478261, -2.30434783, -2.17391304, -2.04347826, -1.91304348,\n",
       "       -1.7826087 , -1.65217391, -1.52173913, -1.39130435, -1.26086957,\n",
       "       -1.13043478, -1.        , -0.86956522, -0.73913043, -0.60869565,\n",
       "       -0.47826087, -0.34782609, -0.2173913 , -0.08695652,  0.04347826,\n",
       "        0.17391304,  0.30434783,  0.43478261,  0.56521739,  0.69565217,\n",
       "        0.82608696,  0.95652174,  1.08695652,  1.2173913 ,  1.34782609,\n",
       "        1.47826087,  1.60869565,  1.73913043,  1.86956522,  2.        ])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "min_val = -7; max_val = 2 ; n_points = 70\n",
    "param_range = pd.np.logspace(min_val,max_val,n_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1.00000000e-07,   1.35031404e-07,   1.82334800e-07,\n",
       "         2.46209240e-07,   3.32459793e-07,   4.48925126e-07,\n",
       "         6.06189899e-07,   8.18546731e-07,   1.10529514e-06,\n",
       "         1.49249555e-06,   2.01533769e-06,   2.72133877e-06,\n",
       "         3.67466194e-06,   4.96194760e-06,   6.70018750e-06,\n",
       "         9.04735724e-06,   1.22167735e-05,   1.64964807e-05,\n",
       "         2.22754295e-05,   3.00788252e-05,   4.06158599e-05,\n",
       "         5.48441658e-05,   7.40568469e-05,   1.00000000e-04,\n",
       "         1.35031404e-04,   1.82334800e-04,   2.46209240e-04,\n",
       "         3.32459793e-04,   4.48925126e-04,   6.06189899e-04,\n",
       "         8.18546731e-04,   1.10529514e-03,   1.49249555e-03,\n",
       "         2.01533769e-03,   2.72133877e-03,   3.67466194e-03,\n",
       "         4.96194760e-03,   6.70018750e-03,   9.04735724e-03,\n",
       "         1.22167735e-02,   1.64964807e-02,   2.22754295e-02,\n",
       "         3.00788252e-02,   4.06158599e-02,   5.48441658e-02,\n",
       "         7.40568469e-02,   1.00000000e-01,   1.35031404e-01,\n",
       "         1.82334800e-01,   2.46209240e-01,   3.32459793e-01,\n",
       "         4.48925126e-01,   6.06189899e-01,   8.18546731e-01,\n",
       "         1.10529514e+00,   1.49249555e+00,   2.01533769e+00,\n",
       "         2.72133877e+00,   3.67466194e+00,   4.96194760e+00,\n",
       "         6.70018750e+00,   9.04735724e+00,   1.22167735e+01,\n",
       "         1.64964807e+01,   2.22754295e+01,   3.00788252e+01,\n",
       "         4.06158599e+01,   5.48441658e+01,   7.40568469e+01,\n",
       "         1.00000000e+02])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define thos hyper params of the model which will be fixed\n",
    "fixed_params = {\n",
    "        'penalty': [\n",
    "                    'l1',\n",
    "#                     'l2',\n",
    "        ], # type of regularization function norm\n",
    "            'max_iter': [\n",
    "#                         40,\n",
    "                        150,\n",
    "#                         200,\n",
    "                        ], # number of descent iterations\n",
    "    \n",
    "            \"fit_intercept\": [ \n",
    "#                         False, \n",
    "                        True,\n",
    "                            ],# fit the constante intercept\n",
    "            \n",
    "               \"class_weight\": [\n",
    "#                                None,\n",
    "                            'balanced',\n",
    "                           ],# if class ratios are as weighted averge when computing the overall loss fn\n",
    "              }\n",
    "\n",
    "# convert all values to scalars and not lists\n",
    "fixed_params = {key:value[0] for key, value in fixed_params.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'class_weight': 'balanced',\n",
       " 'fit_intercept': True,\n",
       " 'max_iter': 150,\n",
       " 'penalty': 'l1'}"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fixed_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define those hyperparams of the model which we will be changing/iterating\n",
    "dynamic_params = {'C': param_range}# the regularization param, the smaller the more regulareized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define loss function\n",
    "\n",
    "# scoring = 'f1'\n",
    "scoring = 'roc_auc'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# manually CV\n",
    "over a range of param values for one single hyperparam argument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "num_jobs = -1\n",
    "\n",
    "logreg  = LogisticRegression(**fixed_params)\n",
    "scoring_fun = SCORERS[scoring]\n",
    "\n",
    "scores_test = []\n",
    "cv_scores_mean = []\n",
    "cv_scores_std = []\n",
    "\n",
    "key = 'C'\n",
    "\n",
    "for val in param_range:\n",
    "    # first init a logistic Regression model with param set\n",
    "    kw = {key:val}\n",
    "    logreg.set_params(**kw)\n",
    "    # get CV error first, doing N folds on the training set\n",
    "    cv_scores = cross_val_score(logreg,\n",
    "                                X_lreg,\n",
    "                                Y,\n",
    "                                cv=12,\n",
    "                                n_jobs=num_jobs,\n",
    "                                scoring = scoring_fun,\n",
    "                                pre_dispatch='4*n_jobs',)\n",
    "    # get folds mean cv score and std score\n",
    "    mean_cv_score, std_cv_score  = (cv_scores.mean(), cv_scores.std())\n",
    "    cv_scores_mean.append(mean_cv_score)\n",
    "    cv_scores_std.append(std_cv_score)    \n",
    "    \n",
    "    # now get test error by fitting the logReg model on the whole training set\n",
    "    # and scoring on the testing set\n",
    "    logreg.fit(X_lreg, Y)\n",
    "    test_error = scoring_fun(logreg,\n",
    "                             X_val_lreg,\n",
    "                             Y_val)\n",
    "    # save test score\n",
    "    scores_test.append(test_error)\n",
    "\n",
    "\n",
    "# capture the test error for each model\n",
    "errors_df = {key : param_range,\n",
    "             'test_error' : scores_test,\n",
    "            'std_cv_error' : cv_scores_std,\n",
    "             'mean_cv_error' : cv_scores_mean,\n",
    "            }\n",
    "errors_df = pd.DataFrame(errors_df)\n",
    "\n",
    "\n",
    "elapsed_time =   time.time() - start_time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# the key column values were extracted by transforming linear space to an exponent.\n",
    "# thus to come back to the linear space we have to take the natural logarithm\n",
    "#  and add it to the DF\n",
    "log_key = 'log_{}'.format(key)\n",
    "errors_df[log_key] = pd.np.linspace(min_val,max_val,n_points)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV vs. Test Error Search took 8559.10971093 seconds to run\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(True, 2.377530475258827)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('CV vs. Test Error Search took %s seconds to run' % (elapsed_time))\n",
    "\n",
    "# este flag es basicamente para chequear que hayamos terminado nomas\n",
    "# we also get elapsed time in hours\n",
    "finished = True\n",
    "finished, elapsed_time/3600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Best CV estimator was C:1.10529514113 \n",
      "\n",
      "\n",
      " Best CV error was 0.756 in \"'roc_auc'\" metric \n",
      "\n",
      "\n",
      " Best estimator for test set was C:2.01533768594 \n",
      "\n",
      "\n",
      " Best Test error was 0.783 in \"'roc_auc'\" metric \n",
      "\n",
      "Param exploration Search took 8559.10971093 seconds to run\n",
      "Our problem type id is 2 which means \"People that migrated in any direction\"\n"
     ]
    }
   ],
   "source": [
    "max_test_error = errors_df['test_error'].max()\n",
    "max_cv_error = errors_df['mean_cv_error'].max()\n",
    "\n",
    "best_estim_test = errors_df.loc[errors_df['test_error'].argmax(),key]#.values[0]\n",
    "best_estim_cv = errors_df.loc[errors_df['mean_cv_error'].argmax(),key]#.values[0]\n",
    "# best_score = errors_df.loc[errors_df['test_error'].argmax(),key].values[0]\n",
    "\n",
    "print('\\n Best CV estimator was {}:{!s} \\n'.format(key,best_estim_cv))\n",
    "print('\\n Best CV error was {:.3f} in \"{!r}\" metric \\n'.format( max_cv_error,\n",
    "                                                    scoring\n",
    "                                                   )\n",
    "     )\n",
    "\n",
    "print('\\n Best estimator for test set was {}:{!s} \\n'.format(key, best_estim_test))\n",
    "print('\\n Best Test error was {:.3f} in \"{!r}\" metric \\n'.format( max_test_error,\n",
    "                                                    scoring\n",
    "                                                   )\n",
    "     )\n",
    "\n",
    "print('Param exploration Search took %s seconds to run' % (elapsed_time))\n",
    "\n",
    "print('Our problem type id is {} which means \\\"{}\\\"'.format(case,case_text.capitalize()))\n",
    "\n",
    "#ojo que esta parte cuando poly ==True no funciona.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'C', u'mean_cv_error', u'std_cv_error', u'test_error'], dtype='object')"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errors_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "error_cols = ['mean_cv_error', 'test_error' ]\n",
    "rev_error_cols = []\n",
    "for col in error_cols:\n",
    "    rev_col = 'rev_'+col\n",
    "    errors_df[rev_col] = 1- errors_df[col]\n",
    "    rev_error_cols+=[rev_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rev_mean_cv_error', 'rev_test_error']"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rev_error_cols "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x7f9a58f63290>"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfwAAAGMCAYAAAA/cBDSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f9a8aea1dd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "\n",
    "x_col = log_key\n",
    "labels = error_cols\n",
    "# plot series\n",
    "# view[an_col].hist()\n",
    "\n",
    "colors = ['g','b']\n",
    "smoother = 7\n",
    "lw = 1\n",
    "for i,col in enumerate(rev_error_cols):\n",
    "    \n",
    "    errors_df.plot(x = x_col, y = col,ax=ax, \n",
    "                   kind = 'line',color = colors[i],\n",
    "                  label = error_cols[1-i])\n",
    "    \n",
    "    \n",
    "\n",
    "plt.fill_between(errors_df[log_key], errors_df['rev_test_error'] - errors_df['std_cv_error']/smoother,\n",
    "                 errors_df['rev_test_error'] + errors_df['std_cv_error']/smoother, alpha=0.2,\n",
    "                 color=colors[1], lw=lw)\n",
    "\n",
    "# sup_title_str = \"\"\n",
    "\n",
    "# plt.suptitle(\"\\n\".join(wrap(sup_title_str)),\n",
    "#          y=1.03,# otherwise twiny and title will overlap\n",
    "#          fontsize=18,\n",
    "#             )\n",
    "\n",
    "title_str = \"Series of CV scores vs. Test scores for different \\\n",
    " parameter values.\"\n",
    "\n",
    "plt.title(title_str, fontsize=10)\n",
    "\n",
    "plt.xlabel(\"$C$ Param value\")\n",
    "plt.ylabel(\"Score\".format(scoring.capitalize()))\n",
    "# plt.ylabel(\"{} Score\".format(scoring.capitalize()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C</th>\n",
       "      <th>mean_cv_error</th>\n",
       "      <th>std_cv_error</th>\n",
       "      <th>test_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>0.580319</td>\n",
       "      <td>0.123133</td>\n",
       "      <td>0.603903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.350314e-07</td>\n",
       "      <td>0.596025</td>\n",
       "      <td>0.136668</td>\n",
       "      <td>0.616239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.823348e-07</td>\n",
       "      <td>0.640106</td>\n",
       "      <td>0.098702</td>\n",
       "      <td>0.641226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.462092e-07</td>\n",
       "      <td>0.653556</td>\n",
       "      <td>0.084641</td>\n",
       "      <td>0.664021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.324598e-07</td>\n",
       "      <td>0.685450</td>\n",
       "      <td>0.055235</td>\n",
       "      <td>0.686344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.489251e-07</td>\n",
       "      <td>0.694925</td>\n",
       "      <td>0.042020</td>\n",
       "      <td>0.693570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6.061899e-07</td>\n",
       "      <td>0.699042</td>\n",
       "      <td>0.036363</td>\n",
       "      <td>0.696540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.185467e-07</td>\n",
       "      <td>0.701011</td>\n",
       "      <td>0.033385</td>\n",
       "      <td>0.698361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.105295e-06</td>\n",
       "      <td>0.701964</td>\n",
       "      <td>0.031540</td>\n",
       "      <td>0.699700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.492496e-06</td>\n",
       "      <td>0.702533</td>\n",
       "      <td>0.030400</td>\n",
       "      <td>0.700434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2.015338e-06</td>\n",
       "      <td>0.702853</td>\n",
       "      <td>0.029677</td>\n",
       "      <td>0.700851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2.721339e-06</td>\n",
       "      <td>0.703000</td>\n",
       "      <td>0.029199</td>\n",
       "      <td>0.701116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3.674662e-06</td>\n",
       "      <td>0.703041</td>\n",
       "      <td>0.028890</td>\n",
       "      <td>0.701248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>4.961948e-06</td>\n",
       "      <td>0.703010</td>\n",
       "      <td>0.028642</td>\n",
       "      <td>0.701308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>6.700188e-06</td>\n",
       "      <td>0.702957</td>\n",
       "      <td>0.028498</td>\n",
       "      <td>0.701340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>9.047357e-06</td>\n",
       "      <td>0.702876</td>\n",
       "      <td>0.028379</td>\n",
       "      <td>0.701297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.221677e-05</td>\n",
       "      <td>0.702771</td>\n",
       "      <td>0.028269</td>\n",
       "      <td>0.701305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.649648e-05</td>\n",
       "      <td>0.703109</td>\n",
       "      <td>0.028082</td>\n",
       "      <td>0.702457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2.227543e-05</td>\n",
       "      <td>0.703925</td>\n",
       "      <td>0.027809</td>\n",
       "      <td>0.704348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>3.007883e-05</td>\n",
       "      <td>0.706089</td>\n",
       "      <td>0.027246</td>\n",
       "      <td>0.706993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>4.061586e-05</td>\n",
       "      <td>0.708037</td>\n",
       "      <td>0.027205</td>\n",
       "      <td>0.708671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>5.484417e-05</td>\n",
       "      <td>0.709145</td>\n",
       "      <td>0.027279</td>\n",
       "      <td>0.709408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>7.405685e-05</td>\n",
       "      <td>0.709528</td>\n",
       "      <td>0.027822</td>\n",
       "      <td>0.710168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1.000000e-04</td>\n",
       "      <td>0.710008</td>\n",
       "      <td>0.029333</td>\n",
       "      <td>0.710971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1.350314e-04</td>\n",
       "      <td>0.705694</td>\n",
       "      <td>0.046794</td>\n",
       "      <td>0.724026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1.823348e-04</td>\n",
       "      <td>0.720327</td>\n",
       "      <td>0.076028</td>\n",
       "      <td>0.734395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2.462092e-04</td>\n",
       "      <td>0.719724</td>\n",
       "      <td>0.108067</td>\n",
       "      <td>0.743688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>3.324598e-04</td>\n",
       "      <td>0.724182</td>\n",
       "      <td>0.142155</td>\n",
       "      <td>0.751340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>4.489251e-04</td>\n",
       "      <td>0.723998</td>\n",
       "      <td>0.175801</td>\n",
       "      <td>0.759742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>6.061899e-04</td>\n",
       "      <td>0.731007</td>\n",
       "      <td>0.198505</td>\n",
       "      <td>0.765270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>1.649648e-02</td>\n",
       "      <td>0.754285</td>\n",
       "      <td>0.221370</td>\n",
       "      <td>0.781800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>2.227543e-02</td>\n",
       "      <td>0.754831</td>\n",
       "      <td>0.220088</td>\n",
       "      <td>0.782245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>3.007883e-02</td>\n",
       "      <td>0.755316</td>\n",
       "      <td>0.218927</td>\n",
       "      <td>0.782556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>4.061586e-02</td>\n",
       "      <td>0.755683</td>\n",
       "      <td>0.217877</td>\n",
       "      <td>0.782716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>5.484417e-02</td>\n",
       "      <td>0.755917</td>\n",
       "      <td>0.217068</td>\n",
       "      <td>0.782817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>7.405685e-02</td>\n",
       "      <td>0.756071</td>\n",
       "      <td>0.216424</td>\n",
       "      <td>0.782876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>1.000000e-01</td>\n",
       "      <td>0.756173</td>\n",
       "      <td>0.215939</td>\n",
       "      <td>0.782913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>1.350314e-01</td>\n",
       "      <td>0.756238</td>\n",
       "      <td>0.215576</td>\n",
       "      <td>0.782930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>1.823348e-01</td>\n",
       "      <td>0.756283</td>\n",
       "      <td>0.215291</td>\n",
       "      <td>0.782941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>2.462092e-01</td>\n",
       "      <td>0.756304</td>\n",
       "      <td>0.215107</td>\n",
       "      <td>0.782948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>3.324598e-01</td>\n",
       "      <td>0.756322</td>\n",
       "      <td>0.214942</td>\n",
       "      <td>0.782972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>4.489251e-01</td>\n",
       "      <td>0.756341</td>\n",
       "      <td>0.214827</td>\n",
       "      <td>0.782973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>6.061899e-01</td>\n",
       "      <td>0.756351</td>\n",
       "      <td>0.214746</td>\n",
       "      <td>0.782979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>8.185467e-01</td>\n",
       "      <td>0.756343</td>\n",
       "      <td>0.214697</td>\n",
       "      <td>0.782983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>1.105295e+00</td>\n",
       "      <td>0.756379</td>\n",
       "      <td>0.214579</td>\n",
       "      <td>0.782984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>1.492496e+00</td>\n",
       "      <td>0.756360</td>\n",
       "      <td>0.214590</td>\n",
       "      <td>0.782990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>2.015338e+00</td>\n",
       "      <td>0.756362</td>\n",
       "      <td>0.214558</td>\n",
       "      <td>0.782991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>2.721339e+00</td>\n",
       "      <td>0.756362</td>\n",
       "      <td>0.214556</td>\n",
       "      <td>0.782990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>3.674662e+00</td>\n",
       "      <td>0.756355</td>\n",
       "      <td>0.214562</td>\n",
       "      <td>0.782987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>4.961948e+00</td>\n",
       "      <td>0.756364</td>\n",
       "      <td>0.214540</td>\n",
       "      <td>0.782989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>6.700188e+00</td>\n",
       "      <td>0.756360</td>\n",
       "      <td>0.214548</td>\n",
       "      <td>0.782985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>9.047357e+00</td>\n",
       "      <td>0.756364</td>\n",
       "      <td>0.214534</td>\n",
       "      <td>0.782985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>1.221677e+01</td>\n",
       "      <td>0.756358</td>\n",
       "      <td>0.214548</td>\n",
       "      <td>0.782984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>1.649648e+01</td>\n",
       "      <td>0.756358</td>\n",
       "      <td>0.214546</td>\n",
       "      <td>0.782984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>2.227543e+01</td>\n",
       "      <td>0.756357</td>\n",
       "      <td>0.214547</td>\n",
       "      <td>0.782983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>3.007883e+01</td>\n",
       "      <td>0.756357</td>\n",
       "      <td>0.214548</td>\n",
       "      <td>0.782982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>4.061586e+01</td>\n",
       "      <td>0.756357</td>\n",
       "      <td>0.214549</td>\n",
       "      <td>0.782986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>5.484417e+01</td>\n",
       "      <td>0.756356</td>\n",
       "      <td>0.214550</td>\n",
       "      <td>0.782983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>7.405685e+01</td>\n",
       "      <td>0.756356</td>\n",
       "      <td>0.214551</td>\n",
       "      <td>0.782983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>1.000000e+02</td>\n",
       "      <td>0.756356</td>\n",
       "      <td>0.214550</td>\n",
       "      <td>0.782980</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               C  mean_cv_error  std_cv_error  test_error\n",
       "0   1.000000e-07       0.580319      0.123133    0.603903\n",
       "1   1.350314e-07       0.596025      0.136668    0.616239\n",
       "2   1.823348e-07       0.640106      0.098702    0.641226\n",
       "3   2.462092e-07       0.653556      0.084641    0.664021\n",
       "4   3.324598e-07       0.685450      0.055235    0.686344\n",
       "5   4.489251e-07       0.694925      0.042020    0.693570\n",
       "6   6.061899e-07       0.699042      0.036363    0.696540\n",
       "7   8.185467e-07       0.701011      0.033385    0.698361\n",
       "8   1.105295e-06       0.701964      0.031540    0.699700\n",
       "9   1.492496e-06       0.702533      0.030400    0.700434\n",
       "10  2.015338e-06       0.702853      0.029677    0.700851\n",
       "11  2.721339e-06       0.703000      0.029199    0.701116\n",
       "12  3.674662e-06       0.703041      0.028890    0.701248\n",
       "13  4.961948e-06       0.703010      0.028642    0.701308\n",
       "14  6.700188e-06       0.702957      0.028498    0.701340\n",
       "15  9.047357e-06       0.702876      0.028379    0.701297\n",
       "16  1.221677e-05       0.702771      0.028269    0.701305\n",
       "17  1.649648e-05       0.703109      0.028082    0.702457\n",
       "18  2.227543e-05       0.703925      0.027809    0.704348\n",
       "19  3.007883e-05       0.706089      0.027246    0.706993\n",
       "20  4.061586e-05       0.708037      0.027205    0.708671\n",
       "21  5.484417e-05       0.709145      0.027279    0.709408\n",
       "22  7.405685e-05       0.709528      0.027822    0.710168\n",
       "23  1.000000e-04       0.710008      0.029333    0.710971\n",
       "24  1.350314e-04       0.705694      0.046794    0.724026\n",
       "25  1.823348e-04       0.720327      0.076028    0.734395\n",
       "26  2.462092e-04       0.719724      0.108067    0.743688\n",
       "27  3.324598e-04       0.724182      0.142155    0.751340\n",
       "28  4.489251e-04       0.723998      0.175801    0.759742\n",
       "29  6.061899e-04       0.731007      0.198505    0.765270\n",
       "..           ...            ...           ...         ...\n",
       "40  1.649648e-02       0.754285      0.221370    0.781800\n",
       "41  2.227543e-02       0.754831      0.220088    0.782245\n",
       "42  3.007883e-02       0.755316      0.218927    0.782556\n",
       "43  4.061586e-02       0.755683      0.217877    0.782716\n",
       "44  5.484417e-02       0.755917      0.217068    0.782817\n",
       "45  7.405685e-02       0.756071      0.216424    0.782876\n",
       "46  1.000000e-01       0.756173      0.215939    0.782913\n",
       "47  1.350314e-01       0.756238      0.215576    0.782930\n",
       "48  1.823348e-01       0.756283      0.215291    0.782941\n",
       "49  2.462092e-01       0.756304      0.215107    0.782948\n",
       "50  3.324598e-01       0.756322      0.214942    0.782972\n",
       "51  4.489251e-01       0.756341      0.214827    0.782973\n",
       "52  6.061899e-01       0.756351      0.214746    0.782979\n",
       "53  8.185467e-01       0.756343      0.214697    0.782983\n",
       "54  1.105295e+00       0.756379      0.214579    0.782984\n",
       "55  1.492496e+00       0.756360      0.214590    0.782990\n",
       "56  2.015338e+00       0.756362      0.214558    0.782991\n",
       "57  2.721339e+00       0.756362      0.214556    0.782990\n",
       "58  3.674662e+00       0.756355      0.214562    0.782987\n",
       "59  4.961948e+00       0.756364      0.214540    0.782989\n",
       "60  6.700188e+00       0.756360      0.214548    0.782985\n",
       "61  9.047357e+00       0.756364      0.214534    0.782985\n",
       "62  1.221677e+01       0.756358      0.214548    0.782984\n",
       "63  1.649648e+01       0.756358      0.214546    0.782984\n",
       "64  2.227543e+01       0.756357      0.214547    0.782983\n",
       "65  3.007883e+01       0.756357      0.214548    0.782982\n",
       "66  4.061586e+01       0.756357      0.214549    0.782986\n",
       "67  5.484417e+01       0.756356      0.214550    0.782983\n",
       "68  7.405685e+01       0.756356      0.214551    0.782983\n",
       "69  1.000000e+02       0.756356      0.214550    0.782980\n",
       "\n",
       "[70 rows x 4 columns]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errors_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "group_cols = [\n",
    "        'penalty',\n",
    "              'C',\n",
    "]\n",
    "\n",
    "an_col = 'mean_score'\n",
    "param_col = 'C'\n",
    "#.groupby(group_cols)['mean_score'].first()\n",
    "filter_col = 'penalty'\n",
    "filter_val = 'l1'\n",
    "view = (cv_result\n",
    "        .query('{}==@filter_val'.format(filter_col))\n",
    "        [[ param_col,filter_col,an_col]]\n",
    "        #.sort_values('mean_score',ascending=False)\n",
    "       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    200.000000\n",
       "mean       0.802970\n",
       "std        0.001776\n",
       "min        0.802210\n",
       "25%        0.802213\n",
       "50%        0.802226\n",
       "75%        0.802275\n",
       "max        0.809081\n",
       "Name: mean_score, dtype: float64"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "view[an_col].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x10904950>"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkoAAAG3CAYAAABLx3rDAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nBYoSAACABYoSAACABYoSAACAhf8HvDYvWZKN96MAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc683a94b10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "# plot histogram on cross validated scores\n",
    "view[an_col].hist()\n",
    "\n",
    "sup_title_str = \"Histogram of CV training scores for different \\\n",
    "parameter values.\"\n",
    "\n",
    "plt.suptitle(\"\\n\".join(wrap(sup_title_str)),\n",
    "         y=1.03,# otherwise twiny and title will overlap\n",
    "         fontsize=18,\n",
    "            )\n",
    "\n",
    "title_str = \"Different $C$ params \\\n",
    "for a Logistic Regression Classifier\\'s with \\\n",
    "{} regularization\".format(\n",
    "    filter_val)\n",
    "\n",
    "plt.title(title_str, fontsize=10)\n",
    "\n",
    "plt.xlabel(\"$C$ Param value\".format(filter_val))\n",
    "plt.ylabel(\"CV {} Score\".format(scoring.capitalize()))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# view = view.sort_values(param_col)\n",
    "# x_vals = view[param_col]\n",
    "# y_vals = view[param_col]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x109a7750>"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgkAAAGjCAYAAACmDYbtAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nl1gSiIiIyCWWBCIiInKJJYGIiIhc+n+oYWPYtdXSqQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1099de90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax, fig = plt.subplots(figsize=(8,6))\n",
    "# plt.title(\"Validation Curve with Logistic Regression Classifier\")\n",
    "# plt.xlabel(\"Regularization $C$ Param\")\n",
    "# plt.ylabel(\"AUC Score\")\n",
    "# plt.ylim(0.0, 10.1)\n",
    "\n",
    "lw = 1\n",
    "\n",
    "plt.semilogx(\n",
    "    view[param_col], \n",
    "    view[an_col],#\n",
    "                          label=\"Training score\",\n",
    "             color=\"navy\", lw=lw)\n",
    "\n",
    "\n",
    "title_str = \"Cross-validated Training Score \\\n",
    "for a Logistic Regression Classifier\\'s $C$ \\\n",
    "param with {} regularization\".format(\n",
    "    filter_val)\n",
    "\n",
    "plt.title(\"\\n\".join(wrap(title_str)),\n",
    "         y=1,# otherwise twiny and title will overlap\n",
    "         )\n",
    "\n",
    "\n",
    "plt.xlabel(\"$C$ Param\".format(filter_val))\n",
    "plt.ylabel(\"{} Score\".format(scoring.capitalize()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## other linspace plot with double axis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0xe371dd0>"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhMAAAHRCAYAAADQazsGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nVZhMEBERUav8f0NC5XoO0yykAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xe33d110>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "N=50\n",
    "\n",
    "labels = ['Smallest {} $C$ values '.format(N), 'Biggest {} $C$ values '.format(N)]\n",
    "\n",
    "c = palette[0]\n",
    "view.head(N).set_index(param_col)[an_col].plot(\n",
    "    ax=ax,\n",
    "    kind = 'line',\n",
    "    color='b',\n",
    "#     legend=True,\n",
    "    label =labels[0],\n",
    ")\n",
    "\n",
    "# set xlabel \n",
    "# ax.set_xlabel(labels[0])\n",
    "# set series legend\n",
    "# ax.legend(loc=0)\n",
    "\n",
    "# get a new axis to plot on with new color\n",
    "ax2 = ax.twiny()\n",
    "c = palette[1]\n",
    "view.tail(N).set_index(param_col)[an_col].plot(\n",
    "    ax=ax2,\n",
    "    kind = 'line',\n",
    "    color='r',\n",
    "#     legend=True,\n",
    "    label =labels[1],\n",
    "                                               \n",
    "         )\n",
    "\n",
    "ax.set_xlabel(labels[0])\n",
    "ax2.set_xlabel(labels[1])\n",
    "\n",
    "# get all plotted line objects\n",
    "lines = ax.get_lines() + ax2.get_lines()\n",
    "# set a common legend\n",
    "ax.legend(lines, [l.get_label() for l in lines], loc='upper center')\n",
    "\n",
    "# pass those lines legends\n",
    "\n",
    "# # set series legend\n",
    "# ax2.legend(loc='best')\n",
    "\n",
    "\n",
    "title_str = \"Cross-validated Training Score \\\n",
    "for a Logistic Regression Classifier\\'s $C$ \\\n",
    "param with {} regularization\".format(\n",
    "    filter_val)\n",
    "\n",
    "plt.title(\"\\n\".join(wrap(title_str)),\n",
    "         y=1.15,# otherwise twiny and title will overlap\n",
    "         )\n",
    "\n",
    "\n",
    "plt.xlabel(\"$C$ Param\".format(filter_val))\n",
    "plt.ylabel(\"{} Score\".format(scoring.capitalize()))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C</th>\n",
       "      <th>penalty</th>\n",
       "      <th>mean_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>108.436597</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.399861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>121.738273</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.401293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>136.671636</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.395969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>153.436841</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.389284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>172.258597</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.385560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>193.389175</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.407473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>217.111795</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.380661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>243.744415</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.380432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>273.644000</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.387889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>307.211300</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.398666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>344.896226</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.377651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>387.203878</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.404169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>434.701316</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.384196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>488.025158</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.383940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>547.890118</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.406795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>615.098579</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.380244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>690.551352</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.377829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>775.259749</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.405910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>870.359136</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.413266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>977.124154</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.385185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>1096.985798</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.391688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>1231.550603</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.406648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>1382.622174</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.395450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>1552.225357</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.405521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>1742.633386</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.377643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>1956.398344</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.409521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>2196.385372</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.377190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>2465.811076</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.391630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>2768.286630</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.405797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>3107.866188</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.387168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>3489.101213</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.383911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>3917.101491</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.378653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>4397.603609</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.380389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>4937.047853</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.411112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>5542.664521</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.408103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351</th>\n",
       "      <td>6222.570837</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.389446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353</th>\n",
       "      <td>6985.879747</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.378755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>7842.822061</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.381505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>8804.883582</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.377421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>9884.959047</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.385547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>11097.524964</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.400973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>12458.833643</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.410306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>13987.131026</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.394954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367</th>\n",
       "      <td>15702.901247</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.386756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>17629.141181</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.393072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>19791.668679</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.384939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>22219.468609</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.401353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>24945.081352</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.425352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377</th>\n",
       "      <td>28005.038942</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.390488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>31440.354716</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.407668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>35297.073027</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.418337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>39626.886387</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.380862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>44487.828311</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.389284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>49945.051159</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.389927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>56071.699382</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.376942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>62949.889902</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.405721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>70671.812739</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.386395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>79340.966658</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.385966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>89073.546386</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.398113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>100000.000000</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.395078</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 C penalty  mean_score\n",
       "281     108.436597      l2    0.399861\n",
       "283     121.738273      l2    0.401293\n",
       "285     136.671636      l2    0.395969\n",
       "287     153.436841      l2    0.389284\n",
       "289     172.258597      l2    0.385560\n",
       "291     193.389175      l2    0.407473\n",
       "293     217.111795      l2    0.380661\n",
       "295     243.744415      l2    0.380432\n",
       "297     273.644000      l2    0.387889\n",
       "299     307.211300      l2    0.398666\n",
       "301     344.896226      l2    0.377651\n",
       "303     387.203878      l2    0.404169\n",
       "305     434.701316      l2    0.384196\n",
       "307     488.025158      l2    0.383940\n",
       "309     547.890118      l2    0.406795\n",
       "311     615.098579      l2    0.380244\n",
       "313     690.551352      l2    0.377829\n",
       "315     775.259749      l2    0.405910\n",
       "317     870.359136      l2    0.413266\n",
       "319     977.124154      l2    0.385185\n",
       "321    1096.985798      l2    0.391688\n",
       "323    1231.550603      l2    0.406648\n",
       "325    1382.622174      l2    0.395450\n",
       "327    1552.225357      l2    0.405521\n",
       "329    1742.633386      l2    0.377643\n",
       "331    1956.398344      l2    0.409521\n",
       "333    2196.385372      l2    0.377190\n",
       "335    2465.811076      l2    0.391630\n",
       "337    2768.286630      l2    0.405797\n",
       "339    3107.866188      l2    0.387168\n",
       "341    3489.101213      l2    0.383911\n",
       "343    3917.101491      l2    0.378653\n",
       "345    4397.603609      l2    0.380389\n",
       "347    4937.047853      l2    0.411112\n",
       "349    5542.664521      l2    0.408103\n",
       "351    6222.570837      l2    0.389446\n",
       "353    6985.879747      l2    0.378755\n",
       "355    7842.822061      l2    0.381505\n",
       "357    8804.883582      l2    0.377421\n",
       "359    9884.959047      l2    0.385547\n",
       "361   11097.524964      l2    0.400973\n",
       "363   12458.833643      l2    0.410306\n",
       "365   13987.131026      l2    0.394954\n",
       "367   15702.901247      l2    0.386756\n",
       "369   17629.141181      l2    0.393072\n",
       "371   19791.668679      l2    0.384939\n",
       "373   22219.468609      l2    0.401353\n",
       "375   24945.081352      l2    0.425352\n",
       "377   28005.038942      l2    0.390488\n",
       "379   31440.354716      l2    0.407668\n",
       "381   35297.073027      l2    0.418337\n",
       "383   39626.886387      l2    0.380862\n",
       "385   44487.828311      l2    0.389284\n",
       "387   49945.051159      l2    0.389927\n",
       "389   56071.699382      l2    0.376942\n",
       "391   62949.889902      l2    0.405721\n",
       "393   70671.812739      l2    0.386395\n",
       "395   79340.966658      l2    0.385966\n",
       "397   89073.546386      l2    0.398113\n",
       "399  100000.000000      l2    0.395078"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "view.tail(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## now get erros along the cv procedure and plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# reverse_scores_train = 1 - train_scores\n",
    "# reverse_scores_test = 1 - test_scores\n",
    "\n",
    "train_scores_mean = errors\n",
    "train_scores_std = pd.np.std(errors)\n",
    "test_scores_mean = errors_val\n",
    "test_scores_std = pd.np.std(errors_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.np.std(errors), param_range.shape, train_scores_mean.shape, test_scores_mean.shape, train_scores_std.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "size = param_range.shape[0]\n",
    "#i = 0.002\n",
    "#pd.np.linspace(1+i,1,size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ax, fig = plt.subplots(figsize=(8,6))\n",
    "plt.title(\"Validation Curve with Logistic Regression Classifier\")\n",
    "plt.xlabel(\"Regularization $C$ Param\")\n",
    "plt.ylabel(\"AUC Score\")\n",
    "# plt.ylim(0.0, 10.1)\n",
    "\n",
    "lw = 1\n",
    "\n",
    "plt.semilogx(param_range, train_scores_mean,#\n",
    "                          label=\"Training score\",\n",
    "             color=\"navy\", lw=lw)\n",
    "\n",
    "# plt.fill_between(param_range, train_scores_mean - train_scores_std,\n",
    "#                  train_scores_mean + train_scores_std, alpha=0.2,\n",
    "#                  color=\"blue\", lw=lw)\n",
    "\n",
    "plt.semilogx(param_range, test_scores_mean,#\n",
    "             label=\"score for test set\",\n",
    "             color=\"darkorange\", lw=lw)\n",
    "\n",
    "# plt.fill_between(param_range, test_scores_mean - test_scores_std,\n",
    "#                  test_scores_mean + test_scores_std, alpha=0.2,\n",
    "#                  color=\"red\", lw=lw)\n",
    "\n",
    "plt.legend(loc=\"best\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# REST of shit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count Featurizer on Antennas\n",
    "nos quedamos con las columnas de antennas y en graphlab aplicamos el algo de CountFeaturizer para cada categoria de\n",
    "Antenna_ID_N\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "import graphlab as gl\n",
    "from graphlab.toolkits.feature_engineering import *\n",
    "ant_cols = [col for col in X_train.columns if \"ANTENNA_ID\" in col]\n",
    "ant_sframe_fit = gl.SFrame(X_fit[ant_cols + ['y']])\n",
    "ant_sframe_train = gl.SFrame(X_train[ant_cols + ['y']])\n",
    "ant_sframe_val = gl.SFrame(X_val[ant_cols + ['y']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "countfeat = gl.feature_engineering.create(ant_sframe_fit, \n",
    "               CountFeaturizer(target='y'))\n",
    "\n",
    "# Transform the train set. This is the dataset I will train my classifier on\n",
    "transformed_ant_train = countfeat.transform(ant_sframe_train)\n",
    "transformed_ant_val = countfeat.transform(ant_sframe_val)\n",
    "\n",
    "del ant_sframe_fit,ant_sframe_train,ant_sframe_val\n",
    "\n",
    "#por alguna razon guarda los valores de probabilidad como una lista de un unico valor\n",
    "for col in [col for col in transformed_ant_train.column_names() if \"prob_\" in col]:\n",
    "    transformed_ant_train[col] = transformed_ant_train[col].apply(lambda x: x[0]) \n",
    "    transformed_ant_val[col] = transformed_ant_val[col].apply(lambda x: x[0]) \n",
    "\n",
    "#me quedo solo con los valores de probabilidad.\n",
    "transformed_ant_train = transformed_ant_train[[col for col in transformed_ant_train.column_names() if \"prob_\" in col]]\n",
    "transformed_ant_val = transformed_ant_val[[col for col in transformed_ant_train.column_names() if \"prob_\" in col]]\n",
    "\n",
    "transformed_ant_val = transformed_ant_val.to_dataframe()\n",
    "transformed_ant_train = transformed_ant_train.to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_val[ant_cols] = transformed_ant_val.values\n",
    "X_train[ant_cols] = transformed_ant_train.values\n",
    "del transformed_ant_train, transformed_ant_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validate SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_grid = [\n",
    "  { 'alpha': [1e-3,5*1e-3,1e-2], 'l1_ratio': [3*1e-2,1e-3,6*1e-4], 'n_iter': [2,3]\n",
    "  }\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 18 candidates, totalling 54 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Virtualenvs/mateo/lib/python3.4/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] n_iter=2, alpha=0.001, l1_ratio=0.03 ............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Virtualenvs/mateo/lib/python3.4/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] n_iter=2, alpha=0.001, l1_ratio=0.03 ............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Virtualenvs/mateo/lib/python3.4/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ... n_iter=2, alpha=0.001, l1_ratio=0.03, score=0.125354 -   2.5s\n",
      "[CV] n_iter=2, alpha=0.001, l1_ratio=0.03 ............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Virtualenvs/mateo/lib/python3.4/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ... n_iter=2, alpha=0.001, l1_ratio=0.03, score=0.127442 -   2.5s\n",
      "[CV] n_iter=3, alpha=0.001, l1_ratio=0.03 ............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Virtualenvs/mateo/lib/python3.4/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ... n_iter=2, alpha=0.001, l1_ratio=0.03, score=0.119463 -   2.5s\n",
      "[CV] n_iter=3, alpha=0.001, l1_ratio=0.03 ............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Virtualenvs/mateo/lib/python3.4/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ... n_iter=3, alpha=0.001, l1_ratio=0.03, score=0.132910 -   3.1s\n",
      "[CV] n_iter=3, alpha=0.001, l1_ratio=0.03 ............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Virtualenvs/mateo/lib/python3.4/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ... n_iter=3, alpha=0.001, l1_ratio=0.03, score=0.133858 -   3.1s\n",
      "[CV] n_iter=2, alpha=0.001, l1_ratio=0.001 ...........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Virtualenvs/mateo/lib/python3.4/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ... n_iter=3, alpha=0.001, l1_ratio=0.03, score=0.125862 -   3.1s\n",
      "[CV] n_iter=2, alpha=0.001, l1_ratio=0.001 ...........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Virtualenvs/mateo/lib/python3.4/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .. n_iter=2, alpha=0.001, l1_ratio=0.001, score=0.114065 -   2.5s\n",
      "[CV] n_iter=2, alpha=0.001, l1_ratio=0.001 ...........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Virtualenvs/mateo/lib/python3.4/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .. n_iter=2, alpha=0.001, l1_ratio=0.001, score=0.125576 -   2.5s\n",
      "[CV] n_iter=3, alpha=0.001, l1_ratio=0.001 ...........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Virtualenvs/mateo/lib/python3.4/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .. n_iter=2, alpha=0.001, l1_ratio=0.001, score=0.125882 -   2.8s\n",
      "[CV] n_iter=3, alpha=0.001, l1_ratio=0.001 ...........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Virtualenvs/mateo/lib/python3.4/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .. n_iter=3, alpha=0.001, l1_ratio=0.001, score=0.138072 -   3.3s\n",
      "[CV] n_iter=3, alpha=0.001, l1_ratio=0.001 ...........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Virtualenvs/mateo/lib/python3.4/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .. n_iter=3, alpha=0.001, l1_ratio=0.001, score=0.133482 -   3.1s\n",
      "[CV] n_iter=2, alpha=0.001, l1_ratio=0.0006000000000000001 ...........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Virtualenvs/mateo/lib/python3.4/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .. n_iter=3, alpha=0.001, l1_ratio=0.001, score=0.133945 -   3.2s\n",
      "[CV] n_iter=2, alpha=0.001, l1_ratio=0.0006000000000000001 ...........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Virtualenvs/mateo/lib/python3.4/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_iter=2, alpha=0.001, l1_ratio=0.0006000000000000001, score=0.124318 -   2.5s\n",
      "[CV] n_iter=2, alpha=0.001, l1_ratio=0.0006000000000000001 ...........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Virtualenvs/mateo/lib/python3.4/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_iter=2, alpha=0.001, l1_ratio=0.0006000000000000001, score=0.125224 -   2.5s\n",
      "[CV] n_iter=3, alpha=0.001, l1_ratio=0.0006000000000000001 ...........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Virtualenvs/mateo/lib/python3.4/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_iter=2, alpha=0.001, l1_ratio=0.0006000000000000001, score=0.129423 -   2.5s\n",
      "[CV] n_iter=3, alpha=0.001, l1_ratio=0.0006000000000000001 ...........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Virtualenvs/mateo/lib/python3.4/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_iter=3, alpha=0.001, l1_ratio=0.0006000000000000001, score=0.131845 -   3.1s\n",
      "[CV] n_iter=3, alpha=0.001, l1_ratio=0.0006000000000000001 ...........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Virtualenvs/mateo/lib/python3.4/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_iter=3, alpha=0.001, l1_ratio=0.0006000000000000001, score=0.135827 -   3.1s\n",
      "[CV] n_iter=2, alpha=0.005, l1_ratio=0.03 ............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Virtualenvs/mateo/lib/python3.4/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_iter=3, alpha=0.001, l1_ratio=0.0006000000000000001, score=0.128485 -   3.1s\n",
      "[CV] n_iter=2, alpha=0.005, l1_ratio=0.03 ............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Virtualenvs/mateo/lib/python3.4/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ... n_iter=2, alpha=0.005, l1_ratio=0.03, score=0.125477 -   2.4s\n",
      "[CV] n_iter=2, alpha=0.005, l1_ratio=0.03 ............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Virtualenvs/mateo/lib/python3.4/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ... n_iter=2, alpha=0.005, l1_ratio=0.03, score=0.125957 -   2.8s\n",
      "[CV] n_iter=3, alpha=0.005, l1_ratio=0.03 ............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Virtualenvs/mateo/lib/python3.4/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ... n_iter=2, alpha=0.005, l1_ratio=0.03, score=0.127511 -   2.6s\n",
      "[CV] n_iter=3, alpha=0.005, l1_ratio=0.03 ............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Virtualenvs/mateo/lib/python3.4/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ... n_iter=3, alpha=0.005, l1_ratio=0.03, score=0.127618 -   2.8s\n",
      "[CV] n_iter=3, alpha=0.005, l1_ratio=0.03 ............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Virtualenvs/mateo/lib/python3.4/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ... n_iter=3, alpha=0.005, l1_ratio=0.03, score=0.125386 -   2.8s\n",
      "[CV] n_iter=2, alpha=0.005, l1_ratio=0.001 ...........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Virtualenvs/mateo/lib/python3.4/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ... n_iter=3, alpha=0.005, l1_ratio=0.03, score=0.136983 -   3.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  24 tasks      | elapsed:   47.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] n_iter=2, alpha=0.005, l1_ratio=0.001 ...........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Virtualenvs/mateo/lib/python3.4/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .. n_iter=2, alpha=0.005, l1_ratio=0.001, score=0.120290 -   2.5s\n",
      "[CV] n_iter=2, alpha=0.005, l1_ratio=0.001 ...........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Virtualenvs/mateo/lib/python3.4/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .. n_iter=2, alpha=0.005, l1_ratio=0.001, score=0.118753 -   2.5s\n",
      "[CV] n_iter=3, alpha=0.005, l1_ratio=0.001 ...........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Virtualenvs/mateo/lib/python3.4/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .. n_iter=2, alpha=0.005, l1_ratio=0.001, score=0.127159 -   2.9s\n",
      "[CV] n_iter=3, alpha=0.005, l1_ratio=0.001 ...........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Virtualenvs/mateo/lib/python3.4/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .. n_iter=3, alpha=0.005, l1_ratio=0.001, score=0.127485 -   3.3s\n",
      "[CV] n_iter=3, alpha=0.005, l1_ratio=0.001 ...........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Virtualenvs/mateo/lib/python3.4/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .. n_iter=3, alpha=0.005, l1_ratio=0.001, score=0.139728 -   3.1s\n",
      "[CV] n_iter=2, alpha=0.005, l1_ratio=0.0006000000000000001 ...........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Virtualenvs/mateo/lib/python3.4/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .. n_iter=3, alpha=0.005, l1_ratio=0.001, score=0.130469 -   3.1s\n",
      "[CV] n_iter=2, alpha=0.005, l1_ratio=0.0006000000000000001 ...........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Virtualenvs/mateo/lib/python3.4/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_iter=2, alpha=0.005, l1_ratio=0.0006000000000000001, score=0.129161 -   2.5s\n",
      "[CV] n_iter=2, alpha=0.005, l1_ratio=0.0006000000000000001 ...........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Virtualenvs/mateo/lib/python3.4/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_iter=2, alpha=0.005, l1_ratio=0.0006000000000000001, score=0.130159 -   2.5s\n",
      "[CV] n_iter=3, alpha=0.005, l1_ratio=0.0006000000000000001 ...........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Virtualenvs/mateo/lib/python3.4/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_iter=2, alpha=0.005, l1_ratio=0.0006000000000000001, score=0.127613 -   2.5s\n",
      "[CV] n_iter=3, alpha=0.005, l1_ratio=0.0006000000000000001 ...........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Virtualenvs/mateo/lib/python3.4/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_iter=3, alpha=0.005, l1_ratio=0.0006000000000000001, score=0.132956 -   3.1s\n",
      "[CV] n_iter=3, alpha=0.005, l1_ratio=0.0006000000000000001 ...........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Virtualenvs/mateo/lib/python3.4/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_iter=3, alpha=0.005, l1_ratio=0.0006000000000000001, score=0.143005 -   3.1s\n",
      "[CV] n_iter=2, alpha=0.01, l1_ratio=0.03 .............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Virtualenvs/mateo/lib/python3.4/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_iter=3, alpha=0.005, l1_ratio=0.0006000000000000001, score=0.135926 -   3.1s\n",
      "[CV] n_iter=2, alpha=0.01, l1_ratio=0.03 .............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Virtualenvs/mateo/lib/python3.4/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .... n_iter=2, alpha=0.01, l1_ratio=0.03, score=0.128098 -   2.4s\n",
      "[CV] n_iter=2, alpha=0.01, l1_ratio=0.03 .............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Virtualenvs/mateo/lib/python3.4/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .... n_iter=2, alpha=0.01, l1_ratio=0.03, score=0.127078 -   2.7s\n",
      "[CV] n_iter=3, alpha=0.01, l1_ratio=0.03 .............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Virtualenvs/mateo/lib/python3.4/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .... n_iter=2, alpha=0.01, l1_ratio=0.03, score=0.126921 -   2.5s\n",
      "[CV] n_iter=3, alpha=0.01, l1_ratio=0.03 .............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Virtualenvs/mateo/lib/python3.4/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .... n_iter=3, alpha=0.01, l1_ratio=0.03, score=0.138152 -   3.6s\n",
      "[CV] n_iter=3, alpha=0.01, l1_ratio=0.03 .............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Virtualenvs/mateo/lib/python3.4/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .... n_iter=3, alpha=0.01, l1_ratio=0.03, score=0.106208 -   3.1s\n",
      "[CV] n_iter=2, alpha=0.01, l1_ratio=0.001 ............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Virtualenvs/mateo/lib/python3.4/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .... n_iter=3, alpha=0.01, l1_ratio=0.03, score=0.143076 -   2.8s\n",
      "[CV] n_iter=2, alpha=0.01, l1_ratio=0.001 ............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Virtualenvs/mateo/lib/python3.4/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ... n_iter=2, alpha=0.01, l1_ratio=0.001, score=0.132427 -   2.5s\n",
      "[CV] n_iter=2, alpha=0.01, l1_ratio=0.001 ............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Virtualenvs/mateo/lib/python3.4/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ... n_iter=2, alpha=0.01, l1_ratio=0.001, score=0.125901 -   2.9s\n",
      "[CV] n_iter=3, alpha=0.01, l1_ratio=0.001 ............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Virtualenvs/mateo/lib/python3.4/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ... n_iter=2, alpha=0.01, l1_ratio=0.001, score=0.128001 -   2.7s\n",
      "[CV] n_iter=3, alpha=0.01, l1_ratio=0.001 ............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Virtualenvs/mateo/lib/python3.4/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ... n_iter=3, alpha=0.01, l1_ratio=0.001, score=0.135568 -   3.1s\n",
      "[CV] n_iter=3, alpha=0.01, l1_ratio=0.001 ............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Virtualenvs/mateo/lib/python3.4/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] n_iter=2, alpha=0.01, l1_ratio=0.0006000000000000001 ............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Virtualenvs/mateo/lib/python3.4/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ... n_iter=3, alpha=0.01, l1_ratio=0.001, score=0.132579 -   4.4s\n",
      "[CV] ... n_iter=3, alpha=0.01, l1_ratio=0.001, score=0.136589 -   3.7s\n",
      "[CV] n_iter=2, alpha=0.01, l1_ratio=0.0006000000000000001 ............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Virtualenvs/mateo/lib/python3.4/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_iter=2, alpha=0.01, l1_ratio=0.0006000000000000001, score=0.124134 -   2.8s\n",
      "[CV] n_iter=2, alpha=0.01, l1_ratio=0.0006000000000000001 ............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Virtualenvs/mateo/lib/python3.4/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_iter=2, alpha=0.01, l1_ratio=0.0006000000000000001, score=0.130883 -   2.5s\n",
      "[CV] n_iter=3, alpha=0.01, l1_ratio=0.0006000000000000001 ............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Virtualenvs/mateo/lib/python3.4/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_iter=2, alpha=0.01, l1_ratio=0.0006000000000000001, score=0.122741 -   3.5s\n",
      "[CV] n_iter=3, alpha=0.01, l1_ratio=0.0006000000000000001 ............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Virtualenvs/mateo/lib/python3.4/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_iter=3, alpha=0.01, l1_ratio=0.0006000000000000001, score=0.132433 -   3.7s\n",
      "[CV] n_iter=3, alpha=0.01, l1_ratio=0.0006000000000000001 ............\n",
      "[CV]  n_iter=3, alpha=0.01, l1_ratio=0.0006000000000000001, score=0.135111 -   3.4s\n",
      "[CV]  n_iter=3, alpha=0.01, l1_ratio=0.0006000000000000001, score=0.135908 -   3.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  54 out of  54 | elapsed:  1.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.31      0.47    355992\n",
      "          1       0.06      0.99      0.11     15152\n",
      "\n",
      "avg / total       0.96      0.33      0.45    371144\n",
      "\n",
      "This cell took 108.56432461738586 seconds to run\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "param_grid = [\n",
    "  { 'alpha': [1e-3,5*1e-3,1e-2], 'l1_ratio': [3*1e-2,1e-3,6*1e-4], 'n_iter': [2,3]\n",
    "  }\n",
    "    ]\n",
    "sgd = SGDClassifier(loss='modified_huber', penalty='elasticnet', \n",
    "             fit_intercept=True,  shuffle=True, \n",
    "                    n_jobs=3,learning_rate='optimal', power_t =2, eta0 =5,\n",
    "                    class_weight='balanced', average=40)\n",
    "\n",
    "clf =GridSearchCV(sgd, param_grid, scoring='roc_auc', fit_params=None, n_jobs=4, iid=True, refit=True, \n",
    "verbose=3, pre_dispatch='2*n_jobs', error_score='raise')\n",
    "\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "\n",
    "\n",
    "predicted_proba = pd.DataFrame()\n",
    "predicted_proba['prob'] = clf.predict_proba(X_test).max(axis=1)\n",
    "predicted_proba['class'] = clf.predict(X_test)\n",
    "predicted_proba[gt] =  y_test\n",
    "predicted_proba.sort_values(by = 'prob',ascending = False, inplace = True)\n",
    "\n",
    "cut_percentages = [10,20,30,40]\n",
    "#converted = (predicted_proba['class']==1)\n",
    "#me fijo todos los users que van a convertir en el futuro\n",
    "\n",
    "\n",
    "start = 0\n",
    "mobility_dict = {}\n",
    "index_segments = []\n",
    "for i in cut_percentages:\n",
    "    cut_size = int(len(predicted_proba)*i/100.0)    \n",
    "    bool_array = (~pd.np.ones(len(predicted_proba), dtype=bool))\n",
    "    bool_array[start: start + cut_size] = True\n",
    "    index_segments += [bool_array]\n",
    "    start = start + cut_size\n",
    "#    subtable = \n",
    "    #mobility_dict[str(i)] = predicted_proba.loc[index_segments[-1],'ref_hash']\n",
    "    \n",
    "    print(classification_report(predicted_proba.loc[index_segments[-1],gt].values,\n",
    "                            predicted_proba.loc[index_segments[-1],'class'].values ))\n",
    "    \n",
    "    \n",
    "print(classification_report(predicted_proba.loc[:,gt].values,\n",
    "                            predicted_proba.loc[:,'class'].values ))\n",
    "    \n",
    "    \n",
    "cv_result = pd.DataFrame(columns=['mean_score' ] + [key for key, value in clf.grid_scores_[0].parameters.items() ] )\n",
    "i=0\n",
    "for setup in clf.grid_scores_:\n",
    "    row = [clf.grid_scores_[i].mean_validation_score ] + [value for key, value in clf.grid_scores_[i].parameters.items() ]\n",
    "    cv_result.loc[i] = row\n",
    "    i+=1\n",
    "#este flag es basicamente para chequear que hayamos terminado nomas\n",
    "finished = True\n",
    "\n",
    "all_time =   time.time() - start_time\n",
    "\n",
    "#este flag es basicamente para chequear que hayamos terminado nomas\n",
    "finished = True\n",
    "\n",
    "print('This cell took %s seconds to run' % all_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "threshold = 0.7\n",
    "ind = predicted_proba['prob']>threshold\n",
    "print(classification_report(predicted_proba.loc[ind,'y'].values,predicted_proba.loc[ind,'class'].values ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.005, average=40, class_weight='balanced', epsilon=0.1,\n",
       "       eta0=5, fit_intercept=True, l1_ratio=0.0006000000000000001,\n",
       "       learning_rate='optimal', loss='modified_huber', n_iter=3, n_jobs=3,\n",
       "       penalty='elasticnet', power_t=2, random_state=None, shuffle=True,\n",
       "       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_iter\n",
      "2.0    0.125741\n",
      "3.0    0.132943\n",
      "Name: mean_score, dtype: float64\n",
      "n_iter\n",
      "2.0    0.002609\n",
      "3.0    0.002703\n",
      "Name: mean_score, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "coln=1\n",
    "print(cv_result.groupby(cv_result.columns[coln])['mean_score'].mean())\n",
    "print(cv_result.groupby(cv_result.columns[coln])['mean_score'].std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Results\n",
    "* l1_ratio = cuanto mas chico mejor con lo cual la perdida l2 parece ser mejor\n",
    "* alpha = 1e-3 es suficiente pues casi no afecta el score\n",
    "* power_t = muy variado, no parece haber correlacion entre el tamanyo y el avg, mean_score\n",
    "* eta0 = no afecta mucho pero parece ser que con ser >1 ya esta\n",
    "* power_t = parecen ser practicamente iguales\n",
    "* n_iter = cuanto mas iter NO mejora el score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "371161"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predicted_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validate NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 144 candidates, totalling 432 fits\n",
      "[CV] algorithm=adam, hidden_layer_sizes=(50,), activation=logistic, power_t=0.001, alpha=0.1, learning_rate=adaptive \n",
      "[CV] algorithm=adam, hidden_layer_sizes=(50,), activation=logistic, power_t=0.001, alpha=0.1, learning_rate=adaptive \n",
      "[CV] algorithm=adam, hidden_layer_sizes=(50,), activation=logistic, power_t=0.001, alpha=0.1, learning_rate=adaptive \n",
      "[CV] algorithm=adam, hidden_layer_sizes=(50,), activation=logistic, power_t=0.0005, alpha=0.1, learning_rate=adaptive \n",
      "Iteration 1, loss = 0.20405210\n",
      "Iteration 1, loss = 0.20380843\n",
      "Iteration 1, loss = 0.20378706\n",
      "Iteration 1, loss = 0.20405210\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/teo/Repositories/scikit-learn/sklearn/metrics/classification.py:1097: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  algorithm=adam, hidden_layer_sizes=(50,), activation=logistic, power_t=0.0005, alpha=0.1, learning_rate=adaptive, score=0.000000 -   1.5s\n",
      "[CV] algorithm=adam, hidden_layer_sizes=(50,), activation=logistic, power_t=0.0005, alpha=0.1, learning_rate=adaptive \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/teo/Repositories/scikit-learn/sklearn/metrics/classification.py:1097: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  algorithm=adam, hidden_layer_sizes=(50,), activation=logistic, power_t=0.001, alpha=0.1, learning_rate=adaptive, score=0.000000 -   1.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/teo/Repositories/scikit-learn/sklearn/metrics/classification.py:1097: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  algorithm=adam, hidden_layer_sizes=(50,), activation=logistic, power_t=0.001, alpha=0.1, learning_rate=adaptive, score=0.000000 -   2.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/teo/Repositories/scikit-learn/sklearn/metrics/classification.py:1097: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  algorithm=adam, hidden_layer_sizes=(50,), activation=logistic, power_t=0.001, alpha=0.1, learning_rate=adaptive, score=0.000000 -   1.9s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-35-3491f77d2a02>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     16\u001b[0m verbose=3, pre_dispatch='2*n_jobs', error_score='raise')\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[0mpredicted_proba\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/teo/Repositories/scikit-learn/sklearn/grid_search.pyc\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    809\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    810\u001b[0m         \"\"\"\n\u001b[1;32m--> 811\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    812\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    813\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/teo/Repositories/scikit-learn/sklearn/grid_search.pyc\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, y, parameter_iterable)\u001b[0m\n\u001b[0;32m    558\u001b[0m                                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_parameters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    559\u001b[0m                                     error_score=self.error_score)\n\u001b[1;32m--> 560\u001b[1;33m                 \u001b[1;32mfor\u001b[0m \u001b[0mparameters\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mparameter_iterable\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    561\u001b[0m                 for train, test in cv)\n\u001b[0;32m    562\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/teo/Repositories/scikit-learn/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    808\u001b[0m                 \u001b[1;31m# consumption.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    809\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 810\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    811\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    812\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/teo/Repositories/scikit-learn/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    755\u001b[0m                     \u001b[1;31m# a working pool as they expect.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    756\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_initialize_pool\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 757\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    758\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    759\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "X_train,X_test,y_train ,y_test = train_test_split(X,y, test_size=0.2, random_state=42)\n",
    "\n",
    "param_grid = { 'alpha': [1e-1,5*1e-2,1e-2],\n",
    "              'hidden_layer_sizes':[(50,),(15,5)],\n",
    "              'learning_rate': ['adaptive',\"invscaling\"],\n",
    "              \"algorithm\": ['adam'],'momentum': [1e-2, 1e-1, 0.5],\n",
    "  'power_t': [1e-3, 5*1e-4, 1e-5], 'activation':['logistic','relu']\n",
    " }\n",
    "\n",
    "mlp = MLPClassifier(shuffle=True, \n",
    "                 verbose=True)\n",
    "\n",
    "clf =GridSearchCV(mlp, param_grid, scoring='roc_auc', fit_params=None, n_jobs=4, iid=True, refit=True, \n",
    "verbose=3, pre_dispatch='2*n_jobs', error_score='raise')\n",
    "\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "predicted_proba = pd.DataFrame()\n",
    "predicted_proba['prob'] = clf.predict_proba(X_test).max(axis=1)\n",
    "predicted_proba['gt'] = y_test\n",
    "predicted_proba['class'] = clf.predict(X_test)\n",
    "\n",
    "threshold = 0.7\n",
    "ind = predicted_proba['prob']>threshold\n",
    "\n",
    "all_time =   time.time() - start_time\n",
    "\n",
    "print(classification_report(predicted_proba.loc[ind,'gt'].values,predicted_proba.loc[ind,'class'].values ))\n",
    "\n",
    "cv_result = pd.DataFrame(columns=['mean_score' ] + [key for key, value in clf.grid_scores_[0].parameters.items() ] )\n",
    "i=0\n",
    "for setup in clf.grid_scores_:\n",
    "    row = [clf.grid_scores_[i].mean_validation_score ] + [value for key, value in clf.grid_scores_[i].parameters.items() ]\n",
    "    cv_result.loc[i] = row\n",
    "    i+=1\n",
    "#este flag es basicamente para chequear que hayamos terminado nomas\n",
    "finished = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'clf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-2d39bdb4c6dd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'clf' is not defined"
     ]
    }
   ],
   "source": [
    "clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "alpha\n",
       "0.00     0.000007\n",
       "0.01     0.000007\n",
       "0.10     0.000007\n",
       "0.50     0.000007\n",
       "1.00     0.000007\n",
       "10.00    0.000007\n",
       "Name: mean_score, dtype: float64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compare best parameters to tune\n",
    "coln=1\n",
    "cv_result.groupby(cv_result.columns[coln])['mean_score'].mean()\n",
    "cv_result.groupby(cv_result.columns[coln])['mean_score'].std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Results\n",
    "* activation = logistic es 10% mejor\n",
    "* alpha = 1e-2 el mejor \n",
    "* power_t = cuanto mas chico mejor, 1e-3 por lo menos\n",
    "* hidden_layer_size = menos layers es mejor..?\n",
    "* power_t = parecen ser practicamente iguales\n",
    "* n_iter = cuanto mas iter NO mejora el score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bernoulli RBM features selection & Logit crossval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-127-8675e4c7d9ab>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     39\u001b[0m verbose=0, pre_dispatch='2*n_jobs', error_score='raise')\n\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[1;31m#este metodo NO tiene predicted proba, lo que hacemos es recorrer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/teo/Repositories/scikit-learn/sklearn/grid_search.pyc\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    809\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    810\u001b[0m         \"\"\"\n\u001b[1;32m--> 811\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    812\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    813\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/teo/Repositories/scikit-learn/sklearn/grid_search.pyc\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, y, parameter_iterable)\u001b[0m\n\u001b[0;32m    558\u001b[0m                                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_parameters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    559\u001b[0m                                     error_score=self.error_score)\n\u001b[1;32m--> 560\u001b[1;33m                 \u001b[1;32mfor\u001b[0m \u001b[0mparameters\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mparameter_iterable\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    561\u001b[0m                 for train, test in cv)\n\u001b[0;32m    562\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/teo/Repositories/scikit-learn/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    808\u001b[0m                 \u001b[1;31m# consumption.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    809\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 810\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    811\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    812\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/teo/Repositories/scikit-learn/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    755\u001b[0m                     \u001b[1;31m# a working pool as they expect.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    756\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_initialize_pool\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 757\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    758\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    759\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "## obs. este metodo es especial y asume que todos los valores son True/False o que \\in [0,1]\n",
    "# luego tengo que pensar en como tomar los features nuevamente.\n",
    "# tampoco 'fittea' en la forma tradicional. Sino que se le puede tomar al y como un feature mas y esta red\n",
    "# va 'modificando' todos los valores del X (minimizando la entropia) para dar un output. Luego corriendo \n",
    "# clf.gibbs(X_test) con el y_test como feature tmb, nos transforma la data para ver el output como la 'prediccion'\n",
    "# obviamente no tiene probabilidades\n",
    "\n",
    "\n",
    "#X = X_train[X_cols].values\n",
    "#y = X_train['ground_truth'].values\n",
    "\n",
    "df = X_train.drop(X_train[X_train[X_train.columns[0:3]].\\\n",
    "                                   sum(axis=1)==0].index)\n",
    "df = df[X_cols + ['ground_truth']]\n",
    "\n",
    "for col in X_train.columns[0:3]:\n",
    "    df[col] = df[col]*1.0/df[df.columns[0:3]].sum(axis=1)\n",
    "\n",
    "df[df.columns[3]] =  df[df.columns[3]]/df[df.columns[3]].max()\n",
    "df[df.columns[4]] =  df[df.columns[4]]/df[df.columns[4]].max()\n",
    "\n",
    "X = df[df.columns[:-1]].values\n",
    "y = df['ground_truth'].values\n",
    "\n",
    "\n",
    "param_grid = {'rbm__n_components': [256, 128,46,10],\n",
    "   'rbm__n_iter':[15,10,5], 'rbm__learning_rate': [1e-4,1e-3,1e-2,1e-1,5*1e-3,5*1e-2,5*1e-1],\n",
    "  'rbm__batch_size': [10e4,3*10e3, 1e3, 300],\"logistic__C\": [1.0, 10.0, 100.0] \n",
    " }\n",
    "\n",
    "rbm = BernoulliRBM(verbose=True)\n",
    "logistic = LogisticRegression()\n",
    "classifier = Pipeline([(\"rbm\", rbm), (\"logistic\", logistic)])\n",
    "\n",
    "X_train,X_test,y_train ,y_test = train_test_split(X,y, test_size=0.2, random_state=42)\n",
    "\n",
    "clf =GridSearchCV(classifier, param_grid, scoring='roc_auc', fit_params=None, n_jobs=4, iid=True, refit=True, \n",
    "verbose=3, pre_dispatch='2*n_jobs', error_score='raise')\n",
    "\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "#este metodo NO tiene predicted proba, lo que hacemos es recorrer \n",
    "#predicted_labels = rbm.gibbs(X_test)[:,-1]\n",
    "#real_labels = X_test[:,-1]\n",
    "#print(classification_report(real_labels,predicted_labels ))\n",
    "\n",
    "\n",
    "predicted_proba = pd.DataFrame()\n",
    "predicted_proba['prob'] = clf.predict_proba(X_test).max(axis=1)\n",
    "predicted_proba['gt'] = y_test\n",
    "predicted_proba['class'] = clf.predict(X_test)\n",
    "\n",
    "threshold = 0.7\n",
    "ind = predicted_proba['prob']>threshold\n",
    "print(classification_report(predicted_proba.loc[ind,'gt'].values,predicted_proba.loc[ind,'class'].values ))\n",
    "all_time =   time.time() - start_time\n",
    "\n",
    "finished = True\n",
    "\n",
    "cv_result = pd.DataFrame(columns=['mean_score' ] + [key for key, value in clf.grid_scores_[0].parameters.items() ] )\n",
    "i=0\n",
    "for setup in clf.grid_scores_:\n",
    "    row = [clf.grid_scores_[i].mean_validation_score ] + [value for key, value in clf.grid_scores_[i].parameters.items() ]\n",
    "    cv_result.loc[i] = row\n",
    "    i+=1\n",
    "    \n",
    "print('This cell took %s seconds to run' % all_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "coln=1\n",
    "print(cv_result.groupby(cv_result.columns[coln])['mean_score'].mean())\n",
    "print(cv_result.groupby(cv_result.columns[coln])['mean_score'].std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "criterion\n",
      "gini    0.802919\n",
      "Name: mean_score, dtype: float64\n",
      "criterion\n",
      "gini    0.000598\n",
      "Name: mean_score, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "coln=3\n",
    "print(cv_result.groupby(cv_result.columns[coln])['mean_score'].mean())\n",
    "print(cv_result.groupby(cv_result.columns[coln])['mean_score'].std())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CrossV SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "param_grid = [{'kernel': ['rbf'], 'gamma': list(10.0 ** pd.np.arange(-2, 3)),\n",
    "                     'C': list(10.0 ** pd.np.arange(0, 4))},\n",
    "                    {'kernel': ['poly'], 'C': list(10.0 ** pd.np.arange(0, 4)), 'degree'[2,3,4]}]\n",
    "\n",
    "svc = SVC(shuffle=True, probability=True,decision_function_shape = 'ovr',\n",
    "           verbose=True, class_weight='balanced'\n",
    "          )\n",
    "\n",
    "clf =GridSearchCV(svc, param_grid, scoring='roc_auc', fit_params=None, n_jobs=4, iid=True, refit=True, \n",
    "verbose=3, pre_dispatch='2*n_jobs', error_score='raise')\n",
    "\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "predicted_proba = pd.DataFrame()\n",
    "predicted_proba['prob'] = clf.predict_proba(X_test).max(axis=1)\n",
    "predicted_proba['gt'] = y_test\n",
    "predicted_proba['class'] = clf.predict(X_test)\n",
    "\n",
    "threshold = 0.7\n",
    "ind = predicted_proba['prob']>threshold\n",
    "\n",
    "all_time =   time.time() - start_time\n",
    "\n",
    "print(classification_report(predicted_proba.loc[ind,'gt'].values,predicted_proba.loc[ind,'class'].values ))\n",
    "\n",
    "cv_result = pd.DataFrame(columns=['mean_score' ] + [key for key, value in clf.grid_scores_[0].parameters.items() ] )\n",
    "i=0\n",
    "for setup in clf.grid_scores_:\n",
    "    row = [clf.grid_scores_[i].mean_validation_score ] + [value for key, value in clf.grid_scores_[i].parameters.items() ]\n",
    "    cv_result.loc[i] = row\n",
    "    i+=1\n",
    "#este flag es basicamente para chequear que hayamos terminado nomas\n",
    "finished = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "coln=3\n",
    "print(cv_result.groupby(cv_result.columns[coln])['mean_score'].mean())\n",
    "print(cv_result.groupby(cv_result.columns[coln])['mean_score'].std())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoosting took 117.26272392272949 seconds to run\n",
      "This cell took 117.26284193992615 seconds to run\n"
     ]
    }
   ],
   "source": [
    "#tomo tiempo para saber cuanto tarda fitear el estimador\n",
    "start_time = time.time()\n",
    "\n",
    "#model = model.fit(X,y,sample_weight=W)\n",
    "\n",
    "W = pd.np.array([10 if i == 1 or i ==2  else 1 for i in y_mini])\n",
    "gradboost.fit(X_mini,y_mini, sample_weight=W)\n",
    "\n",
    "elapsed_time =   time.time() - start_time\n",
    "print('GradientBoosting took %s seconds to run' % elapsed_time)\n",
    "\n",
    "#validated =  cross_val_score(gradboost,X,y,cv=5, scoring = \"f1_weighted\")\n",
    "\n",
    "\n",
    "all_time =   time.time() - start_time\n",
    "print('This cell took %s seconds to run' % all_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Timings\n",
    "* 5s con  10 n_estimadores, 15 max_depth y X.sample(0.2)\n",
    "* 15s con 10 n_estimadores, 15 max_depth y X.sample(0.2)\n",
    "* 47s con 10 n_estimadores, 15 max_depth y X.sample(0.4)\n",
    "* 35s con 10 n_estimadores, 15 max_depth y X.sample(0.4)\n",
    "* 117 con 20 n_estimadores, 20 max_depth y X.sample(0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    128153\n",
       "1      7064\n",
       "Name: ground_truth, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train['ground_truth'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results\n",
    "* NO escalar (normalizar, restar la media  dividir por la std, etc) los resultados pues REVIENTAN los scores.\n",
    "* bootstrap  = False es 5% mejor\n",
    "* min_samples_leaf = mas chico es claramente mejor, pero tmb aumenta el overfitting lo cual me hace caer mucho el valor del recall en el test_set. Sin embargo es un parametro muy sensible en la precision. Resta evaluar asi el tradeoff entre la precision y el volumen de users al cual queremos llegar.\n",
    "* n_estimators = aumentar mas de 30 no tendria mucho sentido\n",
    "* citerion = entropy o gini no cambia. gini podria ser mejor entonces pues entropy usa logs de los valores lo cual es mas computacionalmente costoso\n",
    "* max_features = no afecta al score. con auto esta bien\n",
    "* max_depth =  mas es mejor. intentaria probar con >15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "#con decomposicion qr tratamos de ver si existe alguna columna que sea comb linear de las demas\n",
    "linear_test = pd.np.linalg.qr(X_train.sample(1e6))[1]\n",
    "#notar que devuelve la tabla de tamanyo N`columnas x Ncolumnas\n",
    "\n",
    "#sumo a traves de las columnas para que me de el valor absoluto sumado de c/fila\n",
    "linear_test = abs(linear_test.sum(axis=1))<1e-2\n",
    "#si hubiese alguan que sea linearcomb entonces tendria que aparecer que toda la fila es de ceros\n",
    "for i, col in enumerate(X_train.columns):\n",
    "    if linear_test[i] == True:\n",
    "        print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Todo\n",
    "* evaluate hit_rate and \n",
    "* tune adaboost, bernoulliRBM\n",
    "* xgboost\n",
    "* libffm\n",
    "* SVC muy lento.. speed up in AWS\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ipynb to \n",
    "\n",
    "graph and try out different \n",
    "\n",
    "ML concepts with a sample datasize.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A partir de las 3 tablas ya procesdas : \n",
    "* homeantennas\n",
    "* sumlinks\n",
    "* groundtruth\n",
    "\n",
    "armames un datset para explorar conceptos de ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(180000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 180 seconds\n"
     ]
    }
   ],
   "source": [
    "## seteamos los parametros del notebook\n",
    "%autosave 180\n",
    "import pandas as pd; \n",
    "import numpy as np; \n",
    "import os;\n",
    "import random;\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np; import os;import random;\n",
    "import graphlab as gl\n",
    "from IPython.display import display # para pretty-print con estetica ipython si es que estamos dentro de  un loop, if, etc\n",
    "#esto es para dibujar directo a la notebook\n",
    "gl.canvas.set_target('ipynb')\n",
    "\n",
    "# for nice graphics and plots\n",
    "import seaborn as sns\n",
    "palette = sns.color_palette()\n",
    "\n",
    "# for nice long graphic titles\n",
    "from textwrap import wrap\n",
    "\n",
    "#seteamos el lugar de trabajo\n",
    "HOMEDIR=os.path.expanduser('~')\n",
    "\n",
    "PROJECTDIR = os.getcwd().split(os.sep)\n",
    "PROJECTDIR =  os.sep.join(PROJECTDIR[:PROJECTDIR.index('mexico-scripts-ver2') + 1])\n",
    "\n",
    "DATADIR = os.path.join(PROJECTDIR,'datasets')\n",
    "\n",
    "DATADIR2 = os.path.join(PROJECTDIR,'data')\n",
    "# os.chdir(DATADIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_balanced_sample.csv  gtruth_0215_0715  sl\r\n",
      "gtruth_0114_0715\t  homeant\t    sl.csv.gz\r\n"
     ]
    }
   ],
   "source": [
    "!ls $DATADIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "graphlab_frame = False\n",
    "# graphlab_frame = 'juan' in HOMEDIR\n",
    "\n",
    "def get_input_sframe(ds,graphlab_frame=graphlab_frame):\n",
    "    if graphlab_frame:\n",
    "        if ds == 'home_antenna': url = DATADIR +\"/homeant\"\n",
    "        elif ds == 'sum_links': url  = DATADIR +\"/sl\"\n",
    "        elif ds == 'gtruth_02': url  = DATADIR +\"/gtruth_0215_0715\" # can be near ground truth (previous to july 2015)\n",
    "        elif ds == 'gtruth_01': url  =  DATADIR +\"/gtruth_0114_0715\" # or can be old GT\n",
    "        else: print('type chosen is %s, type should be home_antenna, sum_links, gtruth_02 or gtruth_01' % ds)\n",
    "    else:\n",
    "        url = DATADIR + '/data_balanced_sample.csv'\n",
    "    return url "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#from unbalanced_dataset import UnderSampler, NearMiss, CondensedNearestNeighbour, OneSidedSelection,\\\n",
    "#NeighbourhoodCleaningRule, TomekLinks, ClusterCentroids, OverSampler, SMOTE,\\\n",
    "#SMOTETomek, SMOTEENN, EasyEnsemble, BalanceCascade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## decide if load a reduced size dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set what is the resulting sample we want of the global dataset\n",
    "global_split = 0.25\n",
    "global_split = None\n",
    "\n",
    "# since we have 2 datets that will be later joined and which are going to be previously sampled, in the end this \n",
    "# independent sampling will result in that, after the join, the dataset will have a size of fraction given by \n",
    "# the `global_split` variable\n",
    "if global_split:\n",
    "    \n",
    "    seed = 2015\n",
    "    sample = np.sqrt(global_split)\n",
    "    print(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.81 s, sys: 264 ms, total: 4.08 s\n",
      "Wall time: 4.66 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "if graphlab_frame:\n",
    "    sf_table, _ = gl.load_sframe(get_input_sframe('home_antenna',graphlab_frame))\n",
    "    sl_table, _ = gl.load_sframe(get_input_sframe('sum_links',graphlab_frame))\n",
    "    # no need to sample the gt table since it is very small in memory\n",
    "    gt_table = gl.load_sframe(get_input_sframe('gtruth_01',graphlab_frame))\n",
    "\n",
    "    if global_split:\n",
    "\n",
    "        sf_table, _ = sf_table.random_split(sample,seed=seed)\n",
    "        sl_table, _ = sl_table.random_split(sample,seed=seed)\n",
    "\n",
    "\n",
    "    rename_gt = (dict([(col,col+\"_gt\") for col in gt_table.column_names() if col != 'USER']))\n",
    "\n",
    "    #agrego la etiqueta \"_gt\" a las columnas del ground_truth\n",
    "    gt_table.rename(rename_gt) \n",
    "else:\n",
    "    data = pd.read_csv(get_input_sframe('sum_links',graphlab_frame))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(153010, 176)\n"
     ]
    }
   ],
   "source": [
    "if graphlab_frame:\n",
    "    print(sf_table.shape, sl_table.shape, gt_table.shape)\n",
    "else:\n",
    "    print(data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## simple format description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aca miramos las top 10 antenas que utilizo un usuario, ordeandas de 0 a 10 segun el uso, en numero de llamados, que el user le daba a c. antenna. _0_ Seria la antenna mas utilizada y _10_ la menos utilizada. El count es la cantidad de veces que utilizo esa antenna. \n",
    "\n",
    "Cuando aparece _WEEKNIGHT_ en el nombre de la columna, es porque cumple la condicion de que los llamados fueron hechos de noche fuera del horario [8,20] y dentro de la semana laboral.\n",
    "\n",
    "Siguiendo las definiciones del trabajo de Caro, un user es _EPIDEMIC_ siii su ANTENNA_WEEKNIGHT_0 (esta es la home_antenna) pertence a la zona epidemica.\n",
    "\n",
    "El mobility_diameter es el radio de las antennas (0 si uso una sola, etc.) utilizadas por este user. Nuevamente el modificador _WEEKNIGHT_ solo aplica para antennas utilizadas en esos horarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([u'USER', u'COUNT_0', u'COUNT_1', u'COUNT_2', u'COUNT_3', u'COUNT_4',\n",
      "       u'COUNT_5', u'COUNT_6', u'COUNT_7', u'COUNT_8',\n",
      "       ...\n",
      "       u'TimeWeekDay_IN_11', u'CallsWeekEnd_IN_11', u'TimeWeekNight_IN_11',\n",
      "       u'TimeWeekEnd_IN_VUL_11', u'CallsWeekDay_IN_VUL_11',\n",
      "       u'CallsWeekNight_IN_VUL_11', u'TimeWeekDay_IN_VUL_11',\n",
      "       u'CallsWeekEnd_IN_VUL_11', u'TimeWeekNight_IN_VUL_11',\n",
      "       u'VULNERABLE_IN_11'],\n",
      "      dtype='object', length=176)\n"
     ]
    }
   ],
   "source": [
    "# column names\n",
    "if graphlab_frame:\n",
    "    print(sf_table.column_names())\n",
    "else:\n",
    "    print(data.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sum links description\n",
    "\n",
    "La tabla sum_links tiene mas atributos y con data mas rica en informacion:\n",
    "    \n",
    "Esencialmente para c/ user miramos la cantidad de llamados y el tiempo que duraron esos llamados pero segmentando con distintos modificadores. `Time` representa la duracion del llamado y Calls el conteo de llamados.\n",
    "\n",
    "Los modficadores/ segmentaciones son:\n",
    "\n",
    "* mes en el cual estamos parados (12 == diciembre, ..., 08 == agosto)\n",
    "* OUT/IN, separa por la direccion de los llamados si salientes u entrantes.\n",
    "* _VULN_ : separa los llamados que fueron realizados hacia/desde un target_user (en una llamada hay 2 usuarios, el origin o el target) viviendo en una zona epidemica. Donde la home antena de un target_user determina su vulnerabilidad segun si es zona epidemica o no.\n",
    "* Weekend, WeekDay y WeekNight son lo que suenan. Weekend el finde, Weeknight la semana pero fuera de horario laboral y Weekday en horario laboral y de lunes a viernes.\n",
    "\n",
    "Hay solo una columna que no entra enteramente en este esquema que es VULNERABLE. Esta columna hace un conteo p/c/ usuario d cuantos target_users viven en una zona epidemica. Tambien se segmenta esta columna con los modficiadores anteriores (el mes y el out/in)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# column names\n",
    "if graphlab_frame:\n",
    "    print(sl_table.column_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Para la\n",
    "tabla gt (ground_truth) es mas simple la explicacion. Solo se busco el antenna_ID_0 (nuevamente la antenna mas utilizada) por un user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if graphlab_frame:\n",
    "    print(gt_table.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We need antennas metadata\n",
    "to get the epidemicity of each antenna and add that info to the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/juan/mobility-study/mexico-scripts-ver2/data'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATADIR2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/juan/mobility-study/mexico-scripts-ver2/datasets'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATADIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#agregamos al gt su info de epidemicidad\n",
    "antennas_file = DATADIR2+'/celdas_limpio.csv'\n",
    "\n",
    "if graphlab_frame:\n",
    "    antennas = gl.SFrame.read_csv(antennas_file, \n",
    "                              delimiter= \"|\", \n",
    "                usecols=['LATITUDE','LONGITUDE','CEL_ID','STATE','EPIDEMIC'],\n",
    "                column_type_hints=[float, float, str,str, bool]\n",
    "                            )\n",
    "else:\n",
    "    antennas = pd.read_csv(antennas_file,sep='|')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 5.96 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# enriquecemos la data de gt con info de epidemicidad\n",
    "if graphlab_frame:\n",
    "    # agrego tambien data de epidemicidad al simpleformat table\n",
    "    sf_table = sf_table.join(antennas['CEL_ID','EPIDEMIC','STATE'], \n",
    "                             on = {'ANTENNA_ID_WEEKNIGHT_0':'CEL_ID'},\n",
    "                             how = 'left')\n",
    "    gt_table = gt_table.join(antennas['CEL_ID','EPIDEMIC','STATE'], \n",
    "                             on = {'ANTENNA_ID_WEEKNIGHT_0_gt':'CEL_ID'},\n",
    "                             how = 'left')\n",
    "\n",
    "    gt_table.rename({'EPIDEMIC':'EPIDEMIC_gt'});"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# create data matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(153010, 176)\n",
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 434 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if graphlab_frame:\n",
    "    data = sl_table.join(gt_table['USER','EPIDEMIC_gt'], on = 'USER', how = 'inner')\n",
    "    data = data.join(sf_table, on = 'USER', how = 'inner')\n",
    "    #no podemos tener nulls en el target asi que dropeamos\n",
    "    data = data.dropna(columns = ['EPIDEMIC_gt'], how='any')\n",
    "    del sl_table, sf_table, gt_table\n",
    "\n",
    "print(data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51709, 47344)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['EPIDEMIC_gt'].sum(),data['EPIDEMIC'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# data.query('EPIDEMIC==0  ').STATE.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## preparamos los datasets que no pueden tomar valores negativos o categorical vars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train test split as \n",
    "p% of set as validation and the resulting  as train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "split_perc = 0.9\n",
    "mask = np.random.rand(data.shape[0])< split_perc\n",
    "\n",
    "val_set = data[mask==0]\n",
    "data = data[mask==1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define our real X variable and Y vars\n",
    "\n",
    "exclude/include features. Decide our problem (multi-target, single_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## in our  X features..\n",
    "\n",
    "determine which columns have no meaning.\n",
    "\n",
    "we are going to try different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['USER',\n",
       " 'ANTENNA_ID_0',\n",
       " 'ANTENNA_ID_1',\n",
       " 'ANTENNA_ID_2',\n",
       " 'ANTENNA_ID_3',\n",
       " 'ANTENNA_ID_4',\n",
       " 'ANTENNA_ID_5',\n",
       " 'ANTENNA_ID_6',\n",
       " 'ANTENNA_ID_7',\n",
       " 'ANTENNA_ID_8',\n",
       " 'ANTENNA_ID_9',\n",
       " 'ANTENNA_ID_WEEKNIGHT_0',\n",
       " 'ANTENNA_ID_WEEKNIGHT_1',\n",
       " 'ANTENNA_ID_WEEKNIGHT_2',\n",
       " 'ANTENNA_ID_WEEKNIGHT_3',\n",
       " 'ANTENNA_ID_WEEKNIGHT_4',\n",
       " 'ANTENNA_ID_WEEKNIGHT_5',\n",
       " 'ANTENNA_ID_WEEKNIGHT_6',\n",
       " 'ANTENNA_ID_WEEKNIGHT_7',\n",
       " 'ANTENNA_ID_WEEKNIGHT_8',\n",
       " 'ANTENNA_ID_WEEKNIGHT_9']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if graphlab_frame: iterable=data.column_names()\n",
    "else: iterable=data.columns\n",
    "\n",
    "# this param will *force* the exclusion of these columns in the final X, no matter what.\n",
    "\n",
    "manual_exclude_cols = [     \n",
    "#     'EPIDEMIC',\n",
    "#      'EPIDEMIC_gt',\n",
    "#       'STATE',\n",
    "                ]\n",
    "\n",
    "comprehensive_exclude_cols = [col for col in iterable if col == 'USER' \n",
    "          or ('ANTENNA' in col) ]   \n",
    "                                \n",
    "exclude_cols = manual_exclude_cols + comprehensive_exclude_cols\n",
    "exclude_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## first our Y vars\n",
    "\n",
    "define them with a set of different possible cases/problems to solve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "case = 0\n",
    "\n",
    "## people that used to live in the endemic area\n",
    "if case ==0:\n",
    "    case_text = \"people that used to live in the endemic area\"\n",
    "    Y = data['EPIDEMIC_gt'] == 1\n",
    "    Y_val = val_set['EPIDEMIC_gt'] == 1\n",
    "    add_exclusion_cols =[     \n",
    "            #     'EPIDEMIC',\n",
    "                 'EPIDEMIC_gt',\n",
    "            #       'STATE',\n",
    "                ]\n",
    "\n",
    "## people that used to live in the endemic area *and* migrated\n",
    "if case ==1:\n",
    "    case_text = \"people that used to live in the endemic area *and* migrated\"\n",
    "    Y = (data['EPIDEMIC_gt'] ==1) & (data['EPIDEMIC'] ==0)\n",
    "    Y_val = (val_set['EPIDEMIC_gt'] ==1) & (val_set['EPIDEMIC'] ==0)\n",
    "    add_exclusion_cols = [\n",
    "                        'EPIDEMIC',\n",
    "                          'STATE',\n",
    "                         'EPIDEMIC_gt',\n",
    "                    ]\n",
    "\n",
    "##  people that migrated in any direction\n",
    "if case ==2:\n",
    "    case_text = \"people that migrated in any direction\"\n",
    "    Y = data['EPIDEMIC_gt'] != data['EPIDEMIC']\n",
    "    Y_val = val_set['EPIDEMIC_gt'] != data['EPIDEMIC']\n",
    "    \n",
    "    add_exclusion_cols = [           \n",
    "            #     'EPIDEMIC',\n",
    "#                  'EPIDEMIC_gt',\n",
    "            #       'STATE',\n",
    "]\n",
    "\n",
    "    \n",
    "##  people that migrated in any direction, but are currently non-endemic\n",
    "if case ==3:\n",
    "    case_text = \"currently non_endemic, that used to live in the endemic area\"\n",
    "    \n",
    "    data = data[data['EPIDEMIC'] ==0]\n",
    "    val_set = val_set[val_set['EPIDEMIC'] ==0]\n",
    "\n",
    "    Y = (data['EPIDEMIC_gt'] ==1)\n",
    "    Y_val = (val_set['EPIDEMIC_gt'] ==1) \n",
    "    \n",
    "    add_exclusion_cols = [\n",
    "                'EPIDEMIC'\n",
    "                'EPIDEMIC_gt',\n",
    "            #     'STATE',\n",
    "         \n",
    "                         ]    \n",
    "    \n",
    "## people from the Mexico or DF states\n",
    "if case == 4:\n",
    "    case_text = \"people from the Mexico or DF states\"\n",
    "    Y = (data['STATE'] == 'Distrito_Federal') | (data['STATE'] == 'Mexico')\n",
    "    Y_val = (val_set['STATE'] == 'Distrito_Federal') | (val_set['STATE'] == 'Mexico')\n",
    "    \n",
    "    add_exclusion_cols = [\n",
    "                'EPIDEMIC',\n",
    "                'STATE',\n",
    "                ]\n",
    "                        \n",
    "## people with a HIGH present mobility (>1000 after looking at percentiles of the MOBILITY_DIAMTER)\n",
    "if case == 5:\n",
    "    val = 1000\n",
    "    case_text = \"people with a high mobility during present time (values > {} )\".format(val)\n",
    "    Y = (data['MOBILITY_DIAMETER'] > val) \n",
    "    Y_val = (val_set['MOBILITY_DIAMETER'] > val) \n",
    "    \n",
    "    add_exclusion_cols = [\n",
    "        \n",
    "        'MOBILITY_DIAMETER_WEEKNIGHT',\n",
    "        'MOBILITY_DIAMETER',\n",
    "    ]\n",
    "\n",
    "for col in add_exclusion_cols:\n",
    "    if not col in exclude_cols:\n",
    "        exclude_cols+=[col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if graphlab_frame: iterable=data.column_names()\n",
    "else: iterable=data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'TimeWeekNight_IN_08', u'TimeWeekEnd_IN_VUL_08',\n",
       "       u'CallsWeekDay_IN_VUL_08', u'CallsWeekNight_IN_VUL_08',\n",
       "       u'TimeWeekDay_IN_VUL_08', u'CallsWeekEnd_IN_VUL_08',\n",
       "       u'TimeWeekNight_IN_VUL_08', u'VULNERABLE_IN_08', u'TimeWeekEnd_OUT_09',\n",
       "       u'CallsWeekDay_OUT_09', u'CallsWeekNight_OUT_09', u'TimeWeekDay_OUT_09',\n",
       "       u'CallsWeekEnd_OUT_09', u'TimeWeekNight_OUT_09',\n",
       "       u'TimeWeekEnd_OUT_VUL_09', u'CallsWeekDay_OUT_VUL_09',\n",
       "       u'CallsWeekNight_OUT_VUL_09', u'TimeWeekDay_OUT_VUL_09',\n",
       "       u'CallsWeekEnd_OUT_VUL_09', u'TimeWeekNight_OUT_VUL_09',\n",
       "       u'VULNERABLE_OUT_09', u'TimeWeekEnd_IN_09', u'CallsWeekDay_IN_09',\n",
       "       u'CallsWeekNight_IN_09', u'TimeWeekDay_IN_09', u'CallsWeekEnd_IN_09',\n",
       "       u'TimeWeekNight_IN_09', u'TimeWeekEnd_IN_VUL_09',\n",
       "       u'CallsWeekDay_IN_VUL_09', u'CallsWeekNight_IN_VUL_09'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "width = 30\n",
    "N= np.random.randint(1,int(iterable.shape[0]*1.0/width))\n",
    "data.columns[(N)*width: (N+1)*width]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/juan/mfixman/venv/lib/python2.7/site-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/home/juan/mfixman/venv/lib/python2.7/site-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.51 s, sys: 64 ms, total: 3.58 s\n",
      "Wall time: 3.57 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "X = data[[col for col in iterable if col not in exclude_cols]]\n",
    "\n",
    "X_val = val_set[[col for col in iterable if col not in exclude_cols]]\n",
    "\n",
    "if graphlab_frame: iterable=X.column_names()\n",
    "else: iterable=X.columns\n",
    "    \n",
    "# clean negative/Null vals in count cols \n",
    "for col in [col for col in iterable if 'COUNT' in col]:\n",
    "    X[col]= X[col].apply(lambda x :  x if x>=0 else 0)\n",
    "    X_val[col]= X_val[col].apply(lambda x :  x if x>=0 else 0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((137692, 154), (137692,))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dummy-ize categorical cols\n",
    "if necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if graphlab_frame: iterable=X.column_names()\n",
    "else: iterable=X.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# X.columns\n",
    "# [col for col in X.columns if 'STATE' in col]\n",
    "# [col for col in X_val.columns if 'STATE' in col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "categorical_cols = [\n",
    "    'STATE'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we are categorizing col STATE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/juan/mfixman/venv/lib/python2.7/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n",
      "/home/juan/mfixman/venv/lib/python2.7/site-packages/ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "for col in categorical_cols:\n",
    "    if col not in exclude_cols:\n",
    "        print('we are categorizing col %s' %col)\n",
    "        X[col] = X[col].astype('category')\n",
    "    #     if X[col].dtype != 'category':\n",
    "    #         continue \n",
    "        X = pd.concat([X,pd.get_dummies(X[col], \n",
    "                                          prefix= col, \n",
    "                                          prefix_sep='_', \n",
    "                                          #sparse = True,\n",
    "                                          dummy_na=False).astype(np.int8)],\\\n",
    "                  axis=1 ,join = 'inner')\n",
    "        X.drop(col, axis =1 , inplace=True)\n",
    "\n",
    "        # now onto test_table\n",
    "        X_val[col] = X_val[col].astype('category')\n",
    "        X_val = pd.concat([X_val,pd.get_dummies(X_val[col], \n",
    "                                          prefix= col, \n",
    "                                          prefix_sep='_', \n",
    "                                          #sparse = True,\n",
    "                                          dummy_na=False).astype(np.int8)],\\\n",
    "                  axis=1 ,join = 'inner')\n",
    "\n",
    "        X_val.drop(col, axis =1 , inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## explore correlations to target var\n",
    "\n",
    "with current column configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(186, 186)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr = pd.DataFrame(X).copy()\n",
    "target_col = 'target'\n",
    "corr[target_col] = Y\n",
    "corr = corr.corr()\n",
    "corr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EPIDEMIC</th>\n",
       "      <th>TimeWeekEnd_OUT_VUL_12</th>\n",
       "      <th>CallsWeekDay_OUT_VUL_12</th>\n",
       "      <th>CallsWeekNight_OUT_VUL_12</th>\n",
       "      <th>TimeWeekDay_OUT_VUL_12</th>\n",
       "      <th>CallsWeekEnd_OUT_VUL_12</th>\n",
       "      <th>TimeWeekNight_OUT_VUL_12</th>\n",
       "      <th>VULNERABLE_OUT_12</th>\n",
       "      <th>TimeWeekEnd_IN_VUL_12</th>\n",
       "      <th>CallsWeekDay_IN_VUL_12</th>\n",
       "      <th>...</th>\n",
       "      <th>TimeWeekDay_IN_VUL_11</th>\n",
       "      <th>CallsWeekEnd_IN_VUL_11</th>\n",
       "      <th>TimeWeekNight_IN_VUL_11</th>\n",
       "      <th>VULNERABLE_IN_11</th>\n",
       "      <th>STATE_Hidalgo</th>\n",
       "      <th>STATE_Jalisco</th>\n",
       "      <th>STATE_Morelos</th>\n",
       "      <th>STATE_Puebla</th>\n",
       "      <th>STATE_Veracruz</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>EPIDEMIC</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.171408</td>\n",
       "      <td>0.287120</td>\n",
       "      <td>0.206999</td>\n",
       "      <td>0.222914</td>\n",
       "      <td>0.264443</td>\n",
       "      <td>0.105028</td>\n",
       "      <td>0.497289</td>\n",
       "      <td>0.164613</td>\n",
       "      <td>0.287017</td>\n",
       "      <td>...</td>\n",
       "      <td>0.217212</td>\n",
       "      <td>0.291858</td>\n",
       "      <td>0.100896</td>\n",
       "      <td>0.516003</td>\n",
       "      <td>0.330397</td>\n",
       "      <td>0.489502</td>\n",
       "      <td>0.263178</td>\n",
       "      <td>0.331527</td>\n",
       "      <td>0.297942</td>\n",
       "      <td>0.439418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TimeWeekEnd_OUT_VUL_12</th>\n",
       "      <td>0.171408</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.560496</td>\n",
       "      <td>0.651113</td>\n",
       "      <td>0.629617</td>\n",
       "      <td>0.801017</td>\n",
       "      <td>0.635869</td>\n",
       "      <td>0.315335</td>\n",
       "      <td>0.594255</td>\n",
       "      <td>0.467672</td>\n",
       "      <td>...</td>\n",
       "      <td>0.404869</td>\n",
       "      <td>0.480234</td>\n",
       "      <td>0.384984</td>\n",
       "      <td>0.291700</td>\n",
       "      <td>0.061749</td>\n",
       "      <td>0.102921</td>\n",
       "      <td>0.030067</td>\n",
       "      <td>0.045572</td>\n",
       "      <td>0.026676</td>\n",
       "      <td>0.187130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CallsWeekDay_OUT_VUL_12</th>\n",
       "      <td>0.287120</td>\n",
       "      <td>0.560496</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.628189</td>\n",
       "      <td>0.864216</td>\n",
       "      <td>0.772855</td>\n",
       "      <td>0.378848</td>\n",
       "      <td>0.448494</td>\n",
       "      <td>0.466551</td>\n",
       "      <td>0.834490</td>\n",
       "      <td>...</td>\n",
       "      <td>0.578081</td>\n",
       "      <td>0.633350</td>\n",
       "      <td>0.261531</td>\n",
       "      <td>0.421996</td>\n",
       "      <td>0.097365</td>\n",
       "      <td>0.184278</td>\n",
       "      <td>0.053034</td>\n",
       "      <td>0.079153</td>\n",
       "      <td>0.045011</td>\n",
       "      <td>0.277760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CallsWeekNight_OUT_VUL_12</th>\n",
       "      <td>0.206999</td>\n",
       "      <td>0.651113</td>\n",
       "      <td>0.628189</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.586073</td>\n",
       "      <td>0.735115</td>\n",
       "      <td>0.798162</td>\n",
       "      <td>0.362146</td>\n",
       "      <td>0.515796</td>\n",
       "      <td>0.533153</td>\n",
       "      <td>...</td>\n",
       "      <td>0.388313</td>\n",
       "      <td>0.551986</td>\n",
       "      <td>0.421814</td>\n",
       "      <td>0.337522</td>\n",
       "      <td>0.071198</td>\n",
       "      <td>0.120409</td>\n",
       "      <td>0.041128</td>\n",
       "      <td>0.060885</td>\n",
       "      <td>0.037357</td>\n",
       "      <td>0.225518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TimeWeekDay_OUT_VUL_12</th>\n",
       "      <td>0.222914</td>\n",
       "      <td>0.629617</td>\n",
       "      <td>0.864216</td>\n",
       "      <td>0.586073</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.665776</td>\n",
       "      <td>0.478032</td>\n",
       "      <td>0.399304</td>\n",
       "      <td>0.520518</td>\n",
       "      <td>0.701466</td>\n",
       "      <td>...</td>\n",
       "      <td>0.629497</td>\n",
       "      <td>0.538366</td>\n",
       "      <td>0.327929</td>\n",
       "      <td>0.374658</td>\n",
       "      <td>0.071853</td>\n",
       "      <td>0.149734</td>\n",
       "      <td>0.037512</td>\n",
       "      <td>0.057518</td>\n",
       "      <td>0.034943</td>\n",
       "      <td>0.231432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CallsWeekEnd_OUT_VUL_12</th>\n",
       "      <td>0.264443</td>\n",
       "      <td>0.801017</td>\n",
       "      <td>0.772855</td>\n",
       "      <td>0.735115</td>\n",
       "      <td>0.665776</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.488800</td>\n",
       "      <td>0.417388</td>\n",
       "      <td>0.557234</td>\n",
       "      <td>0.665846</td>\n",
       "      <td>...</td>\n",
       "      <td>0.453263</td>\n",
       "      <td>0.654575</td>\n",
       "      <td>0.314124</td>\n",
       "      <td>0.388609</td>\n",
       "      <td>0.093831</td>\n",
       "      <td>0.157430</td>\n",
       "      <td>0.050305</td>\n",
       "      <td>0.078071</td>\n",
       "      <td>0.043760</td>\n",
       "      <td>0.262159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TimeWeekNight_OUT_VUL_12</th>\n",
       "      <td>0.105028</td>\n",
       "      <td>0.635869</td>\n",
       "      <td>0.378848</td>\n",
       "      <td>0.798162</td>\n",
       "      <td>0.478032</td>\n",
       "      <td>0.488800</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.241688</td>\n",
       "      <td>0.495415</td>\n",
       "      <td>0.307642</td>\n",
       "      <td>...</td>\n",
       "      <td>0.302991</td>\n",
       "      <td>0.351959</td>\n",
       "      <td>0.488910</td>\n",
       "      <td>0.224448</td>\n",
       "      <td>0.035734</td>\n",
       "      <td>0.062305</td>\n",
       "      <td>0.017880</td>\n",
       "      <td>0.028267</td>\n",
       "      <td>0.018045</td>\n",
       "      <td>0.142294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VULNERABLE_OUT_12</th>\n",
       "      <td>0.497289</td>\n",
       "      <td>0.315335</td>\n",
       "      <td>0.448494</td>\n",
       "      <td>0.362146</td>\n",
       "      <td>0.399304</td>\n",
       "      <td>0.417388</td>\n",
       "      <td>0.241688</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.294727</td>\n",
       "      <td>0.431177</td>\n",
       "      <td>...</td>\n",
       "      <td>0.341396</td>\n",
       "      <td>0.410452</td>\n",
       "      <td>0.202933</td>\n",
       "      <td>0.770518</td>\n",
       "      <td>0.176316</td>\n",
       "      <td>0.282054</td>\n",
       "      <td>0.117072</td>\n",
       "      <td>0.155896</td>\n",
       "      <td>0.134299</td>\n",
       "      <td>0.503804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TimeWeekEnd_IN_VUL_12</th>\n",
       "      <td>0.164613</td>\n",
       "      <td>0.594255</td>\n",
       "      <td>0.466551</td>\n",
       "      <td>0.515796</td>\n",
       "      <td>0.520518</td>\n",
       "      <td>0.557234</td>\n",
       "      <td>0.495415</td>\n",
       "      <td>0.294727</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.531593</td>\n",
       "      <td>...</td>\n",
       "      <td>0.517292</td>\n",
       "      <td>0.557891</td>\n",
       "      <td>0.497786</td>\n",
       "      <td>0.283148</td>\n",
       "      <td>0.057281</td>\n",
       "      <td>0.098106</td>\n",
       "      <td>0.030502</td>\n",
       "      <td>0.045343</td>\n",
       "      <td>0.027871</td>\n",
       "      <td>0.177840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CallsWeekDay_IN_VUL_12</th>\n",
       "      <td>0.287017</td>\n",
       "      <td>0.467672</td>\n",
       "      <td>0.834490</td>\n",
       "      <td>0.533153</td>\n",
       "      <td>0.701466</td>\n",
       "      <td>0.665846</td>\n",
       "      <td>0.307642</td>\n",
       "      <td>0.431177</td>\n",
       "      <td>0.531593</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.665681</td>\n",
       "      <td>0.717676</td>\n",
       "      <td>0.289233</td>\n",
       "      <td>0.414842</td>\n",
       "      <td>0.095508</td>\n",
       "      <td>0.184024</td>\n",
       "      <td>0.054348</td>\n",
       "      <td>0.083978</td>\n",
       "      <td>0.044692</td>\n",
       "      <td>0.271915</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 77 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           EPIDEMIC  TimeWeekEnd_OUT_VUL_12  \\\n",
       "EPIDEMIC                   1.000000                0.171408   \n",
       "TimeWeekEnd_OUT_VUL_12     0.171408                1.000000   \n",
       "CallsWeekDay_OUT_VUL_12    0.287120                0.560496   \n",
       "CallsWeekNight_OUT_VUL_12  0.206999                0.651113   \n",
       "TimeWeekDay_OUT_VUL_12     0.222914                0.629617   \n",
       "CallsWeekEnd_OUT_VUL_12    0.264443                0.801017   \n",
       "TimeWeekNight_OUT_VUL_12   0.105028                0.635869   \n",
       "VULNERABLE_OUT_12          0.497289                0.315335   \n",
       "TimeWeekEnd_IN_VUL_12      0.164613                0.594255   \n",
       "CallsWeekDay_IN_VUL_12     0.287017                0.467672   \n",
       "\n",
       "                           CallsWeekDay_OUT_VUL_12  CallsWeekNight_OUT_VUL_12  \\\n",
       "EPIDEMIC                                  0.287120                   0.206999   \n",
       "TimeWeekEnd_OUT_VUL_12                    0.560496                   0.651113   \n",
       "CallsWeekDay_OUT_VUL_12                   1.000000                   0.628189   \n",
       "CallsWeekNight_OUT_VUL_12                 0.628189                   1.000000   \n",
       "TimeWeekDay_OUT_VUL_12                    0.864216                   0.586073   \n",
       "CallsWeekEnd_OUT_VUL_12                   0.772855                   0.735115   \n",
       "TimeWeekNight_OUT_VUL_12                  0.378848                   0.798162   \n",
       "VULNERABLE_OUT_12                         0.448494                   0.362146   \n",
       "TimeWeekEnd_IN_VUL_12                     0.466551                   0.515796   \n",
       "CallsWeekDay_IN_VUL_12                    0.834490                   0.533153   \n",
       "\n",
       "                           TimeWeekDay_OUT_VUL_12  CallsWeekEnd_OUT_VUL_12  \\\n",
       "EPIDEMIC                                 0.222914                 0.264443   \n",
       "TimeWeekEnd_OUT_VUL_12                   0.629617                 0.801017   \n",
       "CallsWeekDay_OUT_VUL_12                  0.864216                 0.772855   \n",
       "CallsWeekNight_OUT_VUL_12                0.586073                 0.735115   \n",
       "TimeWeekDay_OUT_VUL_12                   1.000000                 0.665776   \n",
       "CallsWeekEnd_OUT_VUL_12                  0.665776                 1.000000   \n",
       "TimeWeekNight_OUT_VUL_12                 0.478032                 0.488800   \n",
       "VULNERABLE_OUT_12                        0.399304                 0.417388   \n",
       "TimeWeekEnd_IN_VUL_12                    0.520518                 0.557234   \n",
       "CallsWeekDay_IN_VUL_12                   0.701466                 0.665846   \n",
       "\n",
       "                           TimeWeekNight_OUT_VUL_12  VULNERABLE_OUT_12  \\\n",
       "EPIDEMIC                                   0.105028           0.497289   \n",
       "TimeWeekEnd_OUT_VUL_12                     0.635869           0.315335   \n",
       "CallsWeekDay_OUT_VUL_12                    0.378848           0.448494   \n",
       "CallsWeekNight_OUT_VUL_12                  0.798162           0.362146   \n",
       "TimeWeekDay_OUT_VUL_12                     0.478032           0.399304   \n",
       "CallsWeekEnd_OUT_VUL_12                    0.488800           0.417388   \n",
       "TimeWeekNight_OUT_VUL_12                   1.000000           0.241688   \n",
       "VULNERABLE_OUT_12                          0.241688           1.000000   \n",
       "TimeWeekEnd_IN_VUL_12                      0.495415           0.294727   \n",
       "CallsWeekDay_IN_VUL_12                     0.307642           0.431177   \n",
       "\n",
       "                           TimeWeekEnd_IN_VUL_12  CallsWeekDay_IN_VUL_12  \\\n",
       "EPIDEMIC                                0.164613                0.287017   \n",
       "TimeWeekEnd_OUT_VUL_12                  0.594255                0.467672   \n",
       "CallsWeekDay_OUT_VUL_12                 0.466551                0.834490   \n",
       "CallsWeekNight_OUT_VUL_12               0.515796                0.533153   \n",
       "TimeWeekDay_OUT_VUL_12                  0.520518                0.701466   \n",
       "CallsWeekEnd_OUT_VUL_12                 0.557234                0.665846   \n",
       "TimeWeekNight_OUT_VUL_12                0.495415                0.307642   \n",
       "VULNERABLE_OUT_12                       0.294727                0.431177   \n",
       "TimeWeekEnd_IN_VUL_12                   1.000000                0.531593   \n",
       "CallsWeekDay_IN_VUL_12                  0.531593                1.000000   \n",
       "\n",
       "                             ...     TimeWeekDay_IN_VUL_11  \\\n",
       "EPIDEMIC                     ...                  0.217212   \n",
       "TimeWeekEnd_OUT_VUL_12       ...                  0.404869   \n",
       "CallsWeekDay_OUT_VUL_12      ...                  0.578081   \n",
       "CallsWeekNight_OUT_VUL_12    ...                  0.388313   \n",
       "TimeWeekDay_OUT_VUL_12       ...                  0.629497   \n",
       "CallsWeekEnd_OUT_VUL_12      ...                  0.453263   \n",
       "TimeWeekNight_OUT_VUL_12     ...                  0.302991   \n",
       "VULNERABLE_OUT_12            ...                  0.341396   \n",
       "TimeWeekEnd_IN_VUL_12        ...                  0.517292   \n",
       "CallsWeekDay_IN_VUL_12       ...                  0.665681   \n",
       "\n",
       "                           CallsWeekEnd_IN_VUL_11  TimeWeekNight_IN_VUL_11  \\\n",
       "EPIDEMIC                                 0.291858                 0.100896   \n",
       "TimeWeekEnd_OUT_VUL_12                   0.480234                 0.384984   \n",
       "CallsWeekDay_OUT_VUL_12                  0.633350                 0.261531   \n",
       "CallsWeekNight_OUT_VUL_12                0.551986                 0.421814   \n",
       "TimeWeekDay_OUT_VUL_12                   0.538366                 0.327929   \n",
       "CallsWeekEnd_OUT_VUL_12                  0.654575                 0.314124   \n",
       "TimeWeekNight_OUT_VUL_12                 0.351959                 0.488910   \n",
       "VULNERABLE_OUT_12                        0.410452                 0.202933   \n",
       "TimeWeekEnd_IN_VUL_12                    0.557891                 0.497786   \n",
       "CallsWeekDay_IN_VUL_12                   0.717676                 0.289233   \n",
       "\n",
       "                           VULNERABLE_IN_11  STATE_Hidalgo  STATE_Jalisco  \\\n",
       "EPIDEMIC                           0.516003       0.330397       0.489502   \n",
       "TimeWeekEnd_OUT_VUL_12             0.291700       0.061749       0.102921   \n",
       "CallsWeekDay_OUT_VUL_12            0.421996       0.097365       0.184278   \n",
       "CallsWeekNight_OUT_VUL_12          0.337522       0.071198       0.120409   \n",
       "TimeWeekDay_OUT_VUL_12             0.374658       0.071853       0.149734   \n",
       "CallsWeekEnd_OUT_VUL_12            0.388609       0.093831       0.157430   \n",
       "TimeWeekNight_OUT_VUL_12           0.224448       0.035734       0.062305   \n",
       "VULNERABLE_OUT_12                  0.770518       0.176316       0.282054   \n",
       "TimeWeekEnd_IN_VUL_12              0.283148       0.057281       0.098106   \n",
       "CallsWeekDay_IN_VUL_12             0.414842       0.095508       0.184024   \n",
       "\n",
       "                           STATE_Morelos  STATE_Puebla  STATE_Veracruz  \\\n",
       "EPIDEMIC                        0.263178      0.331527        0.297942   \n",
       "TimeWeekEnd_OUT_VUL_12          0.030067      0.045572        0.026676   \n",
       "CallsWeekDay_OUT_VUL_12         0.053034      0.079153        0.045011   \n",
       "CallsWeekNight_OUT_VUL_12       0.041128      0.060885        0.037357   \n",
       "TimeWeekDay_OUT_VUL_12          0.037512      0.057518        0.034943   \n",
       "CallsWeekEnd_OUT_VUL_12         0.050305      0.078071        0.043760   \n",
       "TimeWeekNight_OUT_VUL_12        0.017880      0.028267        0.018045   \n",
       "VULNERABLE_OUT_12               0.117072      0.155896        0.134299   \n",
       "TimeWeekEnd_IN_VUL_12           0.030502      0.045343        0.027871   \n",
       "CallsWeekDay_IN_VUL_12          0.054348      0.083978        0.044692   \n",
       "\n",
       "                             target  \n",
       "EPIDEMIC                   0.439418  \n",
       "TimeWeekEnd_OUT_VUL_12     0.187130  \n",
       "CallsWeekDay_OUT_VUL_12    0.277760  \n",
       "CallsWeekNight_OUT_VUL_12  0.225518  \n",
       "TimeWeekDay_OUT_VUL_12     0.231432  \n",
       "CallsWeekEnd_OUT_VUL_12    0.262159  \n",
       "TimeWeekNight_OUT_VUL_12   0.142294  \n",
       "VULNERABLE_OUT_12          0.503804  \n",
       "TimeWeekEnd_IN_VUL_12      0.177840  \n",
       "CallsWeekDay_IN_VUL_12     0.271915  \n",
       "\n",
       "[10 rows x 77 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "view = corr.query('target>0.1')\n",
    "# show only those columns which \n",
    "corr_columns = view.index.values\n",
    "\n",
    "view[corr_columns].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATE_Aguascalientes</th>\n",
       "      <th>STATE_Baja_California</th>\n",
       "      <th>STATE_Baja_California_Sur</th>\n",
       "      <th>STATE_Campeche</th>\n",
       "      <th>STATE_Chiapas</th>\n",
       "      <th>STATE_Chihuahua</th>\n",
       "      <th>STATE_Coahuila_de_Zaragoza</th>\n",
       "      <th>STATE_Colima</th>\n",
       "      <th>STATE_Distrito_Federal</th>\n",
       "      <th>STATE_Durango</th>\n",
       "      <th>...</th>\n",
       "      <th>STATE_San_Luis_Potosi</th>\n",
       "      <th>STATE_Sinaloa</th>\n",
       "      <th>STATE_Sonora</th>\n",
       "      <th>STATE_Tabasco</th>\n",
       "      <th>STATE_Tamaulipas</th>\n",
       "      <th>STATE_Tlaxcala</th>\n",
       "      <th>STATE_Veracruz</th>\n",
       "      <th>STATE_Yucatan</th>\n",
       "      <th>STATE_Zacatecas</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MOBILITY_DIAMETER</th>\n",
       "      <td>0.045902</td>\n",
       "      <td>0.145942</td>\n",
       "      <td>0.032684</td>\n",
       "      <td>0.006103</td>\n",
       "      <td>-0.014679</td>\n",
       "      <td>0.024696</td>\n",
       "      <td>-0.002260</td>\n",
       "      <td>-0.006266</td>\n",
       "      <td>-0.138609</td>\n",
       "      <td>-0.009381</td>\n",
       "      <td>...</td>\n",
       "      <td>0.062277</td>\n",
       "      <td>0.051715</td>\n",
       "      <td>0.080137</td>\n",
       "      <td>0.004682</td>\n",
       "      <td>0.005265</td>\n",
       "      <td>-0.019447</td>\n",
       "      <td>0.056086</td>\n",
       "      <td>-0.029270</td>\n",
       "      <td>0.000641</td>\n",
       "      <td>0.013764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MOBILITY_DIAMETER_WEEKNIGHT</th>\n",
       "      <td>0.046654</td>\n",
       "      <td>0.145805</td>\n",
       "      <td>0.033328</td>\n",
       "      <td>0.006141</td>\n",
       "      <td>-0.009792</td>\n",
       "      <td>0.023230</td>\n",
       "      <td>-0.001692</td>\n",
       "      <td>-0.004915</td>\n",
       "      <td>-0.120051</td>\n",
       "      <td>-0.009230</td>\n",
       "      <td>...</td>\n",
       "      <td>0.063803</td>\n",
       "      <td>0.053742</td>\n",
       "      <td>0.082001</td>\n",
       "      <td>0.006905</td>\n",
       "      <td>0.005447</td>\n",
       "      <td>-0.026101</td>\n",
       "      <td>0.045211</td>\n",
       "      <td>-0.021405</td>\n",
       "      <td>-0.005553</td>\n",
       "      <td>0.014906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EPIDEMIC</th>\n",
       "      <td>-0.070297</td>\n",
       "      <td>-0.063463</td>\n",
       "      <td>-0.025483</td>\n",
       "      <td>-0.057895</td>\n",
       "      <td>-0.086392</td>\n",
       "      <td>-0.041519</td>\n",
       "      <td>-0.046698</td>\n",
       "      <td>-0.044976</td>\n",
       "      <td>-0.346309</td>\n",
       "      <td>-0.034628</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.079844</td>\n",
       "      <td>-0.052823</td>\n",
       "      <td>-0.038012</td>\n",
       "      <td>0.223487</td>\n",
       "      <td>-0.051591</td>\n",
       "      <td>-0.088226</td>\n",
       "      <td>0.297942</td>\n",
       "      <td>-0.109580</td>\n",
       "      <td>-0.034769</td>\n",
       "      <td>0.439418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TimeWeekEnd_OUT_VUL_12</th>\n",
       "      <td>-0.013845</td>\n",
       "      <td>-0.004919</td>\n",
       "      <td>0.010538</td>\n",
       "      <td>0.000871</td>\n",
       "      <td>-0.012463</td>\n",
       "      <td>-0.004699</td>\n",
       "      <td>-0.012326</td>\n",
       "      <td>0.007216</td>\n",
       "      <td>-0.058471</td>\n",
       "      <td>-0.009700</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.015667</td>\n",
       "      <td>0.009809</td>\n",
       "      <td>0.008594</td>\n",
       "      <td>0.062447</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>-0.012570</td>\n",
       "      <td>0.026676</td>\n",
       "      <td>-0.025227</td>\n",
       "      <td>-0.004827</td>\n",
       "      <td>0.187130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CallsWeekDay_OUT_VUL_12</th>\n",
       "      <td>-0.023551</td>\n",
       "      <td>-0.016264</td>\n",
       "      <td>0.001278</td>\n",
       "      <td>-0.011864</td>\n",
       "      <td>-0.023981</td>\n",
       "      <td>-0.007346</td>\n",
       "      <td>-0.017427</td>\n",
       "      <td>0.008317</td>\n",
       "      <td>-0.095216</td>\n",
       "      <td>-0.013552</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.029249</td>\n",
       "      <td>0.003711</td>\n",
       "      <td>0.008158</td>\n",
       "      <td>0.086426</td>\n",
       "      <td>-0.008732</td>\n",
       "      <td>-0.021534</td>\n",
       "      <td>0.045011</td>\n",
       "      <td>-0.040492</td>\n",
       "      <td>-0.010899</td>\n",
       "      <td>0.277760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CallsWeekNight_OUT_VUL_12</th>\n",
       "      <td>-0.018538</td>\n",
       "      <td>-0.010279</td>\n",
       "      <td>0.007098</td>\n",
       "      <td>-0.002889</td>\n",
       "      <td>-0.017992</td>\n",
       "      <td>-0.004098</td>\n",
       "      <td>-0.013196</td>\n",
       "      <td>0.007299</td>\n",
       "      <td>-0.065420</td>\n",
       "      <td>-0.010092</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018457</td>\n",
       "      <td>0.007416</td>\n",
       "      <td>0.009478</td>\n",
       "      <td>0.073654</td>\n",
       "      <td>0.000079</td>\n",
       "      <td>-0.013420</td>\n",
       "      <td>0.037357</td>\n",
       "      <td>-0.030622</td>\n",
       "      <td>-0.008207</td>\n",
       "      <td>0.225518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TimeWeekDay_OUT_VUL_12</th>\n",
       "      <td>-0.018978</td>\n",
       "      <td>-0.009812</td>\n",
       "      <td>0.005776</td>\n",
       "      <td>-0.003502</td>\n",
       "      <td>-0.016605</td>\n",
       "      <td>-0.004612</td>\n",
       "      <td>-0.014868</td>\n",
       "      <td>0.013340</td>\n",
       "      <td>-0.072652</td>\n",
       "      <td>-0.011919</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.025230</td>\n",
       "      <td>0.009093</td>\n",
       "      <td>0.012902</td>\n",
       "      <td>0.071986</td>\n",
       "      <td>-0.004842</td>\n",
       "      <td>-0.017533</td>\n",
       "      <td>0.034943</td>\n",
       "      <td>-0.033579</td>\n",
       "      <td>-0.009226</td>\n",
       "      <td>0.231432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CallsWeekEnd_OUT_VUL_12</th>\n",
       "      <td>-0.020222</td>\n",
       "      <td>-0.013935</td>\n",
       "      <td>0.003964</td>\n",
       "      <td>-0.008532</td>\n",
       "      <td>-0.022123</td>\n",
       "      <td>-0.007780</td>\n",
       "      <td>-0.016322</td>\n",
       "      <td>0.005513</td>\n",
       "      <td>-0.087076</td>\n",
       "      <td>-0.013012</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.025451</td>\n",
       "      <td>0.003389</td>\n",
       "      <td>0.007596</td>\n",
       "      <td>0.082011</td>\n",
       "      <td>-0.007149</td>\n",
       "      <td>-0.017540</td>\n",
       "      <td>0.043760</td>\n",
       "      <td>-0.036603</td>\n",
       "      <td>-0.009751</td>\n",
       "      <td>0.262159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TimeWeekNight_OUT_VUL_12</th>\n",
       "      <td>-0.011181</td>\n",
       "      <td>-0.002776</td>\n",
       "      <td>0.011300</td>\n",
       "      <td>0.007510</td>\n",
       "      <td>-0.007542</td>\n",
       "      <td>0.001704</td>\n",
       "      <td>-0.006902</td>\n",
       "      <td>0.004665</td>\n",
       "      <td>-0.032920</td>\n",
       "      <td>-0.006101</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.008368</td>\n",
       "      <td>0.012940</td>\n",
       "      <td>0.011473</td>\n",
       "      <td>0.046054</td>\n",
       "      <td>0.004008</td>\n",
       "      <td>-0.006425</td>\n",
       "      <td>0.018045</td>\n",
       "      <td>-0.017813</td>\n",
       "      <td>-0.003635</td>\n",
       "      <td>0.142294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VULNERABLE_OUT_12</th>\n",
       "      <td>-0.038502</td>\n",
       "      <td>-0.028439</td>\n",
       "      <td>0.010884</td>\n",
       "      <td>-0.015736</td>\n",
       "      <td>-0.041065</td>\n",
       "      <td>-0.014000</td>\n",
       "      <td>-0.034331</td>\n",
       "      <td>0.010190</td>\n",
       "      <td>-0.148067</td>\n",
       "      <td>-0.024705</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.051399</td>\n",
       "      <td>0.016951</td>\n",
       "      <td>0.017911</td>\n",
       "      <td>0.115796</td>\n",
       "      <td>-0.015172</td>\n",
       "      <td>-0.025880</td>\n",
       "      <td>0.134299</td>\n",
       "      <td>-0.074840</td>\n",
       "      <td>-0.019988</td>\n",
       "      <td>0.503804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TimeWeekEnd_IN_VUL_12</th>\n",
       "      <td>-0.011941</td>\n",
       "      <td>-0.007219</td>\n",
       "      <td>0.009124</td>\n",
       "      <td>0.000403</td>\n",
       "      <td>-0.008797</td>\n",
       "      <td>-0.001187</td>\n",
       "      <td>-0.010547</td>\n",
       "      <td>0.009127</td>\n",
       "      <td>-0.055902</td>\n",
       "      <td>-0.008682</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.015849</td>\n",
       "      <td>0.007407</td>\n",
       "      <td>0.004355</td>\n",
       "      <td>0.060743</td>\n",
       "      <td>-0.002125</td>\n",
       "      <td>-0.009439</td>\n",
       "      <td>0.027871</td>\n",
       "      <td>-0.021220</td>\n",
       "      <td>-0.006139</td>\n",
       "      <td>0.177840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CallsWeekDay_IN_VUL_12</th>\n",
       "      <td>-0.022734</td>\n",
       "      <td>-0.017515</td>\n",
       "      <td>0.001092</td>\n",
       "      <td>-0.014149</td>\n",
       "      <td>-0.024679</td>\n",
       "      <td>-0.005824</td>\n",
       "      <td>-0.017638</td>\n",
       "      <td>0.005301</td>\n",
       "      <td>-0.094969</td>\n",
       "      <td>-0.012157</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.028571</td>\n",
       "      <td>0.002017</td>\n",
       "      <td>0.006453</td>\n",
       "      <td>0.084164</td>\n",
       "      <td>-0.009910</td>\n",
       "      <td>-0.020423</td>\n",
       "      <td>0.044692</td>\n",
       "      <td>-0.039479</td>\n",
       "      <td>-0.010699</td>\n",
       "      <td>0.271915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CallsWeekNight_IN_VUL_12</th>\n",
       "      <td>-0.014445</td>\n",
       "      <td>-0.010335</td>\n",
       "      <td>0.003971</td>\n",
       "      <td>-0.007689</td>\n",
       "      <td>-0.015009</td>\n",
       "      <td>-0.003297</td>\n",
       "      <td>-0.011581</td>\n",
       "      <td>0.005283</td>\n",
       "      <td>-0.051608</td>\n",
       "      <td>-0.008645</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.017341</td>\n",
       "      <td>0.001028</td>\n",
       "      <td>0.006369</td>\n",
       "      <td>0.061843</td>\n",
       "      <td>-0.004359</td>\n",
       "      <td>-0.009094</td>\n",
       "      <td>0.030556</td>\n",
       "      <td>-0.023477</td>\n",
       "      <td>-0.006542</td>\n",
       "      <td>0.181260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TimeWeekDay_IN_VUL_12</th>\n",
       "      <td>-0.017269</td>\n",
       "      <td>-0.012512</td>\n",
       "      <td>0.005681</td>\n",
       "      <td>-0.006106</td>\n",
       "      <td>-0.016567</td>\n",
       "      <td>-0.001686</td>\n",
       "      <td>-0.014790</td>\n",
       "      <td>0.010649</td>\n",
       "      <td>-0.073295</td>\n",
       "      <td>-0.010201</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.022686</td>\n",
       "      <td>0.005547</td>\n",
       "      <td>0.010726</td>\n",
       "      <td>0.067460</td>\n",
       "      <td>-0.003426</td>\n",
       "      <td>-0.012760</td>\n",
       "      <td>0.032635</td>\n",
       "      <td>-0.030761</td>\n",
       "      <td>-0.007438</td>\n",
       "      <td>0.218512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CallsWeekEnd_IN_VUL_12</th>\n",
       "      <td>-0.019733</td>\n",
       "      <td>-0.016008</td>\n",
       "      <td>0.002096</td>\n",
       "      <td>-0.010015</td>\n",
       "      <td>-0.021943</td>\n",
       "      <td>-0.005365</td>\n",
       "      <td>-0.016141</td>\n",
       "      <td>0.004797</td>\n",
       "      <td>-0.085622</td>\n",
       "      <td>-0.011813</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.026017</td>\n",
       "      <td>0.003175</td>\n",
       "      <td>0.003951</td>\n",
       "      <td>0.082933</td>\n",
       "      <td>-0.009613</td>\n",
       "      <td>-0.017490</td>\n",
       "      <td>0.044180</td>\n",
       "      <td>-0.035228</td>\n",
       "      <td>-0.010155</td>\n",
       "      <td>0.260075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TimeWeekNight_IN_VUL_12</th>\n",
       "      <td>-0.008331</td>\n",
       "      <td>-0.005395</td>\n",
       "      <td>0.009430</td>\n",
       "      <td>-0.001179</td>\n",
       "      <td>-0.005873</td>\n",
       "      <td>-0.001072</td>\n",
       "      <td>-0.007739</td>\n",
       "      <td>0.006901</td>\n",
       "      <td>-0.033393</td>\n",
       "      <td>-0.006719</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009778</td>\n",
       "      <td>0.001765</td>\n",
       "      <td>0.010466</td>\n",
       "      <td>0.044710</td>\n",
       "      <td>0.002314</td>\n",
       "      <td>-0.002664</td>\n",
       "      <td>0.016526</td>\n",
       "      <td>-0.012363</td>\n",
       "      <td>-0.004821</td>\n",
       "      <td>0.130211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VULNERABLE_IN_12</th>\n",
       "      <td>-0.039073</td>\n",
       "      <td>-0.028259</td>\n",
       "      <td>0.010560</td>\n",
       "      <td>-0.014084</td>\n",
       "      <td>-0.039697</td>\n",
       "      <td>-0.013364</td>\n",
       "      <td>-0.034440</td>\n",
       "      <td>0.012244</td>\n",
       "      <td>-0.148437</td>\n",
       "      <td>-0.022464</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.049569</td>\n",
       "      <td>0.016128</td>\n",
       "      <td>0.016371</td>\n",
       "      <td>0.119048</td>\n",
       "      <td>-0.015639</td>\n",
       "      <td>-0.024392</td>\n",
       "      <td>0.133377</td>\n",
       "      <td>-0.074454</td>\n",
       "      <td>-0.019893</td>\n",
       "      <td>0.501857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TimeWeekEnd_OUT_VUL_08</th>\n",
       "      <td>-0.014888</td>\n",
       "      <td>-0.006016</td>\n",
       "      <td>0.012968</td>\n",
       "      <td>0.000801</td>\n",
       "      <td>-0.010508</td>\n",
       "      <td>-0.002863</td>\n",
       "      <td>-0.009138</td>\n",
       "      <td>0.009581</td>\n",
       "      <td>-0.066524</td>\n",
       "      <td>-0.010299</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.016996</td>\n",
       "      <td>0.008099</td>\n",
       "      <td>0.006049</td>\n",
       "      <td>0.043162</td>\n",
       "      <td>-0.009573</td>\n",
       "      <td>-0.014808</td>\n",
       "      <td>0.028026</td>\n",
       "      <td>-0.027693</td>\n",
       "      <td>-0.009406</td>\n",
       "      <td>0.212387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CallsWeekDay_OUT_VUL_08</th>\n",
       "      <td>-0.023667</td>\n",
       "      <td>-0.015612</td>\n",
       "      <td>0.002006</td>\n",
       "      <td>-0.012350</td>\n",
       "      <td>-0.024371</td>\n",
       "      <td>-0.008413</td>\n",
       "      <td>-0.016763</td>\n",
       "      <td>0.007694</td>\n",
       "      <td>-0.100517</td>\n",
       "      <td>-0.012728</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.027831</td>\n",
       "      <td>-0.000889</td>\n",
       "      <td>0.000859</td>\n",
       "      <td>0.056729</td>\n",
       "      <td>-0.011737</td>\n",
       "      <td>-0.023667</td>\n",
       "      <td>0.033539</td>\n",
       "      <td>-0.040270</td>\n",
       "      <td>-0.011249</td>\n",
       "      <td>0.285261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CallsWeekNight_OUT_VUL_08</th>\n",
       "      <td>-0.017918</td>\n",
       "      <td>-0.012333</td>\n",
       "      <td>0.006172</td>\n",
       "      <td>-0.004510</td>\n",
       "      <td>-0.018119</td>\n",
       "      <td>-0.006373</td>\n",
       "      <td>-0.012421</td>\n",
       "      <td>0.011807</td>\n",
       "      <td>-0.077437</td>\n",
       "      <td>-0.012022</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018302</td>\n",
       "      <td>0.001661</td>\n",
       "      <td>0.000097</td>\n",
       "      <td>0.058156</td>\n",
       "      <td>-0.006670</td>\n",
       "      <td>-0.016671</td>\n",
       "      <td>0.039821</td>\n",
       "      <td>-0.035165</td>\n",
       "      <td>-0.008376</td>\n",
       "      <td>0.251499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TimeWeekDay_OUT_VUL_08</th>\n",
       "      <td>-0.018726</td>\n",
       "      <td>-0.011476</td>\n",
       "      <td>0.004707</td>\n",
       "      <td>-0.003298</td>\n",
       "      <td>-0.017098</td>\n",
       "      <td>-0.004659</td>\n",
       "      <td>-0.013679</td>\n",
       "      <td>0.009222</td>\n",
       "      <td>-0.080285</td>\n",
       "      <td>-0.011460</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.022572</td>\n",
       "      <td>0.001723</td>\n",
       "      <td>0.001539</td>\n",
       "      <td>0.050420</td>\n",
       "      <td>-0.008699</td>\n",
       "      <td>-0.019548</td>\n",
       "      <td>0.028935</td>\n",
       "      <td>-0.032952</td>\n",
       "      <td>-0.009823</td>\n",
       "      <td>0.241347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CallsWeekEnd_OUT_VUL_08</th>\n",
       "      <td>-0.022615</td>\n",
       "      <td>-0.015607</td>\n",
       "      <td>0.006733</td>\n",
       "      <td>-0.011024</td>\n",
       "      <td>-0.023665</td>\n",
       "      <td>-0.008168</td>\n",
       "      <td>-0.015545</td>\n",
       "      <td>0.006173</td>\n",
       "      <td>-0.098373</td>\n",
       "      <td>-0.014137</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.027818</td>\n",
       "      <td>0.001105</td>\n",
       "      <td>0.003801</td>\n",
       "      <td>0.061533</td>\n",
       "      <td>-0.013403</td>\n",
       "      <td>-0.021107</td>\n",
       "      <td>0.040742</td>\n",
       "      <td>-0.041324</td>\n",
       "      <td>-0.012210</td>\n",
       "      <td>0.302695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TimeWeekNight_OUT_VUL_08</th>\n",
       "      <td>-0.009146</td>\n",
       "      <td>-0.004605</td>\n",
       "      <td>0.009587</td>\n",
       "      <td>0.007543</td>\n",
       "      <td>-0.006124</td>\n",
       "      <td>-0.002268</td>\n",
       "      <td>-0.005949</td>\n",
       "      <td>0.014619</td>\n",
       "      <td>-0.041173</td>\n",
       "      <td>-0.008213</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.008381</td>\n",
       "      <td>0.006252</td>\n",
       "      <td>0.001248</td>\n",
       "      <td>0.037715</td>\n",
       "      <td>-0.003574</td>\n",
       "      <td>-0.009628</td>\n",
       "      <td>0.026862</td>\n",
       "      <td>-0.021373</td>\n",
       "      <td>-0.005066</td>\n",
       "      <td>0.158270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VULNERABLE_OUT_08</th>\n",
       "      <td>-0.042068</td>\n",
       "      <td>-0.029876</td>\n",
       "      <td>0.011004</td>\n",
       "      <td>-0.016881</td>\n",
       "      <td>-0.043695</td>\n",
       "      <td>-0.011574</td>\n",
       "      <td>-0.033381</td>\n",
       "      <td>0.009990</td>\n",
       "      <td>-0.163333</td>\n",
       "      <td>-0.024895</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.055620</td>\n",
       "      <td>0.007313</td>\n",
       "      <td>0.008928</td>\n",
       "      <td>0.117939</td>\n",
       "      <td>-0.021691</td>\n",
       "      <td>-0.027511</td>\n",
       "      <td>0.148312</td>\n",
       "      <td>-0.079833</td>\n",
       "      <td>-0.020899</td>\n",
       "      <td>0.553884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TimeWeekEnd_IN_VUL_08</th>\n",
       "      <td>-0.012433</td>\n",
       "      <td>-0.006905</td>\n",
       "      <td>0.010277</td>\n",
       "      <td>0.001186</td>\n",
       "      <td>-0.011913</td>\n",
       "      <td>-0.000447</td>\n",
       "      <td>-0.009536</td>\n",
       "      <td>0.007084</td>\n",
       "      <td>-0.066346</td>\n",
       "      <td>-0.009039</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.016378</td>\n",
       "      <td>0.003768</td>\n",
       "      <td>-0.002875</td>\n",
       "      <td>0.044014</td>\n",
       "      <td>-0.008132</td>\n",
       "      <td>-0.011787</td>\n",
       "      <td>0.029405</td>\n",
       "      <td>-0.024769</td>\n",
       "      <td>-0.009613</td>\n",
       "      <td>0.210637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CallsWeekDay_IN_VUL_08</th>\n",
       "      <td>-0.023635</td>\n",
       "      <td>-0.017116</td>\n",
       "      <td>0.000570</td>\n",
       "      <td>-0.014565</td>\n",
       "      <td>-0.025160</td>\n",
       "      <td>-0.008731</td>\n",
       "      <td>-0.016592</td>\n",
       "      <td>0.003383</td>\n",
       "      <td>-0.102761</td>\n",
       "      <td>-0.012637</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.028898</td>\n",
       "      <td>-0.002120</td>\n",
       "      <td>0.001790</td>\n",
       "      <td>0.056114</td>\n",
       "      <td>-0.013970</td>\n",
       "      <td>-0.022312</td>\n",
       "      <td>0.034086</td>\n",
       "      <td>-0.040130</td>\n",
       "      <td>-0.011147</td>\n",
       "      <td>0.292085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CallsWeekNight_IN_VUL_08</th>\n",
       "      <td>-0.017572</td>\n",
       "      <td>-0.014226</td>\n",
       "      <td>0.004031</td>\n",
       "      <td>-0.007094</td>\n",
       "      <td>-0.020109</td>\n",
       "      <td>-0.007246</td>\n",
       "      <td>-0.013465</td>\n",
       "      <td>0.006743</td>\n",
       "      <td>-0.081616</td>\n",
       "      <td>-0.011378</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.020754</td>\n",
       "      <td>-0.002726</td>\n",
       "      <td>-0.003261</td>\n",
       "      <td>0.057936</td>\n",
       "      <td>-0.011224</td>\n",
       "      <td>-0.015673</td>\n",
       "      <td>0.039996</td>\n",
       "      <td>-0.034734</td>\n",
       "      <td>-0.009078</td>\n",
       "      <td>0.256445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TimeWeekDay_IN_VUL_08</th>\n",
       "      <td>-0.017795</td>\n",
       "      <td>-0.012824</td>\n",
       "      <td>0.003353</td>\n",
       "      <td>-0.005423</td>\n",
       "      <td>-0.015726</td>\n",
       "      <td>-0.004322</td>\n",
       "      <td>-0.013246</td>\n",
       "      <td>0.004251</td>\n",
       "      <td>-0.081709</td>\n",
       "      <td>-0.010805</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.021825</td>\n",
       "      <td>0.000841</td>\n",
       "      <td>0.002633</td>\n",
       "      <td>0.047508</td>\n",
       "      <td>-0.010085</td>\n",
       "      <td>-0.017013</td>\n",
       "      <td>0.030258</td>\n",
       "      <td>-0.032017</td>\n",
       "      <td>-0.009567</td>\n",
       "      <td>0.240071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CallsWeekEnd_IN_VUL_08</th>\n",
       "      <td>-0.022465</td>\n",
       "      <td>-0.017283</td>\n",
       "      <td>0.002169</td>\n",
       "      <td>-0.012631</td>\n",
       "      <td>-0.025949</td>\n",
       "      <td>-0.008586</td>\n",
       "      <td>-0.016163</td>\n",
       "      <td>0.004962</td>\n",
       "      <td>-0.101655</td>\n",
       "      <td>-0.013285</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.029035</td>\n",
       "      <td>-0.001719</td>\n",
       "      <td>-0.002320</td>\n",
       "      <td>0.064650</td>\n",
       "      <td>-0.015482</td>\n",
       "      <td>-0.020940</td>\n",
       "      <td>0.041274</td>\n",
       "      <td>-0.040855</td>\n",
       "      <td>-0.012837</td>\n",
       "      <td>0.311608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TimeWeekNight_IN_VUL_08</th>\n",
       "      <td>-0.007130</td>\n",
       "      <td>-0.005548</td>\n",
       "      <td>0.008463</td>\n",
       "      <td>0.004672</td>\n",
       "      <td>-0.007582</td>\n",
       "      <td>-0.001964</td>\n",
       "      <td>-0.006486</td>\n",
       "      <td>0.007902</td>\n",
       "      <td>-0.042644</td>\n",
       "      <td>-0.007133</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.007680</td>\n",
       "      <td>0.001205</td>\n",
       "      <td>-0.002124</td>\n",
       "      <td>0.039534</td>\n",
       "      <td>-0.004664</td>\n",
       "      <td>-0.007273</td>\n",
       "      <td>0.027516</td>\n",
       "      <td>-0.019412</td>\n",
       "      <td>-0.004548</td>\n",
       "      <td>0.150745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VULNERABLE_IN_10</th>\n",
       "      <td>-0.038625</td>\n",
       "      <td>-0.030801</td>\n",
       "      <td>0.010946</td>\n",
       "      <td>-0.019521</td>\n",
       "      <td>-0.043353</td>\n",
       "      <td>-0.013185</td>\n",
       "      <td>-0.033649</td>\n",
       "      <td>0.008419</td>\n",
       "      <td>-0.153595</td>\n",
       "      <td>-0.024127</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.052471</td>\n",
       "      <td>0.017044</td>\n",
       "      <td>0.012636</td>\n",
       "      <td>0.115118</td>\n",
       "      <td>-0.022143</td>\n",
       "      <td>-0.026024</td>\n",
       "      <td>0.137516</td>\n",
       "      <td>-0.077313</td>\n",
       "      <td>-0.020346</td>\n",
       "      <td>0.520670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TimeWeekEnd_OUT_VUL_11</th>\n",
       "      <td>-0.014707</td>\n",
       "      <td>-0.000894</td>\n",
       "      <td>0.012022</td>\n",
       "      <td>-0.000866</td>\n",
       "      <td>-0.009295</td>\n",
       "      <td>-0.005395</td>\n",
       "      <td>-0.008423</td>\n",
       "      <td>0.010130</td>\n",
       "      <td>-0.060510</td>\n",
       "      <td>-0.009805</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.016946</td>\n",
       "      <td>0.004187</td>\n",
       "      <td>0.010818</td>\n",
       "      <td>0.055936</td>\n",
       "      <td>-0.001120</td>\n",
       "      <td>-0.013572</td>\n",
       "      <td>0.032943</td>\n",
       "      <td>-0.027074</td>\n",
       "      <td>-0.008618</td>\n",
       "      <td>0.200561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CallsWeekDay_OUT_VUL_11</th>\n",
       "      <td>-0.022992</td>\n",
       "      <td>-0.015743</td>\n",
       "      <td>0.001785</td>\n",
       "      <td>-0.012608</td>\n",
       "      <td>-0.024111</td>\n",
       "      <td>-0.008435</td>\n",
       "      <td>-0.016663</td>\n",
       "      <td>0.006639</td>\n",
       "      <td>-0.098876</td>\n",
       "      <td>-0.013194</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.027827</td>\n",
       "      <td>0.000382</td>\n",
       "      <td>0.007579</td>\n",
       "      <td>0.064408</td>\n",
       "      <td>-0.010861</td>\n",
       "      <td>-0.023713</td>\n",
       "      <td>0.037267</td>\n",
       "      <td>-0.040092</td>\n",
       "      <td>-0.011508</td>\n",
       "      <td>0.269011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CallsWeekNight_OUT_VUL_11</th>\n",
       "      <td>-0.018888</td>\n",
       "      <td>-0.007526</td>\n",
       "      <td>0.002922</td>\n",
       "      <td>-0.004930</td>\n",
       "      <td>-0.015121</td>\n",
       "      <td>-0.006878</td>\n",
       "      <td>-0.013044</td>\n",
       "      <td>0.008630</td>\n",
       "      <td>-0.066158</td>\n",
       "      <td>-0.011169</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018366</td>\n",
       "      <td>0.002375</td>\n",
       "      <td>0.006771</td>\n",
       "      <td>0.057972</td>\n",
       "      <td>-0.006027</td>\n",
       "      <td>-0.015346</td>\n",
       "      <td>0.038968</td>\n",
       "      <td>-0.031788</td>\n",
       "      <td>-0.007673</td>\n",
       "      <td>0.228012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TimeWeekDay_OUT_VUL_11</th>\n",
       "      <td>-0.018876</td>\n",
       "      <td>-0.008520</td>\n",
       "      <td>0.006175</td>\n",
       "      <td>-0.005550</td>\n",
       "      <td>-0.016178</td>\n",
       "      <td>-0.005120</td>\n",
       "      <td>-0.013186</td>\n",
       "      <td>0.009317</td>\n",
       "      <td>-0.076616</td>\n",
       "      <td>-0.011626</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.023102</td>\n",
       "      <td>0.005388</td>\n",
       "      <td>0.010241</td>\n",
       "      <td>0.055892</td>\n",
       "      <td>-0.006675</td>\n",
       "      <td>-0.020542</td>\n",
       "      <td>0.030435</td>\n",
       "      <td>-0.032526</td>\n",
       "      <td>-0.010093</td>\n",
       "      <td>0.230498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CallsWeekEnd_OUT_VUL_11</th>\n",
       "      <td>-0.022659</td>\n",
       "      <td>-0.014022</td>\n",
       "      <td>0.004288</td>\n",
       "      <td>-0.010512</td>\n",
       "      <td>-0.022154</td>\n",
       "      <td>-0.008321</td>\n",
       "      <td>-0.015568</td>\n",
       "      <td>0.007385</td>\n",
       "      <td>-0.096141</td>\n",
       "      <td>-0.013460</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.027295</td>\n",
       "      <td>-0.000889</td>\n",
       "      <td>0.008332</td>\n",
       "      <td>0.074566</td>\n",
       "      <td>-0.008616</td>\n",
       "      <td>-0.021581</td>\n",
       "      <td>0.047258</td>\n",
       "      <td>-0.040323</td>\n",
       "      <td>-0.012025</td>\n",
       "      <td>0.281308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TimeWeekNight_OUT_VUL_11</th>\n",
       "      <td>-0.010594</td>\n",
       "      <td>0.002235</td>\n",
       "      <td>0.005578</td>\n",
       "      <td>0.005391</td>\n",
       "      <td>-0.004070</td>\n",
       "      <td>-0.003349</td>\n",
       "      <td>-0.006980</td>\n",
       "      <td>0.007482</td>\n",
       "      <td>-0.029528</td>\n",
       "      <td>-0.007502</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.008709</td>\n",
       "      <td>0.007481</td>\n",
       "      <td>0.009330</td>\n",
       "      <td>0.037985</td>\n",
       "      <td>-0.003169</td>\n",
       "      <td>-0.009030</td>\n",
       "      <td>0.021632</td>\n",
       "      <td>-0.018083</td>\n",
       "      <td>-0.004057</td>\n",
       "      <td>0.150229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VULNERABLE_OUT_11</th>\n",
       "      <td>-0.038449</td>\n",
       "      <td>-0.029018</td>\n",
       "      <td>0.008253</td>\n",
       "      <td>-0.019533</td>\n",
       "      <td>-0.043642</td>\n",
       "      <td>-0.014989</td>\n",
       "      <td>-0.034372</td>\n",
       "      <td>0.010196</td>\n",
       "      <td>-0.154592</td>\n",
       "      <td>-0.025856</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.053477</td>\n",
       "      <td>0.014015</td>\n",
       "      <td>0.016510</td>\n",
       "      <td>0.113726</td>\n",
       "      <td>-0.017535</td>\n",
       "      <td>-0.025637</td>\n",
       "      <td>0.139138</td>\n",
       "      <td>-0.079135</td>\n",
       "      <td>-0.022685</td>\n",
       "      <td>0.514446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TimeWeekEnd_IN_VUL_11</th>\n",
       "      <td>-0.015505</td>\n",
       "      <td>-0.005516</td>\n",
       "      <td>0.013516</td>\n",
       "      <td>-0.000154</td>\n",
       "      <td>-0.011698</td>\n",
       "      <td>-0.000745</td>\n",
       "      <td>-0.009516</td>\n",
       "      <td>0.003122</td>\n",
       "      <td>-0.059657</td>\n",
       "      <td>-0.008961</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.015455</td>\n",
       "      <td>0.004553</td>\n",
       "      <td>0.005230</td>\n",
       "      <td>0.051093</td>\n",
       "      <td>-0.007191</td>\n",
       "      <td>-0.009467</td>\n",
       "      <td>0.035859</td>\n",
       "      <td>-0.019347</td>\n",
       "      <td>-0.008244</td>\n",
       "      <td>0.190351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CallsWeekDay_IN_VUL_11</th>\n",
       "      <td>-0.022309</td>\n",
       "      <td>-0.018199</td>\n",
       "      <td>0.001485</td>\n",
       "      <td>-0.014797</td>\n",
       "      <td>-0.024042</td>\n",
       "      <td>-0.007438</td>\n",
       "      <td>-0.016817</td>\n",
       "      <td>0.003384</td>\n",
       "      <td>-0.098711</td>\n",
       "      <td>-0.012627</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.027713</td>\n",
       "      <td>-0.002496</td>\n",
       "      <td>0.003655</td>\n",
       "      <td>0.064531</td>\n",
       "      <td>-0.012215</td>\n",
       "      <td>-0.022834</td>\n",
       "      <td>0.037939</td>\n",
       "      <td>-0.038280</td>\n",
       "      <td>-0.011395</td>\n",
       "      <td>0.266690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CallsWeekNight_IN_VUL_11</th>\n",
       "      <td>-0.018739</td>\n",
       "      <td>-0.010789</td>\n",
       "      <td>0.004358</td>\n",
       "      <td>-0.008916</td>\n",
       "      <td>-0.017363</td>\n",
       "      <td>-0.004976</td>\n",
       "      <td>-0.011990</td>\n",
       "      <td>0.005618</td>\n",
       "      <td>-0.066532</td>\n",
       "      <td>-0.010646</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.019545</td>\n",
       "      <td>-0.000111</td>\n",
       "      <td>0.003899</td>\n",
       "      <td>0.060754</td>\n",
       "      <td>-0.009046</td>\n",
       "      <td>-0.013440</td>\n",
       "      <td>0.037173</td>\n",
       "      <td>-0.027962</td>\n",
       "      <td>-0.008683</td>\n",
       "      <td>0.218783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TimeWeekDay_IN_VUL_11</th>\n",
       "      <td>-0.016199</td>\n",
       "      <td>-0.011827</td>\n",
       "      <td>0.003853</td>\n",
       "      <td>-0.007973</td>\n",
       "      <td>-0.013790</td>\n",
       "      <td>-0.003741</td>\n",
       "      <td>-0.012845</td>\n",
       "      <td>0.005394</td>\n",
       "      <td>-0.072231</td>\n",
       "      <td>-0.010397</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.021225</td>\n",
       "      <td>0.001796</td>\n",
       "      <td>0.004030</td>\n",
       "      <td>0.053296</td>\n",
       "      <td>-0.007177</td>\n",
       "      <td>-0.017130</td>\n",
       "      <td>0.029249</td>\n",
       "      <td>-0.027297</td>\n",
       "      <td>-0.009044</td>\n",
       "      <td>0.211713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CallsWeekEnd_IN_VUL_11</th>\n",
       "      <td>-0.022474</td>\n",
       "      <td>-0.016748</td>\n",
       "      <td>0.003279</td>\n",
       "      <td>-0.011547</td>\n",
       "      <td>-0.024820</td>\n",
       "      <td>-0.005919</td>\n",
       "      <td>-0.016264</td>\n",
       "      <td>0.001047</td>\n",
       "      <td>-0.095917</td>\n",
       "      <td>-0.013188</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.027310</td>\n",
       "      <td>-0.000805</td>\n",
       "      <td>0.004629</td>\n",
       "      <td>0.073001</td>\n",
       "      <td>-0.013356</td>\n",
       "      <td>-0.019970</td>\n",
       "      <td>0.046165</td>\n",
       "      <td>-0.037765</td>\n",
       "      <td>-0.011987</td>\n",
       "      <td>0.280185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TimeWeekNight_IN_VUL_11</th>\n",
       "      <td>-0.010118</td>\n",
       "      <td>-0.002565</td>\n",
       "      <td>0.007578</td>\n",
       "      <td>-0.000452</td>\n",
       "      <td>-0.005215</td>\n",
       "      <td>-0.000333</td>\n",
       "      <td>-0.004821</td>\n",
       "      <td>0.004545</td>\n",
       "      <td>-0.029192</td>\n",
       "      <td>-0.006366</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.007435</td>\n",
       "      <td>0.004680</td>\n",
       "      <td>0.005555</td>\n",
       "      <td>0.037559</td>\n",
       "      <td>-0.004457</td>\n",
       "      <td>-0.005180</td>\n",
       "      <td>0.018948</td>\n",
       "      <td>-0.010990</td>\n",
       "      <td>-0.004018</td>\n",
       "      <td>0.125179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VULNERABLE_IN_11</th>\n",
       "      <td>-0.038910</td>\n",
       "      <td>-0.030505</td>\n",
       "      <td>0.009835</td>\n",
       "      <td>-0.017472</td>\n",
       "      <td>-0.043343</td>\n",
       "      <td>-0.013814</td>\n",
       "      <td>-0.032883</td>\n",
       "      <td>0.009834</td>\n",
       "      <td>-0.153931</td>\n",
       "      <td>-0.024708</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.053784</td>\n",
       "      <td>0.014667</td>\n",
       "      <td>0.015563</td>\n",
       "      <td>0.116492</td>\n",
       "      <td>-0.019714</td>\n",
       "      <td>-0.026946</td>\n",
       "      <td>0.138680</td>\n",
       "      <td>-0.078379</td>\n",
       "      <td>-0.019417</td>\n",
       "      <td>0.518484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STATE_Baja_California_Sur</th>\n",
       "      <td>-0.003993</td>\n",
       "      <td>-0.003604</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.003288</td>\n",
       "      <td>-0.004907</td>\n",
       "      <td>-0.002358</td>\n",
       "      <td>-0.002652</td>\n",
       "      <td>-0.002554</td>\n",
       "      <td>-0.019669</td>\n",
       "      <td>-0.001967</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.004535</td>\n",
       "      <td>-0.003000</td>\n",
       "      <td>-0.002159</td>\n",
       "      <td>-0.005695</td>\n",
       "      <td>-0.002930</td>\n",
       "      <td>-0.005011</td>\n",
       "      <td>-0.007592</td>\n",
       "      <td>-0.006224</td>\n",
       "      <td>-0.001975</td>\n",
       "      <td>0.027414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STATE_Colima</th>\n",
       "      <td>-0.007047</td>\n",
       "      <td>-0.006362</td>\n",
       "      <td>-0.002554</td>\n",
       "      <td>-0.005804</td>\n",
       "      <td>-0.008660</td>\n",
       "      <td>-0.004162</td>\n",
       "      <td>-0.004681</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.034715</td>\n",
       "      <td>-0.003471</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.008004</td>\n",
       "      <td>-0.005295</td>\n",
       "      <td>-0.003810</td>\n",
       "      <td>-0.010052</td>\n",
       "      <td>-0.005172</td>\n",
       "      <td>-0.008844</td>\n",
       "      <td>-0.013400</td>\n",
       "      <td>-0.010985</td>\n",
       "      <td>-0.003485</td>\n",
       "      <td>0.013175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STATE_Guerrero</th>\n",
       "      <td>-0.013936</td>\n",
       "      <td>-0.012581</td>\n",
       "      <td>-0.005052</td>\n",
       "      <td>-0.011478</td>\n",
       "      <td>-0.017127</td>\n",
       "      <td>-0.008231</td>\n",
       "      <td>-0.009258</td>\n",
       "      <td>-0.008916</td>\n",
       "      <td>-0.068655</td>\n",
       "      <td>-0.006865</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.015829</td>\n",
       "      <td>-0.010472</td>\n",
       "      <td>-0.007536</td>\n",
       "      <td>-0.019879</td>\n",
       "      <td>-0.010228</td>\n",
       "      <td>-0.017491</td>\n",
       "      <td>-0.026502</td>\n",
       "      <td>-0.021724</td>\n",
       "      <td>-0.006893</td>\n",
       "      <td>0.056422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STATE_Hidalgo</th>\n",
       "      <td>-0.023226</td>\n",
       "      <td>-0.020968</td>\n",
       "      <td>-0.008420</td>\n",
       "      <td>-0.019128</td>\n",
       "      <td>-0.028544</td>\n",
       "      <td>-0.013718</td>\n",
       "      <td>-0.015429</td>\n",
       "      <td>-0.014860</td>\n",
       "      <td>-0.114419</td>\n",
       "      <td>-0.011441</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.026380</td>\n",
       "      <td>-0.017452</td>\n",
       "      <td>-0.012559</td>\n",
       "      <td>-0.033130</td>\n",
       "      <td>-0.017045</td>\n",
       "      <td>-0.029149</td>\n",
       "      <td>-0.044167</td>\n",
       "      <td>-0.036205</td>\n",
       "      <td>-0.011488</td>\n",
       "      <td>0.105358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STATE_Jalisco</th>\n",
       "      <td>-0.034410</td>\n",
       "      <td>-0.031065</td>\n",
       "      <td>-0.012474</td>\n",
       "      <td>-0.028340</td>\n",
       "      <td>-0.042289</td>\n",
       "      <td>-0.020324</td>\n",
       "      <td>-0.022859</td>\n",
       "      <td>-0.022016</td>\n",
       "      <td>-0.169519</td>\n",
       "      <td>-0.016950</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.039084</td>\n",
       "      <td>-0.025857</td>\n",
       "      <td>-0.018607</td>\n",
       "      <td>-0.049084</td>\n",
       "      <td>-0.025254</td>\n",
       "      <td>-0.043187</td>\n",
       "      <td>-0.065436</td>\n",
       "      <td>-0.053640</td>\n",
       "      <td>-0.017020</td>\n",
       "      <td>0.258447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STATE_Morelos</th>\n",
       "      <td>-0.018501</td>\n",
       "      <td>-0.016702</td>\n",
       "      <td>-0.006707</td>\n",
       "      <td>-0.015237</td>\n",
       "      <td>-0.022737</td>\n",
       "      <td>-0.010927</td>\n",
       "      <td>-0.012290</td>\n",
       "      <td>-0.011837</td>\n",
       "      <td>-0.091141</td>\n",
       "      <td>-0.009113</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.021013</td>\n",
       "      <td>-0.013902</td>\n",
       "      <td>-0.010004</td>\n",
       "      <td>-0.026390</td>\n",
       "      <td>-0.013578</td>\n",
       "      <td>-0.023219</td>\n",
       "      <td>-0.035181</td>\n",
       "      <td>-0.028839</td>\n",
       "      <td>-0.009151</td>\n",
       "      <td>0.103912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STATE_Nayarit</th>\n",
       "      <td>-0.009512</td>\n",
       "      <td>-0.008588</td>\n",
       "      <td>-0.003448</td>\n",
       "      <td>-0.007834</td>\n",
       "      <td>-0.011690</td>\n",
       "      <td>-0.005618</td>\n",
       "      <td>-0.006319</td>\n",
       "      <td>-0.006086</td>\n",
       "      <td>-0.046862</td>\n",
       "      <td>-0.004686</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.010804</td>\n",
       "      <td>-0.007148</td>\n",
       "      <td>-0.005144</td>\n",
       "      <td>-0.013569</td>\n",
       "      <td>-0.006981</td>\n",
       "      <td>-0.011938</td>\n",
       "      <td>-0.018089</td>\n",
       "      <td>-0.014828</td>\n",
       "      <td>-0.004705</td>\n",
       "      <td>0.010793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STATE_Oaxaca</th>\n",
       "      <td>-0.011202</td>\n",
       "      <td>-0.010113</td>\n",
       "      <td>-0.004061</td>\n",
       "      <td>-0.009225</td>\n",
       "      <td>-0.013766</td>\n",
       "      <td>-0.006616</td>\n",
       "      <td>-0.007441</td>\n",
       "      <td>-0.007167</td>\n",
       "      <td>-0.055184</td>\n",
       "      <td>-0.005518</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.012723</td>\n",
       "      <td>-0.008417</td>\n",
       "      <td>-0.006057</td>\n",
       "      <td>-0.015978</td>\n",
       "      <td>-0.008221</td>\n",
       "      <td>-0.014059</td>\n",
       "      <td>-0.021301</td>\n",
       "      <td>-0.017461</td>\n",
       "      <td>-0.005540</td>\n",
       "      <td>0.051564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STATE_Puebla</th>\n",
       "      <td>-0.023305</td>\n",
       "      <td>-0.021040</td>\n",
       "      <td>-0.008448</td>\n",
       "      <td>-0.019194</td>\n",
       "      <td>-0.028641</td>\n",
       "      <td>-0.013765</td>\n",
       "      <td>-0.015482</td>\n",
       "      <td>-0.014911</td>\n",
       "      <td>-0.114811</td>\n",
       "      <td>-0.011480</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.026470</td>\n",
       "      <td>-0.017512</td>\n",
       "      <td>-0.012602</td>\n",
       "      <td>-0.033243</td>\n",
       "      <td>-0.017104</td>\n",
       "      <td>-0.029249</td>\n",
       "      <td>-0.044318</td>\n",
       "      <td>-0.036329</td>\n",
       "      <td>-0.011527</td>\n",
       "      <td>0.138836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STATE_Sinaloa</th>\n",
       "      <td>-0.008276</td>\n",
       "      <td>-0.007472</td>\n",
       "      <td>-0.003000</td>\n",
       "      <td>-0.006816</td>\n",
       "      <td>-0.010171</td>\n",
       "      <td>-0.004888</td>\n",
       "      <td>-0.005498</td>\n",
       "      <td>-0.005295</td>\n",
       "      <td>-0.040771</td>\n",
       "      <td>-0.004077</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009400</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.004475</td>\n",
       "      <td>-0.011805</td>\n",
       "      <td>-0.006074</td>\n",
       "      <td>-0.010387</td>\n",
       "      <td>-0.015738</td>\n",
       "      <td>-0.012901</td>\n",
       "      <td>-0.004093</td>\n",
       "      <td>0.036188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STATE_Sonora</th>\n",
       "      <td>-0.005956</td>\n",
       "      <td>-0.005377</td>\n",
       "      <td>-0.002159</td>\n",
       "      <td>-0.004905</td>\n",
       "      <td>-0.007319</td>\n",
       "      <td>-0.003518</td>\n",
       "      <td>-0.003956</td>\n",
       "      <td>-0.003810</td>\n",
       "      <td>-0.029340</td>\n",
       "      <td>-0.002934</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.006764</td>\n",
       "      <td>-0.004475</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.008495</td>\n",
       "      <td>-0.004371</td>\n",
       "      <td>-0.007475</td>\n",
       "      <td>-0.011325</td>\n",
       "      <td>-0.009284</td>\n",
       "      <td>-0.002946</td>\n",
       "      <td>0.033602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STATE_Tabasco</th>\n",
       "      <td>-0.015710</td>\n",
       "      <td>-0.014183</td>\n",
       "      <td>-0.005695</td>\n",
       "      <td>-0.012939</td>\n",
       "      <td>-0.019308</td>\n",
       "      <td>-0.009279</td>\n",
       "      <td>-0.010436</td>\n",
       "      <td>-0.010052</td>\n",
       "      <td>-0.077396</td>\n",
       "      <td>-0.007739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.017844</td>\n",
       "      <td>-0.011805</td>\n",
       "      <td>-0.008495</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.011530</td>\n",
       "      <td>-0.019717</td>\n",
       "      <td>-0.029875</td>\n",
       "      <td>-0.024490</td>\n",
       "      <td>-0.007770</td>\n",
       "      <td>0.095242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STATE_Tlaxcala</th>\n",
       "      <td>-0.013823</td>\n",
       "      <td>-0.012479</td>\n",
       "      <td>-0.005011</td>\n",
       "      <td>-0.011384</td>\n",
       "      <td>-0.016988</td>\n",
       "      <td>-0.008164</td>\n",
       "      <td>-0.009183</td>\n",
       "      <td>-0.008844</td>\n",
       "      <td>-0.068097</td>\n",
       "      <td>-0.006809</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.015700</td>\n",
       "      <td>-0.010387</td>\n",
       "      <td>-0.007475</td>\n",
       "      <td>-0.019717</td>\n",
       "      <td>-0.010145</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.026286</td>\n",
       "      <td>-0.021548</td>\n",
       "      <td>-0.006837</td>\n",
       "      <td>0.018890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STATE_Veracruz</th>\n",
       "      <td>-0.020944</td>\n",
       "      <td>-0.018908</td>\n",
       "      <td>-0.007592</td>\n",
       "      <td>-0.017249</td>\n",
       "      <td>-0.025740</td>\n",
       "      <td>-0.012370</td>\n",
       "      <td>-0.013913</td>\n",
       "      <td>-0.013400</td>\n",
       "      <td>-0.103180</td>\n",
       "      <td>-0.010317</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.023789</td>\n",
       "      <td>-0.015738</td>\n",
       "      <td>-0.011325</td>\n",
       "      <td>-0.029875</td>\n",
       "      <td>-0.015371</td>\n",
       "      <td>-0.026286</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.032649</td>\n",
       "      <td>-0.010359</td>\n",
       "      <td>0.159102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>target</th>\n",
       "      <td>-0.042675</td>\n",
       "      <td>-0.017924</td>\n",
       "      <td>0.027414</td>\n",
       "      <td>-0.009259</td>\n",
       "      <td>-0.036156</td>\n",
       "      <td>0.000266</td>\n",
       "      <td>-0.030959</td>\n",
       "      <td>0.013175</td>\n",
       "      <td>-0.138963</td>\n",
       "      <td>-0.021420</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.060276</td>\n",
       "      <td>0.036188</td>\n",
       "      <td>0.033602</td>\n",
       "      <td>0.095242</td>\n",
       "      <td>0.001172</td>\n",
       "      <td>0.018890</td>\n",
       "      <td>0.159102</td>\n",
       "      <td>-0.077954</td>\n",
       "      <td>-0.018073</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>88 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             STATE_Aguascalientes  STATE_Baja_California  \\\n",
       "MOBILITY_DIAMETER                        0.045902               0.145942   \n",
       "MOBILITY_DIAMETER_WEEKNIGHT              0.046654               0.145805   \n",
       "EPIDEMIC                                -0.070297              -0.063463   \n",
       "TimeWeekEnd_OUT_VUL_12                  -0.013845              -0.004919   \n",
       "CallsWeekDay_OUT_VUL_12                 -0.023551              -0.016264   \n",
       "CallsWeekNight_OUT_VUL_12               -0.018538              -0.010279   \n",
       "TimeWeekDay_OUT_VUL_12                  -0.018978              -0.009812   \n",
       "CallsWeekEnd_OUT_VUL_12                 -0.020222              -0.013935   \n",
       "TimeWeekNight_OUT_VUL_12                -0.011181              -0.002776   \n",
       "VULNERABLE_OUT_12                       -0.038502              -0.028439   \n",
       "TimeWeekEnd_IN_VUL_12                   -0.011941              -0.007219   \n",
       "CallsWeekDay_IN_VUL_12                  -0.022734              -0.017515   \n",
       "CallsWeekNight_IN_VUL_12                -0.014445              -0.010335   \n",
       "TimeWeekDay_IN_VUL_12                   -0.017269              -0.012512   \n",
       "CallsWeekEnd_IN_VUL_12                  -0.019733              -0.016008   \n",
       "TimeWeekNight_IN_VUL_12                 -0.008331              -0.005395   \n",
       "VULNERABLE_IN_12                        -0.039073              -0.028259   \n",
       "TimeWeekEnd_OUT_VUL_08                  -0.014888              -0.006016   \n",
       "CallsWeekDay_OUT_VUL_08                 -0.023667              -0.015612   \n",
       "CallsWeekNight_OUT_VUL_08               -0.017918              -0.012333   \n",
       "TimeWeekDay_OUT_VUL_08                  -0.018726              -0.011476   \n",
       "CallsWeekEnd_OUT_VUL_08                 -0.022615              -0.015607   \n",
       "TimeWeekNight_OUT_VUL_08                -0.009146              -0.004605   \n",
       "VULNERABLE_OUT_08                       -0.042068              -0.029876   \n",
       "TimeWeekEnd_IN_VUL_08                   -0.012433              -0.006905   \n",
       "CallsWeekDay_IN_VUL_08                  -0.023635              -0.017116   \n",
       "CallsWeekNight_IN_VUL_08                -0.017572              -0.014226   \n",
       "TimeWeekDay_IN_VUL_08                   -0.017795              -0.012824   \n",
       "CallsWeekEnd_IN_VUL_08                  -0.022465              -0.017283   \n",
       "TimeWeekNight_IN_VUL_08                 -0.007130              -0.005548   \n",
       "...                                           ...                    ...   \n",
       "VULNERABLE_IN_10                        -0.038625              -0.030801   \n",
       "TimeWeekEnd_OUT_VUL_11                  -0.014707              -0.000894   \n",
       "CallsWeekDay_OUT_VUL_11                 -0.022992              -0.015743   \n",
       "CallsWeekNight_OUT_VUL_11               -0.018888              -0.007526   \n",
       "TimeWeekDay_OUT_VUL_11                  -0.018876              -0.008520   \n",
       "CallsWeekEnd_OUT_VUL_11                 -0.022659              -0.014022   \n",
       "TimeWeekNight_OUT_VUL_11                -0.010594               0.002235   \n",
       "VULNERABLE_OUT_11                       -0.038449              -0.029018   \n",
       "TimeWeekEnd_IN_VUL_11                   -0.015505              -0.005516   \n",
       "CallsWeekDay_IN_VUL_11                  -0.022309              -0.018199   \n",
       "CallsWeekNight_IN_VUL_11                -0.018739              -0.010789   \n",
       "TimeWeekDay_IN_VUL_11                   -0.016199              -0.011827   \n",
       "CallsWeekEnd_IN_VUL_11                  -0.022474              -0.016748   \n",
       "TimeWeekNight_IN_VUL_11                 -0.010118              -0.002565   \n",
       "VULNERABLE_IN_11                        -0.038910              -0.030505   \n",
       "STATE_Baja_California_Sur               -0.003993              -0.003604   \n",
       "STATE_Colima                            -0.007047              -0.006362   \n",
       "STATE_Guerrero                          -0.013936              -0.012581   \n",
       "STATE_Hidalgo                           -0.023226              -0.020968   \n",
       "STATE_Jalisco                           -0.034410              -0.031065   \n",
       "STATE_Morelos                           -0.018501              -0.016702   \n",
       "STATE_Nayarit                           -0.009512              -0.008588   \n",
       "STATE_Oaxaca                            -0.011202              -0.010113   \n",
       "STATE_Puebla                            -0.023305              -0.021040   \n",
       "STATE_Sinaloa                           -0.008276              -0.007472   \n",
       "STATE_Sonora                            -0.005956              -0.005377   \n",
       "STATE_Tabasco                           -0.015710              -0.014183   \n",
       "STATE_Tlaxcala                          -0.013823              -0.012479   \n",
       "STATE_Veracruz                          -0.020944              -0.018908   \n",
       "target                                  -0.042675              -0.017924   \n",
       "\n",
       "                             STATE_Baja_California_Sur  STATE_Campeche  \\\n",
       "MOBILITY_DIAMETER                             0.032684        0.006103   \n",
       "MOBILITY_DIAMETER_WEEKNIGHT                   0.033328        0.006141   \n",
       "EPIDEMIC                                     -0.025483       -0.057895   \n",
       "TimeWeekEnd_OUT_VUL_12                        0.010538        0.000871   \n",
       "CallsWeekDay_OUT_VUL_12                       0.001278       -0.011864   \n",
       "CallsWeekNight_OUT_VUL_12                     0.007098       -0.002889   \n",
       "TimeWeekDay_OUT_VUL_12                        0.005776       -0.003502   \n",
       "CallsWeekEnd_OUT_VUL_12                       0.003964       -0.008532   \n",
       "TimeWeekNight_OUT_VUL_12                      0.011300        0.007510   \n",
       "VULNERABLE_OUT_12                             0.010884       -0.015736   \n",
       "TimeWeekEnd_IN_VUL_12                         0.009124        0.000403   \n",
       "CallsWeekDay_IN_VUL_12                        0.001092       -0.014149   \n",
       "CallsWeekNight_IN_VUL_12                      0.003971       -0.007689   \n",
       "TimeWeekDay_IN_VUL_12                         0.005681       -0.006106   \n",
       "CallsWeekEnd_IN_VUL_12                        0.002096       -0.010015   \n",
       "TimeWeekNight_IN_VUL_12                       0.009430       -0.001179   \n",
       "VULNERABLE_IN_12                              0.010560       -0.014084   \n",
       "TimeWeekEnd_OUT_VUL_08                        0.012968        0.000801   \n",
       "CallsWeekDay_OUT_VUL_08                       0.002006       -0.012350   \n",
       "CallsWeekNight_OUT_VUL_08                     0.006172       -0.004510   \n",
       "TimeWeekDay_OUT_VUL_08                        0.004707       -0.003298   \n",
       "CallsWeekEnd_OUT_VUL_08                       0.006733       -0.011024   \n",
       "TimeWeekNight_OUT_VUL_08                      0.009587        0.007543   \n",
       "VULNERABLE_OUT_08                             0.011004       -0.016881   \n",
       "TimeWeekEnd_IN_VUL_08                         0.010277        0.001186   \n",
       "CallsWeekDay_IN_VUL_08                        0.000570       -0.014565   \n",
       "CallsWeekNight_IN_VUL_08                      0.004031       -0.007094   \n",
       "TimeWeekDay_IN_VUL_08                         0.003353       -0.005423   \n",
       "CallsWeekEnd_IN_VUL_08                        0.002169       -0.012631   \n",
       "TimeWeekNight_IN_VUL_08                       0.008463        0.004672   \n",
       "...                                                ...             ...   \n",
       "VULNERABLE_IN_10                              0.010946       -0.019521   \n",
       "TimeWeekEnd_OUT_VUL_11                        0.012022       -0.000866   \n",
       "CallsWeekDay_OUT_VUL_11                       0.001785       -0.012608   \n",
       "CallsWeekNight_OUT_VUL_11                     0.002922       -0.004930   \n",
       "TimeWeekDay_OUT_VUL_11                        0.006175       -0.005550   \n",
       "CallsWeekEnd_OUT_VUL_11                       0.004288       -0.010512   \n",
       "TimeWeekNight_OUT_VUL_11                      0.005578        0.005391   \n",
       "VULNERABLE_OUT_11                             0.008253       -0.019533   \n",
       "TimeWeekEnd_IN_VUL_11                         0.013516       -0.000154   \n",
       "CallsWeekDay_IN_VUL_11                        0.001485       -0.014797   \n",
       "CallsWeekNight_IN_VUL_11                      0.004358       -0.008916   \n",
       "TimeWeekDay_IN_VUL_11                         0.003853       -0.007973   \n",
       "CallsWeekEnd_IN_VUL_11                        0.003279       -0.011547   \n",
       "TimeWeekNight_IN_VUL_11                       0.007578       -0.000452   \n",
       "VULNERABLE_IN_11                              0.009835       -0.017472   \n",
       "STATE_Baja_California_Sur                     1.000000       -0.003288   \n",
       "STATE_Colima                                 -0.002554       -0.005804   \n",
       "STATE_Guerrero                               -0.005052       -0.011478   \n",
       "STATE_Hidalgo                                -0.008420       -0.019128   \n",
       "STATE_Jalisco                                -0.012474       -0.028340   \n",
       "STATE_Morelos                                -0.006707       -0.015237   \n",
       "STATE_Nayarit                                -0.003448       -0.007834   \n",
       "STATE_Oaxaca                                 -0.004061       -0.009225   \n",
       "STATE_Puebla                                 -0.008448       -0.019194   \n",
       "STATE_Sinaloa                                -0.003000       -0.006816   \n",
       "STATE_Sonora                                 -0.002159       -0.004905   \n",
       "STATE_Tabasco                                -0.005695       -0.012939   \n",
       "STATE_Tlaxcala                               -0.005011       -0.011384   \n",
       "STATE_Veracruz                               -0.007592       -0.017249   \n",
       "target                                        0.027414       -0.009259   \n",
       "\n",
       "                             STATE_Chiapas  STATE_Chihuahua  \\\n",
       "MOBILITY_DIAMETER                -0.014679         0.024696   \n",
       "MOBILITY_DIAMETER_WEEKNIGHT      -0.009792         0.023230   \n",
       "EPIDEMIC                         -0.086392        -0.041519   \n",
       "TimeWeekEnd_OUT_VUL_12           -0.012463        -0.004699   \n",
       "CallsWeekDay_OUT_VUL_12          -0.023981        -0.007346   \n",
       "CallsWeekNight_OUT_VUL_12        -0.017992        -0.004098   \n",
       "TimeWeekDay_OUT_VUL_12           -0.016605        -0.004612   \n",
       "CallsWeekEnd_OUT_VUL_12          -0.022123        -0.007780   \n",
       "TimeWeekNight_OUT_VUL_12         -0.007542         0.001704   \n",
       "VULNERABLE_OUT_12                -0.041065        -0.014000   \n",
       "TimeWeekEnd_IN_VUL_12            -0.008797        -0.001187   \n",
       "CallsWeekDay_IN_VUL_12           -0.024679        -0.005824   \n",
       "CallsWeekNight_IN_VUL_12         -0.015009        -0.003297   \n",
       "TimeWeekDay_IN_VUL_12            -0.016567        -0.001686   \n",
       "CallsWeekEnd_IN_VUL_12           -0.021943        -0.005365   \n",
       "TimeWeekNight_IN_VUL_12          -0.005873        -0.001072   \n",
       "VULNERABLE_IN_12                 -0.039697        -0.013364   \n",
       "TimeWeekEnd_OUT_VUL_08           -0.010508        -0.002863   \n",
       "CallsWeekDay_OUT_VUL_08          -0.024371        -0.008413   \n",
       "CallsWeekNight_OUT_VUL_08        -0.018119        -0.006373   \n",
       "TimeWeekDay_OUT_VUL_08           -0.017098        -0.004659   \n",
       "CallsWeekEnd_OUT_VUL_08          -0.023665        -0.008168   \n",
       "TimeWeekNight_OUT_VUL_08         -0.006124        -0.002268   \n",
       "VULNERABLE_OUT_08                -0.043695        -0.011574   \n",
       "TimeWeekEnd_IN_VUL_08            -0.011913        -0.000447   \n",
       "CallsWeekDay_IN_VUL_08           -0.025160        -0.008731   \n",
       "CallsWeekNight_IN_VUL_08         -0.020109        -0.007246   \n",
       "TimeWeekDay_IN_VUL_08            -0.015726        -0.004322   \n",
       "CallsWeekEnd_IN_VUL_08           -0.025949        -0.008586   \n",
       "TimeWeekNight_IN_VUL_08          -0.007582        -0.001964   \n",
       "...                                    ...              ...   \n",
       "VULNERABLE_IN_10                 -0.043353        -0.013185   \n",
       "TimeWeekEnd_OUT_VUL_11           -0.009295        -0.005395   \n",
       "CallsWeekDay_OUT_VUL_11          -0.024111        -0.008435   \n",
       "CallsWeekNight_OUT_VUL_11        -0.015121        -0.006878   \n",
       "TimeWeekDay_OUT_VUL_11           -0.016178        -0.005120   \n",
       "CallsWeekEnd_OUT_VUL_11          -0.022154        -0.008321   \n",
       "TimeWeekNight_OUT_VUL_11         -0.004070        -0.003349   \n",
       "VULNERABLE_OUT_11                -0.043642        -0.014989   \n",
       "TimeWeekEnd_IN_VUL_11            -0.011698        -0.000745   \n",
       "CallsWeekDay_IN_VUL_11           -0.024042        -0.007438   \n",
       "CallsWeekNight_IN_VUL_11         -0.017363        -0.004976   \n",
       "TimeWeekDay_IN_VUL_11            -0.013790        -0.003741   \n",
       "CallsWeekEnd_IN_VUL_11           -0.024820        -0.005919   \n",
       "TimeWeekNight_IN_VUL_11          -0.005215        -0.000333   \n",
       "VULNERABLE_IN_11                 -0.043343        -0.013814   \n",
       "STATE_Baja_California_Sur        -0.004907        -0.002358   \n",
       "STATE_Colima                     -0.008660        -0.004162   \n",
       "STATE_Guerrero                   -0.017127        -0.008231   \n",
       "STATE_Hidalgo                    -0.028544        -0.013718   \n",
       "STATE_Jalisco                    -0.042289        -0.020324   \n",
       "STATE_Morelos                    -0.022737        -0.010927   \n",
       "STATE_Nayarit                    -0.011690        -0.005618   \n",
       "STATE_Oaxaca                     -0.013766        -0.006616   \n",
       "STATE_Puebla                     -0.028641        -0.013765   \n",
       "STATE_Sinaloa                    -0.010171        -0.004888   \n",
       "STATE_Sonora                     -0.007319        -0.003518   \n",
       "STATE_Tabasco                    -0.019308        -0.009279   \n",
       "STATE_Tlaxcala                   -0.016988        -0.008164   \n",
       "STATE_Veracruz                   -0.025740        -0.012370   \n",
       "target                           -0.036156         0.000266   \n",
       "\n",
       "                             STATE_Coahuila_de_Zaragoza  STATE_Colima  \\\n",
       "MOBILITY_DIAMETER                             -0.002260     -0.006266   \n",
       "MOBILITY_DIAMETER_WEEKNIGHT                   -0.001692     -0.004915   \n",
       "EPIDEMIC                                      -0.046698     -0.044976   \n",
       "TimeWeekEnd_OUT_VUL_12                        -0.012326      0.007216   \n",
       "CallsWeekDay_OUT_VUL_12                       -0.017427      0.008317   \n",
       "CallsWeekNight_OUT_VUL_12                     -0.013196      0.007299   \n",
       "TimeWeekDay_OUT_VUL_12                        -0.014868      0.013340   \n",
       "CallsWeekEnd_OUT_VUL_12                       -0.016322      0.005513   \n",
       "TimeWeekNight_OUT_VUL_12                      -0.006902      0.004665   \n",
       "VULNERABLE_OUT_12                             -0.034331      0.010190   \n",
       "TimeWeekEnd_IN_VUL_12                         -0.010547      0.009127   \n",
       "CallsWeekDay_IN_VUL_12                        -0.017638      0.005301   \n",
       "CallsWeekNight_IN_VUL_12                      -0.011581      0.005283   \n",
       "TimeWeekDay_IN_VUL_12                         -0.014790      0.010649   \n",
       "CallsWeekEnd_IN_VUL_12                        -0.016141      0.004797   \n",
       "TimeWeekNight_IN_VUL_12                       -0.007739      0.006901   \n",
       "VULNERABLE_IN_12                              -0.034440      0.012244   \n",
       "TimeWeekEnd_OUT_VUL_08                        -0.009138      0.009581   \n",
       "CallsWeekDay_OUT_VUL_08                       -0.016763      0.007694   \n",
       "CallsWeekNight_OUT_VUL_08                     -0.012421      0.011807   \n",
       "TimeWeekDay_OUT_VUL_08                        -0.013679      0.009222   \n",
       "CallsWeekEnd_OUT_VUL_08                       -0.015545      0.006173   \n",
       "TimeWeekNight_OUT_VUL_08                      -0.005949      0.014619   \n",
       "VULNERABLE_OUT_08                             -0.033381      0.009990   \n",
       "TimeWeekEnd_IN_VUL_08                         -0.009536      0.007084   \n",
       "CallsWeekDay_IN_VUL_08                        -0.016592      0.003383   \n",
       "CallsWeekNight_IN_VUL_08                      -0.013465      0.006743   \n",
       "TimeWeekDay_IN_VUL_08                         -0.013246      0.004251   \n",
       "CallsWeekEnd_IN_VUL_08                        -0.016163      0.004962   \n",
       "TimeWeekNight_IN_VUL_08                       -0.006486      0.007902   \n",
       "...                                                 ...           ...   \n",
       "VULNERABLE_IN_10                              -0.033649      0.008419   \n",
       "TimeWeekEnd_OUT_VUL_11                        -0.008423      0.010130   \n",
       "CallsWeekDay_OUT_VUL_11                       -0.016663      0.006639   \n",
       "CallsWeekNight_OUT_VUL_11                     -0.013044      0.008630   \n",
       "TimeWeekDay_OUT_VUL_11                        -0.013186      0.009317   \n",
       "CallsWeekEnd_OUT_VUL_11                       -0.015568      0.007385   \n",
       "TimeWeekNight_OUT_VUL_11                      -0.006980      0.007482   \n",
       "VULNERABLE_OUT_11                             -0.034372      0.010196   \n",
       "TimeWeekEnd_IN_VUL_11                         -0.009516      0.003122   \n",
       "CallsWeekDay_IN_VUL_11                        -0.016817      0.003384   \n",
       "CallsWeekNight_IN_VUL_11                      -0.011990      0.005618   \n",
       "TimeWeekDay_IN_VUL_11                         -0.012845      0.005394   \n",
       "CallsWeekEnd_IN_VUL_11                        -0.016264      0.001047   \n",
       "TimeWeekNight_IN_VUL_11                       -0.004821      0.004545   \n",
       "VULNERABLE_IN_11                              -0.032883      0.009834   \n",
       "STATE_Baja_California_Sur                     -0.002652     -0.002554   \n",
       "STATE_Colima                                  -0.004681      1.000000   \n",
       "STATE_Guerrero                                -0.009258     -0.008916   \n",
       "STATE_Hidalgo                                 -0.015429     -0.014860   \n",
       "STATE_Jalisco                                 -0.022859     -0.022016   \n",
       "STATE_Morelos                                 -0.012290     -0.011837   \n",
       "STATE_Nayarit                                 -0.006319     -0.006086   \n",
       "STATE_Oaxaca                                  -0.007441     -0.007167   \n",
       "STATE_Puebla                                  -0.015482     -0.014911   \n",
       "STATE_Sinaloa                                 -0.005498     -0.005295   \n",
       "STATE_Sonora                                  -0.003956     -0.003810   \n",
       "STATE_Tabasco                                 -0.010436     -0.010052   \n",
       "STATE_Tlaxcala                                -0.009183     -0.008844   \n",
       "STATE_Veracruz                                -0.013913     -0.013400   \n",
       "target                                        -0.030959      0.013175   \n",
       "\n",
       "                             STATE_Distrito_Federal  STATE_Durango    ...     \\\n",
       "MOBILITY_DIAMETER                         -0.138609      -0.009381    ...      \n",
       "MOBILITY_DIAMETER_WEEKNIGHT               -0.120051      -0.009230    ...      \n",
       "EPIDEMIC                                  -0.346309      -0.034628    ...      \n",
       "TimeWeekEnd_OUT_VUL_12                    -0.058471      -0.009700    ...      \n",
       "CallsWeekDay_OUT_VUL_12                   -0.095216      -0.013552    ...      \n",
       "CallsWeekNight_OUT_VUL_12                 -0.065420      -0.010092    ...      \n",
       "TimeWeekDay_OUT_VUL_12                    -0.072652      -0.011919    ...      \n",
       "CallsWeekEnd_OUT_VUL_12                   -0.087076      -0.013012    ...      \n",
       "TimeWeekNight_OUT_VUL_12                  -0.032920      -0.006101    ...      \n",
       "VULNERABLE_OUT_12                         -0.148067      -0.024705    ...      \n",
       "TimeWeekEnd_IN_VUL_12                     -0.055902      -0.008682    ...      \n",
       "CallsWeekDay_IN_VUL_12                    -0.094969      -0.012157    ...      \n",
       "CallsWeekNight_IN_VUL_12                  -0.051608      -0.008645    ...      \n",
       "TimeWeekDay_IN_VUL_12                     -0.073295      -0.010201    ...      \n",
       "CallsWeekEnd_IN_VUL_12                    -0.085622      -0.011813    ...      \n",
       "TimeWeekNight_IN_VUL_12                   -0.033393      -0.006719    ...      \n",
       "VULNERABLE_IN_12                          -0.148437      -0.022464    ...      \n",
       "TimeWeekEnd_OUT_VUL_08                    -0.066524      -0.010299    ...      \n",
       "CallsWeekDay_OUT_VUL_08                   -0.100517      -0.012728    ...      \n",
       "CallsWeekNight_OUT_VUL_08                 -0.077437      -0.012022    ...      \n",
       "TimeWeekDay_OUT_VUL_08                    -0.080285      -0.011460    ...      \n",
       "CallsWeekEnd_OUT_VUL_08                   -0.098373      -0.014137    ...      \n",
       "TimeWeekNight_OUT_VUL_08                  -0.041173      -0.008213    ...      \n",
       "VULNERABLE_OUT_08                         -0.163333      -0.024895    ...      \n",
       "TimeWeekEnd_IN_VUL_08                     -0.066346      -0.009039    ...      \n",
       "CallsWeekDay_IN_VUL_08                    -0.102761      -0.012637    ...      \n",
       "CallsWeekNight_IN_VUL_08                  -0.081616      -0.011378    ...      \n",
       "TimeWeekDay_IN_VUL_08                     -0.081709      -0.010805    ...      \n",
       "CallsWeekEnd_IN_VUL_08                    -0.101655      -0.013285    ...      \n",
       "TimeWeekNight_IN_VUL_08                   -0.042644      -0.007133    ...      \n",
       "...                                             ...            ...    ...      \n",
       "VULNERABLE_IN_10                          -0.153595      -0.024127    ...      \n",
       "TimeWeekEnd_OUT_VUL_11                    -0.060510      -0.009805    ...      \n",
       "CallsWeekDay_OUT_VUL_11                   -0.098876      -0.013194    ...      \n",
       "CallsWeekNight_OUT_VUL_11                 -0.066158      -0.011169    ...      \n",
       "TimeWeekDay_OUT_VUL_11                    -0.076616      -0.011626    ...      \n",
       "CallsWeekEnd_OUT_VUL_11                   -0.096141      -0.013460    ...      \n",
       "TimeWeekNight_OUT_VUL_11                  -0.029528      -0.007502    ...      \n",
       "VULNERABLE_OUT_11                         -0.154592      -0.025856    ...      \n",
       "TimeWeekEnd_IN_VUL_11                     -0.059657      -0.008961    ...      \n",
       "CallsWeekDay_IN_VUL_11                    -0.098711      -0.012627    ...      \n",
       "CallsWeekNight_IN_VUL_11                  -0.066532      -0.010646    ...      \n",
       "TimeWeekDay_IN_VUL_11                     -0.072231      -0.010397    ...      \n",
       "CallsWeekEnd_IN_VUL_11                    -0.095917      -0.013188    ...      \n",
       "TimeWeekNight_IN_VUL_11                   -0.029192      -0.006366    ...      \n",
       "VULNERABLE_IN_11                          -0.153931      -0.024708    ...      \n",
       "STATE_Baja_California_Sur                 -0.019669      -0.001967    ...      \n",
       "STATE_Colima                              -0.034715      -0.003471    ...      \n",
       "STATE_Guerrero                            -0.068655      -0.006865    ...      \n",
       "STATE_Hidalgo                             -0.114419      -0.011441    ...      \n",
       "STATE_Jalisco                             -0.169519      -0.016950    ...      \n",
       "STATE_Morelos                             -0.091141      -0.009113    ...      \n",
       "STATE_Nayarit                             -0.046862      -0.004686    ...      \n",
       "STATE_Oaxaca                              -0.055184      -0.005518    ...      \n",
       "STATE_Puebla                              -0.114811      -0.011480    ...      \n",
       "STATE_Sinaloa                             -0.040771      -0.004077    ...      \n",
       "STATE_Sonora                              -0.029340      -0.002934    ...      \n",
       "STATE_Tabasco                             -0.077396      -0.007739    ...      \n",
       "STATE_Tlaxcala                            -0.068097      -0.006809    ...      \n",
       "STATE_Veracruz                            -0.103180      -0.010317    ...      \n",
       "target                                    -0.138963      -0.021420    ...      \n",
       "\n",
       "                             STATE_San_Luis_Potosi  STATE_Sinaloa  \\\n",
       "MOBILITY_DIAMETER                         0.062277       0.051715   \n",
       "MOBILITY_DIAMETER_WEEKNIGHT               0.063803       0.053742   \n",
       "EPIDEMIC                                 -0.079844      -0.052823   \n",
       "TimeWeekEnd_OUT_VUL_12                   -0.015667       0.009809   \n",
       "CallsWeekDay_OUT_VUL_12                  -0.029249       0.003711   \n",
       "CallsWeekNight_OUT_VUL_12                -0.018457       0.007416   \n",
       "TimeWeekDay_OUT_VUL_12                   -0.025230       0.009093   \n",
       "CallsWeekEnd_OUT_VUL_12                  -0.025451       0.003389   \n",
       "TimeWeekNight_OUT_VUL_12                 -0.008368       0.012940   \n",
       "VULNERABLE_OUT_12                        -0.051399       0.016951   \n",
       "TimeWeekEnd_IN_VUL_12                    -0.015849       0.007407   \n",
       "CallsWeekDay_IN_VUL_12                   -0.028571       0.002017   \n",
       "CallsWeekNight_IN_VUL_12                 -0.017341       0.001028   \n",
       "TimeWeekDay_IN_VUL_12                    -0.022686       0.005547   \n",
       "CallsWeekEnd_IN_VUL_12                   -0.026017       0.003175   \n",
       "TimeWeekNight_IN_VUL_12                  -0.009778       0.001765   \n",
       "VULNERABLE_IN_12                         -0.049569       0.016128   \n",
       "TimeWeekEnd_OUT_VUL_08                   -0.016996       0.008099   \n",
       "CallsWeekDay_OUT_VUL_08                  -0.027831      -0.000889   \n",
       "CallsWeekNight_OUT_VUL_08                -0.018302       0.001661   \n",
       "TimeWeekDay_OUT_VUL_08                   -0.022572       0.001723   \n",
       "CallsWeekEnd_OUT_VUL_08                  -0.027818       0.001105   \n",
       "TimeWeekNight_OUT_VUL_08                 -0.008381       0.006252   \n",
       "VULNERABLE_OUT_08                        -0.055620       0.007313   \n",
       "TimeWeekEnd_IN_VUL_08                    -0.016378       0.003768   \n",
       "CallsWeekDay_IN_VUL_08                   -0.028898      -0.002120   \n",
       "CallsWeekNight_IN_VUL_08                 -0.020754      -0.002726   \n",
       "TimeWeekDay_IN_VUL_08                    -0.021825       0.000841   \n",
       "CallsWeekEnd_IN_VUL_08                   -0.029035      -0.001719   \n",
       "TimeWeekNight_IN_VUL_08                  -0.007680       0.001205   \n",
       "...                                            ...            ...   \n",
       "VULNERABLE_IN_10                         -0.052471       0.017044   \n",
       "TimeWeekEnd_OUT_VUL_11                   -0.016946       0.004187   \n",
       "CallsWeekDay_OUT_VUL_11                  -0.027827       0.000382   \n",
       "CallsWeekNight_OUT_VUL_11                -0.018366       0.002375   \n",
       "TimeWeekDay_OUT_VUL_11                   -0.023102       0.005388   \n",
       "CallsWeekEnd_OUT_VUL_11                  -0.027295      -0.000889   \n",
       "TimeWeekNight_OUT_VUL_11                 -0.008709       0.007481   \n",
       "VULNERABLE_OUT_11                        -0.053477       0.014015   \n",
       "TimeWeekEnd_IN_VUL_11                    -0.015455       0.004553   \n",
       "CallsWeekDay_IN_VUL_11                   -0.027713      -0.002496   \n",
       "CallsWeekNight_IN_VUL_11                 -0.019545      -0.000111   \n",
       "TimeWeekDay_IN_VUL_11                    -0.021225       0.001796   \n",
       "CallsWeekEnd_IN_VUL_11                   -0.027310      -0.000805   \n",
       "TimeWeekNight_IN_VUL_11                  -0.007435       0.004680   \n",
       "VULNERABLE_IN_11                         -0.053784       0.014667   \n",
       "STATE_Baja_California_Sur                -0.004535      -0.003000   \n",
       "STATE_Colima                             -0.008004      -0.005295   \n",
       "STATE_Guerrero                           -0.015829      -0.010472   \n",
       "STATE_Hidalgo                            -0.026380      -0.017452   \n",
       "STATE_Jalisco                            -0.039084      -0.025857   \n",
       "STATE_Morelos                            -0.021013      -0.013902   \n",
       "STATE_Nayarit                            -0.010804      -0.007148   \n",
       "STATE_Oaxaca                             -0.012723      -0.008417   \n",
       "STATE_Puebla                             -0.026470      -0.017512   \n",
       "STATE_Sinaloa                            -0.009400       1.000000   \n",
       "STATE_Sonora                             -0.006764      -0.004475   \n",
       "STATE_Tabasco                            -0.017844      -0.011805   \n",
       "STATE_Tlaxcala                           -0.015700      -0.010387   \n",
       "STATE_Veracruz                           -0.023789      -0.015738   \n",
       "target                                   -0.060276       0.036188   \n",
       "\n",
       "                             STATE_Sonora  STATE_Tabasco  STATE_Tamaulipas  \\\n",
       "MOBILITY_DIAMETER                0.080137       0.004682          0.005265   \n",
       "MOBILITY_DIAMETER_WEEKNIGHT      0.082001       0.006905          0.005447   \n",
       "EPIDEMIC                        -0.038012       0.223487         -0.051591   \n",
       "TimeWeekEnd_OUT_VUL_12           0.008594       0.062447          0.000011   \n",
       "CallsWeekDay_OUT_VUL_12          0.008158       0.086426         -0.008732   \n",
       "CallsWeekNight_OUT_VUL_12        0.009478       0.073654          0.000079   \n",
       "TimeWeekDay_OUT_VUL_12           0.012902       0.071986         -0.004842   \n",
       "CallsWeekEnd_OUT_VUL_12          0.007596       0.082011         -0.007149   \n",
       "TimeWeekNight_OUT_VUL_12         0.011473       0.046054          0.004008   \n",
       "VULNERABLE_OUT_12                0.017911       0.115796         -0.015172   \n",
       "TimeWeekEnd_IN_VUL_12            0.004355       0.060743         -0.002125   \n",
       "CallsWeekDay_IN_VUL_12           0.006453       0.084164         -0.009910   \n",
       "CallsWeekNight_IN_VUL_12         0.006369       0.061843         -0.004359   \n",
       "TimeWeekDay_IN_VUL_12            0.010726       0.067460         -0.003426   \n",
       "CallsWeekEnd_IN_VUL_12           0.003951       0.082933         -0.009613   \n",
       "TimeWeekNight_IN_VUL_12          0.010466       0.044710          0.002314   \n",
       "VULNERABLE_IN_12                 0.016371       0.119048         -0.015639   \n",
       "TimeWeekEnd_OUT_VUL_08           0.006049       0.043162         -0.009573   \n",
       "CallsWeekDay_OUT_VUL_08          0.000859       0.056729         -0.011737   \n",
       "CallsWeekNight_OUT_VUL_08        0.000097       0.058156         -0.006670   \n",
       "TimeWeekDay_OUT_VUL_08           0.001539       0.050420         -0.008699   \n",
       "CallsWeekEnd_OUT_VUL_08          0.003801       0.061533         -0.013403   \n",
       "TimeWeekNight_OUT_VUL_08         0.001248       0.037715         -0.003574   \n",
       "VULNERABLE_OUT_08                0.008928       0.117939         -0.021691   \n",
       "TimeWeekEnd_IN_VUL_08           -0.002875       0.044014         -0.008132   \n",
       "CallsWeekDay_IN_VUL_08           0.001790       0.056114         -0.013970   \n",
       "CallsWeekNight_IN_VUL_08        -0.003261       0.057936         -0.011224   \n",
       "TimeWeekDay_IN_VUL_08            0.002633       0.047508         -0.010085   \n",
       "CallsWeekEnd_IN_VUL_08          -0.002320       0.064650         -0.015482   \n",
       "TimeWeekNight_IN_VUL_08         -0.002124       0.039534         -0.004664   \n",
       "...                                   ...            ...               ...   \n",
       "VULNERABLE_IN_10                 0.012636       0.115118         -0.022143   \n",
       "TimeWeekEnd_OUT_VUL_11           0.010818       0.055936         -0.001120   \n",
       "CallsWeekDay_OUT_VUL_11          0.007579       0.064408         -0.010861   \n",
       "CallsWeekNight_OUT_VUL_11        0.006771       0.057972         -0.006027   \n",
       "TimeWeekDay_OUT_VUL_11           0.010241       0.055892         -0.006675   \n",
       "CallsWeekEnd_OUT_VUL_11          0.008332       0.074566         -0.008616   \n",
       "TimeWeekNight_OUT_VUL_11         0.009330       0.037985         -0.003169   \n",
       "VULNERABLE_OUT_11                0.016510       0.113726         -0.017535   \n",
       "TimeWeekEnd_IN_VUL_11            0.005230       0.051093         -0.007191   \n",
       "CallsWeekDay_IN_VUL_11           0.003655       0.064531         -0.012215   \n",
       "CallsWeekNight_IN_VUL_11         0.003899       0.060754         -0.009046   \n",
       "TimeWeekDay_IN_VUL_11            0.004030       0.053296         -0.007177   \n",
       "CallsWeekEnd_IN_VUL_11           0.004629       0.073001         -0.013356   \n",
       "TimeWeekNight_IN_VUL_11          0.005555       0.037559         -0.004457   \n",
       "VULNERABLE_IN_11                 0.015563       0.116492         -0.019714   \n",
       "STATE_Baja_California_Sur       -0.002159      -0.005695         -0.002930   \n",
       "STATE_Colima                    -0.003810      -0.010052         -0.005172   \n",
       "STATE_Guerrero                  -0.007536      -0.019879         -0.010228   \n",
       "STATE_Hidalgo                   -0.012559      -0.033130         -0.017045   \n",
       "STATE_Jalisco                   -0.018607      -0.049084         -0.025254   \n",
       "STATE_Morelos                   -0.010004      -0.026390         -0.013578   \n",
       "STATE_Nayarit                   -0.005144      -0.013569         -0.006981   \n",
       "STATE_Oaxaca                    -0.006057      -0.015978         -0.008221   \n",
       "STATE_Puebla                    -0.012602      -0.033243         -0.017104   \n",
       "STATE_Sinaloa                   -0.004475      -0.011805         -0.006074   \n",
       "STATE_Sonora                     1.000000      -0.008495         -0.004371   \n",
       "STATE_Tabasco                   -0.008495       1.000000         -0.011530   \n",
       "STATE_Tlaxcala                  -0.007475      -0.019717         -0.010145   \n",
       "STATE_Veracruz                  -0.011325      -0.029875         -0.015371   \n",
       "target                           0.033602       0.095242          0.001172   \n",
       "\n",
       "                             STATE_Tlaxcala  STATE_Veracruz  STATE_Yucatan  \\\n",
       "MOBILITY_DIAMETER                 -0.019447        0.056086      -0.029270   \n",
       "MOBILITY_DIAMETER_WEEKNIGHT       -0.026101        0.045211      -0.021405   \n",
       "EPIDEMIC                          -0.088226        0.297942      -0.109580   \n",
       "TimeWeekEnd_OUT_VUL_12            -0.012570        0.026676      -0.025227   \n",
       "CallsWeekDay_OUT_VUL_12           -0.021534        0.045011      -0.040492   \n",
       "CallsWeekNight_OUT_VUL_12         -0.013420        0.037357      -0.030622   \n",
       "TimeWeekDay_OUT_VUL_12            -0.017533        0.034943      -0.033579   \n",
       "CallsWeekEnd_OUT_VUL_12           -0.017540        0.043760      -0.036603   \n",
       "TimeWeekNight_OUT_VUL_12          -0.006425        0.018045      -0.017813   \n",
       "VULNERABLE_OUT_12                 -0.025880        0.134299      -0.074840   \n",
       "TimeWeekEnd_IN_VUL_12             -0.009439        0.027871      -0.021220   \n",
       "CallsWeekDay_IN_VUL_12            -0.020423        0.044692      -0.039479   \n",
       "CallsWeekNight_IN_VUL_12          -0.009094        0.030556      -0.023477   \n",
       "TimeWeekDay_IN_VUL_12             -0.012760        0.032635      -0.030761   \n",
       "CallsWeekEnd_IN_VUL_12            -0.017490        0.044180      -0.035228   \n",
       "TimeWeekNight_IN_VUL_12           -0.002664        0.016526      -0.012363   \n",
       "VULNERABLE_IN_12                  -0.024392        0.133377      -0.074454   \n",
       "TimeWeekEnd_OUT_VUL_08            -0.014808        0.028026      -0.027693   \n",
       "CallsWeekDay_OUT_VUL_08           -0.023667        0.033539      -0.040270   \n",
       "CallsWeekNight_OUT_VUL_08         -0.016671        0.039821      -0.035165   \n",
       "TimeWeekDay_OUT_VUL_08            -0.019548        0.028935      -0.032952   \n",
       "CallsWeekEnd_OUT_VUL_08           -0.021107        0.040742      -0.041324   \n",
       "TimeWeekNight_OUT_VUL_08          -0.009628        0.026862      -0.021373   \n",
       "VULNERABLE_OUT_08                 -0.027511        0.148312      -0.079833   \n",
       "TimeWeekEnd_IN_VUL_08             -0.011787        0.029405      -0.024769   \n",
       "CallsWeekDay_IN_VUL_08            -0.022312        0.034086      -0.040130   \n",
       "CallsWeekNight_IN_VUL_08          -0.015673        0.039996      -0.034734   \n",
       "TimeWeekDay_IN_VUL_08             -0.017013        0.030258      -0.032017   \n",
       "CallsWeekEnd_IN_VUL_08            -0.020940        0.041274      -0.040855   \n",
       "TimeWeekNight_IN_VUL_08           -0.007273        0.027516      -0.019412   \n",
       "...                                     ...             ...            ...   \n",
       "VULNERABLE_IN_10                  -0.026024        0.137516      -0.077313   \n",
       "TimeWeekEnd_OUT_VUL_11            -0.013572        0.032943      -0.027074   \n",
       "CallsWeekDay_OUT_VUL_11           -0.023713        0.037267      -0.040092   \n",
       "CallsWeekNight_OUT_VUL_11         -0.015346        0.038968      -0.031788   \n",
       "TimeWeekDay_OUT_VUL_11            -0.020542        0.030435      -0.032526   \n",
       "CallsWeekEnd_OUT_VUL_11           -0.021581        0.047258      -0.040323   \n",
       "TimeWeekNight_OUT_VUL_11          -0.009030        0.021632      -0.018083   \n",
       "VULNERABLE_OUT_11                 -0.025637        0.139138      -0.079135   \n",
       "TimeWeekEnd_IN_VUL_11             -0.009467        0.035859      -0.019347   \n",
       "CallsWeekDay_IN_VUL_11            -0.022834        0.037939      -0.038280   \n",
       "CallsWeekNight_IN_VUL_11          -0.013440        0.037173      -0.027962   \n",
       "TimeWeekDay_IN_VUL_11             -0.017130        0.029249      -0.027297   \n",
       "CallsWeekEnd_IN_VUL_11            -0.019970        0.046165      -0.037765   \n",
       "TimeWeekNight_IN_VUL_11           -0.005180        0.018948      -0.010990   \n",
       "VULNERABLE_IN_11                  -0.026946        0.138680      -0.078379   \n",
       "STATE_Baja_California_Sur         -0.005011       -0.007592      -0.006224   \n",
       "STATE_Colima                      -0.008844       -0.013400      -0.010985   \n",
       "STATE_Guerrero                    -0.017491       -0.026502      -0.021724   \n",
       "STATE_Hidalgo                     -0.029149       -0.044167      -0.036205   \n",
       "STATE_Jalisco                     -0.043187       -0.065436      -0.053640   \n",
       "STATE_Morelos                     -0.023219       -0.035181      -0.028839   \n",
       "STATE_Nayarit                     -0.011938       -0.018089      -0.014828   \n",
       "STATE_Oaxaca                      -0.014059       -0.021301      -0.017461   \n",
       "STATE_Puebla                      -0.029249       -0.044318      -0.036329   \n",
       "STATE_Sinaloa                     -0.010387       -0.015738      -0.012901   \n",
       "STATE_Sonora                      -0.007475       -0.011325      -0.009284   \n",
       "STATE_Tabasco                     -0.019717       -0.029875      -0.024490   \n",
       "STATE_Tlaxcala                     1.000000       -0.026286      -0.021548   \n",
       "STATE_Veracruz                    -0.026286        1.000000      -0.032649   \n",
       "target                             0.018890        0.159102      -0.077954   \n",
       "\n",
       "                             STATE_Zacatecas    target  \n",
       "MOBILITY_DIAMETER                   0.000641  0.013764  \n",
       "MOBILITY_DIAMETER_WEEKNIGHT        -0.005553  0.014906  \n",
       "EPIDEMIC                           -0.034769  0.439418  \n",
       "TimeWeekEnd_OUT_VUL_12             -0.004827  0.187130  \n",
       "CallsWeekDay_OUT_VUL_12            -0.010899  0.277760  \n",
       "CallsWeekNight_OUT_VUL_12          -0.008207  0.225518  \n",
       "TimeWeekDay_OUT_VUL_12             -0.009226  0.231432  \n",
       "CallsWeekEnd_OUT_VUL_12            -0.009751  0.262159  \n",
       "TimeWeekNight_OUT_VUL_12           -0.003635  0.142294  \n",
       "VULNERABLE_OUT_12                  -0.019988  0.503804  \n",
       "TimeWeekEnd_IN_VUL_12              -0.006139  0.177840  \n",
       "CallsWeekDay_IN_VUL_12             -0.010699  0.271915  \n",
       "CallsWeekNight_IN_VUL_12           -0.006542  0.181260  \n",
       "TimeWeekDay_IN_VUL_12              -0.007438  0.218512  \n",
       "CallsWeekEnd_IN_VUL_12             -0.010155  0.260075  \n",
       "TimeWeekNight_IN_VUL_12            -0.004821  0.130211  \n",
       "VULNERABLE_IN_12                   -0.019893  0.501857  \n",
       "TimeWeekEnd_OUT_VUL_08             -0.009406  0.212387  \n",
       "CallsWeekDay_OUT_VUL_08            -0.011249  0.285261  \n",
       "CallsWeekNight_OUT_VUL_08          -0.008376  0.251499  \n",
       "TimeWeekDay_OUT_VUL_08             -0.009823  0.241347  \n",
       "CallsWeekEnd_OUT_VUL_08            -0.012210  0.302695  \n",
       "TimeWeekNight_OUT_VUL_08           -0.005066  0.158270  \n",
       "VULNERABLE_OUT_08                  -0.020899  0.553884  \n",
       "TimeWeekEnd_IN_VUL_08              -0.009613  0.210637  \n",
       "CallsWeekDay_IN_VUL_08             -0.011147  0.292085  \n",
       "CallsWeekNight_IN_VUL_08           -0.009078  0.256445  \n",
       "TimeWeekDay_IN_VUL_08              -0.009567  0.240071  \n",
       "CallsWeekEnd_IN_VUL_08             -0.012837  0.311608  \n",
       "TimeWeekNight_IN_VUL_08            -0.004548  0.150745  \n",
       "...                                      ...       ...  \n",
       "VULNERABLE_IN_10                   -0.020346  0.520670  \n",
       "TimeWeekEnd_OUT_VUL_11             -0.008618  0.200561  \n",
       "CallsWeekDay_OUT_VUL_11            -0.011508  0.269011  \n",
       "CallsWeekNight_OUT_VUL_11          -0.007673  0.228012  \n",
       "TimeWeekDay_OUT_VUL_11             -0.010093  0.230498  \n",
       "CallsWeekEnd_OUT_VUL_11            -0.012025  0.281308  \n",
       "TimeWeekNight_OUT_VUL_11           -0.004057  0.150229  \n",
       "VULNERABLE_OUT_11                  -0.022685  0.514446  \n",
       "TimeWeekEnd_IN_VUL_11              -0.008244  0.190351  \n",
       "CallsWeekDay_IN_VUL_11             -0.011395  0.266690  \n",
       "CallsWeekNight_IN_VUL_11           -0.008683  0.218783  \n",
       "TimeWeekDay_IN_VUL_11              -0.009044  0.211713  \n",
       "CallsWeekEnd_IN_VUL_11             -0.011987  0.280185  \n",
       "TimeWeekNight_IN_VUL_11            -0.004018  0.125179  \n",
       "VULNERABLE_IN_11                   -0.019417  0.518484  \n",
       "STATE_Baja_California_Sur          -0.001975  0.027414  \n",
       "STATE_Colima                       -0.003485  0.013175  \n",
       "STATE_Guerrero                     -0.006893  0.056422  \n",
       "STATE_Hidalgo                      -0.011488  0.105358  \n",
       "STATE_Jalisco                      -0.017020  0.258447  \n",
       "STATE_Morelos                      -0.009151  0.103912  \n",
       "STATE_Nayarit                      -0.004705  0.010793  \n",
       "STATE_Oaxaca                       -0.005540  0.051564  \n",
       "STATE_Puebla                       -0.011527  0.138836  \n",
       "STATE_Sinaloa                      -0.004093  0.036188  \n",
       "STATE_Sonora                       -0.002946  0.033602  \n",
       "STATE_Tabasco                      -0.007770  0.095242  \n",
       "STATE_Tlaxcala                     -0.006837  0.018890  \n",
       "STATE_Veracruz                     -0.010359  0.159102  \n",
       "target                             -0.018073  1.000000  \n",
       "\n",
       "[88 rows x 33 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## show correlation between state and target\n",
    "\n",
    "if not 'STATE' in exclude_cols:    \n",
    "    state_cols = [col for col in corr if 'STATE' in col]\n",
    "    view = corr[state_cols + [target_col]]\n",
    "    display(view.query('target > 0.01'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.33763036341980651"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=data['EPIDEMIC_gt'].sum();b= data.shape[0]\n",
    "a*1.0/b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.30676328502415456"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=val_set['EPIDEMIC'].sum();b= val_set.shape[0]\n",
    "a*1.0/b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get metric functions and sklearn model selectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This non-commercial license of GraphLab Create for academic use is assigned to jdemonasterio@dc.uba.ar and will expire on May 06, 2018.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] graphlab.cython.cy_server: GraphLab Create v2.1 started. Logging: /tmp/graphlab_server_1497135415.log\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import *\n",
    "# from sklearn.cross_validation import *\n",
    "from sklearn.model_selection import (GridSearchCV, RandomizedSearchCV, \n",
    "                                     train_test_split, KFold, cross_val_predict, \n",
    "                                     cross_val_score, learning_curve, validation_curve\n",
    "                                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instance 1st fast model with MNB\n",
    "this is a benchmarking-only process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "from sklearn.naive_bayes import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remember that the Multinomail NB assumes no negative values\n",
    "are present in the dataset as this must be `count` data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n",
      "[CV] alpha=0.001, fit_prior=True .....................................\n",
      "[CV] alpha=0.001, fit_prior=True .....................................\n",
      "[CV] alpha=0.001, fit_prior=True .....................................\n",
      "[CV] ...... alpha=0.001, fit_prior=True, score=0.704388, total=   0.4s\n",
      "[CV] alpha=0.001, fit_prior=False ....................................\n",
      "[CV] ...... alpha=0.001, fit_prior=True, score=0.768092, total=   0.4s\n",
      "[CV] alpha=0.001, fit_prior=False ....................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 out of  24 | elapsed:    1.2s remaining:   13.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ...... alpha=0.001, fit_prior=True, score=0.768343, total=   0.4s\n",
      "[CV] alpha=0.001, fit_prior=False ....................................\n",
      "[CV] ..... alpha=0.001, fit_prior=False, score=0.700921, total=   0.4s\n",
      "[CV] alpha=0.1, fit_prior=True .......................................\n",
      "[CV] ..... alpha=0.001, fit_prior=False, score=0.768012, total=   0.4s\n",
      "[CV] alpha=0.1, fit_prior=True .......................................\n",
      "[CV] ..... alpha=0.001, fit_prior=False, score=0.768308, total=   0.4s\n",
      "[CV] alpha=0.1, fit_prior=True .......................................\n",
      "[CV] ........ alpha=0.1, fit_prior=True, score=0.704388, total=   0.4s\n",
      "[CV] alpha=0.1, fit_prior=False ......................................\n",
      "[CV] ........ alpha=0.1, fit_prior=True, score=0.768092, total=   0.4s\n",
      "[CV] alpha=0.1, fit_prior=False ......................................\n",
      "[CV] ........ alpha=0.1, fit_prior=True, score=0.768343, total=   0.5s\n",
      "[CV] alpha=0.1, fit_prior=False ......................................\n",
      "[CV] ....... alpha=0.1, fit_prior=False, score=0.700921, total=   0.4s\n",
      "[CV] alpha=10.0, fit_prior=True ......................................\n",
      "[CV] ....... alpha=0.1, fit_prior=False, score=0.768012, total=   0.4s\n",
      "[CV] alpha=10.0, fit_prior=True ......................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  11 out of  24 | elapsed:    3.4s remaining:    4.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ....... alpha=0.1, fit_prior=False, score=0.768308, total=   0.4s\n",
      "[CV] alpha=10.0, fit_prior=True ......................................\n",
      "[CV] ....... alpha=10.0, fit_prior=True, score=0.704269, total=   0.4s\n",
      "[CV] alpha=10.0, fit_prior=False .....................................\n",
      "[CV] ....... alpha=10.0, fit_prior=True, score=0.768092, total=   0.4s\n",
      "[CV] alpha=10.0, fit_prior=False .....................................\n",
      "[CV] ....... alpha=10.0, fit_prior=True, score=0.768323, total=   0.4s\n",
      "[CV] alpha=10.0, fit_prior=False .....................................\n",
      "[CV] ...... alpha=10.0, fit_prior=False, score=0.700681, total=   0.4s\n",
      "[CV] alpha=1.0, fit_prior=True .......................................\n",
      "[CV] ...... alpha=10.0, fit_prior=False, score=0.768012, total=   0.4s\n",
      "[CV] alpha=1.0, fit_prior=True .......................................\n",
      "[CV] ...... alpha=10.0, fit_prior=False, score=0.768308, total=   0.4s\n",
      "[CV] alpha=1.0, fit_prior=True .......................................\n",
      "[CV] ........ alpha=1.0, fit_prior=True, score=0.704412, total=   0.4s\n",
      "[CV] alpha=1.0, fit_prior=False ......................................\n",
      "[CV] ........ alpha=1.0, fit_prior=True, score=0.768092, total=   0.4s\n",
      "[CV] alpha=1.0, fit_prior=False ......................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  20 out of  24 | elapsed:    5.6s remaining:    1.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ........ alpha=1.0, fit_prior=True, score=0.768343, total=   0.4s\n",
      "[CV] alpha=1.0, fit_prior=False ......................................\n",
      "[CV] ....... alpha=1.0, fit_prior=False, score=0.700873, total=   0.4s\n",
      "[CV] ....... alpha=1.0, fit_prior=False, score=0.768012, total=   0.4s\n",
      "[CV] ....... alpha=1.0, fit_prior=False, score=0.768308, total=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  24 out of  24 | elapsed:    6.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid Search took 7.40813994408 seconds to run\n",
      "\n",
      " Best estimator was MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True) \n",
      "\n",
      "\n",
      " Best estimator was 0.746948151621 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/juan/mfixman/venv/local/lib/python2.7/site-packages/sklearn/model_selection/_search.py:667: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n",
      "/home/juan/mfixman/venv/local/lib/python2.7/site-packages/sklearn/model_selection/_search.py:667: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n",
      "/home/juan/mfixman/venv/local/lib/python2.7/site-packages/sklearn/model_selection/_search.py:667: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n",
      "/home/juan/mfixman/venv/local/lib/python2.7/site-packages/sklearn/model_selection/_search.py:667: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n",
      "/home/juan/mfixman/venv/local/lib/python2.7/site-packages/sklearn/model_selection/_search.py:667: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n",
      "/home/juan/mfixman/venv/local/lib/python2.7/site-packages/sklearn/model_selection/_search.py:667: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n",
      "/home/juan/mfixman/venv/local/lib/python2.7/site-packages/sklearn/model_selection/_search.py:667: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n",
      "/home/juan/mfixman/venv/local/lib/python2.7/site-packages/sklearn/model_selection/_search.py:667: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n",
      "/home/juan/mfixman/venv/local/lib/python2.7/site-packages/sklearn/model_selection/_search.py:667: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n",
      "/home/juan/mfixman/venv/local/lib/python2.7/site-packages/sklearn/model_selection/_search.py:667: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n",
      "/home/juan/mfixman/venv/local/lib/python2.7/site-packages/sklearn/model_selection/_search.py:667: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n",
      "/home/juan/mfixman/venv/local/lib/python2.7/site-packages/sklearn/model_selection/_search.py:667: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n",
      "/home/juan/mfixman/venv/local/lib/python2.7/site-packages/sklearn/model_selection/_search.py:667: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n",
      "/home/juan/mfixman/venv/local/lib/python2.7/site-packages/sklearn/model_selection/_search.py:667: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n",
      "/home/juan/mfixman/venv/local/lib/python2.7/site-packages/sklearn/model_selection/_search.py:667: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n",
      "/home/juan/mfixman/venv/local/lib/python2.7/site-packages/sklearn/model_selection/_search.py:667: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n",
      "/home/juan/mfixman/venv/local/lib/python2.7/site-packages/sklearn/model_selection/_search.py:667: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n",
      "/home/juan/mfixman/venv/local/lib/python2.7/site-packages/sklearn/model_selection/_search.py:667: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.86      0.85      0.86      9114\n",
      "       True       0.21      0.22      0.21      1644\n",
      "\n",
      "avg / total       0.76      0.76      0.76     10758\n",
      "\n",
      "CPU times: user 6.43 s, sys: 628 ms, total: 7.06 s\n",
      "Wall time: 7.73 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "start_time = time.time()\n",
    "param_grid = {\n",
    "    'alpha':[\n",
    "        1e-3,\n",
    "        1e-1,\n",
    "        1e1,\n",
    "        1e0\n",
    "            ], \n",
    "    'fit_prior': [\n",
    "        True,\n",
    "        False\n",
    "                ],\n",
    "             }\n",
    "\n",
    "mnb  = MultinomialNB( )\n",
    "\n",
    "clf = GridSearchCV(mnb, param_grid, scoring='f1_weighted', fit_params=None, n_jobs=-1, iid=True, refit=True, \n",
    "verbose=3, pre_dispatch='2*n_jobs', error_score='raise')\n",
    "\n",
    "clf2 = MultinomialNB( )\n",
    "#how many parameters to randomly search for\n",
    "#n_iter_search = 45\n",
    "\n",
    "#random_search = RandomizedSearchCV(rforest, param_distributions=param_grid,\n",
    "                                 #  n_iter=n_iter_search, n_jobs =8, verbose=3)\n",
    "\n",
    "elapsed_time =  time.time() - start_time\n",
    "\n",
    "#Y = categorical(train_table_target.values, drop=True).astype(int)\n",
    "\n",
    "clf.fit(X,Y)\n",
    "\n",
    "elapsed_time =   time.time() - start_time \n",
    "\n",
    "print('Grid Search took %s seconds to run' % (elapsed_time))\n",
    "\n",
    "cv_result = pd.DataFrame(columns=['mean_score' ] + [key for key, value in clf.grid_scores_[0].parameters.items() ] )\n",
    "i=0\n",
    "for setup in clf.grid_scores_:\n",
    "    row = [clf.grid_scores_[i].mean_validation_score ] + [value for key, value in clf.grid_scores_[i].parameters.items() ]\n",
    "    cv_result.loc[i] = row\n",
    "    i+=1\n",
    "\n",
    "\n",
    "#este flag es basicamente para chequear que hayamos terminado nomas\n",
    "finished = True\n",
    "\n",
    "print('\\n Best estimator was %s \\n' % str(clf.best_estimator_))\n",
    "print('\\n Best estimator was %s \\n' % str(clf.best_score_))\n",
    "\n",
    "clf2.set_params(**clf.best_params_)\n",
    "\n",
    "clf2.fit(X,Y)\n",
    "\n",
    "\n",
    "#converted_dict = evaluation_print(clf, X_val, test_table_target.values, test_table.index.values, \n",
    "#                              test_table_target[test_table_target>0].index.values,start_date,future)\n",
    "\n",
    "print(classification_report(Y_val,clf2.predict(X_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.53569666623418843"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(Y_val,clf2.predict(X_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((94908,), 14294, {'alpha': 1.0, 'fit_prior': True})"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape, Y.sum(), clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15281650864472951"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_val.sum()*1.0/Y_val.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.53569666623418843"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(Y_val,clf2.predict(X_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.001</th>\n",
       "      <td>0.746343</td>\n",
       "      <td>0.000844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.100</th>\n",
       "      <td>0.746343</td>\n",
       "      <td>0.000844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.000</th>\n",
       "      <td>0.746339</td>\n",
       "      <td>0.000861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10.000</th>\n",
       "      <td>0.746280</td>\n",
       "      <td>0.000868</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            mean       std\n",
       "alpha                     \n",
       "0.001   0.746343  0.000844\n",
       "0.100   0.746343  0.000844\n",
       "1.000   0.746339  0.000861\n",
       "10.000  0.746280  0.000868"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fit_prior</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>0.745722</td>\n",
       "      <td>0.000038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>0.746931</td>\n",
       "      <td>0.000025</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               mean       std\n",
       "fit_prior                    \n",
       "False      0.745722  0.000038\n",
       "True       0.746931  0.000025"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for col in cv_result.columns:\n",
    "    if col != 'mean_score':\n",
    "        df = cv_result.groupby(col)['mean_score'].mean().to_frame().copy()\n",
    "        df.columns = ['mean']\n",
    "        df['std'] = cv_result.groupby(col)['mean_score'].std()\n",
    "\n",
    "        display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " 'EPIDEMIC' in X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## now graphlab models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from graphlab import random_forest_classifier, boosted_trees_classifier, logistic_classifier, decision_tree_classifier\n",
    "from graphlab.toolkits import cross_validation, model_parameter_search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get kfolds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.18 s, sys: 460 ms, total: 6.64 s\n",
      "Wall time: 4.64 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "num_folds = 10\n",
    "\n",
    "target_col = 'target'\n",
    "if graphlab_frame:   \n",
    "    X[target_col] = Y\n",
    "    X_val[target_col] = Y_val\n",
    "    kfold = cross_validation.KFold(\n",
    "    X,num_folds=num_folds)\n",
    "else:\n",
    "    X_gl= gl.SFrame(X)\n",
    "    Y_gl = gl.SArray(Y)\n",
    "    X_val_gl= gl.SFrame(X_val)\n",
    "    Y_val_gl = gl.SArray(Y_val)\n",
    "    X_gl[target_col] = Y_gl\n",
    "    X_val_gl[target_col] = Y_val_gl\n",
    "    \n",
    "    kfold = cross_validation.KFold(\n",
    "    X_gl,num_folds=num_folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'target' in X_gl.column_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandomForest \n",
    "HyperParams Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "param_grid = {\n",
    "    \"target\":target_col,\n",
    "    \n",
    "    'metric': [\n",
    "                'auc',\n",
    "#                 'log_loss',\n",
    "                 ], \n",
    "    \n",
    "    'max_iterations': [\n",
    "#                     50,\n",
    "                    100,\n",
    "                    150,\n",
    "                    200,\n",
    "                    ],\n",
    "    \n",
    "  'column_subsample': [\n",
    "                  np.sqrt(X_gl.shape[1])/X_gl.shape[1],\n",
    "                  np.log2(X_gl.shape[1])/X_gl.shape[1],\n",
    "                  0.5,\n",
    "#                   0.1,\n",
    "                  ], \n",
    "#     \"bootstrap\": [ \n",
    "#                 False,\n",
    "#                 True,\n",
    "#                     ],\n",
    "#     \"min_child_weight\": np.append(np.random.randint(3,15,3),[3]),\n",
    "    'max_depth':[\n",
    "#                  3,\n",
    "                 6,\n",
    "                 9,\n",
    "                 12,\n",
    "                ], \n",
    "   \"class_weights\": [\n",
    "#                    'balanced',\n",
    "                   None,\n",
    "                   ],\n",
    "#     \"validation_set\": X_val_gl,\n",
    "              }\n",
    "\n",
    "model_factory = random_forest_classifier.create"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] graphlab.deploy.job: Validating job.\n",
      "[INFO] graphlab.deploy.job: Creating a LocalAsync environment called 'async'.\n",
      "[INFO] graphlab.deploy.map_job: Validation complete. Job: 'Model-Parameter-Search-May-28-2017-04-13-5100000' ready for execution\n",
      "[INFO] graphlab.deploy.map_job: Job: 'Model-Parameter-Search-May-28-2017-04-13-5100000' scheduled.\n",
      "[INFO] graphlab.deploy.job: Validating job.\n",
      "[INFO] graphlab.deploy.map_job: A job with name 'Model-Parameter-Search-May-28-2017-04-13-5100000' already exists. Renaming the job to 'Model-Parameter-Search-May-28-2017-04-13-5100000-62725'.\n",
      "[INFO] graphlab.deploy.map_job: Validation complete. Job: 'Model-Parameter-Search-May-28-2017-04-13-5100000-62725' ready for execution\n",
      "[INFO] graphlab.deploy.map_job: Job: 'Model-Parameter-Search-May-28-2017-04-13-5100000-62725' scheduled.\n",
      "[INFO] graphlab.deploy.job: Validating job.\n",
      "[INFO] graphlab.deploy.map_job: Validation complete. Job: 'Model-Parameter-Search-May-28-2017-04-13-5100001' ready for execution\n",
      "[INFO] graphlab.deploy.map_job: Job: 'Model-Parameter-Search-May-28-2017-04-13-5100001' scheduled.\n",
      "[INFO] graphlab.deploy.job: Validating job.\n",
      "[INFO] graphlab.deploy.map_job: Validation complete. Job: 'Model-Parameter-Search-May-28-2017-04-13-5100002' ready for execution\n",
      "[INFO] graphlab.deploy.map_job: Job: 'Model-Parameter-Search-May-28-2017-04-13-5100002' scheduled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 36s, sys: 8.24 s, total: 1min 44s\n",
      "Wall time: 1h 7min 3s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "start_time = time.time()\n",
    "model_search = model_parameter_search.create( datasets = kfold, \n",
    "                                             #[data, val_set],\n",
    "                                             model_factory = model_factory,\n",
    "                                            model_parameters = param_grid, \n",
    "                                             perform_trial_run = True,\n",
    "                                            )\n",
    "\n",
    "search_results = model_search.get_results()\n",
    "\n",
    "all_time = time.time() - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 7.054373967647551)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(abs(all_time)/3600) ,(abs(all_time)/3600 %1)*60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\"><table frame=\"box\" rules=\"cols\">\n",
       "    <tr>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">task_name</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">status</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">start_time</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">run_time</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">exception</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">exception_message</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">exception_traceback</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">_train_test_model-0-0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Completed</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2017-05-28 04:15:38</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">142.217834949</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">_train_test_model-0-1</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Completed</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2017-05-28 04:18:00</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">147.120588064</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">_train_test_model-0-2</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Completed</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2017-05-28 04:20:28</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">143.171838999</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">_train_test_model-0-3</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Completed</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2017-05-28 04:22:51</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">142.518718958</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">_train_test_model-0-4</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Completed</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2017-05-28 04:25:13</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">144.32323885</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">_train_test_model-0-5</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Completed</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2017-05-28 04:27:38</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">143.988962889</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">_train_test_model-0-6</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Completed</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2017-05-28 04:30:02</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">148.018715143</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">_train_test_model-0-7</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Completed</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2017-05-28 04:32:30</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">145.34139204</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">_train_test_model-0-8</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Completed</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2017-05-28 04:34:55</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">143.07583499</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">_train_test_model-0-9</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Completed</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2017-05-28 04:37:19</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">138.991053104</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "    </tr>\n",
       "</table>\n",
       "<table frame=\"box\" rules=\"cols\">\n",
       "    <tr>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">job_name</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Model-Parameter-Search-Ma<br>y-28-2017-04-13-51000 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Model-Parameter-Search-Ma<br>y-28-2017-04-13-51000 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Model-Parameter-Search-Ma<br>y-28-2017-04-13-51000 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Model-Parameter-Search-Ma<br>y-28-2017-04-13-51000 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Model-Parameter-Search-Ma<br>y-28-2017-04-13-51000 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Model-Parameter-Search-Ma<br>y-28-2017-04-13-51000 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Model-Parameter-Search-Ma<br>y-28-2017-04-13-51000 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Model-Parameter-Search-Ma<br>y-28-2017-04-13-51000 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Model-Parameter-Search-Ma<br>y-28-2017-04-13-51000 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Model-Parameter-Search-Ma<br>y-28-2017-04-13-51000 ...</td>\n",
       "    </tr>\n",
       "</table>\n",
       "[35 rows x 8 columns]<br/>Note: Only the head of the SFrame is printed.<br/>You can use print_rows(num_rows=m, num_columns=n) to print more rows and columns.\n",
       "</div>"
      ],
      "text/plain": [
       "Columns:\n",
       "\ttask_name\tstr\n",
       "\tstatus\tstr\n",
       "\tstart_time\tstr\n",
       "\trun_time\tfloat\n",
       "\texception\tfloat\n",
       "\texception_message\tfloat\n",
       "\texception_traceback\tfloat\n",
       "\tjob_name\tstr\n",
       "\n",
       "Rows: 35\n",
       "\n",
       "Data:\n",
       "+-----------------------+-----------+---------------------+---------------+-----------+\n",
       "|       task_name       |   status  |      start_time     |    run_time   | exception |\n",
       "+-----------------------+-----------+---------------------+---------------+-----------+\n",
       "| _train_test_model-0-0 | Completed | 2017-05-28 04:15:38 | 142.217834949 |    None   |\n",
       "| _train_test_model-0-1 | Completed | 2017-05-28 04:18:00 | 147.120588064 |    None   |\n",
       "| _train_test_model-0-2 | Completed | 2017-05-28 04:20:28 | 143.171838999 |    None   |\n",
       "| _train_test_model-0-3 | Completed | 2017-05-28 04:22:51 | 142.518718958 |    None   |\n",
       "| _train_test_model-0-4 | Completed | 2017-05-28 04:25:13 |  144.32323885 |    None   |\n",
       "| _train_test_model-0-5 | Completed | 2017-05-28 04:27:38 | 143.988962889 |    None   |\n",
       "| _train_test_model-0-6 | Completed | 2017-05-28 04:30:02 | 148.018715143 |    None   |\n",
       "| _train_test_model-0-7 | Completed | 2017-05-28 04:32:30 |  145.34139204 |    None   |\n",
       "| _train_test_model-0-8 | Completed | 2017-05-28 04:34:55 |  143.07583499 |    None   |\n",
       "| _train_test_model-0-9 | Completed | 2017-05-28 04:37:19 | 138.991053104 |    None   |\n",
       "+-----------------------+-----------+---------------------+---------------+-----------+\n",
       "+-------------------+---------------------+-------------------------------+\n",
       "| exception_message | exception_traceback |            job_name           |\n",
       "+-------------------+---------------------+-------------------------------+\n",
       "|        None       |         None        | Model-Parameter-Search-May... |\n",
       "|        None       |         None        | Model-Parameter-Search-May... |\n",
       "|        None       |         None        | Model-Parameter-Search-May... |\n",
       "|        None       |         None        | Model-Parameter-Search-May... |\n",
       "|        None       |         None        | Model-Parameter-Search-May... |\n",
       "|        None       |         None        | Model-Parameter-Search-May... |\n",
       "|        None       |         None        | Model-Parameter-Search-May... |\n",
       "|        None       |         None        | Model-Parameter-Search-May... |\n",
       "|        None       |         None        | Model-Parameter-Search-May... |\n",
       "|        None       |         None        | Model-Parameter-Search-May... |\n",
       "+-------------------+---------------------+-------------------------------+\n",
       "[35 rows x 8 columns]\n",
       "Note: Only the head of the SFrame is printed.\n",
       "You can use print_rows(num_rows=m, num_columns=n) to print more rows and columns."
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = model_search.get_metrics()\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 14)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_results.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-----------------+----------------+\n",
      "| class_weights |       std       |      mean      |\n",
      "+---------------+-----------------+----------------+\n",
      "|      None     | 0.0159401641879 | 0.889271322173 |\n",
      "+---------------+-----------------+----------------+\n",
      "[1 rows x 3 columns]\n",
      "\n",
      "+------------------+------------------+----------------+\n",
      "| column_subsample |       std        |      mean      |\n",
      "+------------------+------------------+----------------+\n",
      "| 0.0421898618649  |       0.0        | 0.862865681399 |\n",
      "|       0.5        | 0.0127577258664  | 0.900803623544 |\n",
      "| 0.0751646028003  | 0.00549159509322 | 0.881457355654 |\n",
      "+------------------+------------------+----------------+\n",
      "[3 rows x 3 columns]\n",
      "\n",
      "+-----------+----------------+----------------+\n",
      "| max_depth |      std       |      mean      |\n",
      "+-----------+----------------+----------------+\n",
      "|     6     |      0.0       | 0.884267236348 |\n",
      "|     12    | 0.016513145653 | 0.896034414326 |\n",
      "|     9     | 0.013381018859 | 0.882068478439 |\n",
      "+-----------+----------------+----------------+\n",
      "[3 rows x 3 columns]\n",
      "\n",
      "+----------------+------------------+----------------+\n",
      "| max_iterations |       std        |      mean      |\n",
      "+----------------+------------------+----------------+\n",
      "|      200       | 0.0139737979744  | 0.89786836637  |\n",
      "|      150       | 0.00240040371231 | 0.880879114037 |\n",
      "|      100       |       0.0        | 0.862865681399 |\n",
      "+----------------+------------------+----------------+\n",
      "[3 rows x 3 columns]\n",
      "\n",
      "+--------+-----------------+----------------+\n",
      "| metric |       std       |      mean      |\n",
      "+--------+-----------------+----------------+\n",
      "|  auc   | 0.0159401641879 | 0.889271322173 |\n",
      "+--------+-----------------+----------------+\n",
      "[1 rows x 3 columns]\n",
      "\n",
      "+------------------+------------------+----------------+\n",
      "| min_child_weight |       std        |      mean      |\n",
      "+------------------+------------------+----------------+\n",
      "|        2         |       0.0        | 0.913250916392 |\n",
      "|        16        |       0.0        | 0.862865681399 |\n",
      "|        8         | 0.00119880686648 | 0.87834395648  |\n",
      "|        1         | 0.0128187286724  | 0.896103873363 |\n",
      "|        4         |       0.0        | 0.897149261049 |\n",
      "+------------------+------------------+----------------+\n",
      "[5 rows x 3 columns]\n",
      "\n",
      "+--------------------+------------------+----------------+\n",
      "| min_loss_reduction |       std        |      mean      |\n",
      "+--------------------+------------------+----------------+\n",
      "|         10         | 0.0143657631155  | 0.877231444514 |\n",
      "|         0          | 0.00834433680765 | 0.88599408139  |\n",
      "|         1          | 0.0171099202572  | 0.898568501786 |\n",
      "+--------------------+------------------+----------------+\n",
      "[3 rows x 3 columns]\n",
      "\n",
      "+---------------+------------------+----------------+\n",
      "| row_subsample |       std        |      mean      |\n",
      "+---------------+------------------+----------------+\n",
      "|      0.9      | 0.0209762076874  | 0.892265882188 |\n",
      "|      1.0      | 0.00708813094983 | 0.886276762158 |\n",
      "+---------------+------------------+----------------+\n",
      "[2 rows x 3 columns]\n",
      "\n",
      "+--------+-----------------+----------------+\n",
      "| target |       std       |      mean      |\n",
      "+--------+-----------------+----------------+\n",
      "| target | 0.0159401641879 | 0.889271322173 |\n",
      "+--------+-----------------+----------------+\n",
      "[1 rows x 3 columns]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for col in [col for col in search_results.column_names() if \\\n",
    "            not('accuracy' in col) and col!= 'model_id' and col!= 'random_seed' and col!= 'fold_id' \\\n",
    "                               and col!= 'num_folds']:\n",
    "    print(search_results.groupby(col,\n",
    "                             {'mean':gl.aggregate.MEAN('mean_training_accuracy'),\n",
    "                                'std':gl.aggregate.STD('mean_training_accuracy')}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Refit best model for feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 'currently non_endemic, that used to live in the endemic area')"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "case, case_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = model_search.get_best_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'class_weights': None,\n",
       " 'column_subsample': 0.5,\n",
       " 'max_depth': 12,\n",
       " 'max_iterations': 200,\n",
       " 'metric': 'auc',\n",
       " 'min_child_weight': 1,\n",
       " 'min_loss_reduction': 1,\n",
       " 'row_subsample': 0.9,\n",
       " 'target': 'target'}"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ## manually insert params if needed\n",
    "params = {'class_weights': None,\n",
    " 'column_subsample': 0.5,\n",
    " 'max_depth': 12,\n",
    " 'max_iterations': 200,\n",
    " 'metric': 'auc',\n",
    " 'min_child_weight': 1,\n",
    " 'min_loss_reduction': 1,\n",
    " 'row_subsample': 0.9,\n",
    " 'target': 'target'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre>Random forest classifier:</pre>"
      ],
      "text/plain": [
       "Random forest classifier:"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>--------------------------------------------------------</pre>"
      ],
      "text/plain": [
       "--------------------------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of examples          : 95180</pre>"
      ],
      "text/plain": [
       "Number of examples          : 95180"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of classes           : 2</pre>"
      ],
      "text/plain": [
       "Number of classes           : 2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of feature columns   : 176</pre>"
      ],
      "text/plain": [
       "Number of feature columns   : 176"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of unpacked features : 176</pre>"
      ],
      "text/plain": [
       "Number of unpacked features : 176"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>+-----------+--------------+--------------+----------------+</pre>"
      ],
      "text/plain": [
       "+-----------+--------------+--------------+----------------+"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| Iteration | Elapsed Time | Training-auc | Validation-auc |</pre>"
      ],
      "text/plain": [
       "| Iteration | Elapsed Time | Training-auc | Validation-auc |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>+-----------+--------------+--------------+----------------+</pre>"
      ],
      "text/plain": [
       "+-----------+--------------+--------------+----------------+"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 1         | 0.652321     | 0.887324     | 0.857103       |</pre>"
      ],
      "text/plain": [
       "| 1         | 0.652321     | 0.887324     | 0.857103       |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 2         | 1.246490     | 0.901957     | 0.867521       |</pre>"
      ],
      "text/plain": [
       "| 2         | 1.246490     | 0.901957     | 0.867521       |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 3         | 1.806583     | 0.905375     | 0.872422       |</pre>"
      ],
      "text/plain": [
       "| 3         | 1.806583     | 0.905375     | 0.872422       |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 4         | 2.413643     | 0.907046     | 0.874334       |</pre>"
      ],
      "text/plain": [
       "| 4         | 2.413643     | 0.907046     | 0.874334       |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 5         | 2.997941     | 0.907899     | 0.877066       |</pre>"
      ],
      "text/plain": [
       "| 5         | 2.997941     | 0.907899     | 0.877066       |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 6         | 3.560141     | 0.909016     | 0.877600       |</pre>"
      ],
      "text/plain": [
       "| 6         | 3.560141     | 0.909016     | 0.877600       |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 10        | 5.866732     | 0.910702     | 0.878135       |</pre>"
      ],
      "text/plain": [
       "| 10        | 5.866732     | 0.910702     | 0.878135       |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 11        | 6.437765     | 0.911047     | 0.878510       |</pre>"
      ],
      "text/plain": [
       "| 11        | 6.437765     | 0.911047     | 0.878510       |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 15        | 8.785547     | 0.910084     | 0.878787       |</pre>"
      ],
      "text/plain": [
       "| 15        | 8.785547     | 0.910084     | 0.878787       |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 20        | 11.807212    | 0.909904     | 0.878865       |</pre>"
      ],
      "text/plain": [
       "| 20        | 11.807212    | 0.909904     | 0.878865       |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 25        | 14.744240    | 0.910098     | 0.879282       |</pre>"
      ],
      "text/plain": [
       "| 25        | 14.744240    | 0.910098     | 0.879282       |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 30        | 17.685828    | 0.910600     | 0.879573       |</pre>"
      ],
      "text/plain": [
       "| 30        | 17.685828    | 0.910600     | 0.879573       |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 35        | 20.626458    | 0.910753     | 0.879844       |</pre>"
      ],
      "text/plain": [
       "| 35        | 20.626458    | 0.910753     | 0.879844       |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 40        | 23.548323    | 0.911700     | 0.880033       |</pre>"
      ],
      "text/plain": [
       "| 40        | 23.548323    | 0.911700     | 0.880033       |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 45        | 26.465986    | 0.911888     | 0.880170       |</pre>"
      ],
      "text/plain": [
       "| 45        | 26.465986    | 0.911888     | 0.880170       |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 50        | 29.398379    | 0.911304     | 0.880063       |</pre>"
      ],
      "text/plain": [
       "| 50        | 29.398379    | 0.911304     | 0.880063       |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 51        | 29.978672    | 0.911127     | 0.879940       |</pre>"
      ],
      "text/plain": [
       "| 51        | 29.978672    | 0.911127     | 0.879940       |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 55        | 32.421343    | 0.911586     | 0.880214       |</pre>"
      ],
      "text/plain": [
       "| 55        | 32.421343    | 0.911586     | 0.880214       |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 60        | 35.351890    | 0.911719     | 0.880223       |</pre>"
      ],
      "text/plain": [
       "| 60        | 35.351890    | 0.911719     | 0.880223       |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 65        | 38.301109    | 0.911431     | 0.880264       |</pre>"
      ],
      "text/plain": [
       "| 65        | 38.301109    | 0.911431     | 0.880264       |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 70        | 41.233651    | 0.911672     | 0.880431       |</pre>"
      ],
      "text/plain": [
       "| 70        | 41.233651    | 0.911672     | 0.880431       |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 75        | 44.202491    | 0.911783     | 0.880531       |</pre>"
      ],
      "text/plain": [
       "| 75        | 44.202491    | 0.911783     | 0.880531       |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 80        | 47.131820    | 0.911876     | 0.880787       |</pre>"
      ],
      "text/plain": [
       "| 80        | 47.131820    | 0.911876     | 0.880787       |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 85        | 50.115690    | 0.911692     | 0.880654       |</pre>"
      ],
      "text/plain": [
       "| 85        | 50.115690    | 0.911692     | 0.880654       |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 90        | 53.037312    | 0.911642     | 0.880638       |</pre>"
      ],
      "text/plain": [
       "| 90        | 53.037312    | 0.911642     | 0.880638       |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 95        | 55.982949    | 0.911761     | 0.880594       |</pre>"
      ],
      "text/plain": [
       "| 95        | 55.982949    | 0.911761     | 0.880594       |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 100       | 58.942501    | 0.911896     | 0.880770       |</pre>"
      ],
      "text/plain": [
       "| 100       | 58.942501    | 0.911896     | 0.880770       |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 101       | 59.543678    | 0.911917     | 0.880809       |</pre>"
      ],
      "text/plain": [
       "| 101       | 59.543678    | 0.911917     | 0.880809       |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 105       | 61.956159    | 0.912024     | 0.880812       |</pre>"
      ],
      "text/plain": [
       "| 105       | 61.956159    | 0.912024     | 0.880812       |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 110       | 64.997207    | 0.912055     | 0.880836       |</pre>"
      ],
      "text/plain": [
       "| 110       | 64.997207    | 0.912055     | 0.880836       |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 115       | 68.007296    | 0.912050     | 0.880840       |</pre>"
      ],
      "text/plain": [
       "| 115       | 68.007296    | 0.912050     | 0.880840       |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 120       | 70.928535    | 0.912091     | 0.880870       |</pre>"
      ],
      "text/plain": [
       "| 120       | 70.928535    | 0.912091     | 0.880870       |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 125       | 73.922047    | 0.912097     | 0.880861       |</pre>"
      ],
      "text/plain": [
       "| 125       | 73.922047    | 0.912097     | 0.880861       |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 130       | 76.888999    | 0.912162     | 0.880940       |</pre>"
      ],
      "text/plain": [
       "| 130       | 76.888999    | 0.912162     | 0.880940       |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 135       | 79.867156    | 0.912198     | 0.880969       |</pre>"
      ],
      "text/plain": [
       "| 135       | 79.867156    | 0.912198     | 0.880969       |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 140       | 82.805333    | 0.912126     | 0.880958       |</pre>"
      ],
      "text/plain": [
       "| 140       | 82.805333    | 0.912126     | 0.880958       |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 145       | 85.773335    | 0.912173     | 0.880983       |</pre>"
      ],
      "text/plain": [
       "| 145       | 85.773335    | 0.912173     | 0.880983       |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 150       | 88.706009    | 0.912145     | 0.880899       |</pre>"
      ],
      "text/plain": [
       "| 150       | 88.706009    | 0.912145     | 0.880899       |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 155       | 91.627645    | 0.912177     | 0.880941       |</pre>"
      ],
      "text/plain": [
       "| 155       | 91.627645    | 0.912177     | 0.880941       |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 160       | 94.561862    | 0.912095     | 0.880943       |</pre>"
      ],
      "text/plain": [
       "| 160       | 94.561862    | 0.912095     | 0.880943       |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 165       | 97.539032    | 0.912132     | 0.880898       |</pre>"
      ],
      "text/plain": [
       "| 165       | 97.539032    | 0.912132     | 0.880898       |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 170       | 100.415218   | 0.912055     | 0.880924       |</pre>"
      ],
      "text/plain": [
       "| 170       | 100.415218   | 0.912055     | 0.880924       |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 175       | 103.342166   | 0.912047     | 0.881013       |</pre>"
      ],
      "text/plain": [
       "| 175       | 103.342166   | 0.912047     | 0.881013       |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 180       | 106.324004   | 0.912119     | 0.881047       |</pre>"
      ],
      "text/plain": [
       "| 180       | 106.324004   | 0.912119     | 0.881047       |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 185       | 109.276733   | 0.912126     | 0.881056       |</pre>"
      ],
      "text/plain": [
       "| 185       | 109.276733   | 0.912126     | 0.881056       |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 190       | 112.230811   | 0.912185     | 0.881136       |</pre>"
      ],
      "text/plain": [
       "| 190       | 112.230811   | 0.912185     | 0.881136       |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 195       | 115.117248   | 0.912165     | 0.881090       |</pre>"
      ],
      "text/plain": [
       "| 195       | 115.117248   | 0.912165     | 0.881090       |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 200       | 118.090183   | 0.912192     | 0.881041       |</pre>"
      ],
      "text/plain": [
       "| 200       | 118.090183   | 0.912192     | 0.881041       |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>+-----------+--------------+--------------+----------------+</pre>"
      ],
      "text/plain": [
       "+-----------+--------------+--------------+----------------+"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9min 30s, sys: 17.7 s, total: 9min 48s\n",
      "Wall time: 2min 9s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "best_model =  random_forest_classifier.create(dataset=X_gl,\n",
    "                                             validation_set = X_val_gl,\n",
    "                                             **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\"><table frame=\"box\" rules=\"cols\">\n",
       "    <tr>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">name</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">index</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">MOBILITY_DIAMETER</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">7950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">COUNT_0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">7009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">COUNT_WEEKNIGHT_0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">6912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">MOBILITY_DIAMETER_WEEKNIG<br>HT ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">6333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">COUNT_1</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">4335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">COUNT_2</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">3925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">COUNT_WEEKNIGHT_1</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">COUNT_3</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">TimeWeekDay_OUT_08</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">TimeWeekDay_OUT_12</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2482</td>\n",
       "    </tr>\n",
       "</table>\n",
       "[20 rows x 3 columns]<br/>Note: Only the head of the SFrame is printed.<br/>You can use print_rows(num_rows=m, num_columns=n) to print more rows and columns.\n",
       "</div>"
      ],
      "text/plain": [
       "Columns:\n",
       "\tname\tstr\n",
       "\tindex\tstr\n",
       "\tcount\tint\n",
       "\n",
       "Rows: 20\n",
       "\n",
       "Data:\n",
       "+-----------------------------+-------+-------+\n",
       "|             name            | index | count |\n",
       "+-----------------------------+-------+-------+\n",
       "|      MOBILITY_DIAMETER      |  None |  7950 |\n",
       "|           COUNT_0           |  None |  7009 |\n",
       "|      COUNT_WEEKNIGHT_0      |  None |  6912 |\n",
       "| MOBILITY_DIAMETER_WEEKNIGHT |  None |  6333 |\n",
       "|           COUNT_1           |  None |  4335 |\n",
       "|           COUNT_2           |  None |  3925 |\n",
       "|      COUNT_WEEKNIGHT_1      |  None |  2844 |\n",
       "|           COUNT_3           |  None |  2687 |\n",
       "|      TimeWeekDay_OUT_08     |  None |  2509 |\n",
       "|      TimeWeekDay_OUT_12     |  None |  2482 |\n",
       "+-----------------------------+-------+-------+\n",
       "[20 rows x 3 columns]\n",
       "Note: Only the head of the SFrame is printed.\n",
       "You can use print_rows(num_rows=m, num_columns=n) to print more rows and columns."
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_feat = best_model.get_feature_importance()\n",
    "best_feat.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# filter_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MOBILITY_DIAMETER',\n",
       " 'COUNT_0',\n",
       " 'COUNT_WEEKNIGHT_0',\n",
       " 'MOBILITY_DIAMETER_WEEKNIGHT',\n",
       " 'COUNT_1',\n",
       " 'COUNT_2',\n",
       " 'COUNT_WEEKNIGHT_1',\n",
       " 'COUNT_3',\n",
       " 'TimeWeekDay_OUT_08',\n",
       " 'TimeWeekDay_OUT_12',\n",
       " 'TimeWeekDay_IN_08',\n",
       " 'COUNT_4',\n",
       " 'COUNT_5',\n",
       " 'TimeWeekDay_IN_09',\n",
       " 'TimeWeekDay_IN_12',\n",
       " 'TimeWeekDay_OUT_09',\n",
       " 'TimeWeekEnd_IN_08',\n",
       " 'TimeWeekDay_OUT_VUL_08',\n",
       " 'CallsWeekDay_OUT_08',\n",
       " 'TimeWeekEnd_OUT_08',\n",
       " 'COUNT_WEEKNIGHT_2',\n",
       " 'COUNT_7',\n",
       " 'CallsWeekDay_OUT_12',\n",
       " 'TimeWeekDay_OUT_11',\n",
       " 'COUNT_6',\n",
       " 'CallsWeekDay_IN_12',\n",
       " 'TimeWeekDay_IN_10',\n",
       " 'TimeWeekDay_OUT_10',\n",
       " 'TimeWeekDay_IN_VUL_08',\n",
       " 'COUNT_8']"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(best_feat['name'].head(30))\n",
    "#print_rows(num_rows= 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "118.09162"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.training_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.8896624070188823,\n",
       " 'auc': 0.8810393712641603,\n",
       " 'confusion_matrix': Columns:\n",
       " \ttarget_label\tint\n",
       " \tpredicted_label\tint\n",
       " \tcount\tint\n",
       " \n",
       " Rows: 4\n",
       " \n",
       " Data:\n",
       " +--------------+-----------------+-------+\n",
       " | target_label | predicted_label | count |\n",
       " +--------------+-----------------+-------+\n",
       " |      0       |        1        |  258  |\n",
       " |      1       |        0        |  899  |\n",
       " |      1       |        1        |  1139 |\n",
       " |      0       |        0        |  8190 |\n",
       " +--------------+-----------------+-------+\n",
       " [4 rows x 3 columns],\n",
       " 'f1_score': 0.6631732168850072,\n",
       " 'log_loss': 0.337038657437402,\n",
       " 'precision': 0.8153185397279885,\n",
       " 'recall': 0.5588812561334642,\n",
       " 'roc_curve': Columns:\n",
       " \tthreshold\tfloat\n",
       " \tfpr\tfloat\n",
       " \ttpr\tfloat\n",
       " \tp\tint\n",
       " \tn\tint\n",
       " \n",
       " Rows: 100001\n",
       " \n",
       " Data:\n",
       " +-----------+-----+-----+------+------+\n",
       " | threshold | fpr | tpr |  p   |  n   |\n",
       " +-----------+-----+-----+------+------+\n",
       " |    0.0    | 1.0 | 1.0 | 2038 | 8448 |\n",
       " |   1e-05   | 1.0 | 1.0 | 2038 | 8448 |\n",
       " |   2e-05   | 1.0 | 1.0 | 2038 | 8448 |\n",
       " |   3e-05   | 1.0 | 1.0 | 2038 | 8448 |\n",
       " |   4e-05   | 1.0 | 1.0 | 2038 | 8448 |\n",
       " |   5e-05   | 1.0 | 1.0 | 2038 | 8448 |\n",
       " |   6e-05   | 1.0 | 1.0 | 2038 | 8448 |\n",
       " |   7e-05   | 1.0 | 1.0 | 2038 | 8448 |\n",
       " |   8e-05   | 1.0 | 1.0 | 2038 | 8448 |\n",
       " |   9e-05   | 1.0 | 1.0 | 2038 | 8448 |\n",
       " +-----------+-----+-----+------+------+\n",
       " [100001 rows x 5 columns]\n",
       " Note: Only the head of the SFrame is printed.\n",
       " You can use print_rows(num_rows=m, num_columns=n) to print more rows and columns.}"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_error = best_model.evaluate(X_val_gl)\n",
    "\n",
    "test_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method RandomForestClassifier.get_current_options of Class                          : RandomForestClassifier\n",
       "\n",
       "Schema\n",
       "------\n",
       "Number of examples             : 95180\n",
       "Number of feature columns      : 176\n",
       "Number of unpacked features    : 176\n",
       "Number of classes              : 2\n",
       "\n",
       "Settings\n",
       "--------\n",
       "Number of trees                : 200\n",
       "Max tree depth                 : 12\n",
       "Training time (sec)            : 118.0916\n",
       "Training auc                   : 0.9122\n",
       "Validation auc                 : 0.881\n",
       ">"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.get_current_options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boosted Classifier\n",
    "### HyperParams search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Boosted Trees HyperParams\n",
    "\n",
    "# target_col = 'Y'\n",
    "\n",
    "params = {\n",
    "    'target': target_col, ## the target column string name \n",
    "    'max_iterations': [\n",
    "                      200,\n",
    "                       250,\n",
    "#                        90,\n",
    "#                        120,\n",
    "                    300,\n",
    "                      ], #The maximum number of iterations for boosting. Each iteration == extra tree.\n",
    "    'class_weights': [\n",
    "                      None, \n",
    "#                       'auto',\n",
    "    ], #Weights the examples in the training data according to the given class weights.\n",
    "#     'class_weights': [None],\n",
    "    'max_depth': [\n",
    "#         2,\n",
    "#         3,\n",
    "        4,\n",
    "#         6,\n",
    "        9,\n",
    "        15,\n",
    "        20,\n",
    "    ], #Maximum depth of a tree. Must be at least 1.\n",
    "    'step_size': [\n",
    "        1e-1,\n",
    "        0.5,\n",
    "        1e-2,\n",
    "        1,\n",
    "    ], # Step size (shrinkage) used in update to prevents overfitting\n",
    "    'min_loss_reduction': [\n",
    "#         1e-2,\n",
    "        1,\n",
    "        10,\n",
    "    ], #Minimum loss reduction required to make a further partition/split a node during the tree learning\n",
    "    'min_child_weight': [\n",
    "#         1e-2,\n",
    "        2,\n",
    "        5,\n",
    "        10,\n",
    "    ], # Controls the minimum weight of each leaf node . larger values > less overfitting\n",
    "    'row_subsample': [\n",
    "        0.5,\n",
    "        0.75,\n",
    "    ], #Subsample the ratio of the training set in each iteration of tree construction\n",
    "    \n",
    "    'column_subsample': [\n",
    "#         0.01,\n",
    "        0.1,\n",
    "        0.05,\n",
    "        0.8,\n",
    "                        ], # Subsample the ratio of the columns in each iteration of tree construction\n",
    "    #'metric': ['accuracy', 'auc', 'f1_score','recall','precision'], # Performance metric(s) that are tracked during training     \n",
    "    'metric': ['auc'],\n",
    "    'random_seed' : int(abs(hash('im not joking...'))%1e6) \n",
    "}\n",
    "\n",
    "model_factory = boosted_trees_classifier.create"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose if we want to use random forest's top features result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_cols = 30\n",
    "\n",
    "top_rf_features = False\n",
    "# top_rf_features = None\n",
    "\n",
    "if top_rf_features:\n",
    "    filter_cols = list(best_feat['name'].head(n_cols).to_numpy()) + [target_col]\n",
    "\n",
    "    X_val_gl = X_val_gl[filter_cols]\n",
    "    X_gl = X_gl[filter_cols]\n",
    "    \n",
    "    kfold = cross_validation.KFold(\n",
    "    X_gl,num_folds=num_folds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search Boosted "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] graphlab.deploy.job: Validating job.\n",
      "[INFO] graphlab.deploy.map_job: Validation complete. Job: 'Model-Parameter-Search-May-28-2017-05-23-0800000' ready for execution\n",
      "[INFO] graphlab.deploy.map_job: Job: 'Model-Parameter-Search-May-28-2017-05-23-0800000' scheduled.\n",
      "[INFO] graphlab.deploy.job: Validating job.\n",
      "[INFO] graphlab.deploy.map_job: A job with name 'Model-Parameter-Search-May-28-2017-05-23-0800000' already exists. Renaming the job to 'Model-Parameter-Search-May-28-2017-05-23-0800000-804e5'.\n",
      "[INFO] graphlab.deploy.map_job: Validation complete. Job: 'Model-Parameter-Search-May-28-2017-05-23-0800000-804e5' ready for execution\n",
      "[INFO] graphlab.deploy.map_job: Job: 'Model-Parameter-Search-May-28-2017-05-23-0800000-804e5' scheduled.\n",
      "[INFO] graphlab.deploy.job: Validating job.\n",
      "[INFO] graphlab.deploy.map_job: Validation complete. Job: 'Model-Parameter-Search-May-28-2017-05-23-0800001' ready for execution\n",
      "[INFO] graphlab.deploy.map_job: Job: 'Model-Parameter-Search-May-28-2017-05-23-0800001' scheduled.\n",
      "[INFO] graphlab.deploy.job: Validating job.\n",
      "[INFO] graphlab.deploy.map_job: Validation complete. Job: 'Model-Parameter-Search-May-28-2017-05-23-0800002' ready for execution\n",
      "[INFO] graphlab.deploy.map_job: Job: 'Model-Parameter-Search-May-28-2017-05-23-0800002' scheduled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 41.5 s, sys: 9.14 s, total: 50.6 s\n",
      "Wall time: 19min 32s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "start_time = time.time()\n",
    "model_search = model_parameter_search.create( datasets = kfold, \n",
    "                                             #[data, val_set],\n",
    "                                             model_factory = model_factory,\n",
    "                                    model_parameters = params, \n",
    "                                    perform_trial_run = True  )\n",
    "\n",
    "search_results = model_search.get_results()\n",
    "\n",
    "all_time = time.time() - start_time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 19.53582328557968)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert duration in seconds to hours and minutes\n",
    "int(abs(all_time)/3600) ,(abs(all_time)/3600 %1)*60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\"><table frame=\"box\" rules=\"cols\">\n",
       "    <tr>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">task_name</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">status</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">start_time</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">run_time</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">exception</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">exception_message</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">exception_traceback</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">_train_test_model-0-0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Completed</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2017-05-28 05:24:26</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">84.0898089409</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">_train_test_model-0-1</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Completed</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2017-05-28 05:25:50</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">86.6875948906</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">_train_test_model-0-2</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Completed</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2017-05-28 05:27:17</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">59.9590389729</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">_train_test_model-0-3</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Completed</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2017-05-28 05:28:17</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">94.800579071</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">_train_test_model-0-4</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Completed</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2017-05-28 05:29:52</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">138.167016983</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">_train_test_model-0-5</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Completed</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2017-05-28 05:32:10</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">89.2651269436</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">_train_test_model-0-6</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Completed</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2017-05-28 05:33:40</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">101.135102987</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">_train_test_model-0-7</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Completed</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2017-05-28 05:35:21</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">48.8374538422</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">_train_test_model-0-8</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Completed</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2017-05-28 05:36:10</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">62.6350979805</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">_train_test_model-0-9</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Completed</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2017-05-28 05:37:13</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">44.2389678955</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "    </tr>\n",
       "</table>\n",
       "<table frame=\"box\" rules=\"cols\">\n",
       "    <tr>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">job_name</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Model-Parameter-Search-Ma<br>y-28-2017-05-23-08000 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Model-Parameter-Search-Ma<br>y-28-2017-05-23-08000 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Model-Parameter-Search-Ma<br>y-28-2017-05-23-08000 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Model-Parameter-Search-Ma<br>y-28-2017-05-23-08000 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Model-Parameter-Search-Ma<br>y-28-2017-05-23-08000 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Model-Parameter-Search-Ma<br>y-28-2017-05-23-08000 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Model-Parameter-Search-Ma<br>y-28-2017-05-23-08000 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Model-Parameter-Search-Ma<br>y-28-2017-05-23-08000 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Model-Parameter-Search-Ma<br>y-28-2017-05-23-08000 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Model-Parameter-Search-Ma<br>y-28-2017-05-23-08000 ...</td>\n",
       "    </tr>\n",
       "</table>\n",
       "[35 rows x 8 columns]<br/>Note: Only the head of the SFrame is printed.<br/>You can use print_rows(num_rows=m, num_columns=n) to print more rows and columns.\n",
       "</div>"
      ],
      "text/plain": [
       "Columns:\n",
       "\ttask_name\tstr\n",
       "\tstatus\tstr\n",
       "\tstart_time\tstr\n",
       "\trun_time\tfloat\n",
       "\texception\tfloat\n",
       "\texception_message\tfloat\n",
       "\texception_traceback\tfloat\n",
       "\tjob_name\tstr\n",
       "\n",
       "Rows: 35\n",
       "\n",
       "Data:\n",
       "+-----------------------+-----------+---------------------+---------------+-----------+\n",
       "|       task_name       |   status  |      start_time     |    run_time   | exception |\n",
       "+-----------------------+-----------+---------------------+---------------+-----------+\n",
       "| _train_test_model-0-0 | Completed | 2017-05-28 05:24:26 | 84.0898089409 |    None   |\n",
       "| _train_test_model-0-1 | Completed | 2017-05-28 05:25:50 | 86.6875948906 |    None   |\n",
       "| _train_test_model-0-2 | Completed | 2017-05-28 05:27:17 | 59.9590389729 |    None   |\n",
       "| _train_test_model-0-3 | Completed | 2017-05-28 05:28:17 |  94.800579071 |    None   |\n",
       "| _train_test_model-0-4 | Completed | 2017-05-28 05:29:52 | 138.167016983 |    None   |\n",
       "| _train_test_model-0-5 | Completed | 2017-05-28 05:32:10 | 89.2651269436 |    None   |\n",
       "| _train_test_model-0-6 | Completed | 2017-05-28 05:33:40 | 101.135102987 |    None   |\n",
       "| _train_test_model-0-7 | Completed | 2017-05-28 05:35:21 | 48.8374538422 |    None   |\n",
       "| _train_test_model-0-8 | Completed | 2017-05-28 05:36:10 | 62.6350979805 |    None   |\n",
       "| _train_test_model-0-9 | Completed | 2017-05-28 05:37:13 | 44.2389678955 |    None   |\n",
       "+-----------------------+-----------+---------------------+---------------+-----------+\n",
       "+-------------------+---------------------+-------------------------------+\n",
       "| exception_message | exception_traceback |            job_name           |\n",
       "+-------------------+---------------------+-------------------------------+\n",
       "|        None       |         None        | Model-Parameter-Search-May... |\n",
       "|        None       |         None        | Model-Parameter-Search-May... |\n",
       "|        None       |         None        | Model-Parameter-Search-May... |\n",
       "|        None       |         None        | Model-Parameter-Search-May... |\n",
       "|        None       |         None        | Model-Parameter-Search-May... |\n",
       "|        None       |         None        | Model-Parameter-Search-May... |\n",
       "|        None       |         None        | Model-Parameter-Search-May... |\n",
       "|        None       |         None        | Model-Parameter-Search-May... |\n",
       "|        None       |         None        | Model-Parameter-Search-May... |\n",
       "|        None       |         None        | Model-Parameter-Search-May... |\n",
       "+-------------------+---------------------+-------------------------------+\n",
       "[35 rows x 8 columns]\n",
       "Note: Only the head of the SFrame is printed.\n",
       "You can use print_rows(num_rows=m, num_columns=n) to print more rows and columns."
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = model_search.get_metrics()\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# res['exception_message']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\"><table frame=\"box\" rules=\"cols\">\n",
       "    <tr>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">task_name</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">status</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">start_time</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">run_time</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">exception</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">exception_message</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">exception_traceback</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">_train_test_model-0-0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Completed</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2017-05-28 05:24:26</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">84.0898089409</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">_train_test_model-0-1</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Completed</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2017-05-28 05:25:50</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">86.6875948906</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">_train_test_model-0-2</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Completed</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2017-05-28 05:27:17</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">59.9590389729</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">_train_test_model-0-3</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Completed</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2017-05-28 05:28:17</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">94.800579071</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">_train_test_model-0-4</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Completed</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2017-05-28 05:29:52</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">138.167016983</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">_train_test_model-0-5</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Completed</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2017-05-28 05:32:10</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">89.2651269436</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">_train_test_model-0-6</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Completed</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2017-05-28 05:33:40</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">101.135102987</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">_train_test_model-0-7</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Completed</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2017-05-28 05:35:21</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">48.8374538422</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">_train_test_model-0-8</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Completed</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2017-05-28 05:36:10</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">62.6350979805</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">_train_test_model-0-9</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Completed</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2017-05-28 05:37:13</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">44.2389678955</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "    </tr>\n",
       "</table>\n",
       "<table frame=\"box\" rules=\"cols\">\n",
       "    <tr>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">job_name</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Model-Parameter-Search-Ma<br>y-28-2017-05-23-08000 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Model-Parameter-Search-Ma<br>y-28-2017-05-23-08000 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Model-Parameter-Search-Ma<br>y-28-2017-05-23-08000 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Model-Parameter-Search-Ma<br>y-28-2017-05-23-08000 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Model-Parameter-Search-Ma<br>y-28-2017-05-23-08000 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Model-Parameter-Search-Ma<br>y-28-2017-05-23-08000 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Model-Parameter-Search-Ma<br>y-28-2017-05-23-08000 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Model-Parameter-Search-Ma<br>y-28-2017-05-23-08000 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Model-Parameter-Search-Ma<br>y-28-2017-05-23-08000 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Model-Parameter-Search-Ma<br>y-28-2017-05-23-08000 ...</td>\n",
       "    </tr>\n",
       "</table>\n",
       "[35 rows x 8 columns]<br/>Note: Only the head of the SFrame is printed.<br/>You can use print_rows(num_rows=m, num_columns=n) to print more rows and columns.\n",
       "</div>"
      ],
      "text/plain": [
       "Columns:\n",
       "\ttask_name\tstr\n",
       "\tstatus\tstr\n",
       "\tstart_time\tstr\n",
       "\trun_time\tfloat\n",
       "\texception\tfloat\n",
       "\texception_message\tfloat\n",
       "\texception_traceback\tfloat\n",
       "\tjob_name\tstr\n",
       "\n",
       "Rows: 35\n",
       "\n",
       "Data:\n",
       "+-----------------------+-----------+---------------------+---------------+-----------+\n",
       "|       task_name       |   status  |      start_time     |    run_time   | exception |\n",
       "+-----------------------+-----------+---------------------+---------------+-----------+\n",
       "| _train_test_model-0-0 | Completed | 2017-05-28 05:24:26 | 84.0898089409 |    None   |\n",
       "| _train_test_model-0-1 | Completed | 2017-05-28 05:25:50 | 86.6875948906 |    None   |\n",
       "| _train_test_model-0-2 | Completed | 2017-05-28 05:27:17 | 59.9590389729 |    None   |\n",
       "| _train_test_model-0-3 | Completed | 2017-05-28 05:28:17 |  94.800579071 |    None   |\n",
       "| _train_test_model-0-4 | Completed | 2017-05-28 05:29:52 | 138.167016983 |    None   |\n",
       "| _train_test_model-0-5 | Completed | 2017-05-28 05:32:10 | 89.2651269436 |    None   |\n",
       "| _train_test_model-0-6 | Completed | 2017-05-28 05:33:40 | 101.135102987 |    None   |\n",
       "| _train_test_model-0-7 | Completed | 2017-05-28 05:35:21 | 48.8374538422 |    None   |\n",
       "| _train_test_model-0-8 | Completed | 2017-05-28 05:36:10 | 62.6350979805 |    None   |\n",
       "| _train_test_model-0-9 | Completed | 2017-05-28 05:37:13 | 44.2389678955 |    None   |\n",
       "+-----------------------+-----------+---------------------+---------------+-----------+\n",
       "+-------------------+---------------------+-------------------------------+\n",
       "| exception_message | exception_traceback |            job_name           |\n",
       "+-------------------+---------------------+-------------------------------+\n",
       "|        None       |         None        | Model-Parameter-Search-May... |\n",
       "|        None       |         None        | Model-Parameter-Search-May... |\n",
       "|        None       |         None        | Model-Parameter-Search-May... |\n",
       "|        None       |         None        | Model-Parameter-Search-May... |\n",
       "|        None       |         None        | Model-Parameter-Search-May... |\n",
       "|        None       |         None        | Model-Parameter-Search-May... |\n",
       "|        None       |         None        | Model-Parameter-Search-May... |\n",
       "|        None       |         None        | Model-Parameter-Search-May... |\n",
       "|        None       |         None        | Model-Parameter-Search-May... |\n",
       "|        None       |         None        | Model-Parameter-Search-May... |\n",
       "+-------------------+---------------------+-------------------------------+\n",
       "[35 rows x 8 columns]\n",
       "Note: Only the head of the SFrame is printed.\n",
       "You can use print_rows(num_rows=m, num_columns=n) to print more rows and columns."
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 17)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_results.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\"><table frame=\"box\" rules=\"cols\">\n",
       "    <tr>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">class_weights</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">column_subsample</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">early_stopping_rounds</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">max_depth</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">max_iterations</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">metric</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">min_child_weight</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">min_loss_reduction</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.1</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">5</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">9</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">250</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">auc</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.8</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">5</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">15</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">200</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">auc</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">5</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.8</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">5</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">15</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">200</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">auc</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">10</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.05</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">5</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">15</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">200</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">auc</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">5</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.05</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">5</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">9</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">200</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">auc</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">10</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.8</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">5</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">9</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">300</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">auc</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.1</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">5</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">15</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">300</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">auc</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.8</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">5</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">20</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">250</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">auc</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.05</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">5</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">9</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">200</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">auc</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.8</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">5</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">4</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">200</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">auc</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">10</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n",
       "    </tr>\n",
       "</table>\n",
       "<table frame=\"box\" rules=\"cols\">\n",
       "    <tr>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">random_seed</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">row_subsample</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">step_size</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">target</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">num_folds</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">fold_id</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">mean_training_accuracy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">415168</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.75</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1.0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">target</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">10</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">[8, 9, 4, 5, 6, 7, 0, 1,<br>2, 3] ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.888214143961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">415168</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.75</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.5</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">target</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">10</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">[9, 8, 1, 0, 3, 2, 5, 4,<br>7, 6] ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.916128505055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">415168</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.5</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1.0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">target</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">10</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">[1, 8, 9, 4, 5, 6, 7, 0,<br>3, 2] ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.886419882795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">415168</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.75</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1.0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">target</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">10</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">[0, 1, 5, 4, 7, 6, 2, 3,<br>9, 8] ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.886152553057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">415168</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.5</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.1</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">target</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">10</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">[1, 0, 3, 2, 5, 4, 7, 6,<br>9, 8] ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.874481100138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">415168</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.5</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1.0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">target</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">10</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">[8, 9, 1, 0, 3, 2, 5, 4,<br>7, 6] ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.888411430973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">415168</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.5</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.1</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">target</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">10</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">[3, 2, 1, 0, 5, 4, 7, 6,<br>9, 8] ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.882219653989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">415168</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.5</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.01</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">target</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">10</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">[8, 1, 0, 3, 2, 5, 4, 7,<br>9, 6] ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.91135859541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">415168</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.75</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.01</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">target</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">10</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">[3, 4, 5, 0, 1, 9, 8, 6,<br>7, 2] ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.869836100021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">415168</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.5</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.5</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">target</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">10</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">[7, 9, 8, 6, 1, 0, 3, 2,<br>5, 4] ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.889262450095</td>\n",
       "    </tr>\n",
       "</table>\n",
       "<table frame=\"box\" rules=\"cols\">\n",
       "    <tr>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">mean_validation_accuracy</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">model_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.87504727884</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">[28, 29, 24, 25, 26, 27,<br>20, 21, 22, 23] ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.878976675772</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">[19, 18, 11, 10, 13, 12,<br>15, 14, 17, 16] ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.877390208027</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">[51, 58, 59, 54, 55, 56,<br>57, 50, 53, 52] ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.876392099181</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">[60, 61, 65, 64, 67, 66,<br>62, 63, 69, 68] ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.870487497373</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">[31, 30, 33, 32, 35, 34,<br>37, 36, 39, 38] ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.877064509351</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">[88, 89, 81, 80, 83, 82,<br>85, 84, 87, 86] ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.878041605379</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">[43, 42, 41, 40, 45, 44,<br>47, 46, 49, 48] ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.883441899559</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">[8, 1, 0, 3, 2, 5, 4, 7,<br>9, 6] ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.866453036352</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">[93, 94, 95, 90, 91, 99,<br>98, 96, 97, 92] ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.882086572809</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">[77, 79, 78, 76, 71, 70,<br>73, 72, 75, 74] ...</td>\n",
       "    </tr>\n",
       "</table>\n",
       "[10 rows x 17 columns]<br/>\n",
       "</div>"
      ],
      "text/plain": [
       "Columns:\n",
       "\tclass_weights\tfloat\n",
       "\tcolumn_subsample\tfloat\n",
       "\tearly_stopping_rounds\tint\n",
       "\tmax_depth\tint\n",
       "\tmax_iterations\tint\n",
       "\tmetric\tstr\n",
       "\tmin_child_weight\tint\n",
       "\tmin_loss_reduction\tint\n",
       "\trandom_seed\tint\n",
       "\trow_subsample\tfloat\n",
       "\tstep_size\tfloat\n",
       "\ttarget\tstr\n",
       "\tnum_folds\tint\n",
       "\tfold_id\tlist\n",
       "\tmean_training_accuracy\tfloat\n",
       "\tmean_validation_accuracy\tfloat\n",
       "\tmodel_id\tlist\n",
       "\n",
       "Rows: 10\n",
       "\n",
       "Data:\n",
       "+---------------+------------------+-----------------------+-----------+----------------+\n",
       "| class_weights | column_subsample | early_stopping_rounds | max_depth | max_iterations |\n",
       "+---------------+------------------+-----------------------+-----------+----------------+\n",
       "|      None     |       0.1        |           5           |     9     |      250       |\n",
       "|      None     |       0.8        |           5           |     15    |      200       |\n",
       "|      None     |       0.8        |           5           |     15    |      200       |\n",
       "|      None     |       0.05       |           5           |     15    |      200       |\n",
       "|      None     |       0.05       |           5           |     9     |      200       |\n",
       "|      None     |       0.8        |           5           |     9     |      300       |\n",
       "|      None     |       0.1        |           5           |     15    |      300       |\n",
       "|      None     |       0.8        |           5           |     20    |      250       |\n",
       "|      None     |       0.05       |           5           |     9     |      200       |\n",
       "|      None     |       0.8        |           5           |     4     |      200       |\n",
       "+---------------+------------------+-----------------------+-----------+----------------+\n",
       "+--------+------------------+--------------------+-------------+---------------+\n",
       "| metric | min_child_weight | min_loss_reduction | random_seed | row_subsample |\n",
       "+--------+------------------+--------------------+-------------+---------------+\n",
       "|  auc   |        2         |         10         |    415168   |      0.75     |\n",
       "|  auc   |        5         |         1          |    415168   |      0.75     |\n",
       "|  auc   |        10        |         10         |    415168   |      0.5      |\n",
       "|  auc   |        5         |         10         |    415168   |      0.75     |\n",
       "|  auc   |        10        |         1          |    415168   |      0.5      |\n",
       "|  auc   |        2         |         10         |    415168   |      0.5      |\n",
       "|  auc   |        2         |         10         |    415168   |      0.5      |\n",
       "|  auc   |        2         |         1          |    415168   |      0.5      |\n",
       "|  auc   |        2         |         10         |    415168   |      0.75     |\n",
       "|  auc   |        10        |         1          |    415168   |      0.5      |\n",
       "+--------+------------------+--------------------+-------------+---------------+\n",
       "+-----------+--------+-----------+--------------------------------+\n",
       "| step_size | target | num_folds |            fold_id             |\n",
       "+-----------+--------+-----------+--------------------------------+\n",
       "|    1.0    | target |     10    | [8, 9, 4, 5, 6, 7, 0, 1, 2, 3] |\n",
       "|    0.5    | target |     10    | [9, 8, 1, 0, 3, 2, 5, 4, 7, 6] |\n",
       "|    1.0    | target |     10    | [1, 8, 9, 4, 5, 6, 7, 0, 3, 2] |\n",
       "|    1.0    | target |     10    | [0, 1, 5, 4, 7, 6, 2, 3, 9, 8] |\n",
       "|    0.1    | target |     10    | [1, 0, 3, 2, 5, 4, 7, 6, 9, 8] |\n",
       "|    1.0    | target |     10    | [8, 9, 1, 0, 3, 2, 5, 4, 7, 6] |\n",
       "|    0.1    | target |     10    | [3, 2, 1, 0, 5, 4, 7, 6, 9, 8] |\n",
       "|    0.01   | target |     10    | [8, 1, 0, 3, 2, 5, 4, 7, 9, 6] |\n",
       "|    0.01   | target |     10    | [3, 4, 5, 0, 1, 9, 8, 6, 7, 2] |\n",
       "|    0.5    | target |     10    | [7, 9, 8, 6, 1, 0, 3, 2, 5, 4] |\n",
       "+-----------+--------+-----------+--------------------------------+\n",
       "+------------------------+--------------------------+\n",
       "| mean_training_accuracy | mean_validation_accuracy |\n",
       "+------------------------+--------------------------+\n",
       "|     0.888214143961     |      0.87504727884       |\n",
       "|     0.916128505055     |      0.878976675772      |\n",
       "|     0.886419882795     |      0.877390208027      |\n",
       "|     0.886152553057     |      0.876392099181      |\n",
       "|     0.874481100138     |      0.870487497373      |\n",
       "|     0.888411430973     |      0.877064509351      |\n",
       "|     0.882219653989     |      0.878041605379      |\n",
       "|     0.91135859541      |      0.883441899559      |\n",
       "|     0.869836100021     |      0.866453036352      |\n",
       "|     0.889262450095     |      0.882086572809      |\n",
       "+------------------------+--------------------------+\n",
       "+--------------------------------+\n",
       "|            model_id            |\n",
       "+--------------------------------+\n",
       "| [28, 29, 24, 25, 26, 27, 2...  |\n",
       "| [19, 18, 11, 10, 13, 12, 1...  |\n",
       "| [51, 58, 59, 54, 55, 56, 5...  |\n",
       "| [60, 61, 65, 64, 67, 66, 6...  |\n",
       "| [31, 30, 33, 32, 35, 34, 3...  |\n",
       "| [88, 89, 81, 80, 83, 82, 8...  |\n",
       "| [43, 42, 41, 40, 45, 44, 4...  |\n",
       "| [8, 1, 0, 3, 2, 5, 4, 7, 9, 6] |\n",
       "| [93, 94, 95, 90, 91, 99, 9...  |\n",
       "| [77, 79, 78, 76, 71, 70, 7...  |\n",
       "+--------------------------------+\n",
       "[10 rows x 17 columns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-----------------+----------------+\n",
      "| class_weights |       std       |      mean      |\n",
      "+---------------+-----------------+----------------+\n",
      "|      None     | 0.0136933187101 | 0.889248441549 |\n",
      "+---------------+-----------------+----------------+\n",
      "[1 rows x 3 columns]\n",
      "\n",
      "+------------------+------------------+----------------+\n",
      "| column_subsample |       std        |      mean      |\n",
      "+------------------+------------------+----------------+\n",
      "|       0.05       | 0.00686395965271 | 0.876823251072 |\n",
      "|       0.8        | 0.0127199016447  | 0.898316172865 |\n",
      "|       0.1        | 0.00299724498611 | 0.885216898975 |\n",
      "+------------------+------------------+----------------+\n",
      "[3 rows x 3 columns]\n",
      "\n",
      "+-----------------------+-----------------+----------------+\n",
      "| early_stopping_rounds |       std       |      mean      |\n",
      "+-----------------------+-----------------+----------------+\n",
      "|           5           | 0.0136933187101 | 0.889248441549 |\n",
      "+-----------------------+-----------------+----------------+\n",
      "[1 rows x 3 columns]\n",
      "\n",
      "+-----------+-----------------+----------------+\n",
      "| max_depth |       std       |      mean      |\n",
      "+-----------+-----------------+----------------+\n",
      "|     15    | 0.0136110047333 | 0.892730148724 |\n",
      "|     20    |       0.0       | 0.91135859541  |\n",
      "|     4     |       0.0       | 0.889262450095 |\n",
      "|     9     |  0.008242651944 | 0.880235693773 |\n",
      "+-----------+-----------------+----------------+\n",
      "[4 rows x 3 columns]\n",
      "\n",
      "+----------------+------------------+----------------+\n",
      "| max_iterations |       std        |      mean      |\n",
      "+----------------+------------------+----------------+\n",
      "|      200       | 0.0147532616947  | 0.887046765193 |\n",
      "|      250       | 0.0115722257244  | 0.899786369686 |\n",
      "|      300       | 0.00309588849198 | 0.885315542481 |\n",
      "+----------------+------------------+----------------+\n",
      "[3 rows x 3 columns]\n",
      "\n",
      "+--------+-----------------+----------------+\n",
      "| metric |       std       |      mean      |\n",
      "+--------+-----------------+----------------+\n",
      "|  auc   | 0.0136933187101 | 0.889248441549 |\n",
      "+--------+-----------------+----------------+\n",
      "[1 rows x 3 columns]\n",
      "\n",
      "+------------------+------------------+----------------+\n",
      "| min_child_weight |       std        |      mean      |\n",
      "+------------------+------------------+----------------+\n",
      "|        2         | 0.0134846465009  | 0.888007984871 |\n",
      "|        10        | 0.00640401806801 | 0.883387811009 |\n",
      "|        5         | 0.0149879759987  | 0.901140529056 |\n",
      "+------------------+------------------+----------------+\n",
      "[3 rows x 3 columns]\n",
      "\n",
      "+--------------------+------------------+----------------+\n",
      "| min_loss_reduction |       std        |      mean      |\n",
      "+--------------------+------------------+----------------+\n",
      "|         10         | 0.00645804119592 | 0.883542294133 |\n",
      "|         1          | 0.0168554903617  | 0.897807662674 |\n",
      "+--------------------+------------------+----------------+\n",
      "[2 rows x 3 columns]\n",
      "\n",
      "+---------------+-----------------+----------------+\n",
      "| row_subsample |       std       |      mean      |\n",
      "+---------------+-----------------+----------------+\n",
      "|      0.5      | 0.0112781657339 | 0.888692185567 |\n",
      "|      0.75     | 0.0166376555459 | 0.890082825524 |\n",
      "+---------------+-----------------+----------------+\n",
      "[2 rows x 3 columns]\n",
      "\n",
      "+-----------+------------------+----------------+\n",
      "| step_size |       std        |      mean      |\n",
      "+-----------+------------------+----------------+\n",
      "|    0.5    | 0.0134330274801  | 0.902695477575 |\n",
      "|    0.01   | 0.0207612476944  | 0.890597347715 |\n",
      "|    0.1    | 0.00386927692559 | 0.878350377063 |\n",
      "|    1.0    | 0.00102007080396 | 0.887299502697 |\n",
      "+-----------+------------------+----------------+\n",
      "[4 rows x 3 columns]\n",
      "\n",
      "+--------+-----------------+----------------+\n",
      "| target |       std       |      mean      |\n",
      "+--------+-----------------+----------------+\n",
      "| target | 0.0136933187101 | 0.889248441549 |\n",
      "+--------+-----------------+----------------+\n",
      "[1 rows x 3 columns]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for col in [col for col in search_results.column_names() if \\\n",
    "            not('accuracy' in col) and col!= 'model_id' and col!= 'random_seed' and col!= 'fold_id' \\\n",
    "                               and col!= 'num_folds']:\n",
    "    print(search_results.groupby(col,\n",
    "                             {'mean':gl.aggregate.MEAN('mean_training_accuracy'),\n",
    "                                'std':gl.aggregate.STD('mean_training_accuracy')}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## hyperparameter results\n",
    "\n",
    "* class_weights: None, gana por afano\n",
    "* column_subsample : algo menor a 1 pero no queda claro si cuanto menos mejor\n",
    "* row_subsample : algo menor a 1 pero no queda claro si cuanto menos mejor, refinar\n",
    "* max_depth: varia mucho, refinar\n",
    "* max_iterations: tampoco queda claro si poquito o mucho es mejor, reprobar\n",
    "* metric: el f1_score es el unico que no parece variar mucho,los demas cambian demasiado\n",
    "* min_child_weight: varia mucho, reprobar con mas\n",
    "* min_loss_reduction: varia mucho, reprobar\n",
    "* step_size: mas grande parece ser mejor> 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Results\n",
    "\n",
    "* bootstrap  ???= False es 5% mejor\n",
    "* min_samples_leaf ????= mas chico es claramente mejor, pero tmb aumenta el overfitting lo cual me hace caer mucho el valor del recall en el test_set. Sin embargo es un parametro muy sensible en la precision. Resta evaluar asi el tradeoff entre la precision y el volumen de users al cual queremos llegar.\n",
    "* n_estimators ???= mas pareceria mejor, pero depende del app y hay que ver 'cuanto' mejora por app\n",
    "* citerion ???= entropy o gini no cambia. gini podria ser mejor entonces pues entropy usa logs de los valores lo cual es mas computacionalmente costoso\n",
    "* max_features ???= no afecta al score. con auto esta bien\n",
    "* max_depth ??=  mas es mejor. intentaria probar con >15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## boosted run with best params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = model_search.get_best_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'class_weights': None,\n",
       " 'column_subsample': 0.8,\n",
       " 'early_stopping_rounds': 5,\n",
       " 'max_depth': 20,\n",
       " 'max_iterations': 250,\n",
       " 'metric': 'auc',\n",
       " 'min_child_weight': 2,\n",
       " 'min_loss_reduction': 1,\n",
       " 'random_seed': 415168,\n",
       " 'row_subsample': 0.5,\n",
       " 'step_size': 0.01,\n",
       " 'target': 'target'}"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = {'class_weights': None,\n",
    " 'column_subsample': 0.8,\n",
    " 'early_stopping_rounds': 5,\n",
    " 'max_depth': 12,\n",
    " 'max_iterations': 250,\n",
    " 'metric': 'auc',\n",
    " 'min_child_weight': 2,\n",
    " 'min_loss_reduction': 1,\n",
    " 'random_seed': 415168,\n",
    " 'row_subsample': 0.5,\n",
    " 'step_size': 0.01,\n",
    " 'target': 'target'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre>Boosted trees classifier:</pre>"
      ],
      "text/plain": [
       "Boosted trees classifier:"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>--------------------------------------------------------</pre>"
      ],
      "text/plain": [
       "--------------------------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of examples          : 95180</pre>"
      ],
      "text/plain": [
       "Number of examples          : 95180"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of classes           : 2</pre>"
      ],
      "text/plain": [
       "Number of classes           : 2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of feature columns   : 176</pre>"
      ],
      "text/plain": [
       "Number of feature columns   : 176"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of unpacked features : 176</pre>"
      ],
      "text/plain": [
       "Number of unpacked features : 176"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>+-----------+--------------+--------------+----------------+</pre>"
      ],
      "text/plain": [
       "+-----------+--------------+--------------+----------------+"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| Iteration | Elapsed Time | Training-auc | Validation-auc |</pre>"
      ],
      "text/plain": [
       "| Iteration | Elapsed Time | Training-auc | Validation-auc |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>+-----------+--------------+--------------+----------------+</pre>"
      ],
      "text/plain": [
       "+-----------+--------------+--------------+----------------+"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 1         | 0.792755     | 0.870534     | 0.854229       |</pre>"
      ],
      "text/plain": [
       "| 1         | 0.792755     | 0.870534     | 0.854229       |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 2         | 1.599966     | 0.885401     | 0.866128       |</pre>"
      ],
      "text/plain": [
       "| 2         | 1.599966     | 0.885401     | 0.866128       |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 3         | 2.415011     | 0.891582     | 0.872199       |</pre>"
      ],
      "text/plain": [
       "| 3         | 2.415011     | 0.891582     | 0.872199       |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 4         | 3.172991     | 0.896710     | 0.875075       |</pre>"
      ],
      "text/plain": [
       "| 4         | 3.172991     | 0.896710     | 0.875075       |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 5         | 3.932190     | 0.898678     | 0.876098       |</pre>"
      ],
      "text/plain": [
       "| 5         | 3.932190     | 0.898678     | 0.876098       |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 6         | 4.718734     | 0.898829     | 0.875404       |</pre>"
      ],
      "text/plain": [
       "| 6         | 4.718734     | 0.898829     | 0.875404       |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 10        | 7.827187     | 0.901186     | 0.878331       |</pre>"
      ],
      "text/plain": [
       "| 10        | 7.827187     | 0.901186     | 0.878331       |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 11        | 8.619724     | 0.901667     | 0.878403       |</pre>"
      ],
      "text/plain": [
       "| 11        | 8.619724     | 0.901667     | 0.878403       |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 15        | 11.739438    | 0.904433     | 0.879636       |</pre>"
      ],
      "text/plain": [
       "| 15        | 11.739438    | 0.904433     | 0.879636       |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 20        | 15.623586    | 0.905729     | 0.880089       |</pre>"
      ],
      "text/plain": [
       "| 20        | 15.623586    | 0.905729     | 0.880089       |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 25        | 19.480804    | 0.907467     | 0.880335       |</pre>"
      ],
      "text/plain": [
       "| 25        | 19.480804    | 0.907467     | 0.880335       |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 30        | 23.432567    | 0.907983     | 0.880966       |</pre>"
      ],
      "text/plain": [
       "| 30        | 23.432567    | 0.907983     | 0.880966       |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 35        | 27.363924    | 0.908957     | 0.880943       |</pre>"
      ],
      "text/plain": [
       "| 35        | 27.363924    | 0.908957     | 0.880943       |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>+-----------+--------------+--------------+----------------+</pre>"
      ],
      "text/plain": [
       "+-----------+--------------+--------------+----------------+"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Early stop triggered. Returning the best model at iteration: 30</pre>"
      ],
      "text/plain": [
       "Early stop triggered. Returning the best model at iteration: 30"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 27s, sys: 4.76 s, total: 2min 32s\n",
      "Wall time: 30.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "best_model =  boosted_trees_classifier.create(dataset=X_gl,\n",
    "                                             validation_set = X_val_gl,\n",
    "                                             **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['COUNT_0',\n",
       " 'MOBILITY_DIAMETER_WEEKNIGHT',\n",
       " 'MOBILITY_DIAMETER',\n",
       " 'COUNT_WEEKNIGHT_0',\n",
       " 'COUNT_1',\n",
       " 'TimeWeekDay_IN_08',\n",
       " 'COUNT_2',\n",
       " 'TimeWeekDay_OUT_08',\n",
       " 'COUNT_WEEKNIGHT_1',\n",
       " 'TimeWeekDay_OUT_09',\n",
       " 'TimeWeekDay_OUT_12',\n",
       " 'TimeWeekDay_IN_09',\n",
       " 'TimeWeekDay_IN_12',\n",
       " 'TimeWeekDay_OUT_10',\n",
       " 'TimeWeekEnd_OUT_08',\n",
       " 'COUNT_3',\n",
       " 'COUNT_4',\n",
       " 'CallsWeekDay_IN_08',\n",
       " 'TimeWeekDay_OUT_11',\n",
       " 'TimeWeekDay_IN_10']"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_feat = best_model.get_feature_importance()\n",
    "best_feat = list(best_feat['name'].head(20))\n",
    "best_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>LATITUDE</th>\n",
       "      <th>LONGITUDE</th>\n",
       "      <th>CEL_ID</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STATE</th>\n",
       "      <th>EPIDEMIC</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Aguascalientes</th>\n",
       "      <th>0</th>\n",
       "      <td>21.856175</td>\n",
       "      <td>-102.352281</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Baja_California</th>\n",
       "      <th>0</th>\n",
       "      <td>32.642231</td>\n",
       "      <td>-115.408042</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Baja_California_Sur</th>\n",
       "      <th>0</th>\n",
       "      <td>24.142063</td>\n",
       "      <td>-110.294055</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Campeche</th>\n",
       "      <th>0</th>\n",
       "      <td>19.814033</td>\n",
       "      <td>-90.508705</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chiapas</th>\n",
       "      <th>0</th>\n",
       "      <td>16.620228</td>\n",
       "      <td>-93.097100</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chihuahua</th>\n",
       "      <th>0</th>\n",
       "      <td>28.694722</td>\n",
       "      <td>-106.108056</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Coahuila_de_Zaragoza</th>\n",
       "      <th>0</th>\n",
       "      <td>28.637778</td>\n",
       "      <td>-100.553056</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Colima</th>\n",
       "      <th>0</th>\n",
       "      <td>19.052920</td>\n",
       "      <td>-104.320394</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Distrito_Federal</th>\n",
       "      <th>0</th>\n",
       "      <td>19.317872</td>\n",
       "      <td>-99.137003</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Durango</th>\n",
       "      <th>0</th>\n",
       "      <td>25.553119</td>\n",
       "      <td>-103.489508</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Guanajuato</th>\n",
       "      <th>0</th>\n",
       "      <td>21.158572</td>\n",
       "      <td>-100.923861</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Guerrero</th>\n",
       "      <th>1</th>\n",
       "      <td>16.831714</td>\n",
       "      <td>-99.778656</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hidalgo</th>\n",
       "      <th>1</th>\n",
       "      <td>19.832881</td>\n",
       "      <td>-98.950172</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jalisco</th>\n",
       "      <th>1</th>\n",
       "      <td>20.581427</td>\n",
       "      <td>-103.432628</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mexico</th>\n",
       "      <th>0</th>\n",
       "      <td>19.490600</td>\n",
       "      <td>-99.271200</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Michoacan_de_Ocampo</th>\n",
       "      <th>0</th>\n",
       "      <td>19.699532</td>\n",
       "      <td>-101.211267</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Morelos</th>\n",
       "      <th>1</th>\n",
       "      <td>18.828056</td>\n",
       "      <td>-99.244444</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nayarit</th>\n",
       "      <th>0</th>\n",
       "      <td>21.055389</td>\n",
       "      <td>-105.127556</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nuevo_Leon</th>\n",
       "      <th>0</th>\n",
       "      <td>25.806569</td>\n",
       "      <td>-100.325653</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Oaxaca</th>\n",
       "      <th>1</th>\n",
       "      <td>17.071125</td>\n",
       "      <td>-96.676006</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Puebla</th>\n",
       "      <th>1</th>\n",
       "      <td>19.067444</td>\n",
       "      <td>-98.221000</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Queretaro</th>\n",
       "      <th>0</th>\n",
       "      <td>20.594503</td>\n",
       "      <td>-100.393656</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Quintana_Roo</th>\n",
       "      <th>0</th>\n",
       "      <td>21.140333</td>\n",
       "      <td>-86.864528</td>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>San_Luis_Potosi</th>\n",
       "      <th>0</th>\n",
       "      <td>22.186800</td>\n",
       "      <td>-100.945300</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sinaloa</th>\n",
       "      <th>0</th>\n",
       "      <td>23.278450</td>\n",
       "      <td>-106.448220</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sonora</th>\n",
       "      <th>0</th>\n",
       "      <td>32.444358</td>\n",
       "      <td>-114.771023</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tabasco</th>\n",
       "      <th>1</th>\n",
       "      <td>17.879241</td>\n",
       "      <td>-92.480478</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tamaulipas</th>\n",
       "      <th>0</th>\n",
       "      <td>22.415000</td>\n",
       "      <td>-97.938000</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tlaxcala</th>\n",
       "      <th>0</th>\n",
       "      <td>19.212956</td>\n",
       "      <td>-98.240853</td>\n",
       "      <td>162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Veracruz</th>\n",
       "      <th>1</th>\n",
       "      <td>17.994111</td>\n",
       "      <td>-94.566444</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Yucatan</th>\n",
       "      <th>0</th>\n",
       "      <td>21.016680</td>\n",
       "      <td>-89.607927</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Zacatecas</th>\n",
       "      <th>0</th>\n",
       "      <td>22.738691</td>\n",
       "      <td>-102.555193</td>\n",
       "      <td>131</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                LATITUDE   LONGITUDE  CEL_ID\n",
       "STATE                EPIDEMIC                               \n",
       "Aguascalientes       0         21.856175 -102.352281      37\n",
       "Baja_California      0         32.642231 -115.408042      67\n",
       "Baja_California_Sur  0         24.142063 -110.294055       1\n",
       "Campeche             0         19.814033  -90.508705      49\n",
       "Chiapas              0         16.620228  -93.097100      76\n",
       "Chihuahua            0         28.694722 -106.108056      55\n",
       "Coahuila_de_Zaragoza 0         28.637778 -100.553056     118\n",
       "Colima               0         19.052920 -104.320394      87\n",
       "Distrito_Federal     0         19.317872  -99.137003       2\n",
       "Durango              0         25.553119 -103.489508      35\n",
       "Guanajuato           0         21.158572 -100.923861      30\n",
       "Guerrero             1         16.831714  -99.778656      57\n",
       "Hidalgo              1         19.832881  -98.950172      60\n",
       "Jalisco              1         20.581427 -103.432628      10\n",
       "Mexico               0         19.490600  -99.271200       9\n",
       "Michoacan_de_Ocampo  0         19.699532 -101.211267     102\n",
       "Morelos              1         18.828056  -99.244444       6\n",
       "Nayarit              0         21.055389 -105.127556      56\n",
       "Nuevo_Leon           0         25.806569 -100.325653       8\n",
       "Oaxaca               1         17.071125  -96.676006      24\n",
       "Puebla               1         19.067444  -98.221000       5\n",
       "Queretaro            0         20.594503 -100.393656      17\n",
       "Quintana_Roo         0         21.140333  -86.864528     123\n",
       "San_Luis_Potosi      0         22.186800 -100.945300     105\n",
       "Sinaloa              0         23.278450 -106.448220      86\n",
       "Sonora               0         32.444358 -114.771023      38\n",
       "Tabasco              1         17.879241  -92.480478       3\n",
       "Tamaulipas           0         22.415000  -97.938000       4\n",
       "Tlaxcala             0         19.212956  -98.240853     162\n",
       "Veracruz             1         17.994111  -94.566444      13\n",
       "Yucatan              0         21.016680  -89.607927      12\n",
       "Zacatecas            0         22.738691 -102.555193     131"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if best feat states are epidemic or not\n",
    "antennas.groupby(['STATE','EPIDEMIC']).first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.8897577722677856,\n",
       " 'auc': 0.8809650552848158,\n",
       " 'confusion_matrix': Columns:\n",
       " \ttarget_label\tint\n",
       " \tpredicted_label\tint\n",
       " \tcount\tint\n",
       " \n",
       " Rows: 4\n",
       " \n",
       " Data:\n",
       " +--------------+-----------------+-------+\n",
       " | target_label | predicted_label | count |\n",
       " +--------------+-----------------+-------+\n",
       " |      0       |        1        |  281  |\n",
       " |      1       |        0        |  875  |\n",
       " |      1       |        1        |  1163 |\n",
       " |      0       |        0        |  8167 |\n",
       " +--------------+-----------------+-------+\n",
       " [4 rows x 3 columns],\n",
       " 'f1_score': 0.6680068925904652,\n",
       " 'log_loss': 0.5461287424860415,\n",
       " 'precision': 0.8054016620498615,\n",
       " 'recall': 0.570657507360157,\n",
       " 'roc_curve': Columns:\n",
       " \tthreshold\tfloat\n",
       " \tfpr\tfloat\n",
       " \ttpr\tfloat\n",
       " \tp\tint\n",
       " \tn\tint\n",
       " \n",
       " Rows: 100001\n",
       " \n",
       " Data:\n",
       " +-----------+-----+-----+------+------+\n",
       " | threshold | fpr | tpr |  p   |  n   |\n",
       " +-----------+-----+-----+------+------+\n",
       " |    0.0    | 1.0 | 1.0 | 2038 | 8448 |\n",
       " |   1e-05   | 1.0 | 1.0 | 2038 | 8448 |\n",
       " |   2e-05   | 1.0 | 1.0 | 2038 | 8448 |\n",
       " |   3e-05   | 1.0 | 1.0 | 2038 | 8448 |\n",
       " |   4e-05   | 1.0 | 1.0 | 2038 | 8448 |\n",
       " |   5e-05   | 1.0 | 1.0 | 2038 | 8448 |\n",
       " |   6e-05   | 1.0 | 1.0 | 2038 | 8448 |\n",
       " |   7e-05   | 1.0 | 1.0 | 2038 | 8448 |\n",
       " |   8e-05   | 1.0 | 1.0 | 2038 | 8448 |\n",
       " |   9e-05   | 1.0 | 1.0 | 2038 | 8448 |\n",
       " +-----------+-----+-----+------+------+\n",
       " [100001 rows x 5 columns]\n",
       " Note: Only the head of the SFrame is printed.\n",
       " You can use print_rows(num_rows=m, num_columns=n) to print more rows and columns.}"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_error = best_model.evaluate(X_val_gl)\n",
    "test_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method BoostedTreesClassifier.get_current_options of Class                          : BoostedTreesClassifier\n",
       "\n",
       "Schema\n",
       "------\n",
       "Number of examples             : 95180\n",
       "Number of feature columns      : 176\n",
       "Number of unpacked features    : 176\n",
       "Number of classes              : 2\n",
       "\n",
       "Settings\n",
       "--------\n",
       "Number of trees                : 30\n",
       "Max tree depth                 : 12\n",
       "Training time (sec)            : 27.3684\n",
       "Training auc                   : 0.908\n",
       "Validation auc                 : 0.881\n",
       ">"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.get_current_options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sklearn \n",
    "\n",
    "validation, bias variance, learning curves  and decision tree models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/juan/mfixman/venv/local/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/home/juan/mfixman/venv/local/lib/python2.7/site-packages/sklearn/grid_search.py:43: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import *\n",
    "from sklearn.ensemble import *\n",
    "\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import validation_curve\n",
    "\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "from sklearn.utils import *\n",
    "\n",
    "from sklearn.preprocessing import label_binarize, scale, StandardScaler, MinMaxScaler\n",
    "\n",
    "from sklearn.metrics import *\n",
    "\n",
    "from sklearn.tree import *\n",
    "\n",
    "from sklearn.grid_search import *\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# dimensionality reduction  with SVD might improve the fit\n",
    "from sklearn.decomposition import TruncatedSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## bias variance trade-off in the number of attributes\n",
    "we first used a random forest to get the best attributes in the model and now will try to overfit the validation set using too many features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'MOBILITY_DIAMETER', u'COUNT_0', u'COUNT_WEEKNIGHT_0',\n",
       "       u'MOBILITY_DIAMETER_WEEKNIGHT', u'COUNT_1', u'COUNT_2',\n",
       "       u'COUNT_WEEKNIGHT_1', u'COUNT_3', u'TimeWeekDay_OUT_08',\n",
       "       u'TimeWeekDay_OUT_12',\n",
       "       ...\n",
       "       u'STATE_Yucatan', u'STATE_Aguascalientes', u'STATE_Colima',\n",
       "       u'STATE_Baja_California_Sur', u'STATE_Sinaloa', u'STATE_Sonora',\n",
       "       u'STATE_Tamaulipas', u'STATE_Zacatecas', u'STATE_Durango',\n",
       "       u'STATE_Coahuila_de_Zaragoza'],\n",
       "      dtype='object', length=176)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_columns = best_feat['name'].to_numpy()\n",
    "\n",
    "X[best_columns].columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## scale numerical features when necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scale_cols = None\n",
    "# scale_cols = True\n",
    "if scale_cols:\n",
    "\n",
    "    # by definition any column which is outside of [-1,1]\n",
    "    scaling_cols = (X.max()) >1 | (X.min()<-1)\n",
    "\n",
    "    scaling_cols = scaling_cols[scaling_cols==True].index\n",
    "\n",
    "    scale = MinMaxScaler(copy=True)\n",
    "    \n",
    "    X[scaling_cols] = scale.fit_transform(X[scaling_cols])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## make validation curve\n",
    "with DecisionTreeClassifier to overfit and compare without cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can't have more binary splits in a tree than the data we train with\n",
    "max_tree_depth = int(np.log2(X.shape[0]))\n",
    "max_tree_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define our tree_depth range to compare in cross validation\n",
    "\n",
    "param_range = np.arange(2,17,)\n",
    "param_range\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/juan/mfixman/venv/local/lib/python2.7/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/juan/mfixman/venv/local/lib/python2.7/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 48.8 s, sys: 564 ms, total: 49.3 s\n",
      "Wall time: 1min 43s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_scores, test_scores = validation_curve(\n",
    "    DecisionTreeClassifier(\n",
    "                       # max_depth = 100,\n",
    "                      criterion='gini'\n",
    "    ),\n",
    "    X, Y, \n",
    "    param_name=\"max_depth\", \n",
    "        param_range=param_range,\n",
    "\n",
    "        cv=10, \n",
    "    scoring='f1_weighted', \n",
    "    n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### check results by standarizing scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reverse_scores_train = 1 - train_scores\n",
    "reverse_scores_test = 1 - test_scores\n",
    "\n",
    "train_scores_mean = np.mean(reverse_scores_train, axis=1)\n",
    "train_scores_std = np.std(reverse_scores_train, axis=1)\n",
    "test_scores_mean = np.mean(reverse_scores_test, axis=1)\n",
    "test_scores_std = np.std(reverse_scores_test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f7640032d10>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfYAAAGNCAYAAADjDlO+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkP8H++AyJY85aEgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7544fd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 6)) \n",
    "plt.title(\"Validation Curve with Decision Tree Classifier\")\n",
    "plt.xlabel(\"$Max Depth$ value\".format())\n",
    "plt.ylabel(\"1 - Score\")\n",
    "plt.ylim(0.0, 0.5)\n",
    "\n",
    "lw = 1\n",
    "\n",
    "plt.plot(param_range, train_scores_mean, label=\"Training score with std-dev band\",\n",
    "             color=\"navy\", lw=lw)\n",
    "\n",
    "plt.fill_between(param_range, train_scores_mean - train_scores_std,\n",
    "                 train_scores_mean + train_scores_std, alpha=0.2,\n",
    "                 color=\"blue\", lw=lw)\n",
    "\n",
    "plt.plot(param_range, test_scores_mean, label=\"Cross-validation score avg\",\n",
    "             color=\"darkorange\", lw=lw)\n",
    "\n",
    "plt.fill_between(param_range, test_scores_mean - test_scores_std,\n",
    "                 test_scores_mean + test_scores_std, alpha=0.2,\n",
    "                 color=\"red\", lw=lw)\n",
    "\n",
    "plt.legend(loc=\"best\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show the importance of cross validation and regularization using the logistic regression. \n",
    "\n",
    "try with different \n",
    "\n",
    "* cv values: (1, 3, 10 and 20)\n",
    "\n",
    "* C regularization values (L2): (1/10, 1, 10000,20000 ,etc. - high values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1.001,   2.112,   3.223,   4.334,   5.445,   6.556,   7.667,\n",
       "         8.778,   9.889,  11.   ])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  1.00000000e-05,   1.12266777e-05,   1.26038293e-05,\n",
       "          1.41499130e-05,   1.58856513e-05,   1.78343088e-05,\n",
       "          2.00220037e-05,   2.24780583e-05,   2.52353917e-05,\n",
       "          2.83309610e-05,   3.18062569e-05,   3.57078596e-05,\n",
       "          4.00880633e-05,   4.50055768e-05,   5.05263107e-05,\n",
       "          5.67242607e-05,   6.36824994e-05,   7.14942899e-05,\n",
       "          8.02643352e-05,   9.01101825e-05]),\n",
       " array([  11097.52496412,   12458.83364295,   13987.13102647,\n",
       "          15702.90124729,   17629.14118096,   19791.66867854,\n",
       "          22219.4686094 ,   24945.0813523 ,   28005.03894184,\n",
       "          31440.35471592,   35297.07302731,   39626.88638701,\n",
       "          44487.82831128,   49945.05115855,   56071.69938205,\n",
       "          62949.88990222,   70671.81273928,   79340.96665797,\n",
       "          89073.5463861 ,  100000.        ]))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # define our c range to compare\n",
    "# inv_c_range = np.logspace(-4, 100, 15)\n",
    "\n",
    "# # param_range = 1./inv_c_range\n",
    "# param_range = np.linspace(-3,0.5,30)\n",
    "# # param_range = np.ceil(param_range)\n",
    "# param_range = np.exp((param_range)*np.log(10))\n",
    "\n",
    "# low_values = np.linspace(0.001,1,10) \n",
    "# high_values = np.linspace(10000,20000,10)\n",
    "# param_range = np.concatenate([low_values,high_values])\n",
    "\n",
    "param_range = np.logspace(-5, 5, 200)\n",
    "\n",
    "\n",
    "param_range[:20],param_range[-20:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## with no cv, high and low regularization comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# make this algorithm nilpotent (copy the data from the original case's X)\n",
    "# in case we want to run this again without re-building the whole X\n",
    "X_lreg = X.copy()\n",
    "X_val_lreg = X_val.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### check if we want SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 55s, sys: 5min 16s, total: 8min 11s\n",
      "Wall time: 1min 35s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "svd_features = True\n",
    "num_features_limit = 30\n",
    "\n",
    "#note that some svd algorithms are non-deterministic and thus results will vary if random state is not specified\n",
    "svd = TruncatedSVD(\n",
    "    n_components=num_features_limit, \n",
    "    n_iter=100, \n",
    "    random_state=42 ,\n",
    "    \n",
    "                )\n",
    "if svd_features: # only for train and test\n",
    "    svd.fit(X_lreg) \n",
    "    X_lreg = pd.DataFrame(svd.transform(X_lreg), index = X_lreg.index.values)\n",
    "    X_val_lreg = pd.DataFrame(svd.transform(X_val_lreg), index = X_val_lreg.index.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((137692, 30), (137692, 185))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_lreg.shape, X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define loss function\n",
    "\n",
    "# scoring = 'f1'\n",
    "scoring = 'roc_auc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5min 28s, sys: 9min 2s, total: 14min 31s\n",
      "Wall time: 4h 46min 55s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "num_jobs = -1\n",
    "\n",
    "logreg  =  LogisticRegression(solver = 'lbfgs', \n",
    "                       max_iter = 200,\n",
    "                      warm_start=False,\n",
    "                              verbose = 0,\n",
    "                              n_jobs =-1,\n",
    "                        )\n",
    "# init fit over a range of parameters and load these into the\n",
    "# test and train scoring lists\n",
    "scores = []\n",
    "scores_val = []\n",
    "\n",
    "## get testing score fun with our defined str score\n",
    "scoring_fun = SCORERS[scoring]\n",
    "\n",
    "for param in param_range:\n",
    "\n",
    "    logreg.set_params(C=param)\n",
    "    logreg.fit(X_lreg, Y)\n",
    "    \n",
    "    # get train and \"test\" errors without CV\n",
    "    error = scoring_fun(logreg,X_lreg,Y)\n",
    "\n",
    "    scores.append(error)\n",
    "    error_val = scoring_fun(logreg,\n",
    "                            X_val_lreg,\n",
    "                            Y_val)\n",
    "    scores_val.append(error_val)\n",
    "\n",
    "# cast to numpy arrays type\n",
    "scores = np.asarray(scores)\n",
    "scores_val = np.asarray(scores_val)\n",
    "\n",
    "elapsed_time =   time.time() - start_time \n",
    "#este flag es basicamente para chequear que hayamos terminado nomas\n",
    "finished = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finished"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Param exploration Search took 17215.576601 seconds to run\n",
      "\n",
      " Best estimator had (0.5101094833795522, 0.5103664577447542) error and error_val score \n",
      "\n",
      "\n",
      " Best param was (3.5707859649004625e-05, 3.5707859649004625e-05) \n",
      "\n",
      "Our problem type id is 0 which means \"People that used to live in the endemic area\"\n"
     ]
    }
   ],
   "source": [
    "print('Param exploration Search took %s seconds to run' % (elapsed_time))\n",
    "\n",
    "max_score_index = np.nonzero(errors == errors.max())[0][0]\n",
    "\n",
    "max_val_score_index = np.nonzero(errors_val == errors_val.max())[0][0]\n",
    "\n",
    "print('\\n Best estimator had ({:.3f},{:.3f}) error and error_val score\\\n",
    "with scoring metric {} \\n'.format(\n",
    "                                 errors[max_score_index] ,\n",
    "                                 errors_val[max_val_score_index],\n",
    "                                scoring,\n",
    "                               )\n",
    "    )\n",
    "\n",
    "print('\\n Best param found with this metric was {} \\n'.format( str( (param_range[max_score_index],\n",
    "                                           param_range[max_val_score_index])\n",
    "                                           )\n",
    "                                      )\n",
    "     )\n",
    "\n",
    "print('Our problem type id is {} which means \\\"{}\\\"'.format(case,case_text.capitalize()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('\\n Best estimator was %s \\n' % str(clf.best_estimator_))\n",
    "\n",
    "print('\\n Best estimator was {:.3f} in \"{}\" metric \\n'.format( clf.best_score_,\n",
    "                                                    scoring\n",
    "                                                   )\n",
    "     )\n",
    "\n",
    "\n",
    "## get testing score fun with our defined str score\n",
    "scoring_fun = SCORERS[scoring]\n",
    "test_score = scoring_fun(clf,X_val_lreg,Y_val)\n",
    "\n",
    "print('\\nBest estimator\\'s performance with \\\n",
    "\"{}\" metric on the test set is: {:.3f}\\n'.format( scoring,\n",
    "                                                 test_score,  \n",
    "                                            )\n",
    "     )\n",
    "\n",
    "\n",
    "\n",
    "print('Param exploration Search took %s seconds to run' % (elapsed_time))\n",
    "\n",
    "print('Our problem type id is {} which means \\\"{}\\\"'.format(case,case_text.capitalize()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.7821046113967896"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get elapsed time in hours\n",
    "elapsed_time/3600, finished"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# reverse_scores_train = 1 - train_scores\n",
    "# reverse_scores_test = 1 - test_scores\n",
    "\n",
    "train_scores_mean = errors\n",
    "train_scores_std = np.std(errors)\n",
    "test_scores_mean = errors_val\n",
    "test_scores_std = np.std(errors_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((200,), (200,), (200,), ())"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(errors), param_range.shape, train_scores_mean.shape, test_scores_mean.shape, train_scores_std.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "size = param_range.shape[0]\n",
    "#i = 0.002\n",
    "#np.linspace(1+i,1,size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x117283d0>"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgYAAAGRCAYAAAAetHvGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x90ec8d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax, fig = plt.subplots(figsize=(8,6))\n",
    "plt.title(\"Validation Curve with Logistic Regression Classifier\")\n",
    "plt.xlabel(\"Regularization $C$ Param\")\n",
    "plt.ylabel(\"AUC Score\")\n",
    "# plt.ylim(0.0, 10.1)\n",
    "\n",
    "lw = 1\n",
    "\n",
    "plt.semilogx(param_range, train_scores_mean,#\n",
    "                          label=\"Training score\",\n",
    "             color=\"navy\", lw=lw)\n",
    "\n",
    "# plt.fill_between(param_range, train_scores_mean - train_scores_std,\n",
    "#                  train_scores_mean + train_scores_std, alpha=0.2,\n",
    "#                  color=\"blue\", lw=lw)\n",
    "\n",
    "plt.semilogx(param_range, test_scores_mean,#\n",
    "             label=\"score for test set\",\n",
    "             color=\"darkorange\", lw=lw)\n",
    "\n",
    "# plt.fill_between(param_range, test_scores_mean - test_scores_std,\n",
    "#                  test_scores_mean + test_scores_std, alpha=0.2,\n",
    "#                  color=\"red\", lw=lw)\n",
    "\n",
    "plt.legend(loc=\"best\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.007843137254901968"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a =0.51\n",
    "b= 0.506\n",
    "(a-b)/a\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## now add cross validation to the problem\n",
    "\n",
    "show different instances of l1 and l2 regularization (low C) vs. non-regularizing (high C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "        'penalty': [\n",
    "                    'l1',\n",
    "                    'l2',\n",
    "        ], # type of regularization function norm\n",
    "            'C': param_range, # the regularization param, the smaller the more regulareized\n",
    "            'max_iter': [\n",
    "#                         40,\n",
    "                        150,\n",
    "#                         200,\n",
    "                        ], # number of descent iterations\n",
    "    \n",
    "            \"fit_intercept\": [ \n",
    "#                         False, \n",
    "                        True,\n",
    "                            ],# fit the constante intercept\n",
    "            \n",
    "               \"class_weight\": [\n",
    "                               None,\n",
    "#                             'balanced',\n",
    "                           ],# if class ratios are as weighted averge when computing the overall loss fn\n",
    "              }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cardinality  = 1\n",
    "for key in param_grid.keys():\n",
    "    cardinality = cardinality*len(param_grid[key])\n",
    "cardinality\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# lr_no_regularization = True\n",
    "# if lr_no_regularization:\n",
    "#     param_grid['C'] = [1e5]\n",
    "#     param_grid['penalty'] = ['l2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define loss function\n",
    "\n",
    "# scoring = 'f1'\n",
    "scoring = 'roc_auc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "num_jobs = -1\n",
    "\n",
    "logreg  = LogisticRegression( )\n",
    "\n",
    "clf =GridSearchCV( logreg, \n",
    "                  param_grid, \n",
    "                  scoring=scoring, \n",
    "                  fit_params=None,\n",
    "                  n_jobs=num_jobs, \n",
    "                  iid=True, \n",
    "                  refit=True, \n",
    "                verbose=0, \n",
    "                pre_dispatch='2*n_jobs', \n",
    "                  error_score='ignore')\n",
    "\n",
    "clf2 = LogisticRegression()\n",
    "\n",
    "\n",
    "# # when cardinality of grid search is too big, we randomly search for\n",
    "# n_iter_search = 100\n",
    "\n",
    "# if n_iter_search < cardinality:\n",
    "#     clf = RandomizedSearchCV(logreg, param_distributions=param_grid,\n",
    "#                                  n_iter=n_iter_search, n_jobs = num_jobs, verbose=3,\n",
    "#                                        iid=True, refit=True, )\n",
    "\n",
    "# X = X\n",
    "# Y = Y.values\n",
    "\n",
    "logreg  = LogisticRegression( )\n",
    "clf.fit(X_lreg, Y)\n",
    "\n",
    "elapsed_time =   time.time() - start_time \n",
    "print('HyperParam Search took %s seconds to run' % (elapsed_time))\n",
    "\n",
    "\n",
    "cv_result = pd.DataFrame(columns=['mean_score' ] + [key for key, \n",
    "                            value in clf.grid_scores_[0].parameters.items() ] )\n",
    "i=0\n",
    "for setup in clf.grid_scores_:\n",
    "    row = [clf.grid_scores_[i].mean_validation_score ] + [value for key,\n",
    "                                        value in clf.grid_scores_[i].parameters.items() ]\n",
    "    cv_result.loc[i] = row\n",
    "    i+=1\n",
    "\n",
    "elapsed_time =   time.time() - start_time\n",
    "\n",
    "#este flag es basicamente para chequear que hayamos terminado nomas\n",
    "finished = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finished"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Best estimator was LogisticRegression(C=1.0000000000000001e-05, class_weight=None, dual=False,\n",
      "          fit_intercept=True, intercept_scaling=1, max_iter=150,\n",
      "          multi_class='ovr', n_jobs=1, penalty='l1', random_state=None,\n",
      "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False) \n",
      "\n",
      "\n",
      " Best estimator was 0.809 in \"roc_auc\" metric \n",
      "\n",
      "\n",
      "Best estimator's performance with \"roc_auc\" metric on the test set is: 0.835\n",
      "\n",
      "Param exploration Search took 1876.78548408 seconds to run\n",
      "Our problem type id is 0 which means \"People that used to live in the endemic area\"\n"
     ]
    }
   ],
   "source": [
    "print('\\n Best estimator was %s \\n' % str(clf.best_estimator_))\n",
    "\n",
    "print('\\n Best estimator was {:.3f} in \"{}\" metric \\n'.format( clf.best_score_,\n",
    "                                                    scoring\n",
    "                                                   )\n",
    "     )\n",
    "\n",
    "\n",
    "## get testing score with the score used inour function\n",
    "scoring_fun = SCORERS[scoring]\n",
    "test_score = scoring_fun(clf,X_val_lreg,Y_val)\n",
    "\n",
    "print('\\nBest estimator\\'s performance with \\\n",
    "\"{}\" metric on the test set is: {:.3f}\\n'.format( scoring,\n",
    "                                                 test_score,  \n",
    "                                            )\n",
    "     )\n",
    "\n",
    "\n",
    "\n",
    "print('Param exploration Search took %s seconds to run' % (elapsed_time))\n",
    "\n",
    "print('Our problem type id is {} which means \\\"{}\\\"'.format(case,case_text.capitalize()))\n",
    "\n",
    "#ojo que esta parte cuando poly ==True no funciona.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get elapsed time in hours\n",
    "elapsed_time/3600, finished"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "group_cols = [\n",
    "        'penalty',\n",
    "              'C',\n",
    "]\n",
    "\n",
    "an_col = 'mean_score'\n",
    "param_col = 'C'\n",
    "#.groupby(group_cols)['mean_score'].first()\n",
    "filter_col = 'penalty'\n",
    "filter_val = 'l1'\n",
    "view = (cv_result\n",
    "        .query('{}==@filter_val'.format(filter_col))\n",
    "        [[ param_col,filter_col,an_col]]\n",
    "        #.sort_values('mean_score',ascending=False)\n",
    "       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    200.000000\n",
       "mean       0.802970\n",
       "std        0.001776\n",
       "min        0.802210\n",
       "25%        0.802213\n",
       "50%        0.802226\n",
       "75%        0.802275\n",
       "max        0.809081\n",
       "Name: mean_score, dtype: float64"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "view[an_col].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x10904950>"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkoAAAG3CAYAAABLx3rDAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nBYoSAACABYoSAACABYoSAACAhf8HvDYvWZKN96MAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc683a94b10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "# plot histogram on cross validated scores\n",
    "view[an_col].hist()\n",
    "\n",
    "sup_title_str = \"Histogram of CV training scores for different \\\n",
    "parameter values.\"\n",
    "\n",
    "plt.suptitle(\"\\n\".join(wrap(sup_title_str)),\n",
    "         y=1.03,# otherwise twiny and title will overlap\n",
    "         fontsize=18,\n",
    "            )\n",
    "\n",
    "title_str = \"Different $C$ params \\\n",
    "for a Logistic Regression Classifier\\'s with \\\n",
    "{} regularization\".format(\n",
    "    filter_val)\n",
    "\n",
    "plt.title(title_str, fontsize=10)\n",
    "\n",
    "plt.xlabel(\"$C$ Param value\".format(filter_val))\n",
    "plt.ylabel(\"CV {} Score\".format(scoring.capitalize()))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# view = view.sort_values(param_col)\n",
    "# x_vals = view[param_col]\n",
    "# y_vals = view[param_col]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x109a7750>"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgkAAAGjCAYAAACmDYbtAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nl1gSiIiIyCWWBCIiInKJJYGIiIhc+n+oYWPYtdXSqQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1099de90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax, fig = plt.subplots(figsize=(8,6))\n",
    "# plt.title(\"Validation Curve with Logistic Regression Classifier\")\n",
    "# plt.xlabel(\"Regularization $C$ Param\")\n",
    "# plt.ylabel(\"AUC Score\")\n",
    "# plt.ylim(0.0, 10.1)\n",
    "\n",
    "lw = 1\n",
    "\n",
    "plt.semilogx(\n",
    "    view[param_col], \n",
    "    view[an_col],#\n",
    "                          label=\"Training score\",\n",
    "             color=\"navy\", lw=lw)\n",
    "\n",
    "\n",
    "title_str = \"Cross-validated Training Score \\\n",
    "for a Logistic Regression Classifier\\'s $C$ \\\n",
    "param with {} regularization\".format(\n",
    "    filter_val)\n",
    "\n",
    "plt.title(\"\\n\".join(wrap(title_str)),\n",
    "         y=1,# otherwise twiny and title will overlap\n",
    "         )\n",
    "\n",
    "\n",
    "plt.xlabel(\"$C$ Param\".format(filter_val))\n",
    "plt.ylabel(\"{} Score\".format(scoring.capitalize()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## other linspace plot with double axis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0xe371dd0>"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhMAAAHRCAYAAADQazsGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nVZhMEBERUav8f0NC5XoO0yykAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xe33d110>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "N=50\n",
    "\n",
    "labels = ['Smallest {} $C$ values '.format(N), 'Biggest {} $C$ values '.format(N)]\n",
    "\n",
    "c = palette[0]\n",
    "view.head(N).set_index(param_col)[an_col].plot(\n",
    "    ax=ax,\n",
    "    kind = 'line',\n",
    "    color='b',\n",
    "#     legend=True,\n",
    "    label =labels[0],\n",
    ")\n",
    "\n",
    "# set xlabel \n",
    "# ax.set_xlabel(labels[0])\n",
    "# set series legend\n",
    "# ax.legend(loc=0)\n",
    "\n",
    "# get a new axis to plot on with new color\n",
    "ax2 = ax.twiny()\n",
    "c = palette[1]\n",
    "view.tail(N).set_index(param_col)[an_col].plot(\n",
    "    ax=ax2,\n",
    "    kind = 'line',\n",
    "    color='r',\n",
    "#     legend=True,\n",
    "    label =labels[1],\n",
    "                                               \n",
    "         )\n",
    "\n",
    "ax.set_xlabel(labels[0])\n",
    "ax2.set_xlabel(labels[1])\n",
    "\n",
    "# get all plotted line objects\n",
    "lines = ax.get_lines() + ax2.get_lines()\n",
    "# set a common legend\n",
    "ax.legend(lines, [l.get_label() for l in lines], loc='upper center')\n",
    "\n",
    "# pass those lines legends\n",
    "\n",
    "# # set series legend\n",
    "# ax2.legend(loc='best')\n",
    "\n",
    "\n",
    "title_str = \"Cross-validated Training Score \\\n",
    "for a Logistic Regression Classifier\\'s $C$ \\\n",
    "param with {} regularization\".format(\n",
    "    filter_val)\n",
    "\n",
    "plt.title(\"\\n\".join(wrap(title_str)),\n",
    "         y=1.15,# otherwise twiny and title will overlap\n",
    "         )\n",
    "\n",
    "\n",
    "plt.xlabel(\"$C$ Param\".format(filter_val))\n",
    "plt.ylabel(\"{} Score\".format(scoring.capitalize()))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C</th>\n",
       "      <th>penalty</th>\n",
       "      <th>mean_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>108.436597</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.399861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>121.738273</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.401293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>136.671636</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.395969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>153.436841</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.389284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>172.258597</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.385560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>193.389175</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.407473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>217.111795</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.380661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>243.744415</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.380432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>273.644000</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.387889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>307.211300</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.398666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>344.896226</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.377651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>387.203878</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.404169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>434.701316</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.384196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>488.025158</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.383940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>547.890118</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.406795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>615.098579</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.380244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>690.551352</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.377829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>775.259749</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.405910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>870.359136</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.413266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>977.124154</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.385185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>1096.985798</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.391688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>1231.550603</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.406648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>1382.622174</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.395450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>1552.225357</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.405521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>1742.633386</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.377643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>1956.398344</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.409521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>2196.385372</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.377190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>2465.811076</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.391630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>2768.286630</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.405797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>3107.866188</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.387168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>3489.101213</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.383911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>3917.101491</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.378653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>4397.603609</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.380389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>4937.047853</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.411112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>5542.664521</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.408103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351</th>\n",
       "      <td>6222.570837</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.389446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353</th>\n",
       "      <td>6985.879747</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.378755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>7842.822061</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.381505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>8804.883582</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.377421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>9884.959047</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.385547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>11097.524964</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.400973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>12458.833643</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.410306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>13987.131026</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.394954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367</th>\n",
       "      <td>15702.901247</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.386756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>17629.141181</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.393072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>19791.668679</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.384939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>22219.468609</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.401353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>24945.081352</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.425352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377</th>\n",
       "      <td>28005.038942</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.390488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>31440.354716</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.407668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>35297.073027</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.418337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>39626.886387</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.380862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>44487.828311</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.389284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>49945.051159</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.389927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>56071.699382</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.376942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>62949.889902</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.405721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>70671.812739</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.386395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>79340.966658</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.385966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>89073.546386</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.398113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>100000.000000</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.395078</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 C penalty  mean_score\n",
       "281     108.436597      l2    0.399861\n",
       "283     121.738273      l2    0.401293\n",
       "285     136.671636      l2    0.395969\n",
       "287     153.436841      l2    0.389284\n",
       "289     172.258597      l2    0.385560\n",
       "291     193.389175      l2    0.407473\n",
       "293     217.111795      l2    0.380661\n",
       "295     243.744415      l2    0.380432\n",
       "297     273.644000      l2    0.387889\n",
       "299     307.211300      l2    0.398666\n",
       "301     344.896226      l2    0.377651\n",
       "303     387.203878      l2    0.404169\n",
       "305     434.701316      l2    0.384196\n",
       "307     488.025158      l2    0.383940\n",
       "309     547.890118      l2    0.406795\n",
       "311     615.098579      l2    0.380244\n",
       "313     690.551352      l2    0.377829\n",
       "315     775.259749      l2    0.405910\n",
       "317     870.359136      l2    0.413266\n",
       "319     977.124154      l2    0.385185\n",
       "321    1096.985798      l2    0.391688\n",
       "323    1231.550603      l2    0.406648\n",
       "325    1382.622174      l2    0.395450\n",
       "327    1552.225357      l2    0.405521\n",
       "329    1742.633386      l2    0.377643\n",
       "331    1956.398344      l2    0.409521\n",
       "333    2196.385372      l2    0.377190\n",
       "335    2465.811076      l2    0.391630\n",
       "337    2768.286630      l2    0.405797\n",
       "339    3107.866188      l2    0.387168\n",
       "341    3489.101213      l2    0.383911\n",
       "343    3917.101491      l2    0.378653\n",
       "345    4397.603609      l2    0.380389\n",
       "347    4937.047853      l2    0.411112\n",
       "349    5542.664521      l2    0.408103\n",
       "351    6222.570837      l2    0.389446\n",
       "353    6985.879747      l2    0.378755\n",
       "355    7842.822061      l2    0.381505\n",
       "357    8804.883582      l2    0.377421\n",
       "359    9884.959047      l2    0.385547\n",
       "361   11097.524964      l2    0.400973\n",
       "363   12458.833643      l2    0.410306\n",
       "365   13987.131026      l2    0.394954\n",
       "367   15702.901247      l2    0.386756\n",
       "369   17629.141181      l2    0.393072\n",
       "371   19791.668679      l2    0.384939\n",
       "373   22219.468609      l2    0.401353\n",
       "375   24945.081352      l2    0.425352\n",
       "377   28005.038942      l2    0.390488\n",
       "379   31440.354716      l2    0.407668\n",
       "381   35297.073027      l2    0.418337\n",
       "383   39626.886387      l2    0.380862\n",
       "385   44487.828311      l2    0.389284\n",
       "387   49945.051159      l2    0.389927\n",
       "389   56071.699382      l2    0.376942\n",
       "391   62949.889902      l2    0.405721\n",
       "393   70671.812739      l2    0.386395\n",
       "395   79340.966658      l2    0.385966\n",
       "397   89073.546386      l2    0.398113\n",
       "399  100000.000000      l2    0.395078"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "view.tail(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## now get erros along the cv procedure and plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# reverse_scores_train = 1 - train_scores\n",
    "# reverse_scores_test = 1 - test_scores\n",
    "\n",
    "train_scores_mean = errors\n",
    "train_scores_std = np.std(errors)\n",
    "test_scores_mean = errors_val\n",
    "test_scores_std = np.std(errors_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.std(errors), param_range.shape, train_scores_mean.shape, test_scores_mean.shape, train_scores_std.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "size = param_range.shape[0]\n",
    "#i = 0.002\n",
    "#np.linspace(1+i,1,size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ax, fig = plt.subplots(figsize=(8,6))\n",
    "plt.title(\"Validation Curve with Logistic Regression Classifier\")\n",
    "plt.xlabel(\"Regularization $C$ Param\")\n",
    "plt.ylabel(\"AUC Score\")\n",
    "# plt.ylim(0.0, 10.1)\n",
    "\n",
    "lw = 1\n",
    "\n",
    "plt.semilogx(param_range, train_scores_mean,#\n",
    "                          label=\"Training score\",\n",
    "             color=\"navy\", lw=lw)\n",
    "\n",
    "# plt.fill_between(param_range, train_scores_mean - train_scores_std,\n",
    "#                  train_scores_mean + train_scores_std, alpha=0.2,\n",
    "#                  color=\"blue\", lw=lw)\n",
    "\n",
    "plt.semilogx(param_range, test_scores_mean,#\n",
    "             label=\"score for test set\",\n",
    "             color=\"darkorange\", lw=lw)\n",
    "\n",
    "# plt.fill_between(param_range, test_scores_mean - test_scores_std,\n",
    "#                  test_scores_mean + test_scores_std, alpha=0.2,\n",
    "#                  color=\"red\", lw=lw)\n",
    "\n",
    "plt.legend(loc=\"best\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# REST of shit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count Featurizer on Antennas\n",
    "nos quedamos con las columnas de antennas y en graphlab aplicamos el algo de CountFeaturizer para cada categoria de\n",
    "Antenna_ID_N\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "import graphlab as gl\n",
    "from graphlab.toolkits.feature_engineering import *\n",
    "ant_cols = [col for col in X_train.columns if \"ANTENNA_ID\" in col]\n",
    "ant_sframe_fit = gl.SFrame(X_fit[ant_cols + ['y']])\n",
    "ant_sframe_train = gl.SFrame(X_train[ant_cols + ['y']])\n",
    "ant_sframe_val = gl.SFrame(X_val[ant_cols + ['y']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "countfeat = gl.feature_engineering.create(ant_sframe_fit, \n",
    "               CountFeaturizer(target='y'))\n",
    "\n",
    "# Transform the train set. This is the dataset I will train my classifier on\n",
    "transformed_ant_train = countfeat.transform(ant_sframe_train)\n",
    "transformed_ant_val = countfeat.transform(ant_sframe_val)\n",
    "\n",
    "del ant_sframe_fit,ant_sframe_train,ant_sframe_val\n",
    "\n",
    "#por alguna razon guarda los valores de probabilidad como una lista de un unico valor\n",
    "for col in [col for col in transformed_ant_train.column_names() if \"prob_\" in col]:\n",
    "    transformed_ant_train[col] = transformed_ant_train[col].apply(lambda x: x[0]) \n",
    "    transformed_ant_val[col] = transformed_ant_val[col].apply(lambda x: x[0]) \n",
    "\n",
    "#me quedo solo con los valores de probabilidad.\n",
    "transformed_ant_train = transformed_ant_train[[col for col in transformed_ant_train.column_names() if \"prob_\" in col]]\n",
    "transformed_ant_val = transformed_ant_val[[col for col in transformed_ant_train.column_names() if \"prob_\" in col]]\n",
    "\n",
    "transformed_ant_val = transformed_ant_val.to_dataframe()\n",
    "transformed_ant_train = transformed_ant_train.to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_val[ant_cols] = transformed_ant_val.values\n",
    "X_train[ant_cols] = transformed_ant_train.values\n",
    "del transformed_ant_train, transformed_ant_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validate SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_grid = [\n",
    "  { 'alpha': [1e-3,5*1e-3,1e-2], 'l1_ratio': [3*1e-2,1e-3,6*1e-4], 'n_iter': [2,3]\n",
    "  }\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 18 candidates, totalling 54 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Virtualenvs/mateo/lib/python3.4/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] n_iter=2, alpha=0.001, l1_ratio=0.03 ............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Virtualenvs/mateo/lib/python3.4/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] n_iter=2, alpha=0.001, l1_ratio=0.03 ............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Virtualenvs/mateo/lib/python3.4/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ... n_iter=2, alpha=0.001, l1_ratio=0.03, score=0.125354 -   2.5s\n",
      "[CV] n_iter=2, alpha=0.001, l1_ratio=0.03 ............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Virtualenvs/mateo/lib/python3.4/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ... n_iter=2, alpha=0.001, l1_ratio=0.03, score=0.127442 -   2.5s\n",
      "[CV] n_iter=3, alpha=0.001, l1_ratio=0.03 ............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Virtualenvs/mateo/lib/python3.4/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ... n_iter=2, alpha=0.001, l1_ratio=0.03, score=0.119463 -   2.5s\n",
      "[CV] n_iter=3, alpha=0.001, l1_ratio=0.03 ............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Virtualenvs/mateo/lib/python3.4/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ... n_iter=3, alpha=0.001, l1_ratio=0.03, score=0.132910 -   3.1s\n",
      "[CV] n_iter=3, alpha=0.001, l1_ratio=0.03 ............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Virtualenvs/mateo/lib/python3.4/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ... n_iter=3, alpha=0.001, l1_ratio=0.03, score=0.133858 -   3.1s\n",
      "[CV] n_iter=2, alpha=0.001, l1_ratio=0.001 ...........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Virtualenvs/mateo/lib/python3.4/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ... n_iter=3, alpha=0.001, l1_ratio=0.03, score=0.125862 -   3.1s\n",
      "[CV] n_iter=2, alpha=0.001, l1_ratio=0.001 ...........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Virtualenvs/mateo/lib/python3.4/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .. n_iter=2, alpha=0.001, l1_ratio=0.001, score=0.114065 -   2.5s\n",
      "[CV] n_iter=2, alpha=0.001, l1_ratio=0.001 ...........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Virtualenvs/mateo/lib/python3.4/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .. n_iter=2, alpha=0.001, l1_ratio=0.001, score=0.125576 -   2.5s\n",
      "[CV] n_iter=3, alpha=0.001, l1_ratio=0.001 ...........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Virtualenvs/mateo/lib/python3.4/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .. n_iter=2, alpha=0.001, l1_ratio=0.001, score=0.125882 -   2.8s\n",
      "[CV] n_iter=3, alpha=0.001, l1_ratio=0.001 ...........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Virtualenvs/mateo/lib/python3.4/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .. n_iter=3, alpha=0.001, l1_ratio=0.001, score=0.138072 -   3.3s\n",
      "[CV] n_iter=3, alpha=0.001, l1_ratio=0.001 ...........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Virtualenvs/mateo/lib/python3.4/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .. n_iter=3, alpha=0.001, l1_ratio=0.001, score=0.133482 -   3.1s\n",
      "[CV] n_iter=2, alpha=0.001, l1_ratio=0.0006000000000000001 ...........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Virtualenvs/mateo/lib/python3.4/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .. n_iter=3, alpha=0.001, l1_ratio=0.001, score=0.133945 -   3.2s\n",
      "[CV] n_iter=2, alpha=0.001, l1_ratio=0.0006000000000000001 ...........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Virtualenvs/mateo/lib/python3.4/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_iter=2, alpha=0.001, l1_ratio=0.0006000000000000001, score=0.124318 -   2.5s\n",
      "[CV] n_iter=2, alpha=0.001, l1_ratio=0.0006000000000000001 ...........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Virtualenvs/mateo/lib/python3.4/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_iter=2, alpha=0.001, l1_ratio=0.0006000000000000001, score=0.125224 -   2.5s\n",
      "[CV] n_iter=3, alpha=0.001, l1_ratio=0.0006000000000000001 ...........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Virtualenvs/mateo/lib/python3.4/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_iter=2, alpha=0.001, l1_ratio=0.0006000000000000001, score=0.129423 -   2.5s\n",
      "[CV] n_iter=3, alpha=0.001, l1_ratio=0.0006000000000000001 ...........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Virtualenvs/mateo/lib/python3.4/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_iter=3, alpha=0.001, l1_ratio=0.0006000000000000001, score=0.131845 -   3.1s\n",
      "[CV] n_iter=3, alpha=0.001, l1_ratio=0.0006000000000000001 ...........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Virtualenvs/mateo/lib/python3.4/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_iter=3, alpha=0.001, l1_ratio=0.0006000000000000001, score=0.135827 -   3.1s\n",
      "[CV] n_iter=2, alpha=0.005, l1_ratio=0.03 ............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Virtualenvs/mateo/lib/python3.4/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_iter=3, alpha=0.001, l1_ratio=0.0006000000000000001, score=0.128485 -   3.1s\n",
      "[CV] n_iter=2, alpha=0.005, l1_ratio=0.03 ............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Virtualenvs/mateo/lib/python3.4/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ... n_iter=2, alpha=0.005, l1_ratio=0.03, score=0.125477 -   2.4s\n",
      "[CV] n_iter=2, alpha=0.005, l1_ratio=0.03 ............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Virtualenvs/mateo/lib/python3.4/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ... n_iter=2, alpha=0.005, l1_ratio=0.03, score=0.125957 -   2.8s\n",
      "[CV] n_iter=3, alpha=0.005, l1_ratio=0.03 ............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Virtualenvs/mateo/lib/python3.4/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ... n_iter=2, alpha=0.005, l1_ratio=0.03, score=0.127511 -   2.6s\n",
      "[CV] n_iter=3, alpha=0.005, l1_ratio=0.03 ............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Virtualenvs/mateo/lib/python3.4/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ... n_iter=3, alpha=0.005, l1_ratio=0.03, score=0.127618 -   2.8s\n",
      "[CV] n_iter=3, alpha=0.005, l1_ratio=0.03 ............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Virtualenvs/mateo/lib/python3.4/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ... n_iter=3, alpha=0.005, l1_ratio=0.03, score=0.125386 -   2.8s\n",
      "[CV] n_iter=2, alpha=0.005, l1_ratio=0.001 ...........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Virtualenvs/mateo/lib/python3.4/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ... n_iter=3, alpha=0.005, l1_ratio=0.03, score=0.136983 -   3.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  24 tasks      | elapsed:   47.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] n_iter=2, alpha=0.005, l1_ratio=0.001 ...........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Virtualenvs/mateo/lib/python3.4/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .. n_iter=2, alpha=0.005, l1_ratio=0.001, score=0.120290 -   2.5s\n",
      "[CV] n_iter=2, alpha=0.005, l1_ratio=0.001 ...........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Virtualenvs/mateo/lib/python3.4/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .. n_iter=2, alpha=0.005, l1_ratio=0.001, score=0.118753 -   2.5s\n",
      "[CV] n_iter=3, alpha=0.005, l1_ratio=0.001 ...........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Virtualenvs/mateo/lib/python3.4/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .. n_iter=2, alpha=0.005, l1_ratio=0.001, score=0.127159 -   2.9s\n",
      "[CV] n_iter=3, alpha=0.005, l1_ratio=0.001 ...........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Virtualenvs/mateo/lib/python3.4/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .. n_iter=3, alpha=0.005, l1_ratio=0.001, score=0.127485 -   3.3s\n",
      "[CV] n_iter=3, alpha=0.005, l1_ratio=0.001 ...........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Virtualenvs/mateo/lib/python3.4/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .. n_iter=3, alpha=0.005, l1_ratio=0.001, score=0.139728 -   3.1s\n",
      "[CV] n_iter=2, alpha=0.005, l1_ratio=0.0006000000000000001 ...........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Virtualenvs/mateo/lib/python3.4/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .. n_iter=3, alpha=0.005, l1_ratio=0.001, score=0.130469 -   3.1s\n",
      "[CV] n_iter=2, alpha=0.005, l1_ratio=0.0006000000000000001 ...........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Virtualenvs/mateo/lib/python3.4/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_iter=2, alpha=0.005, l1_ratio=0.0006000000000000001, score=0.129161 -   2.5s\n",
      "[CV] n_iter=2, alpha=0.005, l1_ratio=0.0006000000000000001 ...........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Virtualenvs/mateo/lib/python3.4/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_iter=2, alpha=0.005, l1_ratio=0.0006000000000000001, score=0.130159 -   2.5s\n",
      "[CV] n_iter=3, alpha=0.005, l1_ratio=0.0006000000000000001 ...........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Virtualenvs/mateo/lib/python3.4/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_iter=2, alpha=0.005, l1_ratio=0.0006000000000000001, score=0.127613 -   2.5s\n",
      "[CV] n_iter=3, alpha=0.005, l1_ratio=0.0006000000000000001 ...........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Virtualenvs/mateo/lib/python3.4/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_iter=3, alpha=0.005, l1_ratio=0.0006000000000000001, score=0.132956 -   3.1s\n",
      "[CV] n_iter=3, alpha=0.005, l1_ratio=0.0006000000000000001 ...........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Virtualenvs/mateo/lib/python3.4/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_iter=3, alpha=0.005, l1_ratio=0.0006000000000000001, score=0.143005 -   3.1s\n",
      "[CV] n_iter=2, alpha=0.01, l1_ratio=0.03 .............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Virtualenvs/mateo/lib/python3.4/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_iter=3, alpha=0.005, l1_ratio=0.0006000000000000001, score=0.135926 -   3.1s\n",
      "[CV] n_iter=2, alpha=0.01, l1_ratio=0.03 .............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Virtualenvs/mateo/lib/python3.4/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .... n_iter=2, alpha=0.01, l1_ratio=0.03, score=0.128098 -   2.4s\n",
      "[CV] n_iter=2, alpha=0.01, l1_ratio=0.03 .............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Virtualenvs/mateo/lib/python3.4/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .... n_iter=2, alpha=0.01, l1_ratio=0.03, score=0.127078 -   2.7s\n",
      "[CV] n_iter=3, alpha=0.01, l1_ratio=0.03 .............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Virtualenvs/mateo/lib/python3.4/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .... n_iter=2, alpha=0.01, l1_ratio=0.03, score=0.126921 -   2.5s\n",
      "[CV] n_iter=3, alpha=0.01, l1_ratio=0.03 .............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Virtualenvs/mateo/lib/python3.4/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .... n_iter=3, alpha=0.01, l1_ratio=0.03, score=0.138152 -   3.6s\n",
      "[CV] n_iter=3, alpha=0.01, l1_ratio=0.03 .............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Virtualenvs/mateo/lib/python3.4/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .... n_iter=3, alpha=0.01, l1_ratio=0.03, score=0.106208 -   3.1s\n",
      "[CV] n_iter=2, alpha=0.01, l1_ratio=0.001 ............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Virtualenvs/mateo/lib/python3.4/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .... n_iter=3, alpha=0.01, l1_ratio=0.03, score=0.143076 -   2.8s\n",
      "[CV] n_iter=2, alpha=0.01, l1_ratio=0.001 ............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Virtualenvs/mateo/lib/python3.4/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ... n_iter=2, alpha=0.01, l1_ratio=0.001, score=0.132427 -   2.5s\n",
      "[CV] n_iter=2, alpha=0.01, l1_ratio=0.001 ............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Virtualenvs/mateo/lib/python3.4/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ... n_iter=2, alpha=0.01, l1_ratio=0.001, score=0.125901 -   2.9s\n",
      "[CV] n_iter=3, alpha=0.01, l1_ratio=0.001 ............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Virtualenvs/mateo/lib/python3.4/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ... n_iter=2, alpha=0.01, l1_ratio=0.001, score=0.128001 -   2.7s\n",
      "[CV] n_iter=3, alpha=0.01, l1_ratio=0.001 ............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Virtualenvs/mateo/lib/python3.4/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ... n_iter=3, alpha=0.01, l1_ratio=0.001, score=0.135568 -   3.1s\n",
      "[CV] n_iter=3, alpha=0.01, l1_ratio=0.001 ............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Virtualenvs/mateo/lib/python3.4/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] n_iter=2, alpha=0.01, l1_ratio=0.0006000000000000001 ............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Virtualenvs/mateo/lib/python3.4/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ... n_iter=3, alpha=0.01, l1_ratio=0.001, score=0.132579 -   4.4s\n",
      "[CV] ... n_iter=3, alpha=0.01, l1_ratio=0.001, score=0.136589 -   3.7s\n",
      "[CV] n_iter=2, alpha=0.01, l1_ratio=0.0006000000000000001 ............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Virtualenvs/mateo/lib/python3.4/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_iter=2, alpha=0.01, l1_ratio=0.0006000000000000001, score=0.124134 -   2.8s\n",
      "[CV] n_iter=2, alpha=0.01, l1_ratio=0.0006000000000000001 ............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Virtualenvs/mateo/lib/python3.4/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_iter=2, alpha=0.01, l1_ratio=0.0006000000000000001, score=0.130883 -   2.5s\n",
      "[CV] n_iter=3, alpha=0.01, l1_ratio=0.0006000000000000001 ............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Virtualenvs/mateo/lib/python3.4/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_iter=2, alpha=0.01, l1_ratio=0.0006000000000000001, score=0.122741 -   3.5s\n",
      "[CV] n_iter=3, alpha=0.01, l1_ratio=0.0006000000000000001 ............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Virtualenvs/mateo/lib/python3.4/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_iter=3, alpha=0.01, l1_ratio=0.0006000000000000001, score=0.132433 -   3.7s\n",
      "[CV] n_iter=3, alpha=0.01, l1_ratio=0.0006000000000000001 ............\n",
      "[CV]  n_iter=3, alpha=0.01, l1_ratio=0.0006000000000000001, score=0.135111 -   3.4s\n",
      "[CV]  n_iter=3, alpha=0.01, l1_ratio=0.0006000000000000001, score=0.135908 -   3.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  54 out of  54 | elapsed:  1.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.31      0.47    355992\n",
      "          1       0.06      0.99      0.11     15152\n",
      "\n",
      "avg / total       0.96      0.33      0.45    371144\n",
      "\n",
      "This cell took 108.56432461738586 seconds to run\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "param_grid = [\n",
    "  { 'alpha': [1e-3,5*1e-3,1e-2], 'l1_ratio': [3*1e-2,1e-3,6*1e-4], 'n_iter': [2,3]\n",
    "  }\n",
    "    ]\n",
    "sgd = SGDClassifier(loss='modified_huber', penalty='elasticnet', \n",
    "             fit_intercept=True,  shuffle=True, \n",
    "                    n_jobs=3,learning_rate='optimal', power_t =2, eta0 =5,\n",
    "                    class_weight='balanced', average=40)\n",
    "\n",
    "clf =GridSearchCV(sgd, param_grid, scoring='roc_auc', fit_params=None, n_jobs=4, iid=True, refit=True, \n",
    "verbose=3, pre_dispatch='2*n_jobs', error_score='raise')\n",
    "\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "\n",
    "\n",
    "predicted_proba = pd.DataFrame()\n",
    "predicted_proba['prob'] = clf.predict_proba(X_test).max(axis=1)\n",
    "predicted_proba['class'] = clf.predict(X_test)\n",
    "predicted_proba[gt] =  y_test\n",
    "predicted_proba.sort_values(by = 'prob',ascending = False, inplace = True)\n",
    "\n",
    "cut_percentages = [10,20,30,40]\n",
    "#converted = (predicted_proba['class']==1)\n",
    "#me fijo todos los users que van a convertir en el futuro\n",
    "\n",
    "\n",
    "start = 0\n",
    "mobility_dict = {}\n",
    "index_segments = []\n",
    "for i in cut_percentages:\n",
    "    cut_size = int(len(predicted_proba)*i/100.0)    \n",
    "    bool_array = (~np.ones(len(predicted_proba), dtype=bool))\n",
    "    bool_array[start: start + cut_size] = True\n",
    "    index_segments += [bool_array]\n",
    "    start = start + cut_size\n",
    "#    subtable = \n",
    "    #mobility_dict[str(i)] = predicted_proba.loc[index_segments[-1],'ref_hash']\n",
    "    \n",
    "    print(classification_report(predicted_proba.loc[index_segments[-1],gt].values,\n",
    "                            predicted_proba.loc[index_segments[-1],'class'].values ))\n",
    "    \n",
    "    \n",
    "print(classification_report(predicted_proba.loc[:,gt].values,\n",
    "                            predicted_proba.loc[:,'class'].values ))\n",
    "    \n",
    "    \n",
    "cv_result = pd.DataFrame(columns=['mean_score' ] + [key for key, value in clf.grid_scores_[0].parameters.items() ] )\n",
    "i=0\n",
    "for setup in clf.grid_scores_:\n",
    "    row = [clf.grid_scores_[i].mean_validation_score ] + [value for key, value in clf.grid_scores_[i].parameters.items() ]\n",
    "    cv_result.loc[i] = row\n",
    "    i+=1\n",
    "#este flag es basicamente para chequear que hayamos terminado nomas\n",
    "finished = True\n",
    "\n",
    "all_time =   time.time() - start_time\n",
    "\n",
    "#este flag es basicamente para chequear que hayamos terminado nomas\n",
    "finished = True\n",
    "\n",
    "print('This cell took %s seconds to run' % all_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "threshold = 0.7\n",
    "ind = predicted_proba['prob']>threshold\n",
    "print(classification_report(predicted_proba.loc[ind,'y'].values,predicted_proba.loc[ind,'class'].values ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.005, average=40, class_weight='balanced', epsilon=0.1,\n",
       "       eta0=5, fit_intercept=True, l1_ratio=0.0006000000000000001,\n",
       "       learning_rate='optimal', loss='modified_huber', n_iter=3, n_jobs=3,\n",
       "       penalty='elasticnet', power_t=2, random_state=None, shuffle=True,\n",
       "       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_iter\n",
      "2.0    0.125741\n",
      "3.0    0.132943\n",
      "Name: mean_score, dtype: float64\n",
      "n_iter\n",
      "2.0    0.002609\n",
      "3.0    0.002703\n",
      "Name: mean_score, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "coln=1\n",
    "print(cv_result.groupby(cv_result.columns[coln])['mean_score'].mean())\n",
    "print(cv_result.groupby(cv_result.columns[coln])['mean_score'].std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Results\n",
    "* l1_ratio = cuanto mas chico mejor con lo cual la perdida l2 parece ser mejor\n",
    "* alpha = 1e-3 es suficiente pues casi no afecta el score\n",
    "* power_t = muy variado, no parece haber correlacion entre el tamanyo y el avg, mean_score\n",
    "* eta0 = no afecta mucho pero parece ser que con ser >1 ya esta\n",
    "* power_t = parecen ser practicamente iguales\n",
    "* n_iter = cuanto mas iter NO mejora el score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "371161"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predicted_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validate NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 144 candidates, totalling 432 fits\n",
      "[CV] algorithm=adam, hidden_layer_sizes=(50,), activation=logistic, power_t=0.001, alpha=0.1, learning_rate=adaptive \n",
      "[CV] algorithm=adam, hidden_layer_sizes=(50,), activation=logistic, power_t=0.001, alpha=0.1, learning_rate=adaptive \n",
      "[CV] algorithm=adam, hidden_layer_sizes=(50,), activation=logistic, power_t=0.001, alpha=0.1, learning_rate=adaptive \n",
      "[CV] algorithm=adam, hidden_layer_sizes=(50,), activation=logistic, power_t=0.0005, alpha=0.1, learning_rate=adaptive \n",
      "Iteration 1, loss = 0.20405210\n",
      "Iteration 1, loss = 0.20380843\n",
      "Iteration 1, loss = 0.20378706\n",
      "Iteration 1, loss = 0.20405210\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/teo/Repositories/scikit-learn/sklearn/metrics/classification.py:1097: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  algorithm=adam, hidden_layer_sizes=(50,), activation=logistic, power_t=0.0005, alpha=0.1, learning_rate=adaptive, score=0.000000 -   1.5s\n",
      "[CV] algorithm=adam, hidden_layer_sizes=(50,), activation=logistic, power_t=0.0005, alpha=0.1, learning_rate=adaptive \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/teo/Repositories/scikit-learn/sklearn/metrics/classification.py:1097: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  algorithm=adam, hidden_layer_sizes=(50,), activation=logistic, power_t=0.001, alpha=0.1, learning_rate=adaptive, score=0.000000 -   1.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/teo/Repositories/scikit-learn/sklearn/metrics/classification.py:1097: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  algorithm=adam, hidden_layer_sizes=(50,), activation=logistic, power_t=0.001, alpha=0.1, learning_rate=adaptive, score=0.000000 -   2.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/teo/Repositories/scikit-learn/sklearn/metrics/classification.py:1097: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  algorithm=adam, hidden_layer_sizes=(50,), activation=logistic, power_t=0.001, alpha=0.1, learning_rate=adaptive, score=0.000000 -   1.9s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-35-3491f77d2a02>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     16\u001b[0m verbose=3, pre_dispatch='2*n_jobs', error_score='raise')\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[0mpredicted_proba\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/teo/Repositories/scikit-learn/sklearn/grid_search.pyc\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    809\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    810\u001b[0m         \"\"\"\n\u001b[1;32m--> 811\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    812\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    813\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/teo/Repositories/scikit-learn/sklearn/grid_search.pyc\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, y, parameter_iterable)\u001b[0m\n\u001b[0;32m    558\u001b[0m                                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_parameters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    559\u001b[0m                                     error_score=self.error_score)\n\u001b[1;32m--> 560\u001b[1;33m                 \u001b[1;32mfor\u001b[0m \u001b[0mparameters\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mparameter_iterable\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    561\u001b[0m                 for train, test in cv)\n\u001b[0;32m    562\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/teo/Repositories/scikit-learn/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    808\u001b[0m                 \u001b[1;31m# consumption.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    809\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 810\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    811\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    812\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/teo/Repositories/scikit-learn/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    755\u001b[0m                     \u001b[1;31m# a working pool as they expect.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    756\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_initialize_pool\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 757\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    758\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    759\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "X_train,X_test,y_train ,y_test = train_test_split(X,y, test_size=0.2, random_state=42)\n",
    "\n",
    "param_grid = { 'alpha': [1e-1,5*1e-2,1e-2],\n",
    "              'hidden_layer_sizes':[(50,),(15,5)],\n",
    "              'learning_rate': ['adaptive',\"invscaling\"],\n",
    "              \"algorithm\": ['adam'],'momentum': [1e-2, 1e-1, 0.5],\n",
    "  'power_t': [1e-3, 5*1e-4, 1e-5], 'activation':['logistic','relu']\n",
    " }\n",
    "\n",
    "mlp = MLPClassifier(shuffle=True, \n",
    "                 verbose=True)\n",
    "\n",
    "clf =GridSearchCV(mlp, param_grid, scoring='roc_auc', fit_params=None, n_jobs=4, iid=True, refit=True, \n",
    "verbose=3, pre_dispatch='2*n_jobs', error_score='raise')\n",
    "\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "predicted_proba = pd.DataFrame()\n",
    "predicted_proba['prob'] = clf.predict_proba(X_test).max(axis=1)\n",
    "predicted_proba['gt'] = y_test\n",
    "predicted_proba['class'] = clf.predict(X_test)\n",
    "\n",
    "threshold = 0.7\n",
    "ind = predicted_proba['prob']>threshold\n",
    "\n",
    "all_time =   time.time() - start_time\n",
    "\n",
    "print(classification_report(predicted_proba.loc[ind,'gt'].values,predicted_proba.loc[ind,'class'].values ))\n",
    "\n",
    "cv_result = pd.DataFrame(columns=['mean_score' ] + [key for key, value in clf.grid_scores_[0].parameters.items() ] )\n",
    "i=0\n",
    "for setup in clf.grid_scores_:\n",
    "    row = [clf.grid_scores_[i].mean_validation_score ] + [value for key, value in clf.grid_scores_[i].parameters.items() ]\n",
    "    cv_result.loc[i] = row\n",
    "    i+=1\n",
    "#este flag es basicamente para chequear que hayamos terminado nomas\n",
    "finished = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'clf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-2d39bdb4c6dd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'clf' is not defined"
     ]
    }
   ],
   "source": [
    "clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "alpha\n",
       "0.00     0.000007\n",
       "0.01     0.000007\n",
       "0.10     0.000007\n",
       "0.50     0.000007\n",
       "1.00     0.000007\n",
       "10.00    0.000007\n",
       "Name: mean_score, dtype: float64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compare best parameters to tune\n",
    "coln=1\n",
    "cv_result.groupby(cv_result.columns[coln])['mean_score'].mean()\n",
    "cv_result.groupby(cv_result.columns[coln])['mean_score'].std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Results\n",
    "* activation = logistic es 10% mejor\n",
    "* alpha = 1e-2 el mejor \n",
    "* power_t = cuanto mas chico mejor, 1e-3 por lo menos\n",
    "* hidden_layer_size = menos layers es mejor..?\n",
    "* power_t = parecen ser practicamente iguales\n",
    "* n_iter = cuanto mas iter NO mejora el score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bernoulli RBM features selection & Logit crossval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-127-8675e4c7d9ab>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     39\u001b[0m verbose=0, pre_dispatch='2*n_jobs', error_score='raise')\n\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[1;31m#este metodo NO tiene predicted proba, lo que hacemos es recorrer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/teo/Repositories/scikit-learn/sklearn/grid_search.pyc\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    809\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    810\u001b[0m         \"\"\"\n\u001b[1;32m--> 811\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    812\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    813\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/teo/Repositories/scikit-learn/sklearn/grid_search.pyc\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, y, parameter_iterable)\u001b[0m\n\u001b[0;32m    558\u001b[0m                                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_parameters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    559\u001b[0m                                     error_score=self.error_score)\n\u001b[1;32m--> 560\u001b[1;33m                 \u001b[1;32mfor\u001b[0m \u001b[0mparameters\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mparameter_iterable\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    561\u001b[0m                 for train, test in cv)\n\u001b[0;32m    562\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/teo/Repositories/scikit-learn/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    808\u001b[0m                 \u001b[1;31m# consumption.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    809\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 810\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    811\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    812\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/teo/Repositories/scikit-learn/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    755\u001b[0m                     \u001b[1;31m# a working pool as they expect.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    756\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_initialize_pool\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 757\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    758\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    759\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "## obs. este metodo es especial y asume que todos los valores son True/False o que \\in [0,1]\n",
    "# luego tengo que pensar en como tomar los features nuevamente.\n",
    "# tampoco 'fittea' en la forma tradicional. Sino que se le puede tomar al y como un feature mas y esta red\n",
    "# va 'modificando' todos los valores del X (minimizando la entropia) para dar un output. Luego corriendo \n",
    "# clf.gibbs(X_test) con el y_test como feature tmb, nos transforma la data para ver el output como la 'prediccion'\n",
    "# obviamente no tiene probabilidades\n",
    "\n",
    "\n",
    "#X = X_train[X_cols].values\n",
    "#y = X_train['ground_truth'].values\n",
    "\n",
    "df = X_train.drop(X_train[X_train[X_train.columns[0:3]].\\\n",
    "                                   sum(axis=1)==0].index)\n",
    "df = df[X_cols + ['ground_truth']]\n",
    "\n",
    "for col in X_train.columns[0:3]:\n",
    "    df[col] = df[col]*1.0/df[df.columns[0:3]].sum(axis=1)\n",
    "\n",
    "df[df.columns[3]] =  df[df.columns[3]]/df[df.columns[3]].max()\n",
    "df[df.columns[4]] =  df[df.columns[4]]/df[df.columns[4]].max()\n",
    "\n",
    "X = df[df.columns[:-1]].values\n",
    "y = df['ground_truth'].values\n",
    "\n",
    "\n",
    "param_grid = {'rbm__n_components': [256, 128,46,10],\n",
    "   'rbm__n_iter':[15,10,5], 'rbm__learning_rate': [1e-4,1e-3,1e-2,1e-1,5*1e-3,5*1e-2,5*1e-1],\n",
    "  'rbm__batch_size': [10e4,3*10e3, 1e3, 300],\"logistic__C\": [1.0, 10.0, 100.0] \n",
    " }\n",
    "\n",
    "rbm = BernoulliRBM(verbose=True)\n",
    "logistic = LogisticRegression()\n",
    "classifier = Pipeline([(\"rbm\", rbm), (\"logistic\", logistic)])\n",
    "\n",
    "X_train,X_test,y_train ,y_test = train_test_split(X,y, test_size=0.2, random_state=42)\n",
    "\n",
    "clf =GridSearchCV(classifier, param_grid, scoring='roc_auc', fit_params=None, n_jobs=4, iid=True, refit=True, \n",
    "verbose=3, pre_dispatch='2*n_jobs', error_score='raise')\n",
    "\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "#este metodo NO tiene predicted proba, lo que hacemos es recorrer \n",
    "#predicted_labels = rbm.gibbs(X_test)[:,-1]\n",
    "#real_labels = X_test[:,-1]\n",
    "#print(classification_report(real_labels,predicted_labels ))\n",
    "\n",
    "\n",
    "predicted_proba = pd.DataFrame()\n",
    "predicted_proba['prob'] = clf.predict_proba(X_test).max(axis=1)\n",
    "predicted_proba['gt'] = y_test\n",
    "predicted_proba['class'] = clf.predict(X_test)\n",
    "\n",
    "threshold = 0.7\n",
    "ind = predicted_proba['prob']>threshold\n",
    "print(classification_report(predicted_proba.loc[ind,'gt'].values,predicted_proba.loc[ind,'class'].values ))\n",
    "all_time =   time.time() - start_time\n",
    "\n",
    "finished = True\n",
    "\n",
    "cv_result = pd.DataFrame(columns=['mean_score' ] + [key for key, value in clf.grid_scores_[0].parameters.items() ] )\n",
    "i=0\n",
    "for setup in clf.grid_scores_:\n",
    "    row = [clf.grid_scores_[i].mean_validation_score ] + [value for key, value in clf.grid_scores_[i].parameters.items() ]\n",
    "    cv_result.loc[i] = row\n",
    "    i+=1\n",
    "    \n",
    "print('This cell took %s seconds to run' % all_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "coln=1\n",
    "print(cv_result.groupby(cv_result.columns[coln])['mean_score'].mean())\n",
    "print(cv_result.groupby(cv_result.columns[coln])['mean_score'].std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "criterion\n",
      "gini    0.802919\n",
      "Name: mean_score, dtype: float64\n",
      "criterion\n",
      "gini    0.000598\n",
      "Name: mean_score, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "coln=3\n",
    "print(cv_result.groupby(cv_result.columns[coln])['mean_score'].mean())\n",
    "print(cv_result.groupby(cv_result.columns[coln])['mean_score'].std())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CrossV SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "param_grid = [{'kernel': ['rbf'], 'gamma': list(10.0 ** np.arange(-2, 3)),\n",
    "                     'C': list(10.0 ** np.arange(0, 4))},\n",
    "                    {'kernel': ['poly'], 'C': list(10.0 ** np.arange(0, 4)), 'degree'[2,3,4]}]\n",
    "\n",
    "svc = SVC(shuffle=True, probability=True,decision_function_shape = 'ovr',\n",
    "           verbose=True, class_weight='balanced'\n",
    "          )\n",
    "\n",
    "clf =GridSearchCV(svc, param_grid, scoring='roc_auc', fit_params=None, n_jobs=4, iid=True, refit=True, \n",
    "verbose=3, pre_dispatch='2*n_jobs', error_score='raise')\n",
    "\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "predicted_proba = pd.DataFrame()\n",
    "predicted_proba['prob'] = clf.predict_proba(X_test).max(axis=1)\n",
    "predicted_proba['gt'] = y_test\n",
    "predicted_proba['class'] = clf.predict(X_test)\n",
    "\n",
    "threshold = 0.7\n",
    "ind = predicted_proba['prob']>threshold\n",
    "\n",
    "all_time =   time.time() - start_time\n",
    "\n",
    "print(classification_report(predicted_proba.loc[ind,'gt'].values,predicted_proba.loc[ind,'class'].values ))\n",
    "\n",
    "cv_result = pd.DataFrame(columns=['mean_score' ] + [key for key, value in clf.grid_scores_[0].parameters.items() ] )\n",
    "i=0\n",
    "for setup in clf.grid_scores_:\n",
    "    row = [clf.grid_scores_[i].mean_validation_score ] + [value for key, value in clf.grid_scores_[i].parameters.items() ]\n",
    "    cv_result.loc[i] = row\n",
    "    i+=1\n",
    "#este flag es basicamente para chequear que hayamos terminado nomas\n",
    "finished = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "coln=3\n",
    "print(cv_result.groupby(cv_result.columns[coln])['mean_score'].mean())\n",
    "print(cv_result.groupby(cv_result.columns[coln])['mean_score'].std())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoosting took 117.26272392272949 seconds to run\n",
      "This cell took 117.26284193992615 seconds to run\n"
     ]
    }
   ],
   "source": [
    "#tomo tiempo para saber cuanto tarda fitear el estimador\n",
    "start_time = time.time()\n",
    "\n",
    "#model = model.fit(X,y,sample_weight=W)\n",
    "\n",
    "W = np.array([10 if i == 1 or i ==2  else 1 for i in y_mini])\n",
    "gradboost.fit(X_mini,y_mini, sample_weight=W)\n",
    "\n",
    "elapsed_time =   time.time() - start_time\n",
    "print('GradientBoosting took %s seconds to run' % elapsed_time)\n",
    "\n",
    "#validated =  cross_val_score(gradboost,X,y,cv=5, scoring = \"f1_weighted\")\n",
    "\n",
    "\n",
    "all_time =   time.time() - start_time\n",
    "print('This cell took %s seconds to run' % all_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Timings\n",
    "* 5s con  10 n_estimadores, 15 max_depth y X.sample(0.2)\n",
    "* 15s con 10 n_estimadores, 15 max_depth y X.sample(0.2)\n",
    "* 47s con 10 n_estimadores, 15 max_depth y X.sample(0.4)\n",
    "* 35s con 10 n_estimadores, 15 max_depth y X.sample(0.4)\n",
    "* 117 con 20 n_estimadores, 20 max_depth y X.sample(0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    128153\n",
       "1      7064\n",
       "Name: ground_truth, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train['ground_truth'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results\n",
    "* NO escalar (normalizar, restar la media  dividir por la std, etc) los resultados pues REVIENTAN los scores.\n",
    "* bootstrap  = False es 5% mejor\n",
    "* min_samples_leaf = mas chico es claramente mejor, pero tmb aumenta el overfitting lo cual me hace caer mucho el valor del recall en el test_set. Sin embargo es un parametro muy sensible en la precision. Resta evaluar asi el tradeoff entre la precision y el volumen de users al cual queremos llegar.\n",
    "* n_estimators = aumentar mas de 30 no tendria mucho sentido\n",
    "* citerion = entropy o gini no cambia. gini podria ser mejor entonces pues entropy usa logs de los valores lo cual es mas computacionalmente costoso\n",
    "* max_features = no afecta al score. con auto esta bien\n",
    "* max_depth =  mas es mejor. intentaria probar con >15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "#con decomposicion qr tratamos de ver si existe alguna columna que sea comb linear de las demas\n",
    "linear_test = np.linalg.qr(X_train.sample(1e6))[1]\n",
    "#notar que devuelve la tabla de tamanyo N`columnas x Ncolumnas\n",
    "\n",
    "#sumo a traves de las columnas para que me de el valor absoluto sumado de c/fila\n",
    "linear_test = abs(linear_test.sum(axis=1))<1e-2\n",
    "#si hubiese alguan que sea linearcomb entonces tendria que aparecer que toda la fila es de ceros\n",
    "for i, col in enumerate(X_train.columns):\n",
    "    if linear_test[i] == True:\n",
    "        print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Todo\n",
    "* evaluate hit_rate and \n",
    "* tune adaboost, bernoulliRBM\n",
    "* xgboost\n",
    "* libffm\n",
    "* SVC muy lento.. speed up in AWS\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

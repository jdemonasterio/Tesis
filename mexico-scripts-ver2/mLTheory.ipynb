{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ipynb to \n",
    "\n",
    "graph and try out different \n",
    "\n",
    "ML concepts with a sample datasize.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A partir de las 3 tablas ya procesdas : \n",
    "* homeantennas\n",
    "* sumlinks\n",
    "* groundtruth\n",
    "\n",
    "armames un datset para explorar conceptos de ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(180000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 180 seconds\n"
     ]
    }
   ],
   "source": [
    "## seteamos los parametros del notebook\n",
    "%autosave 180\n",
    "import pandas as pd; \n",
    "import numpy as np; \n",
    "import os;\n",
    "import random;\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np; import os;import random;\n",
    "import graphlab as gl\n",
    "from IPython.display import display # para pretty-print con estetica ipython si es que estamos dentro de  un loop, if, etc\n",
    "#esto es para dibujar directo a la notebook\n",
    "gl.canvas.set_target('ipynb')\n",
    "\n",
    "# for nice graphics and plots\n",
    "import seaborn as sns\n",
    "palette = sns.color_palette()\n",
    "\n",
    "# for nice long graphic titles\n",
    "from textwrap import wrap\n",
    "\n",
    "#seteamos el lugar de trabajo\n",
    "HOMEDIR=os.path.expanduser('~')\n",
    "\n",
    "PROJECTDIR = os.getcwd().split(os.sep)\n",
    "PROJECTDIR =  os.sep.join(PROJECTDIR[:PROJECTDIR.index('mexico-scripts-ver2') + 1])\n",
    "\n",
    "DATADIR = os.path.join(PROJECTDIR,'datasets')\n",
    "\n",
    "DATADIR2 = os.path.join(PROJECTDIR,'data')\n",
    "# os.chdir(DATADIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_balanced_sample.csv  gtruth_0215_0715  sl\r\n",
      "gtruth_0114_0715\t  homeant\t    sl.csv.gz\r\n"
     ]
    }
   ],
   "source": [
    "!ls $DATADIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "graphlab_frame = False\n",
    "# graphlab_frame = 'juan' in HOMEDIR\n",
    "\n",
    "def get_input_sframe(ds,graphlab_frame=graphlab_frame):\n",
    "    if graphlab_frame:\n",
    "        if ds == 'home_antenna': url = DATADIR +\"/homeant\"\n",
    "        elif ds == 'sum_links': url  = DATADIR +\"/sl\"\n",
    "        elif ds == 'gtruth_02': url  = DATADIR +\"/gtruth_0215_0715\" # can be near ground truth (previous to july 2015)\n",
    "        elif ds == 'gtruth_01': url  =  DATADIR +\"/gtruth_0114_0715\" # or can be old GT\n",
    "        else: print('type chosen is %s, type should be home_antenna, sum_links, gtruth_02 or gtruth_01' % ds)\n",
    "    else:\n",
    "        url = DATADIR + '/data_balanced_sample.csv'\n",
    "    return url "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#from unbalanced_dataset import UnderSampler, NearMiss, CondensedNearestNeighbour, OneSidedSelection,\\\n",
    "#NeighbourhoodCleaningRule, TomekLinks, ClusterCentroids, OverSampler, SMOTE,\\\n",
    "#SMOTETomek, SMOTEENN, EasyEnsemble, BalanceCascade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## decide if load a reduced size dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set what is the resulting sample we want of the global dataset\n",
    "global_split = 0.25\n",
    "global_split = None\n",
    "\n",
    "# since we have 2 datets that will be later joined and which are going to be previously sampled, in the end this \n",
    "# independent sampling will result in that, after the join, the dataset will have a size of fraction given by \n",
    "# the `global_split` variable\n",
    "if global_split:\n",
    "    \n",
    "    seed = 2015\n",
    "    sample = np.sqrt(global_split)\n",
    "    print(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.81 s, sys: 264 ms, total: 4.08 s\n",
      "Wall time: 4.66 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "if graphlab_frame:\n",
    "    sf_table, _ = gl.load_sframe(get_input_sframe('home_antenna',graphlab_frame))\n",
    "    sl_table, _ = gl.load_sframe(get_input_sframe('sum_links',graphlab_frame))\n",
    "    # no need to sample the gt table since it is very small in memory\n",
    "    gt_table = gl.load_sframe(get_input_sframe('gtruth_01',graphlab_frame))\n",
    "\n",
    "    if global_split:\n",
    "\n",
    "        sf_table, _ = sf_table.random_split(sample,seed=seed)\n",
    "        sl_table, _ = sl_table.random_split(sample,seed=seed)\n",
    "\n",
    "\n",
    "    rename_gt = (dict([(col,col+\"_gt\") for col in gt_table.column_names() if col != 'USER']))\n",
    "\n",
    "    #agrego la etiqueta \"_gt\" a las columnas del ground_truth\n",
    "    gt_table.rename(rename_gt) \n",
    "else:\n",
    "    data = pd.read_csv(get_input_sframe('sum_links',graphlab_frame))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(153010, 176)\n"
     ]
    }
   ],
   "source": [
    "if graphlab_frame:\n",
    "    print(sf_table.shape, sl_table.shape, gt_table.shape)\n",
    "else:\n",
    "    print(data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## simple format description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aca miramos las top 10 antenas que utilizo un usuario, ordeandas de 0 a 10 segun el uso, en numero de llamados, que el user le daba a c. antenna. _0_ Seria la antenna mas utilizada y _10_ la menos utilizada. El count es la cantidad de veces que utilizo esa antenna. \n",
    "\n",
    "Cuando aparece _WEEKNIGHT_ en el nombre de la columna, es porque cumple la condicion de que los llamados fueron hechos de noche fuera del horario [8,20] y dentro de la semana laboral.\n",
    "\n",
    "Siguiendo las definiciones del trabajo de Caro, un user es _EPIDEMIC_ siii su ANTENNA_WEEKNIGHT_0 (esta es la home_antenna) pertence a la zona epidemica.\n",
    "\n",
    "El mobility_diameter es el radio de las antennas (0 si uso una sola, etc.) utilizadas por este user. Nuevamente el modificador _WEEKNIGHT_ solo aplica para antennas utilizadas en esos horarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([u'USER', u'COUNT_0', u'COUNT_1', u'COUNT_2', u'COUNT_3', u'COUNT_4',\n",
      "       u'COUNT_5', u'COUNT_6', u'COUNT_7', u'COUNT_8',\n",
      "       ...\n",
      "       u'TimeWeekDay_IN_11', u'CallsWeekEnd_IN_11', u'TimeWeekNight_IN_11',\n",
      "       u'TimeWeekEnd_IN_VUL_11', u'CallsWeekDay_IN_VUL_11',\n",
      "       u'CallsWeekNight_IN_VUL_11', u'TimeWeekDay_IN_VUL_11',\n",
      "       u'CallsWeekEnd_IN_VUL_11', u'TimeWeekNight_IN_VUL_11',\n",
      "       u'VULNERABLE_IN_11'],\n",
      "      dtype='object', length=176)\n"
     ]
    }
   ],
   "source": [
    "# column names\n",
    "if graphlab_frame:\n",
    "    print(sf_table.column_names())\n",
    "else:\n",
    "    print(data.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sum links description\n",
    "\n",
    "La tabla sum_links tiene mas atributos y con data mas rica en informacion:\n",
    "    \n",
    "Esencialmente para c/ user miramos la cantidad de llamados y el tiempo que duraron esos llamados pero segmentando con distintos modificadores. `Time` representa la duracion del llamado y Calls el conteo de llamados.\n",
    "\n",
    "Los modficadores/ segmentaciones son:\n",
    "\n",
    "* mes en el cual estamos parados (12 == diciembre, ..., 08 == agosto)\n",
    "* OUT/IN, separa por la direccion de los llamados si salientes u entrantes.\n",
    "* _VULN_ : separa los llamados que fueron realizados hacia/desde un target_user (en una llamada hay 2 usuarios, el origin o el target) viviendo en una zona epidemica. Donde la home antena de un target_user determina su vulnerabilidad segun si es zona epidemica o no.\n",
    "* Weekend, WeekDay y WeekNight son lo que suenan. Weekend el finde, Weeknight la semana pero fuera de horario laboral y Weekday en horario laboral y de lunes a viernes.\n",
    "\n",
    "Hay solo una columna que no entra enteramente en este esquema que es VULNERABLE. Esta columna hace un conteo p/c/ usuario d cuantos target_users viven en una zona epidemica. Tambien se segmenta esta columna con los modficiadores anteriores (el mes y el out/in)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# column names\n",
    "if graphlab_frame:\n",
    "    print(sl_table.column_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Para la\n",
    "tabla gt (ground_truth) es mas simple la explicacion. Solo se busco el antenna_ID_0 (nuevamente la antenna mas utilizada) por un user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if graphlab_frame:\n",
    "    print(gt_table.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We need antennas metadata\n",
    "to get the epidemicity of each antenna and add that info to the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/juan/mobility-study/mexico-scripts-ver2/data'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATADIR2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/juan/mobility-study/mexico-scripts-ver2/datasets'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATADIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#agregamos al gt su info de epidemicidad\n",
    "antennas_file = DATADIR2+'/celdas_limpio.csv'\n",
    "\n",
    "if graphlab_frame:\n",
    "    antennas = gl.SFrame.read_csv(antennas_file, \n",
    "                              delimiter= \"|\", \n",
    "                usecols=['LATITUDE','LONGITUDE','CEL_ID','STATE','EPIDEMIC'],\n",
    "                column_type_hints=[float, float, str,str, bool]\n",
    "                            )\n",
    "else:\n",
    "    antennas = pd.read_csv(antennas_file,sep='|')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 5.96 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# enriquecemos la data de gt con info de epidemicidad\n",
    "if graphlab_frame:\n",
    "    # agrego tambien data de epidemicidad al simpleformat table\n",
    "    sf_table = sf_table.join(antennas['CEL_ID','EPIDEMIC','STATE'], \n",
    "                             on = {'ANTENNA_ID_WEEKNIGHT_0':'CEL_ID'},\n",
    "                             how = 'left')\n",
    "    gt_table = gt_table.join(antennas['CEL_ID','EPIDEMIC','STATE'], \n",
    "                             on = {'ANTENNA_ID_WEEKNIGHT_0_gt':'CEL_ID'},\n",
    "                             how = 'left')\n",
    "\n",
    "    gt_table.rename({'EPIDEMIC':'EPIDEMIC_gt'});"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# create data matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(153010, 176)\n",
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 434 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if graphlab_frame:\n",
    "    data = sl_table.join(gt_table['USER','EPIDEMIC_gt'], on = 'USER', how = 'inner')\n",
    "    data = data.join(sf_table, on = 'USER', how = 'inner')\n",
    "    #no podemos tener nulls en el target asi que dropeamos\n",
    "    data = data.dropna(columns = ['EPIDEMIC_gt'], how='any')\n",
    "    del sl_table, sf_table, gt_table\n",
    "\n",
    "print(data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51709, 47344)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['EPIDEMIC_gt'].sum(),data['EPIDEMIC'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# data.query('EPIDEMIC==0  ').STATE.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## preparamos los datasets que no pueden tomar valores negativos o categorical vars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train test split as \n",
    "p% of set as validation and the resulting  as train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "split_perc = 0.9\n",
    "mask = np.random.rand(data.shape[0])< split_perc\n",
    "\n",
    "val_set = data[mask==0]\n",
    "data = data[mask==1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define our real X variable and Y vars\n",
    "\n",
    "exclude/include features. Decide our problem (multi-target, single_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## in our  X features..\n",
    "\n",
    "determine which columns have no meaning.\n",
    "\n",
    "we are going to try different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['USER',\n",
       " 'ANTENNA_ID_0',\n",
       " 'ANTENNA_ID_1',\n",
       " 'ANTENNA_ID_2',\n",
       " 'ANTENNA_ID_3',\n",
       " 'ANTENNA_ID_4',\n",
       " 'ANTENNA_ID_5',\n",
       " 'ANTENNA_ID_6',\n",
       " 'ANTENNA_ID_7',\n",
       " 'ANTENNA_ID_8',\n",
       " 'ANTENNA_ID_9',\n",
       " 'ANTENNA_ID_WEEKNIGHT_0',\n",
       " 'ANTENNA_ID_WEEKNIGHT_1',\n",
       " 'ANTENNA_ID_WEEKNIGHT_2',\n",
       " 'ANTENNA_ID_WEEKNIGHT_3',\n",
       " 'ANTENNA_ID_WEEKNIGHT_4',\n",
       " 'ANTENNA_ID_WEEKNIGHT_5',\n",
       " 'ANTENNA_ID_WEEKNIGHT_6',\n",
       " 'ANTENNA_ID_WEEKNIGHT_7',\n",
       " 'ANTENNA_ID_WEEKNIGHT_8',\n",
       " 'ANTENNA_ID_WEEKNIGHT_9']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if graphlab_frame: iterable=data.column_names()\n",
    "else: iterable=data.columns\n",
    "\n",
    "# this param will *force* the exclusion of these columns in the final X, no matter what.\n",
    "\n",
    "manual_exclude_cols = [     \n",
    "#     'EPIDEMIC',\n",
    "#      'EPIDEMIC_gt',\n",
    "#       'STATE',\n",
    "                ]\n",
    "\n",
    "comprehensive_exclude_cols = [col for col in iterable if col == 'USER' \n",
    "          or ('ANTENNA' in col) ]   \n",
    "                                \n",
    "exclude_cols = manual_exclude_cols + comprehensive_exclude_cols\n",
    "exclude_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## first our Y vars\n",
    "\n",
    "define them with a set of different possible cases/problems to solve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "case = 0\n",
    "\n",
    "## people that used to live in the endemic area\n",
    "if case ==0:\n",
    "    case_text = \"people that used to live in the endemic area\"\n",
    "    Y = data['EPIDEMIC_gt'] == 1\n",
    "    Y_val = val_set['EPIDEMIC_gt'] == 1\n",
    "    add_exclusion_cols =[     \n",
    "            #     'EPIDEMIC',\n",
    "                 'EPIDEMIC_gt',\n",
    "            #       'STATE',\n",
    "                ]\n",
    "\n",
    "## people that used to live in the endemic area *and* migrated\n",
    "if case ==1:\n",
    "    case_text = \"people that used to live in the endemic area *and* migrated\"\n",
    "    Y = (data['EPIDEMIC_gt'] ==1) & (data['EPIDEMIC'] ==0)\n",
    "    Y_val = (val_set['EPIDEMIC_gt'] ==1) & (val_set['EPIDEMIC'] ==0)\n",
    "    add_exclusion_cols = [\n",
    "                        'EPIDEMIC',\n",
    "                          'STATE',\n",
    "                         'EPIDEMIC_gt',\n",
    "                    ]\n",
    "\n",
    "##  people that migrated in any direction\n",
    "if case ==2:\n",
    "    case_text = \"people that migrated in any direction\"\n",
    "    Y = data['EPIDEMIC_gt'] != data['EPIDEMIC']\n",
    "    Y_val = val_set['EPIDEMIC_gt'] != data['EPIDEMIC']\n",
    "    \n",
    "    add_exclusion_cols = [           \n",
    "            #     'EPIDEMIC',\n",
    "#                  'EPIDEMIC_gt',\n",
    "            #       'STATE',\n",
    "]\n",
    "\n",
    "    \n",
    "##  people that migrated in any direction, but are currently non-endemic\n",
    "if case ==3:\n",
    "    case_text = \"currently non_endemic, that used to live in the endemic area\"\n",
    "    \n",
    "    data = data[data['EPIDEMIC'] ==0]\n",
    "    val_set = val_set[val_set['EPIDEMIC'] ==0]\n",
    "\n",
    "    Y = (data['EPIDEMIC_gt'] ==1)\n",
    "    Y_val = (val_set['EPIDEMIC_gt'] ==1) \n",
    "    \n",
    "    add_exclusion_cols = [\n",
    "                'EPIDEMIC'\n",
    "                'EPIDEMIC_gt',\n",
    "            #     'STATE',\n",
    "         \n",
    "                         ]    \n",
    "    \n",
    "## people from the Mexico or DF states\n",
    "if case == 4:\n",
    "    case_text = \"people from the Mexico or DF states\"\n",
    "    Y = (data['STATE'] == 'Distrito_Federal') | (data['STATE'] == 'Mexico')\n",
    "    Y_val = (val_set['STATE'] == 'Distrito_Federal') | (val_set['STATE'] == 'Mexico')\n",
    "    \n",
    "    add_exclusion_cols = [\n",
    "                'EPIDEMIC',\n",
    "                'STATE',\n",
    "                ]\n",
    "                        \n",
    "## people with a HIGH present mobility (>1000 after looking at percentiles of the MOBILITY_DIAMTER)\n",
    "if case == 5:\n",
    "    val = 1000\n",
    "    case_text = \"people with a high mobility during present time (values > {} )\".format(val)\n",
    "    Y = (data['MOBILITY_DIAMETER'] > val) \n",
    "    Y_val = (val_set['MOBILITY_DIAMETER'] > val) \n",
    "    \n",
    "    add_exclusion_cols = [\n",
    "        \n",
    "        'MOBILITY_DIAMETER_WEEKNIGHT',\n",
    "        'MOBILITY_DIAMETER',\n",
    "    ]\n",
    "\n",
    "for col in add_exclusion_cols:\n",
    "    if not col in exclude_cols:\n",
    "        exclude_cols+=[col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if graphlab_frame: iterable=data.column_names()\n",
    "else: iterable=data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'TimeWeekNight_IN_08', u'TimeWeekEnd_IN_VUL_08',\n",
       "       u'CallsWeekDay_IN_VUL_08', u'CallsWeekNight_IN_VUL_08',\n",
       "       u'TimeWeekDay_IN_VUL_08', u'CallsWeekEnd_IN_VUL_08',\n",
       "       u'TimeWeekNight_IN_VUL_08', u'VULNERABLE_IN_08', u'TimeWeekEnd_OUT_09',\n",
       "       u'CallsWeekDay_OUT_09', u'CallsWeekNight_OUT_09', u'TimeWeekDay_OUT_09',\n",
       "       u'CallsWeekEnd_OUT_09', u'TimeWeekNight_OUT_09',\n",
       "       u'TimeWeekEnd_OUT_VUL_09', u'CallsWeekDay_OUT_VUL_09',\n",
       "       u'CallsWeekNight_OUT_VUL_09', u'TimeWeekDay_OUT_VUL_09',\n",
       "       u'CallsWeekEnd_OUT_VUL_09', u'TimeWeekNight_OUT_VUL_09',\n",
       "       u'VULNERABLE_OUT_09', u'TimeWeekEnd_IN_09', u'CallsWeekDay_IN_09',\n",
       "       u'CallsWeekNight_IN_09', u'TimeWeekDay_IN_09', u'CallsWeekEnd_IN_09',\n",
       "       u'TimeWeekNight_IN_09', u'TimeWeekEnd_IN_VUL_09',\n",
       "       u'CallsWeekDay_IN_VUL_09', u'CallsWeekNight_IN_VUL_09'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "width = 30\n",
    "N= np.random.randint(1,int(iterable.shape[0]*1.0/width))\n",
    "data.columns[(N)*width: (N+1)*width]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/juan/mfixman/venv/lib/python2.7/site-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/home/juan/mfixman/venv/lib/python2.7/site-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.51 s, sys: 64 ms, total: 3.58 s\n",
      "Wall time: 3.57 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "X = data[[col for col in iterable if col not in exclude_cols]]\n",
    "\n",
    "X_val = val_set[[col for col in iterable if col not in exclude_cols]]\n",
    "\n",
    "if graphlab_frame: iterable=X.column_names()\n",
    "else: iterable=X.columns\n",
    "    \n",
    "# clean negative/Null vals in count cols \n",
    "for col in [col for col in iterable if 'COUNT' in col]:\n",
    "    X[col]= X[col].apply(lambda x :  x if x>=0 else 0)\n",
    "    X_val[col]= X_val[col].apply(lambda x :  x if x>=0 else 0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((137692, 154), (137692,))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dummy-ize categorical cols\n",
    "if necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if graphlab_frame: iterable=X.column_names()\n",
    "else: iterable=X.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# X.columns\n",
    "# [col for col in X.columns if 'STATE' in col]\n",
    "# [col for col in X_val.columns if 'STATE' in col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "categorical_cols = [\n",
    "    'STATE'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we are categorizing col STATE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/juan/mfixman/venv/lib/python2.7/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n",
      "/home/juan/mfixman/venv/lib/python2.7/site-packages/ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "for col in categorical_cols:\n",
    "    if col not in exclude_cols:\n",
    "        print('we are categorizing col %s' %col)\n",
    "        X[col] = X[col].astype('category')\n",
    "    #     if X[col].dtype != 'category':\n",
    "    #         continue \n",
    "        X = pd.concat([X,pd.get_dummies(X[col], \n",
    "                                          prefix= col, \n",
    "                                          prefix_sep='_', \n",
    "                                          #sparse = True,\n",
    "                                          dummy_na=False).astype(np.int8)],\\\n",
    "                  axis=1 ,join = 'inner')\n",
    "        X.drop(col, axis =1 , inplace=True)\n",
    "\n",
    "        # now onto test_table\n",
    "        X_val[col] = X_val[col].astype('category')\n",
    "        X_val = pd.concat([X_val,pd.get_dummies(X_val[col], \n",
    "                                          prefix= col, \n",
    "                                          prefix_sep='_', \n",
    "                                          #sparse = True,\n",
    "                                          dummy_na=False).astype(np.int8)],\\\n",
    "                  axis=1 ,join = 'inner')\n",
    "\n",
    "        X_val.drop(col, axis =1 , inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## explore correlations to target var\n",
    "\n",
    "with current column configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(186, 186)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr = pd.DataFrame(X).copy()\n",
    "target_col = 'target'\n",
    "corr[target_col] = Y\n",
    "corr = corr.corr()\n",
    "corr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EPIDEMIC</th>\n",
       "      <th>TimeWeekEnd_OUT_VUL_12</th>\n",
       "      <th>CallsWeekDay_OUT_VUL_12</th>\n",
       "      <th>CallsWeekNight_OUT_VUL_12</th>\n",
       "      <th>TimeWeekDay_OUT_VUL_12</th>\n",
       "      <th>CallsWeekEnd_OUT_VUL_12</th>\n",
       "      <th>TimeWeekNight_OUT_VUL_12</th>\n",
       "      <th>VULNERABLE_OUT_12</th>\n",
       "      <th>TimeWeekEnd_IN_VUL_12</th>\n",
       "      <th>CallsWeekDay_IN_VUL_12</th>\n",
       "      <th>...</th>\n",
       "      <th>TimeWeekDay_IN_VUL_11</th>\n",
       "      <th>CallsWeekEnd_IN_VUL_11</th>\n",
       "      <th>TimeWeekNight_IN_VUL_11</th>\n",
       "      <th>VULNERABLE_IN_11</th>\n",
       "      <th>STATE_Hidalgo</th>\n",
       "      <th>STATE_Jalisco</th>\n",
       "      <th>STATE_Morelos</th>\n",
       "      <th>STATE_Puebla</th>\n",
       "      <th>STATE_Veracruz</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>EPIDEMIC</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.171408</td>\n",
       "      <td>0.287120</td>\n",
       "      <td>0.206999</td>\n",
       "      <td>0.222914</td>\n",
       "      <td>0.264443</td>\n",
       "      <td>0.105028</td>\n",
       "      <td>0.497289</td>\n",
       "      <td>0.164613</td>\n",
       "      <td>0.287017</td>\n",
       "      <td>...</td>\n",
       "      <td>0.217212</td>\n",
       "      <td>0.291858</td>\n",
       "      <td>0.100896</td>\n",
       "      <td>0.516003</td>\n",
       "      <td>0.330397</td>\n",
       "      <td>0.489502</td>\n",
       "      <td>0.263178</td>\n",
       "      <td>0.331527</td>\n",
       "      <td>0.297942</td>\n",
       "      <td>0.439418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TimeWeekEnd_OUT_VUL_12</th>\n",
       "      <td>0.171408</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.560496</td>\n",
       "      <td>0.651113</td>\n",
       "      <td>0.629617</td>\n",
       "      <td>0.801017</td>\n",
       "      <td>0.635869</td>\n",
       "      <td>0.315335</td>\n",
       "      <td>0.594255</td>\n",
       "      <td>0.467672</td>\n",
       "      <td>...</td>\n",
       "      <td>0.404869</td>\n",
       "      <td>0.480234</td>\n",
       "      <td>0.384984</td>\n",
       "      <td>0.291700</td>\n",
       "      <td>0.061749</td>\n",
       "      <td>0.102921</td>\n",
       "      <td>0.030067</td>\n",
       "      <td>0.045572</td>\n",
       "      <td>0.026676</td>\n",
       "      <td>0.187130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CallsWeekDay_OUT_VUL_12</th>\n",
       "      <td>0.287120</td>\n",
       "      <td>0.560496</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.628189</td>\n",
       "      <td>0.864216</td>\n",
       "      <td>0.772855</td>\n",
       "      <td>0.378848</td>\n",
       "      <td>0.448494</td>\n",
       "      <td>0.466551</td>\n",
       "      <td>0.834490</td>\n",
       "      <td>...</td>\n",
       "      <td>0.578081</td>\n",
       "      <td>0.633350</td>\n",
       "      <td>0.261531</td>\n",
       "      <td>0.421996</td>\n",
       "      <td>0.097365</td>\n",
       "      <td>0.184278</td>\n",
       "      <td>0.053034</td>\n",
       "      <td>0.079153</td>\n",
       "      <td>0.045011</td>\n",
       "      <td>0.277760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CallsWeekNight_OUT_VUL_12</th>\n",
       "      <td>0.206999</td>\n",
       "      <td>0.651113</td>\n",
       "      <td>0.628189</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.586073</td>\n",
       "      <td>0.735115</td>\n",
       "      <td>0.798162</td>\n",
       "      <td>0.362146</td>\n",
       "      <td>0.515796</td>\n",
       "      <td>0.533153</td>\n",
       "      <td>...</td>\n",
       "      <td>0.388313</td>\n",
       "      <td>0.551986</td>\n",
       "      <td>0.421814</td>\n",
       "      <td>0.337522</td>\n",
       "      <td>0.071198</td>\n",
       "      <td>0.120409</td>\n",
       "      <td>0.041128</td>\n",
       "      <td>0.060885</td>\n",
       "      <td>0.037357</td>\n",
       "      <td>0.225518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TimeWeekDay_OUT_VUL_12</th>\n",
       "      <td>0.222914</td>\n",
       "      <td>0.629617</td>\n",
       "      <td>0.864216</td>\n",
       "      <td>0.586073</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.665776</td>\n",
       "      <td>0.478032</td>\n",
       "      <td>0.399304</td>\n",
       "      <td>0.520518</td>\n",
       "      <td>0.701466</td>\n",
       "      <td>...</td>\n",
       "      <td>0.629497</td>\n",
       "      <td>0.538366</td>\n",
       "      <td>0.327929</td>\n",
       "      <td>0.374658</td>\n",
       "      <td>0.071853</td>\n",
       "      <td>0.149734</td>\n",
       "      <td>0.037512</td>\n",
       "      <td>0.057518</td>\n",
       "      <td>0.034943</td>\n",
       "      <td>0.231432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CallsWeekEnd_OUT_VUL_12</th>\n",
       "      <td>0.264443</td>\n",
       "      <td>0.801017</td>\n",
       "      <td>0.772855</td>\n",
       "      <td>0.735115</td>\n",
       "      <td>0.665776</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.488800</td>\n",
       "      <td>0.417388</td>\n",
       "      <td>0.557234</td>\n",
       "      <td>0.665846</td>\n",
       "      <td>...</td>\n",
       "      <td>0.453263</td>\n",
       "      <td>0.654575</td>\n",
       "      <td>0.314124</td>\n",
       "      <td>0.388609</td>\n",
       "      <td>0.093831</td>\n",
       "      <td>0.157430</td>\n",
       "      <td>0.050305</td>\n",
       "      <td>0.078071</td>\n",
       "      <td>0.043760</td>\n",
       "      <td>0.262159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TimeWeekNight_OUT_VUL_12</th>\n",
       "      <td>0.105028</td>\n",
       "      <td>0.635869</td>\n",
       "      <td>0.378848</td>\n",
       "      <td>0.798162</td>\n",
       "      <td>0.478032</td>\n",
       "      <td>0.488800</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.241688</td>\n",
       "      <td>0.495415</td>\n",
       "      <td>0.307642</td>\n",
       "      <td>...</td>\n",
       "      <td>0.302991</td>\n",
       "      <td>0.351959</td>\n",
       "      <td>0.488910</td>\n",
       "      <td>0.224448</td>\n",
       "      <td>0.035734</td>\n",
       "      <td>0.062305</td>\n",
       "      <td>0.017880</td>\n",
       "      <td>0.028267</td>\n",
       "      <td>0.018045</td>\n",
       "      <td>0.142294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VULNERABLE_OUT_12</th>\n",
       "      <td>0.497289</td>\n",
       "      <td>0.315335</td>\n",
       "      <td>0.448494</td>\n",
       "      <td>0.362146</td>\n",
       "      <td>0.399304</td>\n",
       "      <td>0.417388</td>\n",
       "      <td>0.241688</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.294727</td>\n",
       "      <td>0.431177</td>\n",
       "      <td>...</td>\n",
       "      <td>0.341396</td>\n",
       "      <td>0.410452</td>\n",
       "      <td>0.202933</td>\n",
       "      <td>0.770518</td>\n",
       "      <td>0.176316</td>\n",
       "      <td>0.282054</td>\n",
       "      <td>0.117072</td>\n",
       "      <td>0.155896</td>\n",
       "      <td>0.134299</td>\n",
       "      <td>0.503804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TimeWeekEnd_IN_VUL_12</th>\n",
       "      <td>0.164613</td>\n",
       "      <td>0.594255</td>\n",
       "      <td>0.466551</td>\n",
       "      <td>0.515796</td>\n",
       "      <td>0.520518</td>\n",
       "      <td>0.557234</td>\n",
       "      <td>0.495415</td>\n",
       "      <td>0.294727</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.531593</td>\n",
       "      <td>...</td>\n",
       "      <td>0.517292</td>\n",
       "      <td>0.557891</td>\n",
       "      <td>0.497786</td>\n",
       "      <td>0.283148</td>\n",
       "      <td>0.057281</td>\n",
       "      <td>0.098106</td>\n",
       "      <td>0.030502</td>\n",
       "      <td>0.045343</td>\n",
       "      <td>0.027871</td>\n",
       "      <td>0.177840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CallsWeekDay_IN_VUL_12</th>\n",
       "      <td>0.287017</td>\n",
       "      <td>0.467672</td>\n",
       "      <td>0.834490</td>\n",
       "      <td>0.533153</td>\n",
       "      <td>0.701466</td>\n",
       "      <td>0.665846</td>\n",
       "      <td>0.307642</td>\n",
       "      <td>0.431177</td>\n",
       "      <td>0.531593</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.665681</td>\n",
       "      <td>0.717676</td>\n",
       "      <td>0.289233</td>\n",
       "      <td>0.414842</td>\n",
       "      <td>0.095508</td>\n",
       "      <td>0.184024</td>\n",
       "      <td>0.054348</td>\n",
       "      <td>0.083978</td>\n",
       "      <td>0.044692</td>\n",
       "      <td>0.271915</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 77 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           EPIDEMIC  TimeWeekEnd_OUT_VUL_12  \\\n",
       "EPIDEMIC                   1.000000                0.171408   \n",
       "TimeWeekEnd_OUT_VUL_12     0.171408                1.000000   \n",
       "CallsWeekDay_OUT_VUL_12    0.287120                0.560496   \n",
       "CallsWeekNight_OUT_VUL_12  0.206999                0.651113   \n",
       "TimeWeekDay_OUT_VUL_12     0.222914                0.629617   \n",
       "CallsWeekEnd_OUT_VUL_12    0.264443                0.801017   \n",
       "TimeWeekNight_OUT_VUL_12   0.105028                0.635869   \n",
       "VULNERABLE_OUT_12          0.497289                0.315335   \n",
       "TimeWeekEnd_IN_VUL_12      0.164613                0.594255   \n",
       "CallsWeekDay_IN_VUL_12     0.287017                0.467672   \n",
       "\n",
       "                           CallsWeekDay_OUT_VUL_12  CallsWeekNight_OUT_VUL_12  \\\n",
       "EPIDEMIC                                  0.287120                   0.206999   \n",
       "TimeWeekEnd_OUT_VUL_12                    0.560496                   0.651113   \n",
       "CallsWeekDay_OUT_VUL_12                   1.000000                   0.628189   \n",
       "CallsWeekNight_OUT_VUL_12                 0.628189                   1.000000   \n",
       "TimeWeekDay_OUT_VUL_12                    0.864216                   0.586073   \n",
       "CallsWeekEnd_OUT_VUL_12                   0.772855                   0.735115   \n",
       "TimeWeekNight_OUT_VUL_12                  0.378848                   0.798162   \n",
       "VULNERABLE_OUT_12                         0.448494                   0.362146   \n",
       "TimeWeekEnd_IN_VUL_12                     0.466551                   0.515796   \n",
       "CallsWeekDay_IN_VUL_12                    0.834490                   0.533153   \n",
       "\n",
       "                           TimeWeekDay_OUT_VUL_12  CallsWeekEnd_OUT_VUL_12  \\\n",
       "EPIDEMIC                                 0.222914                 0.264443   \n",
       "TimeWeekEnd_OUT_VUL_12                   0.629617                 0.801017   \n",
       "CallsWeekDay_OUT_VUL_12                  0.864216                 0.772855   \n",
       "CallsWeekNight_OUT_VUL_12                0.586073                 0.735115   \n",
       "TimeWeekDay_OUT_VUL_12                   1.000000                 0.665776   \n",
       "CallsWeekEnd_OUT_VUL_12                  0.665776                 1.000000   \n",
       "TimeWeekNight_OUT_VUL_12                 0.478032                 0.488800   \n",
       "VULNERABLE_OUT_12                        0.399304                 0.417388   \n",
       "TimeWeekEnd_IN_VUL_12                    0.520518                 0.557234   \n",
       "CallsWeekDay_IN_VUL_12                   0.701466                 0.665846   \n",
       "\n",
       "                           TimeWeekNight_OUT_VUL_12  VULNERABLE_OUT_12  \\\n",
       "EPIDEMIC                                   0.105028           0.497289   \n",
       "TimeWeekEnd_OUT_VUL_12                     0.635869           0.315335   \n",
       "CallsWeekDay_OUT_VUL_12                    0.378848           0.448494   \n",
       "CallsWeekNight_OUT_VUL_12                  0.798162           0.362146   \n",
       "TimeWeekDay_OUT_VUL_12                     0.478032           0.399304   \n",
       "CallsWeekEnd_OUT_VUL_12                    0.488800           0.417388   \n",
       "TimeWeekNight_OUT_VUL_12                   1.000000           0.241688   \n",
       "VULNERABLE_OUT_12                          0.241688           1.000000   \n",
       "TimeWeekEnd_IN_VUL_12                      0.495415           0.294727   \n",
       "CallsWeekDay_IN_VUL_12                     0.307642           0.431177   \n",
       "\n",
       "                           TimeWeekEnd_IN_VUL_12  CallsWeekDay_IN_VUL_12  \\\n",
       "EPIDEMIC                                0.164613                0.287017   \n",
       "TimeWeekEnd_OUT_VUL_12                  0.594255                0.467672   \n",
       "CallsWeekDay_OUT_VUL_12                 0.466551                0.834490   \n",
       "CallsWeekNight_OUT_VUL_12               0.515796                0.533153   \n",
       "TimeWeekDay_OUT_VUL_12                  0.520518                0.701466   \n",
       "CallsWeekEnd_OUT_VUL_12                 0.557234                0.665846   \n",
       "TimeWeekNight_OUT_VUL_12                0.495415                0.307642   \n",
       "VULNERABLE_OUT_12                       0.294727                0.431177   \n",
       "TimeWeekEnd_IN_VUL_12                   1.000000                0.531593   \n",
       "CallsWeekDay_IN_VUL_12                  0.531593                1.000000   \n",
       "\n",
       "                             ...     TimeWeekDay_IN_VUL_11  \\\n",
       "EPIDEMIC                     ...                  0.217212   \n",
       "TimeWeekEnd_OUT_VUL_12       ...                  0.404869   \n",
       "CallsWeekDay_OUT_VUL_12      ...                  0.578081   \n",
       "CallsWeekNight_OUT_VUL_12    ...                  0.388313   \n",
       "TimeWeekDay_OUT_VUL_12       ...                  0.629497   \n",
       "CallsWeekEnd_OUT_VUL_12      ...                  0.453263   \n",
       "TimeWeekNight_OUT_VUL_12     ...                  0.302991   \n",
       "VULNERABLE_OUT_12            ...                  0.341396   \n",
       "TimeWeekEnd_IN_VUL_12        ...                  0.517292   \n",
       "CallsWeekDay_IN_VUL_12       ...                  0.665681   \n",
       "\n",
       "                           CallsWeekEnd_IN_VUL_11  TimeWeekNight_IN_VUL_11  \\\n",
       "EPIDEMIC                                 0.291858                 0.100896   \n",
       "TimeWeekEnd_OUT_VUL_12                   0.480234                 0.384984   \n",
       "CallsWeekDay_OUT_VUL_12                  0.633350                 0.261531   \n",
       "CallsWeekNight_OUT_VUL_12                0.551986                 0.421814   \n",
       "TimeWeekDay_OUT_VUL_12                   0.538366                 0.327929   \n",
       "CallsWeekEnd_OUT_VUL_12                  0.654575                 0.314124   \n",
       "TimeWeekNight_OUT_VUL_12                 0.351959                 0.488910   \n",
       "VULNERABLE_OUT_12                        0.410452                 0.202933   \n",
       "TimeWeekEnd_IN_VUL_12                    0.557891                 0.497786   \n",
       "CallsWeekDay_IN_VUL_12                   0.717676                 0.289233   \n",
       "\n",
       "                           VULNERABLE_IN_11  STATE_Hidalgo  STATE_Jalisco  \\\n",
       "EPIDEMIC                           0.516003       0.330397       0.489502   \n",
       "TimeWeekEnd_OUT_VUL_12             0.291700       0.061749       0.102921   \n",
       "CallsWeekDay_OUT_VUL_12            0.421996       0.097365       0.184278   \n",
       "CallsWeekNight_OUT_VUL_12          0.337522       0.071198       0.120409   \n",
       "TimeWeekDay_OUT_VUL_12             0.374658       0.071853       0.149734   \n",
       "CallsWeekEnd_OUT_VUL_12            0.388609       0.093831       0.157430   \n",
       "TimeWeekNight_OUT_VUL_12           0.224448       0.035734       0.062305   \n",
       "VULNERABLE_OUT_12                  0.770518       0.176316       0.282054   \n",
       "TimeWeekEnd_IN_VUL_12              0.283148       0.057281       0.098106   \n",
       "CallsWeekDay_IN_VUL_12             0.414842       0.095508       0.184024   \n",
       "\n",
       "                           STATE_Morelos  STATE_Puebla  STATE_Veracruz  \\\n",
       "EPIDEMIC                        0.263178      0.331527        0.297942   \n",
       "TimeWeekEnd_OUT_VUL_12          0.030067      0.045572        0.026676   \n",
       "CallsWeekDay_OUT_VUL_12         0.053034      0.079153        0.045011   \n",
       "CallsWeekNight_OUT_VUL_12       0.041128      0.060885        0.037357   \n",
       "TimeWeekDay_OUT_VUL_12          0.037512      0.057518        0.034943   \n",
       "CallsWeekEnd_OUT_VUL_12         0.050305      0.078071        0.043760   \n",
       "TimeWeekNight_OUT_VUL_12        0.017880      0.028267        0.018045   \n",
       "VULNERABLE_OUT_12               0.117072      0.155896        0.134299   \n",
       "TimeWeekEnd_IN_VUL_12           0.030502      0.045343        0.027871   \n",
       "CallsWeekDay_IN_VUL_12          0.054348      0.083978        0.044692   \n",
       "\n",
       "                             target  \n",
       "EPIDEMIC                   0.439418  \n",
       "TimeWeekEnd_OUT_VUL_12     0.187130  \n",
       "CallsWeekDay_OUT_VUL_12    0.277760  \n",
       "CallsWeekNight_OUT_VUL_12  0.225518  \n",
       "TimeWeekDay_OUT_VUL_12     0.231432  \n",
       "CallsWeekEnd_OUT_VUL_12    0.262159  \n",
       "TimeWeekNight_OUT_VUL_12   0.142294  \n",
       "VULNERABLE_OUT_12          0.503804  \n",
       "TimeWeekEnd_IN_VUL_12      0.177840  \n",
       "CallsWeekDay_IN_VUL_12     0.271915  \n",
       "\n",
       "[10 rows x 77 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "view = corr.query('target>0.1')\n",
    "# show only those columns which \n",
    "corr_columns = view.index.values\n",
    "\n",
    "view[corr_columns].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATE_Aguascalientes</th>\n",
       "      <th>STATE_Baja_California</th>\n",
       "      <th>STATE_Baja_California_Sur</th>\n",
       "      <th>STATE_Campeche</th>\n",
       "      <th>STATE_Chiapas</th>\n",
       "      <th>STATE_Chihuahua</th>\n",
       "      <th>STATE_Coahuila_de_Zaragoza</th>\n",
       "      <th>STATE_Colima</th>\n",
       "      <th>STATE_Distrito_Federal</th>\n",
       "      <th>STATE_Durango</th>\n",
       "      <th>...</th>\n",
       "      <th>STATE_San_Luis_Potosi</th>\n",
       "      <th>STATE_Sinaloa</th>\n",
       "      <th>STATE_Sonora</th>\n",
       "      <th>STATE_Tabasco</th>\n",
       "      <th>STATE_Tamaulipas</th>\n",
       "      <th>STATE_Tlaxcala</th>\n",
       "      <th>STATE_Veracruz</th>\n",
       "      <th>STATE_Yucatan</th>\n",
       "      <th>STATE_Zacatecas</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MOBILITY_DIAMETER</th>\n",
       "      <td>0.045902</td>\n",
       "      <td>0.145942</td>\n",
       "      <td>0.032684</td>\n",
       "      <td>0.006103</td>\n",
       "      <td>-0.014679</td>\n",
       "      <td>0.024696</td>\n",
       "      <td>-0.002260</td>\n",
       "      <td>-0.006266</td>\n",
       "      <td>-0.138609</td>\n",
       "      <td>-0.009381</td>\n",
       "      <td>...</td>\n",
       "      <td>0.062277</td>\n",
       "      <td>0.051715</td>\n",
       "      <td>0.080137</td>\n",
       "      <td>0.004682</td>\n",
       "      <td>0.005265</td>\n",
       "      <td>-0.019447</td>\n",
       "      <td>0.056086</td>\n",
       "      <td>-0.029270</td>\n",
       "      <td>0.000641</td>\n",
       "      <td>0.013764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MOBILITY_DIAMETER_WEEKNIGHT</th>\n",
       "      <td>0.046654</td>\n",
       "      <td>0.145805</td>\n",
       "      <td>0.033328</td>\n",
       "      <td>0.006141</td>\n",
       "      <td>-0.009792</td>\n",
       "      <td>0.023230</td>\n",
       "      <td>-0.001692</td>\n",
       "      <td>-0.004915</td>\n",
       "      <td>-0.120051</td>\n",
       "      <td>-0.009230</td>\n",
       "      <td>...</td>\n",
       "      <td>0.063803</td>\n",
       "      <td>0.053742</td>\n",
       "      <td>0.082001</td>\n",
       "      <td>0.006905</td>\n",
       "      <td>0.005447</td>\n",
       "      <td>-0.026101</td>\n",
       "      <td>0.045211</td>\n",
       "      <td>-0.021405</td>\n",
       "      <td>-0.005553</td>\n",
       "      <td>0.014906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EPIDEMIC</th>\n",
       "      <td>-0.070297</td>\n",
       "      <td>-0.063463</td>\n",
       "      <td>-0.025483</td>\n",
       "      <td>-0.057895</td>\n",
       "      <td>-0.086392</td>\n",
       "      <td>-0.041519</td>\n",
       "      <td>-0.046698</td>\n",
       "      <td>-0.044976</td>\n",
       "      <td>-0.346309</td>\n",
       "      <td>-0.034628</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.079844</td>\n",
       "      <td>-0.052823</td>\n",
       "      <td>-0.038012</td>\n",
       "      <td>0.223487</td>\n",
       "      <td>-0.051591</td>\n",
       "      <td>-0.088226</td>\n",
       "      <td>0.297942</td>\n",
       "      <td>-0.109580</td>\n",
       "      <td>-0.034769</td>\n",
       "      <td>0.439418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TimeWeekEnd_OUT_VUL_12</th>\n",
       "      <td>-0.013845</td>\n",
       "      <td>-0.004919</td>\n",
       "      <td>0.010538</td>\n",
       "      <td>0.000871</td>\n",
       "      <td>-0.012463</td>\n",
       "      <td>-0.004699</td>\n",
       "      <td>-0.012326</td>\n",
       "      <td>0.007216</td>\n",
       "      <td>-0.058471</td>\n",
       "      <td>-0.009700</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.015667</td>\n",
       "      <td>0.009809</td>\n",
       "      <td>0.008594</td>\n",
       "      <td>0.062447</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>-0.012570</td>\n",
       "      <td>0.026676</td>\n",
       "      <td>-0.025227</td>\n",
       "      <td>-0.004827</td>\n",
       "      <td>0.187130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CallsWeekDay_OUT_VUL_12</th>\n",
       "      <td>-0.023551</td>\n",
       "      <td>-0.016264</td>\n",
       "      <td>0.001278</td>\n",
       "      <td>-0.011864</td>\n",
       "      <td>-0.023981</td>\n",
       "      <td>-0.007346</td>\n",
       "      <td>-0.017427</td>\n",
       "      <td>0.008317</td>\n",
       "      <td>-0.095216</td>\n",
       "      <td>-0.013552</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.029249</td>\n",
       "      <td>0.003711</td>\n",
       "      <td>0.008158</td>\n",
       "      <td>0.086426</td>\n",
       "      <td>-0.008732</td>\n",
       "      <td>-0.021534</td>\n",
       "      <td>0.045011</td>\n",
       "      <td>-0.040492</td>\n",
       "      <td>-0.010899</td>\n",
       "      <td>0.277760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CallsWeekNight_OUT_VUL_12</th>\n",
       "      <td>-0.018538</td>\n",
       "      <td>-0.010279</td>\n",
       "      <td>0.007098</td>\n",
       "      <td>-0.002889</td>\n",
       "      <td>-0.017992</td>\n",
       "      <td>-0.004098</td>\n",
       "      <td>-0.013196</td>\n",
       "      <td>0.007299</td>\n",
       "      <td>-0.065420</td>\n",
       "      <td>-0.010092</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018457</td>\n",
       "      <td>0.007416</td>\n",
       "      <td>0.009478</td>\n",
       "      <td>0.073654</td>\n",
       "      <td>0.000079</td>\n",
       "      <td>-0.013420</td>\n",
       "      <td>0.037357</td>\n",
       "      <td>-0.030622</td>\n",
       "      <td>-0.008207</td>\n",
       "      <td>0.225518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TimeWeekDay_OUT_VUL_12</th>\n",
       "      <td>-0.018978</td>\n",
       "      <td>-0.009812</td>\n",
       "      <td>0.005776</td>\n",
       "      <td>-0.003502</td>\n",
       "      <td>-0.016605</td>\n",
       "      <td>-0.004612</td>\n",
       "      <td>-0.014868</td>\n",
       "      <td>0.013340</td>\n",
       "      <td>-0.072652</td>\n",
       "      <td>-0.011919</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.025230</td>\n",
       "      <td>0.009093</td>\n",
       "      <td>0.012902</td>\n",
       "      <td>0.071986</td>\n",
       "      <td>-0.004842</td>\n",
       "      <td>-0.017533</td>\n",
       "      <td>0.034943</td>\n",
       "      <td>-0.033579</td>\n",
       "      <td>-0.009226</td>\n",
       "      <td>0.231432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CallsWeekEnd_OUT_VUL_12</th>\n",
       "      <td>-0.020222</td>\n",
       "      <td>-0.013935</td>\n",
       "      <td>0.003964</td>\n",
       "      <td>-0.008532</td>\n",
       "      <td>-0.022123</td>\n",
       "      <td>-0.007780</td>\n",
       "      <td>-0.016322</td>\n",
       "      <td>0.005513</td>\n",
       "      <td>-0.087076</td>\n",
       "      <td>-0.013012</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.025451</td>\n",
       "      <td>0.003389</td>\n",
       "      <td>0.007596</td>\n",
       "      <td>0.082011</td>\n",
       "      <td>-0.007149</td>\n",
       "      <td>-0.017540</td>\n",
       "      <td>0.043760</td>\n",
       "      <td>-0.036603</td>\n",
       "      <td>-0.009751</td>\n",
       "      <td>0.262159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TimeWeekNight_OUT_VUL_12</th>\n",
       "      <td>-0.011181</td>\n",
       "      <td>-0.002776</td>\n",
       "      <td>0.011300</td>\n",
       "      <td>0.007510</td>\n",
       "      <td>-0.007542</td>\n",
       "      <td>0.001704</td>\n",
       "      <td>-0.006902</td>\n",
       "      <td>0.004665</td>\n",
       "      <td>-0.032920</td>\n",
       "      <td>-0.006101</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.008368</td>\n",
       "      <td>0.012940</td>\n",
       "      <td>0.011473</td>\n",
       "      <td>0.046054</td>\n",
       "      <td>0.004008</td>\n",
       "      <td>-0.006425</td>\n",
       "      <td>0.018045</td>\n",
       "      <td>-0.017813</td>\n",
       "      <td>-0.003635</td>\n",
       "      <td>0.142294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VULNERABLE_OUT_12</th>\n",
       "      <td>-0.038502</td>\n",
       "      <td>-0.028439</td>\n",
       "      <td>0.010884</td>\n",
       "      <td>-0.015736</td>\n",
       "      <td>-0.041065</td>\n",
       "      <td>-0.014000</td>\n",
       "      <td>-0.034331</td>\n",
       "      <td>0.010190</td>\n",
       "      <td>-0.148067</td>\n",
       "      <td>-0.024705</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.051399</td>\n",
       "      <td>0.016951</td>\n",
       "      <td>0.017911</td>\n",
       "      <td>0.115796</td>\n",
       "      <td>-0.015172</td>\n",
       "      <td>-0.025880</td>\n",
       "      <td>0.134299</td>\n",
       "      <td>-0.074840</td>\n",
       "      <td>-0.019988</td>\n",
       "      <td>0.503804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TimeWeekEnd_IN_VUL_12</th>\n",
       "      <td>-0.011941</td>\n",
       "      <td>-0.007219</td>\n",
       "      <td>0.009124</td>\n",
       "      <td>0.000403</td>\n",
       "      <td>-0.008797</td>\n",
       "      <td>-0.001187</td>\n",
       "      <td>-0.010547</td>\n",
       "      <td>0.009127</td>\n",
       "      <td>-0.055902</td>\n",
       "      <td>-0.008682</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.015849</td>\n",
       "      <td>0.007407</td>\n",
       "      <td>0.004355</td>\n",
       "      <td>0.060743</td>\n",
       "      <td>-0.002125</td>\n",
       "      <td>-0.009439</td>\n",
       "      <td>0.027871</td>\n",
       "      <td>-0.021220</td>\n",
       "      <td>-0.006139</td>\n",
       "      <td>0.177840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CallsWeekDay_IN_VUL_12</th>\n",
       "      <td>-0.022734</td>\n",
       "      <td>-0.017515</td>\n",
       "      <td>0.001092</td>\n",
       "      <td>-0.014149</td>\n",
       "      <td>-0.024679</td>\n",
       "      <td>-0.005824</td>\n",
       "      <td>-0.017638</td>\n",
       "      <td>0.005301</td>\n",
       "      <td>-0.094969</td>\n",
       "      <td>-0.012157</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.028571</td>\n",
       "      <td>0.002017</td>\n",
       "      <td>0.006453</td>\n",
       "      <td>0.084164</td>\n",
       "      <td>-0.009910</td>\n",
       "      <td>-0.020423</td>\n",
       "      <td>0.044692</td>\n",
       "      <td>-0.039479</td>\n",
       "      <td>-0.010699</td>\n",
       "      <td>0.271915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CallsWeekNight_IN_VUL_12</th>\n",
       "      <td>-0.014445</td>\n",
       "      <td>-0.010335</td>\n",
       "      <td>0.003971</td>\n",
       "      <td>-0.007689</td>\n",
       "      <td>-0.015009</td>\n",
       "      <td>-0.003297</td>\n",
       "      <td>-0.011581</td>\n",
       "      <td>0.005283</td>\n",
       "      <td>-0.051608</td>\n",
       "      <td>-0.008645</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.017341</td>\n",
       "      <td>0.001028</td>\n",
       "      <td>0.006369</td>\n",
       "      <td>0.061843</td>\n",
       "      <td>-0.004359</td>\n",
       "      <td>-0.009094</td>\n",
       "      <td>0.030556</td>\n",
       "      <td>-0.023477</td>\n",
       "      <td>-0.006542</td>\n",
       "      <td>0.181260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TimeWeekDay_IN_VUL_12</th>\n",
       "      <td>-0.017269</td>\n",
       "      <td>-0.012512</td>\n",
       "      <td>0.005681</td>\n",
       "      <td>-0.006106</td>\n",
       "      <td>-0.016567</td>\n",
       "      <td>-0.001686</td>\n",
       "      <td>-0.014790</td>\n",
       "      <td>0.010649</td>\n",
       "      <td>-0.073295</td>\n",
       "      <td>-0.010201</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.022686</td>\n",
       "      <td>0.005547</td>\n",
       "      <td>0.010726</td>\n",
       "      <td>0.067460</td>\n",
       "      <td>-0.003426</td>\n",
       "      <td>-0.012760</td>\n",
       "      <td>0.032635</td>\n",
       "      <td>-0.030761</td>\n",
       "      <td>-0.007438</td>\n",
       "      <td>0.218512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CallsWeekEnd_IN_VUL_12</th>\n",
       "      <td>-0.019733</td>\n",
       "      <td>-0.016008</td>\n",
       "      <td>0.002096</td>\n",
       "      <td>-0.010015</td>\n",
       "      <td>-0.021943</td>\n",
       "      <td>-0.005365</td>\n",
       "      <td>-0.016141</td>\n",
       "      <td>0.004797</td>\n",
       "      <td>-0.085622</td>\n",
       "      <td>-0.011813</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.026017</td>\n",
       "      <td>0.003175</td>\n",
       "      <td>0.003951</td>\n",
       "      <td>0.082933</td>\n",
       "      <td>-0.009613</td>\n",
       "      <td>-0.017490</td>\n",
       "      <td>0.044180</td>\n",
       "      <td>-0.035228</td>\n",
       "      <td>-0.010155</td>\n",
       "      <td>0.260075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TimeWeekNight_IN_VUL_12</th>\n",
       "      <td>-0.008331</td>\n",
       "      <td>-0.005395</td>\n",
       "      <td>0.009430</td>\n",
       "      <td>-0.001179</td>\n",
       "      <td>-0.005873</td>\n",
       "      <td>-0.001072</td>\n",
       "      <td>-0.007739</td>\n",
       "      <td>0.006901</td>\n",
       "      <td>-0.033393</td>\n",
       "      <td>-0.006719</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009778</td>\n",
       "      <td>0.001765</td>\n",
       "      <td>0.010466</td>\n",
       "      <td>0.044710</td>\n",
       "      <td>0.002314</td>\n",
       "      <td>-0.002664</td>\n",
       "      <td>0.016526</td>\n",
       "      <td>-0.012363</td>\n",
       "      <td>-0.004821</td>\n",
       "      <td>0.130211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VULNERABLE_IN_12</th>\n",
       "      <td>-0.039073</td>\n",
       "      <td>-0.028259</td>\n",
       "      <td>0.010560</td>\n",
       "      <td>-0.014084</td>\n",
       "      <td>-0.039697</td>\n",
       "      <td>-0.013364</td>\n",
       "      <td>-0.034440</td>\n",
       "      <td>0.012244</td>\n",
       "      <td>-0.148437</td>\n",
       "      <td>-0.022464</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.049569</td>\n",
       "      <td>0.016128</td>\n",
       "      <td>0.016371</td>\n",
       "      <td>0.119048</td>\n",
       "      <td>-0.015639</td>\n",
       "      <td>-0.024392</td>\n",
       "      <td>0.133377</td>\n",
       "      <td>-0.074454</td>\n",
       "      <td>-0.019893</td>\n",
       "      <td>0.501857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TimeWeekEnd_OUT_VUL_08</th>\n",
       "      <td>-0.014888</td>\n",
       "      <td>-0.006016</td>\n",
       "      <td>0.012968</td>\n",
       "      <td>0.000801</td>\n",
       "      <td>-0.010508</td>\n",
       "      <td>-0.002863</td>\n",
       "      <td>-0.009138</td>\n",
       "      <td>0.009581</td>\n",
       "      <td>-0.066524</td>\n",
       "      <td>-0.010299</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.016996</td>\n",
       "      <td>0.008099</td>\n",
       "      <td>0.006049</td>\n",
       "      <td>0.043162</td>\n",
       "      <td>-0.009573</td>\n",
       "      <td>-0.014808</td>\n",
       "      <td>0.028026</td>\n",
       "      <td>-0.027693</td>\n",
       "      <td>-0.009406</td>\n",
       "      <td>0.212387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CallsWeekDay_OUT_VUL_08</th>\n",
       "      <td>-0.023667</td>\n",
       "      <td>-0.015612</td>\n",
       "      <td>0.002006</td>\n",
       "      <td>-0.012350</td>\n",
       "      <td>-0.024371</td>\n",
       "      <td>-0.008413</td>\n",
       "      <td>-0.016763</td>\n",
       "      <td>0.007694</td>\n",
       "      <td>-0.100517</td>\n",
       "      <td>-0.012728</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.027831</td>\n",
       "      <td>-0.000889</td>\n",
       "      <td>0.000859</td>\n",
       "      <td>0.056729</td>\n",
       "      <td>-0.011737</td>\n",
       "      <td>-0.023667</td>\n",
       "      <td>0.033539</td>\n",
       "      <td>-0.040270</td>\n",
       "      <td>-0.011249</td>\n",
       "      <td>0.285261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CallsWeekNight_OUT_VUL_08</th>\n",
       "      <td>-0.017918</td>\n",
       "      <td>-0.012333</td>\n",
       "      <td>0.006172</td>\n",
       "      <td>-0.004510</td>\n",
       "      <td>-0.018119</td>\n",
       "      <td>-0.006373</td>\n",
       "      <td>-0.012421</td>\n",
       "      <td>0.011807</td>\n",
       "      <td>-0.077437</td>\n",
       "      <td>-0.012022</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018302</td>\n",
       "      <td>0.001661</td>\n",
       "      <td>0.000097</td>\n",
       "      <td>0.058156</td>\n",
       "      <td>-0.006670</td>\n",
       "      <td>-0.016671</td>\n",
       "      <td>0.039821</td>\n",
       "      <td>-0.035165</td>\n",
       "      <td>-0.008376</td>\n",
       "      <td>0.251499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TimeWeekDay_OUT_VUL_08</th>\n",
       "      <td>-0.018726</td>\n",
       "      <td>-0.011476</td>\n",
       "      <td>0.004707</td>\n",
       "      <td>-0.003298</td>\n",
       "      <td>-0.017098</td>\n",
       "      <td>-0.004659</td>\n",
       "      <td>-0.013679</td>\n",
       "      <td>0.009222</td>\n",
       "      <td>-0.080285</td>\n",
       "      <td>-0.011460</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.022572</td>\n",
       "      <td>0.001723</td>\n",
       "      <td>0.001539</td>\n",
       "      <td>0.050420</td>\n",
       "      <td>-0.008699</td>\n",
       "      <td>-0.019548</td>\n",
       "      <td>0.028935</td>\n",
       "      <td>-0.032952</td>\n",
       "      <td>-0.009823</td>\n",
       "      <td>0.241347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CallsWeekEnd_OUT_VUL_08</th>\n",
       "      <td>-0.022615</td>\n",
       "      <td>-0.015607</td>\n",
       "      <td>0.006733</td>\n",
       "      <td>-0.011024</td>\n",
       "      <td>-0.023665</td>\n",
       "      <td>-0.008168</td>\n",
       "      <td>-0.015545</td>\n",
       "      <td>0.006173</td>\n",
       "      <td>-0.098373</td>\n",
       "      <td>-0.014137</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.027818</td>\n",
       "      <td>0.001105</td>\n",
       "      <td>0.003801</td>\n",
       "      <td>0.061533</td>\n",
       "      <td>-0.013403</td>\n",
       "      <td>-0.021107</td>\n",
       "      <td>0.040742</td>\n",
       "      <td>-0.041324</td>\n",
       "      <td>-0.012210</td>\n",
       "      <td>0.302695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TimeWeekNight_OUT_VUL_08</th>\n",
       "      <td>-0.009146</td>\n",
       "      <td>-0.004605</td>\n",
       "      <td>0.009587</td>\n",
       "      <td>0.007543</td>\n",
       "      <td>-0.006124</td>\n",
       "      <td>-0.002268</td>\n",
       "      <td>-0.005949</td>\n",
       "      <td>0.014619</td>\n",
       "      <td>-0.041173</td>\n",
       "      <td>-0.008213</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.008381</td>\n",
       "      <td>0.006252</td>\n",
       "      <td>0.001248</td>\n",
       "      <td>0.037715</td>\n",
       "      <td>-0.003574</td>\n",
       "      <td>-0.009628</td>\n",
       "      <td>0.026862</td>\n",
       "      <td>-0.021373</td>\n",
       "      <td>-0.005066</td>\n",
       "      <td>0.158270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VULNERABLE_OUT_08</th>\n",
       "      <td>-0.042068</td>\n",
       "      <td>-0.029876</td>\n",
       "      <td>0.011004</td>\n",
       "      <td>-0.016881</td>\n",
       "      <td>-0.043695</td>\n",
       "      <td>-0.011574</td>\n",
       "      <td>-0.033381</td>\n",
       "      <td>0.009990</td>\n",
       "      <td>-0.163333</td>\n",
       "      <td>-0.024895</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.055620</td>\n",
       "      <td>0.007313</td>\n",
       "      <td>0.008928</td>\n",
       "      <td>0.117939</td>\n",
       "      <td>-0.021691</td>\n",
       "      <td>-0.027511</td>\n",
       "      <td>0.148312</td>\n",
       "      <td>-0.079833</td>\n",
       "      <td>-0.020899</td>\n",
       "      <td>0.553884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TimeWeekEnd_IN_VUL_08</th>\n",
       "      <td>-0.012433</td>\n",
       "      <td>-0.006905</td>\n",
       "      <td>0.010277</td>\n",
       "      <td>0.001186</td>\n",
       "      <td>-0.011913</td>\n",
       "      <td>-0.000447</td>\n",
       "      <td>-0.009536</td>\n",
       "      <td>0.007084</td>\n",
       "      <td>-0.066346</td>\n",
       "      <td>-0.009039</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.016378</td>\n",
       "      <td>0.003768</td>\n",
       "      <td>-0.002875</td>\n",
       "      <td>0.044014</td>\n",
       "      <td>-0.008132</td>\n",
       "      <td>-0.011787</td>\n",
       "      <td>0.029405</td>\n",
       "      <td>-0.024769</td>\n",
       "      <td>-0.009613</td>\n",
       "      <td>0.210637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CallsWeekDay_IN_VUL_08</th>\n",
       "      <td>-0.023635</td>\n",
       "      <td>-0.017116</td>\n",
       "      <td>0.000570</td>\n",
       "      <td>-0.014565</td>\n",
       "      <td>-0.025160</td>\n",
       "      <td>-0.008731</td>\n",
       "      <td>-0.016592</td>\n",
       "      <td>0.003383</td>\n",
       "      <td>-0.102761</td>\n",
       "      <td>-0.012637</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.028898</td>\n",
       "      <td>-0.002120</td>\n",
       "      <td>0.001790</td>\n",
       "      <td>0.056114</td>\n",
       "      <td>-0.013970</td>\n",
       "      <td>-0.022312</td>\n",
       "      <td>0.034086</td>\n",
       "      <td>-0.040130</td>\n",
       "      <td>-0.011147</td>\n",
       "      <td>0.292085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CallsWeekNight_IN_VUL_08</th>\n",
       "      <td>-0.017572</td>\n",
       "      <td>-0.014226</td>\n",
       "      <td>0.004031</td>\n",
       "      <td>-0.007094</td>\n",
       "      <td>-0.020109</td>\n",
       "      <td>-0.007246</td>\n",
       "      <td>-0.013465</td>\n",
       "      <td>0.006743</td>\n",
       "      <td>-0.081616</td>\n",
       "      <td>-0.011378</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.020754</td>\n",
       "      <td>-0.002726</td>\n",
       "      <td>-0.003261</td>\n",
       "      <td>0.057936</td>\n",
       "      <td>-0.011224</td>\n",
       "      <td>-0.015673</td>\n",
       "      <td>0.039996</td>\n",
       "      <td>-0.034734</td>\n",
       "      <td>-0.009078</td>\n",
       "      <td>0.256445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TimeWeekDay_IN_VUL_08</th>\n",
       "      <td>-0.017795</td>\n",
       "      <td>-0.012824</td>\n",
       "      <td>0.003353</td>\n",
       "      <td>-0.005423</td>\n",
       "      <td>-0.015726</td>\n",
       "      <td>-0.004322</td>\n",
       "      <td>-0.013246</td>\n",
       "      <td>0.004251</td>\n",
       "      <td>-0.081709</td>\n",
       "      <td>-0.010805</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.021825</td>\n",
       "      <td>0.000841</td>\n",
       "      <td>0.002633</td>\n",
       "      <td>0.047508</td>\n",
       "      <td>-0.010085</td>\n",
       "      <td>-0.017013</td>\n",
       "      <td>0.030258</td>\n",
       "      <td>-0.032017</td>\n",
       "      <td>-0.009567</td>\n",
       "      <td>0.240071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CallsWeekEnd_IN_VUL_08</th>\n",
       "      <td>-0.022465</td>\n",
       "      <td>-0.017283</td>\n",
       "      <td>0.002169</td>\n",
       "      <td>-0.012631</td>\n",
       "      <td>-0.025949</td>\n",
       "      <td>-0.008586</td>\n",
       "      <td>-0.016163</td>\n",
       "      <td>0.004962</td>\n",
       "      <td>-0.101655</td>\n",
       "      <td>-0.013285</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.029035</td>\n",
       "      <td>-0.001719</td>\n",
       "      <td>-0.002320</td>\n",
       "      <td>0.064650</td>\n",
       "      <td>-0.015482</td>\n",
       "      <td>-0.020940</td>\n",
       "      <td>0.041274</td>\n",
       "      <td>-0.040855</td>\n",
       "      <td>-0.012837</td>\n",
       "      <td>0.311608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TimeWeekNight_IN_VUL_08</th>\n",
       "      <td>-0.007130</td>\n",
       "      <td>-0.005548</td>\n",
       "      <td>0.008463</td>\n",
       "      <td>0.004672</td>\n",
       "      <td>-0.007582</td>\n",
       "      <td>-0.001964</td>\n",
       "      <td>-0.006486</td>\n",
       "      <td>0.007902</td>\n",
       "      <td>-0.042644</td>\n",
       "      <td>-0.007133</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.007680</td>\n",
       "      <td>0.001205</td>\n",
       "      <td>-0.002124</td>\n",
       "      <td>0.039534</td>\n",
       "      <td>-0.004664</td>\n",
       "      <td>-0.007273</td>\n",
       "      <td>0.027516</td>\n",
       "      <td>-0.019412</td>\n",
       "      <td>-0.004548</td>\n",
       "      <td>0.150745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VULNERABLE_IN_10</th>\n",
       "      <td>-0.038625</td>\n",
       "      <td>-0.030801</td>\n",
       "      <td>0.010946</td>\n",
       "      <td>-0.019521</td>\n",
       "      <td>-0.043353</td>\n",
       "      <td>-0.013185</td>\n",
       "      <td>-0.033649</td>\n",
       "      <td>0.008419</td>\n",
       "      <td>-0.153595</td>\n",
       "      <td>-0.024127</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.052471</td>\n",
       "      <td>0.017044</td>\n",
       "      <td>0.012636</td>\n",
       "      <td>0.115118</td>\n",
       "      <td>-0.022143</td>\n",
       "      <td>-0.026024</td>\n",
       "      <td>0.137516</td>\n",
       "      <td>-0.077313</td>\n",
       "      <td>-0.020346</td>\n",
       "      <td>0.520670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TimeWeekEnd_OUT_VUL_11</th>\n",
       "      <td>-0.014707</td>\n",
       "      <td>-0.000894</td>\n",
       "      <td>0.012022</td>\n",
       "      <td>-0.000866</td>\n",
       "      <td>-0.009295</td>\n",
       "      <td>-0.005395</td>\n",
       "      <td>-0.008423</td>\n",
       "      <td>0.010130</td>\n",
       "      <td>-0.060510</td>\n",
       "      <td>-0.009805</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.016946</td>\n",
       "      <td>0.004187</td>\n",
       "      <td>0.010818</td>\n",
       "      <td>0.055936</td>\n",
       "      <td>-0.001120</td>\n",
       "      <td>-0.013572</td>\n",
       "      <td>0.032943</td>\n",
       "      <td>-0.027074</td>\n",
       "      <td>-0.008618</td>\n",
       "      <td>0.200561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CallsWeekDay_OUT_VUL_11</th>\n",
       "      <td>-0.022992</td>\n",
       "      <td>-0.015743</td>\n",
       "      <td>0.001785</td>\n",
       "      <td>-0.012608</td>\n",
       "      <td>-0.024111</td>\n",
       "      <td>-0.008435</td>\n",
       "      <td>-0.016663</td>\n",
       "      <td>0.006639</td>\n",
       "      <td>-0.098876</td>\n",
       "      <td>-0.013194</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.027827</td>\n",
       "      <td>0.000382</td>\n",
       "      <td>0.007579</td>\n",
       "      <td>0.064408</td>\n",
       "      <td>-0.010861</td>\n",
       "      <td>-0.023713</td>\n",
       "      <td>0.037267</td>\n",
       "      <td>-0.040092</td>\n",
       "      <td>-0.011508</td>\n",
       "      <td>0.269011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CallsWeekNight_OUT_VUL_11</th>\n",
       "      <td>-0.018888</td>\n",
       "      <td>-0.007526</td>\n",
       "      <td>0.002922</td>\n",
       "      <td>-0.004930</td>\n",
       "      <td>-0.015121</td>\n",
       "      <td>-0.006878</td>\n",
       "      <td>-0.013044</td>\n",
       "      <td>0.008630</td>\n",
       "      <td>-0.066158</td>\n",
       "      <td>-0.011169</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018366</td>\n",
       "      <td>0.002375</td>\n",
       "      <td>0.006771</td>\n",
       "      <td>0.057972</td>\n",
       "      <td>-0.006027</td>\n",
       "      <td>-0.015346</td>\n",
       "      <td>0.038968</td>\n",
       "      <td>-0.031788</td>\n",
       "      <td>-0.007673</td>\n",
       "      <td>0.228012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TimeWeekDay_OUT_VUL_11</th>\n",
       "      <td>-0.018876</td>\n",
       "      <td>-0.008520</td>\n",
       "      <td>0.006175</td>\n",
       "      <td>-0.005550</td>\n",
       "      <td>-0.016178</td>\n",
       "      <td>-0.005120</td>\n",
       "      <td>-0.013186</td>\n",
       "      <td>0.009317</td>\n",
       "      <td>-0.076616</td>\n",
       "      <td>-0.011626</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.023102</td>\n",
       "      <td>0.005388</td>\n",
       "      <td>0.010241</td>\n",
       "      <td>0.055892</td>\n",
       "      <td>-0.006675</td>\n",
       "      <td>-0.020542</td>\n",
       "      <td>0.030435</td>\n",
       "      <td>-0.032526</td>\n",
       "      <td>-0.010093</td>\n",
       "      <td>0.230498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CallsWeekEnd_OUT_VUL_11</th>\n",
       "      <td>-0.022659</td>\n",
       "      <td>-0.014022</td>\n",
       "      <td>0.004288</td>\n",
       "      <td>-0.010512</td>\n",
       "      <td>-0.022154</td>\n",
       "      <td>-0.008321</td>\n",
       "      <td>-0.015568</td>\n",
       "      <td>0.007385</td>\n",
       "      <td>-0.096141</td>\n",
       "      <td>-0.013460</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.027295</td>\n",
       "      <td>-0.000889</td>\n",
       "      <td>0.008332</td>\n",
       "      <td>0.074566</td>\n",
       "      <td>-0.008616</td>\n",
       "      <td>-0.021581</td>\n",
       "      <td>0.047258</td>\n",
       "      <td>-0.040323</td>\n",
       "      <td>-0.012025</td>\n",
       "      <td>0.281308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TimeWeekNight_OUT_VUL_11</th>\n",
       "      <td>-0.010594</td>\n",
       "      <td>0.002235</td>\n",
       "      <td>0.005578</td>\n",
       "      <td>0.005391</td>\n",
       "      <td>-0.004070</td>\n",
       "      <td>-0.003349</td>\n",
       "      <td>-0.006980</td>\n",
       "      <td>0.007482</td>\n",
       "      <td>-0.029528</td>\n",
       "      <td>-0.007502</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.008709</td>\n",
       "      <td>0.007481</td>\n",
       "      <td>0.009330</td>\n",
       "      <td>0.037985</td>\n",
       "      <td>-0.003169</td>\n",
       "      <td>-0.009030</td>\n",
       "      <td>0.021632</td>\n",
       "      <td>-0.018083</td>\n",
       "      <td>-0.004057</td>\n",
       "      <td>0.150229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VULNERABLE_OUT_11</th>\n",
       "      <td>-0.038449</td>\n",
       "      <td>-0.029018</td>\n",
       "      <td>0.008253</td>\n",
       "      <td>-0.019533</td>\n",
       "      <td>-0.043642</td>\n",
       "      <td>-0.014989</td>\n",
       "      <td>-0.034372</td>\n",
       "      <td>0.010196</td>\n",
       "      <td>-0.154592</td>\n",
       "      <td>-0.025856</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.053477</td>\n",
       "      <td>0.014015</td>\n",
       "      <td>0.016510</td>\n",
       "      <td>0.113726</td>\n",
       "      <td>-0.017535</td>\n",
       "      <td>-0.025637</td>\n",
       "      <td>0.139138</td>\n",
       "      <td>-0.079135</td>\n",
       "      <td>-0.022685</td>\n",
       "      <td>0.514446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TimeWeekEnd_IN_VUL_11</th>\n",
       "      <td>-0.015505</td>\n",
       "      <td>-0.005516</td>\n",
       "      <td>0.013516</td>\n",
       "      <td>-0.000154</td>\n",
       "      <td>-0.011698</td>\n",
       "      <td>-0.000745</td>\n",
       "      <td>-0.009516</td>\n",
       "      <td>0.003122</td>\n",
       "      <td>-0.059657</td>\n",
       "      <td>-0.008961</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.015455</td>\n",
       "      <td>0.004553</td>\n",
       "      <td>0.005230</td>\n",
       "      <td>0.051093</td>\n",
       "      <td>-0.007191</td>\n",
       "      <td>-0.009467</td>\n",
       "      <td>0.035859</td>\n",
       "      <td>-0.019347</td>\n",
       "      <td>-0.008244</td>\n",
       "      <td>0.190351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CallsWeekDay_IN_VUL_11</th>\n",
       "      <td>-0.022309</td>\n",
       "      <td>-0.018199</td>\n",
       "      <td>0.001485</td>\n",
       "      <td>-0.014797</td>\n",
       "      <td>-0.024042</td>\n",
       "      <td>-0.007438</td>\n",
       "      <td>-0.016817</td>\n",
       "      <td>0.003384</td>\n",
       "      <td>-0.098711</td>\n",
       "      <td>-0.012627</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.027713</td>\n",
       "      <td>-0.002496</td>\n",
       "      <td>0.003655</td>\n",
       "      <td>0.064531</td>\n",
       "      <td>-0.012215</td>\n",
       "      <td>-0.022834</td>\n",
       "      <td>0.037939</td>\n",
       "      <td>-0.038280</td>\n",
       "      <td>-0.011395</td>\n",
       "      <td>0.266690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CallsWeekNight_IN_VUL_11</th>\n",
       "      <td>-0.018739</td>\n",
       "      <td>-0.010789</td>\n",
       "      <td>0.004358</td>\n",
       "      <td>-0.008916</td>\n",
       "      <td>-0.017363</td>\n",
       "      <td>-0.004976</td>\n",
       "      <td>-0.011990</td>\n",
       "      <td>0.005618</td>\n",
       "      <td>-0.066532</td>\n",
       "      <td>-0.010646</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.019545</td>\n",
       "      <td>-0.000111</td>\n",
       "      <td>0.003899</td>\n",
       "      <td>0.060754</td>\n",
       "      <td>-0.009046</td>\n",
       "      <td>-0.013440</td>\n",
       "      <td>0.037173</td>\n",
       "      <td>-0.027962</td>\n",
       "      <td>-0.008683</td>\n",
       "      <td>0.218783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TimeWeekDay_IN_VUL_11</th>\n",
       "      <td>-0.016199</td>\n",
       "      <td>-0.011827</td>\n",
       "      <td>0.003853</td>\n",
       "      <td>-0.007973</td>\n",
       "      <td>-0.013790</td>\n",
       "      <td>-0.003741</td>\n",
       "      <td>-0.012845</td>\n",
       "      <td>0.005394</td>\n",
       "      <td>-0.072231</td>\n",
       "      <td>-0.010397</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.021225</td>\n",
       "      <td>0.001796</td>\n",
       "      <td>0.004030</td>\n",
       "      <td>0.053296</td>\n",
       "      <td>-0.007177</td>\n",
       "      <td>-0.017130</td>\n",
       "      <td>0.029249</td>\n",
       "      <td>-0.027297</td>\n",
       "      <td>-0.009044</td>\n",
       "      <td>0.211713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CallsWeekEnd_IN_VUL_11</th>\n",
       "      <td>-0.022474</td>\n",
       "      <td>-0.016748</td>\n",
       "      <td>0.003279</td>\n",
       "      <td>-0.011547</td>\n",
       "      <td>-0.024820</td>\n",
       "      <td>-0.005919</td>\n",
       "      <td>-0.016264</td>\n",
       "      <td>0.001047</td>\n",
       "      <td>-0.095917</td>\n",
       "      <td>-0.013188</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.027310</td>\n",
       "      <td>-0.000805</td>\n",
       "      <td>0.004629</td>\n",
       "      <td>0.073001</td>\n",
       "      <td>-0.013356</td>\n",
       "      <td>-0.019970</td>\n",
       "      <td>0.046165</td>\n",
       "      <td>-0.037765</td>\n",
       "      <td>-0.011987</td>\n",
       "      <td>0.280185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TimeWeekNight_IN_VUL_11</th>\n",
       "      <td>-0.010118</td>\n",
       "      <td>-0.002565</td>\n",
       "      <td>0.007578</td>\n",
       "      <td>-0.000452</td>\n",
       "      <td>-0.005215</td>\n",
       "      <td>-0.000333</td>\n",
       "      <td>-0.004821</td>\n",
       "      <td>0.004545</td>\n",
       "      <td>-0.029192</td>\n",
       "      <td>-0.006366</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.007435</td>\n",
       "      <td>0.004680</td>\n",
       "      <td>0.005555</td>\n",
       "      <td>0.037559</td>\n",
       "      <td>-0.004457</td>\n",
       "      <td>-0.005180</td>\n",
       "      <td>0.018948</td>\n",
       "      <td>-0.010990</td>\n",
       "      <td>-0.004018</td>\n",
       "      <td>0.125179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VULNERABLE_IN_11</th>\n",
       "      <td>-0.038910</td>\n",
       "      <td>-0.030505</td>\n",
       "      <td>0.009835</td>\n",
       "      <td>-0.017472</td>\n",
       "      <td>-0.043343</td>\n",
       "      <td>-0.013814</td>\n",
       "      <td>-0.032883</td>\n",
       "      <td>0.009834</td>\n",
       "      <td>-0.153931</td>\n",
       "      <td>-0.024708</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.053784</td>\n",
       "      <td>0.014667</td>\n",
       "      <td>0.015563</td>\n",
       "      <td>0.116492</td>\n",
       "      <td>-0.019714</td>\n",
       "      <td>-0.026946</td>\n",
       "      <td>0.138680</td>\n",
       "      <td>-0.078379</td>\n",
       "      <td>-0.019417</td>\n",
       "      <td>0.518484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STATE_Baja_California_Sur</th>\n",
       "      <td>-0.003993</td>\n",
       "      <td>-0.003604</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.003288</td>\n",
       "      <td>-0.004907</td>\n",
       "      <td>-0.002358</td>\n",
       "      <td>-0.002652</td>\n",
       "      <td>-0.002554</td>\n",
       "      <td>-0.019669</td>\n",
       "      <td>-0.001967</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.004535</td>\n",
       "      <td>-0.003000</td>\n",
       "      <td>-0.002159</td>\n",
       "      <td>-0.005695</td>\n",
       "      <td>-0.002930</td>\n",
       "      <td>-0.005011</td>\n",
       "      <td>-0.007592</td>\n",
       "      <td>-0.006224</td>\n",
       "      <td>-0.001975</td>\n",
       "      <td>0.027414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STATE_Colima</th>\n",
       "      <td>-0.007047</td>\n",
       "      <td>-0.006362</td>\n",
       "      <td>-0.002554</td>\n",
       "      <td>-0.005804</td>\n",
       "      <td>-0.008660</td>\n",
       "      <td>-0.004162</td>\n",
       "      <td>-0.004681</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.034715</td>\n",
       "      <td>-0.003471</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.008004</td>\n",
       "      <td>-0.005295</td>\n",
       "      <td>-0.003810</td>\n",
       "      <td>-0.010052</td>\n",
       "      <td>-0.005172</td>\n",
       "      <td>-0.008844</td>\n",
       "      <td>-0.013400</td>\n",
       "      <td>-0.010985</td>\n",
       "      <td>-0.003485</td>\n",
       "      <td>0.013175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STATE_Guerrero</th>\n",
       "      <td>-0.013936</td>\n",
       "      <td>-0.012581</td>\n",
       "      <td>-0.005052</td>\n",
       "      <td>-0.011478</td>\n",
       "      <td>-0.017127</td>\n",
       "      <td>-0.008231</td>\n",
       "      <td>-0.009258</td>\n",
       "      <td>-0.008916</td>\n",
       "      <td>-0.068655</td>\n",
       "      <td>-0.006865</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.015829</td>\n",
       "      <td>-0.010472</td>\n",
       "      <td>-0.007536</td>\n",
       "      <td>-0.019879</td>\n",
       "      <td>-0.010228</td>\n",
       "      <td>-0.017491</td>\n",
       "      <td>-0.026502</td>\n",
       "      <td>-0.021724</td>\n",
       "      <td>-0.006893</td>\n",
       "      <td>0.056422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STATE_Hidalgo</th>\n",
       "      <td>-0.023226</td>\n",
       "      <td>-0.020968</td>\n",
       "      <td>-0.008420</td>\n",
       "      <td>-0.019128</td>\n",
       "      <td>-0.028544</td>\n",
       "      <td>-0.013718</td>\n",
       "      <td>-0.015429</td>\n",
       "      <td>-0.014860</td>\n",
       "      <td>-0.114419</td>\n",
       "      <td>-0.011441</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.026380</td>\n",
       "      <td>-0.017452</td>\n",
       "      <td>-0.012559</td>\n",
       "      <td>-0.033130</td>\n",
       "      <td>-0.017045</td>\n",
       "      <td>-0.029149</td>\n",
       "      <td>-0.044167</td>\n",
       "      <td>-0.036205</td>\n",
       "      <td>-0.011488</td>\n",
       "      <td>0.105358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STATE_Jalisco</th>\n",
       "      <td>-0.034410</td>\n",
       "      <td>-0.031065</td>\n",
       "      <td>-0.012474</td>\n",
       "      <td>-0.028340</td>\n",
       "      <td>-0.042289</td>\n",
       "      <td>-0.020324</td>\n",
       "      <td>-0.022859</td>\n",
       "      <td>-0.022016</td>\n",
       "      <td>-0.169519</td>\n",
       "      <td>-0.016950</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.039084</td>\n",
       "      <td>-0.025857</td>\n",
       "      <td>-0.018607</td>\n",
       "      <td>-0.049084</td>\n",
       "      <td>-0.025254</td>\n",
       "      <td>-0.043187</td>\n",
       "      <td>-0.065436</td>\n",
       "      <td>-0.053640</td>\n",
       "      <td>-0.017020</td>\n",
       "      <td>0.258447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STATE_Morelos</th>\n",
       "      <td>-0.018501</td>\n",
       "      <td>-0.016702</td>\n",
       "      <td>-0.006707</td>\n",
       "      <td>-0.015237</td>\n",
       "      <td>-0.022737</td>\n",
       "      <td>-0.010927</td>\n",
       "      <td>-0.012290</td>\n",
       "      <td>-0.011837</td>\n",
       "      <td>-0.091141</td>\n",
       "      <td>-0.009113</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.021013</td>\n",
       "      <td>-0.013902</td>\n",
       "      <td>-0.010004</td>\n",
       "      <td>-0.026390</td>\n",
       "      <td>-0.013578</td>\n",
       "      <td>-0.023219</td>\n",
       "      <td>-0.035181</td>\n",
       "      <td>-0.028839</td>\n",
       "      <td>-0.009151</td>\n",
       "      <td>0.103912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STATE_Nayarit</th>\n",
       "      <td>-0.009512</td>\n",
       "      <td>-0.008588</td>\n",
       "      <td>-0.003448</td>\n",
       "      <td>-0.007834</td>\n",
       "      <td>-0.011690</td>\n",
       "      <td>-0.005618</td>\n",
       "      <td>-0.006319</td>\n",
       "      <td>-0.006086</td>\n",
       "      <td>-0.046862</td>\n",
       "      <td>-0.004686</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.010804</td>\n",
       "      <td>-0.007148</td>\n",
       "      <td>-0.005144</td>\n",
       "      <td>-0.013569</td>\n",
       "      <td>-0.006981</td>\n",
       "      <td>-0.011938</td>\n",
       "      <td>-0.018089</td>\n",
       "      <td>-0.014828</td>\n",
       "      <td>-0.004705</td>\n",
       "      <td>0.010793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STATE_Oaxaca</th>\n",
       "      <td>-0.011202</td>\n",
       "      <td>-0.010113</td>\n",
       "      <td>-0.004061</td>\n",
       "      <td>-0.009225</td>\n",
       "      <td>-0.013766</td>\n",
       "      <td>-0.006616</td>\n",
       "      <td>-0.007441</td>\n",
       "      <td>-0.007167</td>\n",
       "      <td>-0.055184</td>\n",
       "      <td>-0.005518</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.012723</td>\n",
       "      <td>-0.008417</td>\n",
       "      <td>-0.006057</td>\n",
       "      <td>-0.015978</td>\n",
       "      <td>-0.008221</td>\n",
       "      <td>-0.014059</td>\n",
       "      <td>-0.021301</td>\n",
       "      <td>-0.017461</td>\n",
       "      <td>-0.005540</td>\n",
       "      <td>0.051564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STATE_Puebla</th>\n",
       "      <td>-0.023305</td>\n",
       "      <td>-0.021040</td>\n",
       "      <td>-0.008448</td>\n",
       "      <td>-0.019194</td>\n",
       "      <td>-0.028641</td>\n",
       "      <td>-0.013765</td>\n",
       "      <td>-0.015482</td>\n",
       "      <td>-0.014911</td>\n",
       "      <td>-0.114811</td>\n",
       "      <td>-0.011480</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.026470</td>\n",
       "      <td>-0.017512</td>\n",
       "      <td>-0.012602</td>\n",
       "      <td>-0.033243</td>\n",
       "      <td>-0.017104</td>\n",
       "      <td>-0.029249</td>\n",
       "      <td>-0.044318</td>\n",
       "      <td>-0.036329</td>\n",
       "      <td>-0.011527</td>\n",
       "      <td>0.138836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STATE_Sinaloa</th>\n",
       "      <td>-0.008276</td>\n",
       "      <td>-0.007472</td>\n",
       "      <td>-0.003000</td>\n",
       "      <td>-0.006816</td>\n",
       "      <td>-0.010171</td>\n",
       "      <td>-0.004888</td>\n",
       "      <td>-0.005498</td>\n",
       "      <td>-0.005295</td>\n",
       "      <td>-0.040771</td>\n",
       "      <td>-0.004077</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009400</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.004475</td>\n",
       "      <td>-0.011805</td>\n",
       "      <td>-0.006074</td>\n",
       "      <td>-0.010387</td>\n",
       "      <td>-0.015738</td>\n",
       "      <td>-0.012901</td>\n",
       "      <td>-0.004093</td>\n",
       "      <td>0.036188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STATE_Sonora</th>\n",
       "      <td>-0.005956</td>\n",
       "      <td>-0.005377</td>\n",
       "      <td>-0.002159</td>\n",
       "      <td>-0.004905</td>\n",
       "      <td>-0.007319</td>\n",
       "      <td>-0.003518</td>\n",
       "      <td>-0.003956</td>\n",
       "      <td>-0.003810</td>\n",
       "      <td>-0.029340</td>\n",
       "      <td>-0.002934</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.006764</td>\n",
       "      <td>-0.004475</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.008495</td>\n",
       "      <td>-0.004371</td>\n",
       "      <td>-0.007475</td>\n",
       "      <td>-0.011325</td>\n",
       "      <td>-0.009284</td>\n",
       "      <td>-0.002946</td>\n",
       "      <td>0.033602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STATE_Tabasco</th>\n",
       "      <td>-0.015710</td>\n",
       "      <td>-0.014183</td>\n",
       "      <td>-0.005695</td>\n",
       "      <td>-0.012939</td>\n",
       "      <td>-0.019308</td>\n",
       "      <td>-0.009279</td>\n",
       "      <td>-0.010436</td>\n",
       "      <td>-0.010052</td>\n",
       "      <td>-0.077396</td>\n",
       "      <td>-0.007739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.017844</td>\n",
       "      <td>-0.011805</td>\n",
       "      <td>-0.008495</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.011530</td>\n",
       "      <td>-0.019717</td>\n",
       "      <td>-0.029875</td>\n",
       "      <td>-0.024490</td>\n",
       "      <td>-0.007770</td>\n",
       "      <td>0.095242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STATE_Tlaxcala</th>\n",
       "      <td>-0.013823</td>\n",
       "      <td>-0.012479</td>\n",
       "      <td>-0.005011</td>\n",
       "      <td>-0.011384</td>\n",
       "      <td>-0.016988</td>\n",
       "      <td>-0.008164</td>\n",
       "      <td>-0.009183</td>\n",
       "      <td>-0.008844</td>\n",
       "      <td>-0.068097</td>\n",
       "      <td>-0.006809</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.015700</td>\n",
       "      <td>-0.010387</td>\n",
       "      <td>-0.007475</td>\n",
       "      <td>-0.019717</td>\n",
       "      <td>-0.010145</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.026286</td>\n",
       "      <td>-0.021548</td>\n",
       "      <td>-0.006837</td>\n",
       "      <td>0.018890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STATE_Veracruz</th>\n",
       "      <td>-0.020944</td>\n",
       "      <td>-0.018908</td>\n",
       "      <td>-0.007592</td>\n",
       "      <td>-0.017249</td>\n",
       "      <td>-0.025740</td>\n",
       "      <td>-0.012370</td>\n",
       "      <td>-0.013913</td>\n",
       "      <td>-0.013400</td>\n",
       "      <td>-0.103180</td>\n",
       "      <td>-0.010317</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.023789</td>\n",
       "      <td>-0.015738</td>\n",
       "      <td>-0.011325</td>\n",
       "      <td>-0.029875</td>\n",
       "      <td>-0.015371</td>\n",
       "      <td>-0.026286</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.032649</td>\n",
       "      <td>-0.010359</td>\n",
       "      <td>0.159102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>target</th>\n",
       "      <td>-0.042675</td>\n",
       "      <td>-0.017924</td>\n",
       "      <td>0.027414</td>\n",
       "      <td>-0.009259</td>\n",
       "      <td>-0.036156</td>\n",
       "      <td>0.000266</td>\n",
       "      <td>-0.030959</td>\n",
       "      <td>0.013175</td>\n",
       "      <td>-0.138963</td>\n",
       "      <td>-0.021420</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.060276</td>\n",
       "      <td>0.036188</td>\n",
       "      <td>0.033602</td>\n",
       "      <td>0.095242</td>\n",
       "      <td>0.001172</td>\n",
       "      <td>0.018890</td>\n",
       "      <td>0.159102</td>\n",
       "      <td>-0.077954</td>\n",
       "      <td>-0.018073</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>88 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             STATE_Aguascalientes  STATE_Baja_California  \\\n",
       "MOBILITY_DIAMETER                        0.045902               0.145942   \n",
       "MOBILITY_DIAMETER_WEEKNIGHT              0.046654               0.145805   \n",
       "EPIDEMIC                                -0.070297              -0.063463   \n",
       "TimeWeekEnd_OUT_VUL_12                  -0.013845              -0.004919   \n",
       "CallsWeekDay_OUT_VUL_12                 -0.023551              -0.016264   \n",
       "CallsWeekNight_OUT_VUL_12               -0.018538              -0.010279   \n",
       "TimeWeekDay_OUT_VUL_12                  -0.018978              -0.009812   \n",
       "CallsWeekEnd_OUT_VUL_12                 -0.020222              -0.013935   \n",
       "TimeWeekNight_OUT_VUL_12                -0.011181              -0.002776   \n",
       "VULNERABLE_OUT_12                       -0.038502              -0.028439   \n",
       "TimeWeekEnd_IN_VUL_12                   -0.011941              -0.007219   \n",
       "CallsWeekDay_IN_VUL_12                  -0.022734              -0.017515   \n",
       "CallsWeekNight_IN_VUL_12                -0.014445              -0.010335   \n",
       "TimeWeekDay_IN_VUL_12                   -0.017269              -0.012512   \n",
       "CallsWeekEnd_IN_VUL_12                  -0.019733              -0.016008   \n",
       "TimeWeekNight_IN_VUL_12                 -0.008331              -0.005395   \n",
       "VULNERABLE_IN_12                        -0.039073              -0.028259   \n",
       "TimeWeekEnd_OUT_VUL_08                  -0.014888              -0.006016   \n",
       "CallsWeekDay_OUT_VUL_08                 -0.023667              -0.015612   \n",
       "CallsWeekNight_OUT_VUL_08               -0.017918              -0.012333   \n",
       "TimeWeekDay_OUT_VUL_08                  -0.018726              -0.011476   \n",
       "CallsWeekEnd_OUT_VUL_08                 -0.022615              -0.015607   \n",
       "TimeWeekNight_OUT_VUL_08                -0.009146              -0.004605   \n",
       "VULNERABLE_OUT_08                       -0.042068              -0.029876   \n",
       "TimeWeekEnd_IN_VUL_08                   -0.012433              -0.006905   \n",
       "CallsWeekDay_IN_VUL_08                  -0.023635              -0.017116   \n",
       "CallsWeekNight_IN_VUL_08                -0.017572              -0.014226   \n",
       "TimeWeekDay_IN_VUL_08                   -0.017795              -0.012824   \n",
       "CallsWeekEnd_IN_VUL_08                  -0.022465              -0.017283   \n",
       "TimeWeekNight_IN_VUL_08                 -0.007130              -0.005548   \n",
       "...                                           ...                    ...   \n",
       "VULNERABLE_IN_10                        -0.038625              -0.030801   \n",
       "TimeWeekEnd_OUT_VUL_11                  -0.014707              -0.000894   \n",
       "CallsWeekDay_OUT_VUL_11                 -0.022992              -0.015743   \n",
       "CallsWeekNight_OUT_VUL_11               -0.018888              -0.007526   \n",
       "TimeWeekDay_OUT_VUL_11                  -0.018876              -0.008520   \n",
       "CallsWeekEnd_OUT_VUL_11                 -0.022659              -0.014022   \n",
       "TimeWeekNight_OUT_VUL_11                -0.010594               0.002235   \n",
       "VULNERABLE_OUT_11                       -0.038449              -0.029018   \n",
       "TimeWeekEnd_IN_VUL_11                   -0.015505              -0.005516   \n",
       "CallsWeekDay_IN_VUL_11                  -0.022309              -0.018199   \n",
       "CallsWeekNight_IN_VUL_11                -0.018739              -0.010789   \n",
       "TimeWeekDay_IN_VUL_11                   -0.016199              -0.011827   \n",
       "CallsWeekEnd_IN_VUL_11                  -0.022474              -0.016748   \n",
       "TimeWeekNight_IN_VUL_11                 -0.010118              -0.002565   \n",
       "VULNERABLE_IN_11                        -0.038910              -0.030505   \n",
       "STATE_Baja_California_Sur               -0.003993              -0.003604   \n",
       "STATE_Colima                            -0.007047              -0.006362   \n",
       "STATE_Guerrero                          -0.013936              -0.012581   \n",
       "STATE_Hidalgo                           -0.023226              -0.020968   \n",
       "STATE_Jalisco                           -0.034410              -0.031065   \n",
       "STATE_Morelos                           -0.018501              -0.016702   \n",
       "STATE_Nayarit                           -0.009512              -0.008588   \n",
       "STATE_Oaxaca                            -0.011202              -0.010113   \n",
       "STATE_Puebla                            -0.023305              -0.021040   \n",
       "STATE_Sinaloa                           -0.008276              -0.007472   \n",
       "STATE_Sonora                            -0.005956              -0.005377   \n",
       "STATE_Tabasco                           -0.015710              -0.014183   \n",
       "STATE_Tlaxcala                          -0.013823              -0.012479   \n",
       "STATE_Veracruz                          -0.020944              -0.018908   \n",
       "target                                  -0.042675              -0.017924   \n",
       "\n",
       "                             STATE_Baja_California_Sur  STATE_Campeche  \\\n",
       "MOBILITY_DIAMETER                             0.032684        0.006103   \n",
       "MOBILITY_DIAMETER_WEEKNIGHT                   0.033328        0.006141   \n",
       "EPIDEMIC                                     -0.025483       -0.057895   \n",
       "TimeWeekEnd_OUT_VUL_12                        0.010538        0.000871   \n",
       "CallsWeekDay_OUT_VUL_12                       0.001278       -0.011864   \n",
       "CallsWeekNight_OUT_VUL_12                     0.007098       -0.002889   \n",
       "TimeWeekDay_OUT_VUL_12                        0.005776       -0.003502   \n",
       "CallsWeekEnd_OUT_VUL_12                       0.003964       -0.008532   \n",
       "TimeWeekNight_OUT_VUL_12                      0.011300        0.007510   \n",
       "VULNERABLE_OUT_12                             0.010884       -0.015736   \n",
       "TimeWeekEnd_IN_VUL_12                         0.009124        0.000403   \n",
       "CallsWeekDay_IN_VUL_12                        0.001092       -0.014149   \n",
       "CallsWeekNight_IN_VUL_12                      0.003971       -0.007689   \n",
       "TimeWeekDay_IN_VUL_12                         0.005681       -0.006106   \n",
       "CallsWeekEnd_IN_VUL_12                        0.002096       -0.010015   \n",
       "TimeWeekNight_IN_VUL_12                       0.009430       -0.001179   \n",
       "VULNERABLE_IN_12                              0.010560       -0.014084   \n",
       "TimeWeekEnd_OUT_VUL_08                        0.012968        0.000801   \n",
       "CallsWeekDay_OUT_VUL_08                       0.002006       -0.012350   \n",
       "CallsWeekNight_OUT_VUL_08                     0.006172       -0.004510   \n",
       "TimeWeekDay_OUT_VUL_08                        0.004707       -0.003298   \n",
       "CallsWeekEnd_OUT_VUL_08                       0.006733       -0.011024   \n",
       "TimeWeekNight_OUT_VUL_08                      0.009587        0.007543   \n",
       "VULNERABLE_OUT_08                             0.011004       -0.016881   \n",
       "TimeWeekEnd_IN_VUL_08                         0.010277        0.001186   \n",
       "CallsWeekDay_IN_VUL_08                        0.000570       -0.014565   \n",
       "CallsWeekNight_IN_VUL_08                      0.004031       -0.007094   \n",
       "TimeWeekDay_IN_VUL_08                         0.003353       -0.005423   \n",
       "CallsWeekEnd_IN_VUL_08                        0.002169       -0.012631   \n",
       "TimeWeekNight_IN_VUL_08                       0.008463        0.004672   \n",
       "...                                                ...             ...   \n",
       "VULNERABLE_IN_10                              0.010946       -0.019521   \n",
       "TimeWeekEnd_OUT_VUL_11                        0.012022       -0.000866   \n",
       "CallsWeekDay_OUT_VUL_11                       0.001785       -0.012608   \n",
       "CallsWeekNight_OUT_VUL_11                     0.002922       -0.004930   \n",
       "TimeWeekDay_OUT_VUL_11                        0.006175       -0.005550   \n",
       "CallsWeekEnd_OUT_VUL_11                       0.004288       -0.010512   \n",
       "TimeWeekNight_OUT_VUL_11                      0.005578        0.005391   \n",
       "VULNERABLE_OUT_11                             0.008253       -0.019533   \n",
       "TimeWeekEnd_IN_VUL_11                         0.013516       -0.000154   \n",
       "CallsWeekDay_IN_VUL_11                        0.001485       -0.014797   \n",
       "CallsWeekNight_IN_VUL_11                      0.004358       -0.008916   \n",
       "TimeWeekDay_IN_VUL_11                         0.003853       -0.007973   \n",
       "CallsWeekEnd_IN_VUL_11                        0.003279       -0.011547   \n",
       "TimeWeekNight_IN_VUL_11                       0.007578       -0.000452   \n",
       "VULNERABLE_IN_11                              0.009835       -0.017472   \n",
       "STATE_Baja_California_Sur                     1.000000       -0.003288   \n",
       "STATE_Colima                                 -0.002554       -0.005804   \n",
       "STATE_Guerrero                               -0.005052       -0.011478   \n",
       "STATE_Hidalgo                                -0.008420       -0.019128   \n",
       "STATE_Jalisco                                -0.012474       -0.028340   \n",
       "STATE_Morelos                                -0.006707       -0.015237   \n",
       "STATE_Nayarit                                -0.003448       -0.007834   \n",
       "STATE_Oaxaca                                 -0.004061       -0.009225   \n",
       "STATE_Puebla                                 -0.008448       -0.019194   \n",
       "STATE_Sinaloa                                -0.003000       -0.006816   \n",
       "STATE_Sonora                                 -0.002159       -0.004905   \n",
       "STATE_Tabasco                                -0.005695       -0.012939   \n",
       "STATE_Tlaxcala                               -0.005011       -0.011384   \n",
       "STATE_Veracruz                               -0.007592       -0.017249   \n",
       "target                                        0.027414       -0.009259   \n",
       "\n",
       "                             STATE_Chiapas  STATE_Chihuahua  \\\n",
       "MOBILITY_DIAMETER                -0.014679         0.024696   \n",
       "MOBILITY_DIAMETER_WEEKNIGHT      -0.009792         0.023230   \n",
       "EPIDEMIC                         -0.086392        -0.041519   \n",
       "TimeWeekEnd_OUT_VUL_12           -0.012463        -0.004699   \n",
       "CallsWeekDay_OUT_VUL_12          -0.023981        -0.007346   \n",
       "CallsWeekNight_OUT_VUL_12        -0.017992        -0.004098   \n",
       "TimeWeekDay_OUT_VUL_12           -0.016605        -0.004612   \n",
       "CallsWeekEnd_OUT_VUL_12          -0.022123        -0.007780   \n",
       "TimeWeekNight_OUT_VUL_12         -0.007542         0.001704   \n",
       "VULNERABLE_OUT_12                -0.041065        -0.014000   \n",
       "TimeWeekEnd_IN_VUL_12            -0.008797        -0.001187   \n",
       "CallsWeekDay_IN_VUL_12           -0.024679        -0.005824   \n",
       "CallsWeekNight_IN_VUL_12         -0.015009        -0.003297   \n",
       "TimeWeekDay_IN_VUL_12            -0.016567        -0.001686   \n",
       "CallsWeekEnd_IN_VUL_12           -0.021943        -0.005365   \n",
       "TimeWeekNight_IN_VUL_12          -0.005873        -0.001072   \n",
       "VULNERABLE_IN_12                 -0.039697        -0.013364   \n",
       "TimeWeekEnd_OUT_VUL_08           -0.010508        -0.002863   \n",
       "CallsWeekDay_OUT_VUL_08          -0.024371        -0.008413   \n",
       "CallsWeekNight_OUT_VUL_08        -0.018119        -0.006373   \n",
       "TimeWeekDay_OUT_VUL_08           -0.017098        -0.004659   \n",
       "CallsWeekEnd_OUT_VUL_08          -0.023665        -0.008168   \n",
       "TimeWeekNight_OUT_VUL_08         -0.006124        -0.002268   \n",
       "VULNERABLE_OUT_08                -0.043695        -0.011574   \n",
       "TimeWeekEnd_IN_VUL_08            -0.011913        -0.000447   \n",
       "CallsWeekDay_IN_VUL_08           -0.025160        -0.008731   \n",
       "CallsWeekNight_IN_VUL_08         -0.020109        -0.007246   \n",
       "TimeWeekDay_IN_VUL_08            -0.015726        -0.004322   \n",
       "CallsWeekEnd_IN_VUL_08           -0.025949        -0.008586   \n",
       "TimeWeekNight_IN_VUL_08          -0.007582        -0.001964   \n",
       "...                                    ...              ...   \n",
       "VULNERABLE_IN_10                 -0.043353        -0.013185   \n",
       "TimeWeekEnd_OUT_VUL_11           -0.009295        -0.005395   \n",
       "CallsWeekDay_OUT_VUL_11          -0.024111        -0.008435   \n",
       "CallsWeekNight_OUT_VUL_11        -0.015121        -0.006878   \n",
       "TimeWeekDay_OUT_VUL_11           -0.016178        -0.005120   \n",
       "CallsWeekEnd_OUT_VUL_11          -0.022154        -0.008321   \n",
       "TimeWeekNight_OUT_VUL_11         -0.004070        -0.003349   \n",
       "VULNERABLE_OUT_11                -0.043642        -0.014989   \n",
       "TimeWeekEnd_IN_VUL_11            -0.011698        -0.000745   \n",
       "CallsWeekDay_IN_VUL_11           -0.024042        -0.007438   \n",
       "CallsWeekNight_IN_VUL_11         -0.017363        -0.004976   \n",
       "TimeWeekDay_IN_VUL_11            -0.013790        -0.003741   \n",
       "CallsWeekEnd_IN_VUL_11           -0.024820        -0.005919   \n",
       "TimeWeekNight_IN_VUL_11          -0.005215        -0.000333   \n",
       "VULNERABLE_IN_11                 -0.043343        -0.013814   \n",
       "STATE_Baja_California_Sur        -0.004907        -0.002358   \n",
       "STATE_Colima                     -0.008660        -0.004162   \n",
       "STATE_Guerrero                   -0.017127        -0.008231   \n",
       "STATE_Hidalgo                    -0.028544        -0.013718   \n",
       "STATE_Jalisco                    -0.042289        -0.020324   \n",
       "STATE_Morelos                    -0.022737        -0.010927   \n",
       "STATE_Nayarit                    -0.011690        -0.005618   \n",
       "STATE_Oaxaca                     -0.013766        -0.006616   \n",
       "STATE_Puebla                     -0.028641        -0.013765   \n",
       "STATE_Sinaloa                    -0.010171        -0.004888   \n",
       "STATE_Sonora                     -0.007319        -0.003518   \n",
       "STATE_Tabasco                    -0.019308        -0.009279   \n",
       "STATE_Tlaxcala                   -0.016988        -0.008164   \n",
       "STATE_Veracruz                   -0.025740        -0.012370   \n",
       "target                           -0.036156         0.000266   \n",
       "\n",
       "                             STATE_Coahuila_de_Zaragoza  STATE_Colima  \\\n",
       "MOBILITY_DIAMETER                             -0.002260     -0.006266   \n",
       "MOBILITY_DIAMETER_WEEKNIGHT                   -0.001692     -0.004915   \n",
       "EPIDEMIC                                      -0.046698     -0.044976   \n",
       "TimeWeekEnd_OUT_VUL_12                        -0.012326      0.007216   \n",
       "CallsWeekDay_OUT_VUL_12                       -0.017427      0.008317   \n",
       "CallsWeekNight_OUT_VUL_12                     -0.013196      0.007299   \n",
       "TimeWeekDay_OUT_VUL_12                        -0.014868      0.013340   \n",
       "CallsWeekEnd_OUT_VUL_12                       -0.016322      0.005513   \n",
       "TimeWeekNight_OUT_VUL_12                      -0.006902      0.004665   \n",
       "VULNERABLE_OUT_12                             -0.034331      0.010190   \n",
       "TimeWeekEnd_IN_VUL_12                         -0.010547      0.009127   \n",
       "CallsWeekDay_IN_VUL_12                        -0.017638      0.005301   \n",
       "CallsWeekNight_IN_VUL_12                      -0.011581      0.005283   \n",
       "TimeWeekDay_IN_VUL_12                         -0.014790      0.010649   \n",
       "CallsWeekEnd_IN_VUL_12                        -0.016141      0.004797   \n",
       "TimeWeekNight_IN_VUL_12                       -0.007739      0.006901   \n",
       "VULNERABLE_IN_12                              -0.034440      0.012244   \n",
       "TimeWeekEnd_OUT_VUL_08                        -0.009138      0.009581   \n",
       "CallsWeekDay_OUT_VUL_08                       -0.016763      0.007694   \n",
       "CallsWeekNight_OUT_VUL_08                     -0.012421      0.011807   \n",
       "TimeWeekDay_OUT_VUL_08                        -0.013679      0.009222   \n",
       "CallsWeekEnd_OUT_VUL_08                       -0.015545      0.006173   \n",
       "TimeWeekNight_OUT_VUL_08                      -0.005949      0.014619   \n",
       "VULNERABLE_OUT_08                             -0.033381      0.009990   \n",
       "TimeWeekEnd_IN_VUL_08                         -0.009536      0.007084   \n",
       "CallsWeekDay_IN_VUL_08                        -0.016592      0.003383   \n",
       "CallsWeekNight_IN_VUL_08                      -0.013465      0.006743   \n",
       "TimeWeekDay_IN_VUL_08                         -0.013246      0.004251   \n",
       "CallsWeekEnd_IN_VUL_08                        -0.016163      0.004962   \n",
       "TimeWeekNight_IN_VUL_08                       -0.006486      0.007902   \n",
       "...                                                 ...           ...   \n",
       "VULNERABLE_IN_10                              -0.033649      0.008419   \n",
       "TimeWeekEnd_OUT_VUL_11                        -0.008423      0.010130   \n",
       "CallsWeekDay_OUT_VUL_11                       -0.016663      0.006639   \n",
       "CallsWeekNight_OUT_VUL_11                     -0.013044      0.008630   \n",
       "TimeWeekDay_OUT_VUL_11                        -0.013186      0.009317   \n",
       "CallsWeekEnd_OUT_VUL_11                       -0.015568      0.007385   \n",
       "TimeWeekNight_OUT_VUL_11                      -0.006980      0.007482   \n",
       "VULNERABLE_OUT_11                             -0.034372      0.010196   \n",
       "TimeWeekEnd_IN_VUL_11                         -0.009516      0.003122   \n",
       "CallsWeekDay_IN_VUL_11                        -0.016817      0.003384   \n",
       "CallsWeekNight_IN_VUL_11                      -0.011990      0.005618   \n",
       "TimeWeekDay_IN_VUL_11                         -0.012845      0.005394   \n",
       "CallsWeekEnd_IN_VUL_11                        -0.016264      0.001047   \n",
       "TimeWeekNight_IN_VUL_11                       -0.004821      0.004545   \n",
       "VULNERABLE_IN_11                              -0.032883      0.009834   \n",
       "STATE_Baja_California_Sur                     -0.002652     -0.002554   \n",
       "STATE_Colima                                  -0.004681      1.000000   \n",
       "STATE_Guerrero                                -0.009258     -0.008916   \n",
       "STATE_Hidalgo                                 -0.015429     -0.014860   \n",
       "STATE_Jalisco                                 -0.022859     -0.022016   \n",
       "STATE_Morelos                                 -0.012290     -0.011837   \n",
       "STATE_Nayarit                                 -0.006319     -0.006086   \n",
       "STATE_Oaxaca                                  -0.007441     -0.007167   \n",
       "STATE_Puebla                                  -0.015482     -0.014911   \n",
       "STATE_Sinaloa                                 -0.005498     -0.005295   \n",
       "STATE_Sonora                                  -0.003956     -0.003810   \n",
       "STATE_Tabasco                                 -0.010436     -0.010052   \n",
       "STATE_Tlaxcala                                -0.009183     -0.008844   \n",
       "STATE_Veracruz                                -0.013913     -0.013400   \n",
       "target                                        -0.030959      0.013175   \n",
       "\n",
       "                             STATE_Distrito_Federal  STATE_Durango    ...     \\\n",
       "MOBILITY_DIAMETER                         -0.138609      -0.009381    ...      \n",
       "MOBILITY_DIAMETER_WEEKNIGHT               -0.120051      -0.009230    ...      \n",
       "EPIDEMIC                                  -0.346309      -0.034628    ...      \n",
       "TimeWeekEnd_OUT_VUL_12                    -0.058471      -0.009700    ...      \n",
       "CallsWeekDay_OUT_VUL_12                   -0.095216      -0.013552    ...      \n",
       "CallsWeekNight_OUT_VUL_12                 -0.065420      -0.010092    ...      \n",
       "TimeWeekDay_OUT_VUL_12                    -0.072652      -0.011919    ...      \n",
       "CallsWeekEnd_OUT_VUL_12                   -0.087076      -0.013012    ...      \n",
       "TimeWeekNight_OUT_VUL_12                  -0.032920      -0.006101    ...      \n",
       "VULNERABLE_OUT_12                         -0.148067      -0.024705    ...      \n",
       "TimeWeekEnd_IN_VUL_12                     -0.055902      -0.008682    ...      \n",
       "CallsWeekDay_IN_VUL_12                    -0.094969      -0.012157    ...      \n",
       "CallsWeekNight_IN_VUL_12                  -0.051608      -0.008645    ...      \n",
       "TimeWeekDay_IN_VUL_12                     -0.073295      -0.010201    ...      \n",
       "CallsWeekEnd_IN_VUL_12                    -0.085622      -0.011813    ...      \n",
       "TimeWeekNight_IN_VUL_12                   -0.033393      -0.006719    ...      \n",
       "VULNERABLE_IN_12                          -0.148437      -0.022464    ...      \n",
       "TimeWeekEnd_OUT_VUL_08                    -0.066524      -0.010299    ...      \n",
       "CallsWeekDay_OUT_VUL_08                   -0.100517      -0.012728    ...      \n",
       "CallsWeekNight_OUT_VUL_08                 -0.077437      -0.012022    ...      \n",
       "TimeWeekDay_OUT_VUL_08                    -0.080285      -0.011460    ...      \n",
       "CallsWeekEnd_OUT_VUL_08                   -0.098373      -0.014137    ...      \n",
       "TimeWeekNight_OUT_VUL_08                  -0.041173      -0.008213    ...      \n",
       "VULNERABLE_OUT_08                         -0.163333      -0.024895    ...      \n",
       "TimeWeekEnd_IN_VUL_08                     -0.066346      -0.009039    ...      \n",
       "CallsWeekDay_IN_VUL_08                    -0.102761      -0.012637    ...      \n",
       "CallsWeekNight_IN_VUL_08                  -0.081616      -0.011378    ...      \n",
       "TimeWeekDay_IN_VUL_08                     -0.081709      -0.010805    ...      \n",
       "CallsWeekEnd_IN_VUL_08                    -0.101655      -0.013285    ...      \n",
       "TimeWeekNight_IN_VUL_08                   -0.042644      -0.007133    ...      \n",
       "...                                             ...            ...    ...      \n",
       "VULNERABLE_IN_10                          -0.153595      -0.024127    ...      \n",
       "TimeWeekEnd_OUT_VUL_11                    -0.060510      -0.009805    ...      \n",
       "CallsWeekDay_OUT_VUL_11                   -0.098876      -0.013194    ...      \n",
       "CallsWeekNight_OUT_VUL_11                 -0.066158      -0.011169    ...      \n",
       "TimeWeekDay_OUT_VUL_11                    -0.076616      -0.011626    ...      \n",
       "CallsWeekEnd_OUT_VUL_11                   -0.096141      -0.013460    ...      \n",
       "TimeWeekNight_OUT_VUL_11                  -0.029528      -0.007502    ...      \n",
       "VULNERABLE_OUT_11                         -0.154592      -0.025856    ...      \n",
       "TimeWeekEnd_IN_VUL_11                     -0.059657      -0.008961    ...      \n",
       "CallsWeekDay_IN_VUL_11                    -0.098711      -0.012627    ...      \n",
       "CallsWeekNight_IN_VUL_11                  -0.066532      -0.010646    ...      \n",
       "TimeWeekDay_IN_VUL_11                     -0.072231      -0.010397    ...      \n",
       "CallsWeekEnd_IN_VUL_11                    -0.095917      -0.013188    ...      \n",
       "TimeWeekNight_IN_VUL_11                   -0.029192      -0.006366    ...      \n",
       "VULNERABLE_IN_11                          -0.153931      -0.024708    ...      \n",
       "STATE_Baja_California_Sur                 -0.019669      -0.001967    ...      \n",
       "STATE_Colima                              -0.034715      -0.003471    ...      \n",
       "STATE_Guerrero                            -0.068655      -0.006865    ...      \n",
       "STATE_Hidalgo                             -0.114419      -0.011441    ...      \n",
       "STATE_Jalisco                             -0.169519      -0.016950    ...      \n",
       "STATE_Morelos                             -0.091141      -0.009113    ...      \n",
       "STATE_Nayarit                             -0.046862      -0.004686    ...      \n",
       "STATE_Oaxaca                              -0.055184      -0.005518    ...      \n",
       "STATE_Puebla                              -0.114811      -0.011480    ...      \n",
       "STATE_Sinaloa                             -0.040771      -0.004077    ...      \n",
       "STATE_Sonora                              -0.029340      -0.002934    ...      \n",
       "STATE_Tabasco                             -0.077396      -0.007739    ...      \n",
       "STATE_Tlaxcala                            -0.068097      -0.006809    ...      \n",
       "STATE_Veracruz                            -0.103180      -0.010317    ...      \n",
       "target                                    -0.138963      -0.021420    ...      \n",
       "\n",
       "                             STATE_San_Luis_Potosi  STATE_Sinaloa  \\\n",
       "MOBILITY_DIAMETER                         0.062277       0.051715   \n",
       "MOBILITY_DIAMETER_WEEKNIGHT               0.063803       0.053742   \n",
       "EPIDEMIC                                 -0.079844      -0.052823   \n",
       "TimeWeekEnd_OUT_VUL_12                   -0.015667       0.009809   \n",
       "CallsWeekDay_OUT_VUL_12                  -0.029249       0.003711   \n",
       "CallsWeekNight_OUT_VUL_12                -0.018457       0.007416   \n",
       "TimeWeekDay_OUT_VUL_12                   -0.025230       0.009093   \n",
       "CallsWeekEnd_OUT_VUL_12                  -0.025451       0.003389   \n",
       "TimeWeekNight_OUT_VUL_12                 -0.008368       0.012940   \n",
       "VULNERABLE_OUT_12                        -0.051399       0.016951   \n",
       "TimeWeekEnd_IN_VUL_12                    -0.015849       0.007407   \n",
       "CallsWeekDay_IN_VUL_12                   -0.028571       0.002017   \n",
       "CallsWeekNight_IN_VUL_12                 -0.017341       0.001028   \n",
       "TimeWeekDay_IN_VUL_12                    -0.022686       0.005547   \n",
       "CallsWeekEnd_IN_VUL_12                   -0.026017       0.003175   \n",
       "TimeWeekNight_IN_VUL_12                  -0.009778       0.001765   \n",
       "VULNERABLE_IN_12                         -0.049569       0.016128   \n",
       "TimeWeekEnd_OUT_VUL_08                   -0.016996       0.008099   \n",
       "CallsWeekDay_OUT_VUL_08                  -0.027831      -0.000889   \n",
       "CallsWeekNight_OUT_VUL_08                -0.018302       0.001661   \n",
       "TimeWeekDay_OUT_VUL_08                   -0.022572       0.001723   \n",
       "CallsWeekEnd_OUT_VUL_08                  -0.027818       0.001105   \n",
       "TimeWeekNight_OUT_VUL_08                 -0.008381       0.006252   \n",
       "VULNERABLE_OUT_08                        -0.055620       0.007313   \n",
       "TimeWeekEnd_IN_VUL_08                    -0.016378       0.003768   \n",
       "CallsWeekDay_IN_VUL_08                   -0.028898      -0.002120   \n",
       "CallsWeekNight_IN_VUL_08                 -0.020754      -0.002726   \n",
       "TimeWeekDay_IN_VUL_08                    -0.021825       0.000841   \n",
       "CallsWeekEnd_IN_VUL_08                   -0.029035      -0.001719   \n",
       "TimeWeekNight_IN_VUL_08                  -0.007680       0.001205   \n",
       "...                                            ...            ...   \n",
       "VULNERABLE_IN_10                         -0.052471       0.017044   \n",
       "TimeWeekEnd_OUT_VUL_11                   -0.016946       0.004187   \n",
       "CallsWeekDay_OUT_VUL_11                  -0.027827       0.000382   \n",
       "CallsWeekNight_OUT_VUL_11                -0.018366       0.002375   \n",
       "TimeWeekDay_OUT_VUL_11                   -0.023102       0.005388   \n",
       "CallsWeekEnd_OUT_VUL_11                  -0.027295      -0.000889   \n",
       "TimeWeekNight_OUT_VUL_11                 -0.008709       0.007481   \n",
       "VULNERABLE_OUT_11                        -0.053477       0.014015   \n",
       "TimeWeekEnd_IN_VUL_11                    -0.015455       0.004553   \n",
       "CallsWeekDay_IN_VUL_11                   -0.027713      -0.002496   \n",
       "CallsWeekNight_IN_VUL_11                 -0.019545      -0.000111   \n",
       "TimeWeekDay_IN_VUL_11                    -0.021225       0.001796   \n",
       "CallsWeekEnd_IN_VUL_11                   -0.027310      -0.000805   \n",
       "TimeWeekNight_IN_VUL_11                  -0.007435       0.004680   \n",
       "VULNERABLE_IN_11                         -0.053784       0.014667   \n",
       "STATE_Baja_California_Sur                -0.004535      -0.003000   \n",
       "STATE_Colima                             -0.008004      -0.005295   \n",
       "STATE_Guerrero                           -0.015829      -0.010472   \n",
       "STATE_Hidalgo                            -0.026380      -0.017452   \n",
       "STATE_Jalisco                            -0.039084      -0.025857   \n",
       "STATE_Morelos                            -0.021013      -0.013902   \n",
       "STATE_Nayarit                            -0.010804      -0.007148   \n",
       "STATE_Oaxaca                             -0.012723      -0.008417   \n",
       "STATE_Puebla                             -0.026470      -0.017512   \n",
       "STATE_Sinaloa                            -0.009400       1.000000   \n",
       "STATE_Sonora                             -0.006764      -0.004475   \n",
       "STATE_Tabasco                            -0.017844      -0.011805   \n",
       "STATE_Tlaxcala                           -0.015700      -0.010387   \n",
       "STATE_Veracruz                           -0.023789      -0.015738   \n",
       "target                                   -0.060276       0.036188   \n",
       "\n",
       "                             STATE_Sonora  STATE_Tabasco  STATE_Tamaulipas  \\\n",
       "MOBILITY_DIAMETER                0.080137       0.004682          0.005265   \n",
       "MOBILITY_DIAMETER_WEEKNIGHT      0.082001       0.006905          0.005447   \n",
       "EPIDEMIC                        -0.038012       0.223487         -0.051591   \n",
       "TimeWeekEnd_OUT_VUL_12           0.008594       0.062447          0.000011   \n",
       "CallsWeekDay_OUT_VUL_12          0.008158       0.086426         -0.008732   \n",
       "CallsWeekNight_OUT_VUL_12        0.009478       0.073654          0.000079   \n",
       "TimeWeekDay_OUT_VUL_12           0.012902       0.071986         -0.004842   \n",
       "CallsWeekEnd_OUT_VUL_12          0.007596       0.082011         -0.007149   \n",
       "TimeWeekNight_OUT_VUL_12         0.011473       0.046054          0.004008   \n",
       "VULNERABLE_OUT_12                0.017911       0.115796         -0.015172   \n",
       "TimeWeekEnd_IN_VUL_12            0.004355       0.060743         -0.002125   \n",
       "CallsWeekDay_IN_VUL_12           0.006453       0.084164         -0.009910   \n",
       "CallsWeekNight_IN_VUL_12         0.006369       0.061843         -0.004359   \n",
       "TimeWeekDay_IN_VUL_12            0.010726       0.067460         -0.003426   \n",
       "CallsWeekEnd_IN_VUL_12           0.003951       0.082933         -0.009613   \n",
       "TimeWeekNight_IN_VUL_12          0.010466       0.044710          0.002314   \n",
       "VULNERABLE_IN_12                 0.016371       0.119048         -0.015639   \n",
       "TimeWeekEnd_OUT_VUL_08           0.006049       0.043162         -0.009573   \n",
       "CallsWeekDay_OUT_VUL_08          0.000859       0.056729         -0.011737   \n",
       "CallsWeekNight_OUT_VUL_08        0.000097       0.058156         -0.006670   \n",
       "TimeWeekDay_OUT_VUL_08           0.001539       0.050420         -0.008699   \n",
       "CallsWeekEnd_OUT_VUL_08          0.003801       0.061533         -0.013403   \n",
       "TimeWeekNight_OUT_VUL_08         0.001248       0.037715         -0.003574   \n",
       "VULNERABLE_OUT_08                0.008928       0.117939         -0.021691   \n",
       "TimeWeekEnd_IN_VUL_08           -0.002875       0.044014         -0.008132   \n",
       "CallsWeekDay_IN_VUL_08           0.001790       0.056114         -0.013970   \n",
       "CallsWeekNight_IN_VUL_08        -0.003261       0.057936         -0.011224   \n",
       "TimeWeekDay_IN_VUL_08            0.002633       0.047508         -0.010085   \n",
       "CallsWeekEnd_IN_VUL_08          -0.002320       0.064650         -0.015482   \n",
       "TimeWeekNight_IN_VUL_08         -0.002124       0.039534         -0.004664   \n",
       "...                                   ...            ...               ...   \n",
       "VULNERABLE_IN_10                 0.012636       0.115118         -0.022143   \n",
       "TimeWeekEnd_OUT_VUL_11           0.010818       0.055936         -0.001120   \n",
       "CallsWeekDay_OUT_VUL_11          0.007579       0.064408         -0.010861   \n",
       "CallsWeekNight_OUT_VUL_11        0.006771       0.057972         -0.006027   \n",
       "TimeWeekDay_OUT_VUL_11           0.010241       0.055892         -0.006675   \n",
       "CallsWeekEnd_OUT_VUL_11          0.008332       0.074566         -0.008616   \n",
       "TimeWeekNight_OUT_VUL_11         0.009330       0.037985         -0.003169   \n",
       "VULNERABLE_OUT_11                0.016510       0.113726         -0.017535   \n",
       "TimeWeekEnd_IN_VUL_11            0.005230       0.051093         -0.007191   \n",
       "CallsWeekDay_IN_VUL_11           0.003655       0.064531         -0.012215   \n",
       "CallsWeekNight_IN_VUL_11         0.003899       0.060754         -0.009046   \n",
       "TimeWeekDay_IN_VUL_11            0.004030       0.053296         -0.007177   \n",
       "CallsWeekEnd_IN_VUL_11           0.004629       0.073001         -0.013356   \n",
       "TimeWeekNight_IN_VUL_11          0.005555       0.037559         -0.004457   \n",
       "VULNERABLE_IN_11                 0.015563       0.116492         -0.019714   \n",
       "STATE_Baja_California_Sur       -0.002159      -0.005695         -0.002930   \n",
       "STATE_Colima                    -0.003810      -0.010052         -0.005172   \n",
       "STATE_Guerrero                  -0.007536      -0.019879         -0.010228   \n",
       "STATE_Hidalgo                   -0.012559      -0.033130         -0.017045   \n",
       "STATE_Jalisco                   -0.018607      -0.049084         -0.025254   \n",
       "STATE_Morelos                   -0.010004      -0.026390         -0.013578   \n",
       "STATE_Nayarit                   -0.005144      -0.013569         -0.006981   \n",
       "STATE_Oaxaca                    -0.006057      -0.015978         -0.008221   \n",
       "STATE_Puebla                    -0.012602      -0.033243         -0.017104   \n",
       "STATE_Sinaloa                   -0.004475      -0.011805         -0.006074   \n",
       "STATE_Sonora                     1.000000      -0.008495         -0.004371   \n",
       "STATE_Tabasco                   -0.008495       1.000000         -0.011530   \n",
       "STATE_Tlaxcala                  -0.007475      -0.019717         -0.010145   \n",
       "STATE_Veracruz                  -0.011325      -0.029875         -0.015371   \n",
       "target                           0.033602       0.095242          0.001172   \n",
       "\n",
       "                             STATE_Tlaxcala  STATE_Veracruz  STATE_Yucatan  \\\n",
       "MOBILITY_DIAMETER                 -0.019447        0.056086      -0.029270   \n",
       "MOBILITY_DIAMETER_WEEKNIGHT       -0.026101        0.045211      -0.021405   \n",
       "EPIDEMIC                          -0.088226        0.297942      -0.109580   \n",
       "TimeWeekEnd_OUT_VUL_12            -0.012570        0.026676      -0.025227   \n",
       "CallsWeekDay_OUT_VUL_12           -0.021534        0.045011      -0.040492   \n",
       "CallsWeekNight_OUT_VUL_12         -0.013420        0.037357      -0.030622   \n",
       "TimeWeekDay_OUT_VUL_12            -0.017533        0.034943      -0.033579   \n",
       "CallsWeekEnd_OUT_VUL_12           -0.017540        0.043760      -0.036603   \n",
       "TimeWeekNight_OUT_VUL_12          -0.006425        0.018045      -0.017813   \n",
       "VULNERABLE_OUT_12                 -0.025880        0.134299      -0.074840   \n",
       "TimeWeekEnd_IN_VUL_12             -0.009439        0.027871      -0.021220   \n",
       "CallsWeekDay_IN_VUL_12            -0.020423        0.044692      -0.039479   \n",
       "CallsWeekNight_IN_VUL_12          -0.009094        0.030556      -0.023477   \n",
       "TimeWeekDay_IN_VUL_12             -0.012760        0.032635      -0.030761   \n",
       "CallsWeekEnd_IN_VUL_12            -0.017490        0.044180      -0.035228   \n",
       "TimeWeekNight_IN_VUL_12           -0.002664        0.016526      -0.012363   \n",
       "VULNERABLE_IN_12                  -0.024392        0.133377      -0.074454   \n",
       "TimeWeekEnd_OUT_VUL_08            -0.014808        0.028026      -0.027693   \n",
       "CallsWeekDay_OUT_VUL_08           -0.023667        0.033539      -0.040270   \n",
       "CallsWeekNight_OUT_VUL_08         -0.016671        0.039821      -0.035165   \n",
       "TimeWeekDay_OUT_VUL_08            -0.019548        0.028935      -0.032952   \n",
       "CallsWeekEnd_OUT_VUL_08           -0.021107        0.040742      -0.041324   \n",
       "TimeWeekNight_OUT_VUL_08          -0.009628        0.026862      -0.021373   \n",
       "VULNERABLE_OUT_08                 -0.027511        0.148312      -0.079833   \n",
       "TimeWeekEnd_IN_VUL_08             -0.011787        0.029405      -0.024769   \n",
       "CallsWeekDay_IN_VUL_08            -0.022312        0.034086      -0.040130   \n",
       "CallsWeekNight_IN_VUL_08          -0.015673        0.039996      -0.034734   \n",
       "TimeWeekDay_IN_VUL_08             -0.017013        0.030258      -0.032017   \n",
       "CallsWeekEnd_IN_VUL_08            -0.020940        0.041274      -0.040855   \n",
       "TimeWeekNight_IN_VUL_08           -0.007273        0.027516      -0.019412   \n",
       "...                                     ...             ...            ...   \n",
       "VULNERABLE_IN_10                  -0.026024        0.137516      -0.077313   \n",
       "TimeWeekEnd_OUT_VUL_11            -0.013572        0.032943      -0.027074   \n",
       "CallsWeekDay_OUT_VUL_11           -0.023713        0.037267      -0.040092   \n",
       "CallsWeekNight_OUT_VUL_11         -0.015346        0.038968      -0.031788   \n",
       "TimeWeekDay_OUT_VUL_11            -0.020542        0.030435      -0.032526   \n",
       "CallsWeekEnd_OUT_VUL_11           -0.021581        0.047258      -0.040323   \n",
       "TimeWeekNight_OUT_VUL_11          -0.009030        0.021632      -0.018083   \n",
       "VULNERABLE_OUT_11                 -0.025637        0.139138      -0.079135   \n",
       "TimeWeekEnd_IN_VUL_11             -0.009467        0.035859      -0.019347   \n",
       "CallsWeekDay_IN_VUL_11            -0.022834        0.037939      -0.038280   \n",
       "CallsWeekNight_IN_VUL_11          -0.013440        0.037173      -0.027962   \n",
       "TimeWeekDay_IN_VUL_11             -0.017130        0.029249      -0.027297   \n",
       "CallsWeekEnd_IN_VUL_11            -0.019970        0.046165      -0.037765   \n",
       "TimeWeekNight_IN_VUL_11           -0.005180        0.018948      -0.010990   \n",
       "VULNERABLE_IN_11                  -0.026946        0.138680      -0.078379   \n",
       "STATE_Baja_California_Sur         -0.005011       -0.007592      -0.006224   \n",
       "STATE_Colima                      -0.008844       -0.013400      -0.010985   \n",
       "STATE_Guerrero                    -0.017491       -0.026502      -0.021724   \n",
       "STATE_Hidalgo                     -0.029149       -0.044167      -0.036205   \n",
       "STATE_Jalisco                     -0.043187       -0.065436      -0.053640   \n",
       "STATE_Morelos                     -0.023219       -0.035181      -0.028839   \n",
       "STATE_Nayarit                     -0.011938       -0.018089      -0.014828   \n",
       "STATE_Oaxaca                      -0.014059       -0.021301      -0.017461   \n",
       "STATE_Puebla                      -0.029249       -0.044318      -0.036329   \n",
       "STATE_Sinaloa                     -0.010387       -0.015738      -0.012901   \n",
       "STATE_Sonora                      -0.007475       -0.011325      -0.009284   \n",
       "STATE_Tabasco                     -0.019717       -0.029875      -0.024490   \n",
       "STATE_Tlaxcala                     1.000000       -0.026286      -0.021548   \n",
       "STATE_Veracruz                    -0.026286        1.000000      -0.032649   \n",
       "target                             0.018890        0.159102      -0.077954   \n",
       "\n",
       "                             STATE_Zacatecas    target  \n",
       "MOBILITY_DIAMETER                   0.000641  0.013764  \n",
       "MOBILITY_DIAMETER_WEEKNIGHT        -0.005553  0.014906  \n",
       "EPIDEMIC                           -0.034769  0.439418  \n",
       "TimeWeekEnd_OUT_VUL_12             -0.004827  0.187130  \n",
       "CallsWeekDay_OUT_VUL_12            -0.010899  0.277760  \n",
       "CallsWeekNight_OUT_VUL_12          -0.008207  0.225518  \n",
       "TimeWeekDay_OUT_VUL_12             -0.009226  0.231432  \n",
       "CallsWeekEnd_OUT_VUL_12            -0.009751  0.262159  \n",
       "TimeWeekNight_OUT_VUL_12           -0.003635  0.142294  \n",
       "VULNERABLE_OUT_12                  -0.019988  0.503804  \n",
       "TimeWeekEnd_IN_VUL_12              -0.006139  0.177840  \n",
       "CallsWeekDay_IN_VUL_12             -0.010699  0.271915  \n",
       "CallsWeekNight_IN_VUL_12           -0.006542  0.181260  \n",
       "TimeWeekDay_IN_VUL_12              -0.007438  0.218512  \n",
       "CallsWeekEnd_IN_VUL_12             -0.010155  0.260075  \n",
       "TimeWeekNight_IN_VUL_12            -0.004821  0.130211  \n",
       "VULNERABLE_IN_12                   -0.019893  0.501857  \n",
       "TimeWeekEnd_OUT_VUL_08             -0.009406  0.212387  \n",
       "CallsWeekDay_OUT_VUL_08            -0.011249  0.285261  \n",
       "CallsWeekNight_OUT_VUL_08          -0.008376  0.251499  \n",
       "TimeWeekDay_OUT_VUL_08             -0.009823  0.241347  \n",
       "CallsWeekEnd_OUT_VUL_08            -0.012210  0.302695  \n",
       "TimeWeekNight_OUT_VUL_08           -0.005066  0.158270  \n",
       "VULNERABLE_OUT_08                  -0.020899  0.553884  \n",
       "TimeWeekEnd_IN_VUL_08              -0.009613  0.210637  \n",
       "CallsWeekDay_IN_VUL_08             -0.011147  0.292085  \n",
       "CallsWeekNight_IN_VUL_08           -0.009078  0.256445  \n",
       "TimeWeekDay_IN_VUL_08              -0.009567  0.240071  \n",
       "CallsWeekEnd_IN_VUL_08             -0.012837  0.311608  \n",
       "TimeWeekNight_IN_VUL_08            -0.004548  0.150745  \n",
       "...                                      ...       ...  \n",
       "VULNERABLE_IN_10                   -0.020346  0.520670  \n",
       "TimeWeekEnd_OUT_VUL_11             -0.008618  0.200561  \n",
       "CallsWeekDay_OUT_VUL_11            -0.011508  0.269011  \n",
       "CallsWeekNight_OUT_VUL_11          -0.007673  0.228012  \n",
       "TimeWeekDay_OUT_VUL_11             -0.010093  0.230498  \n",
       "CallsWeekEnd_OUT_VUL_11            -0.012025  0.281308  \n",
       "TimeWeekNight_OUT_VUL_11           -0.004057  0.150229  \n",
       "VULNERABLE_OUT_11                  -0.022685  0.514446  \n",
       "TimeWeekEnd_IN_VUL_11              -0.008244  0.190351  \n",
       "CallsWeekDay_IN_VUL_11             -0.011395  0.266690  \n",
       "CallsWeekNight_IN_VUL_11           -0.008683  0.218783  \n",
       "TimeWeekDay_IN_VUL_11              -0.009044  0.211713  \n",
       "CallsWeekEnd_IN_VUL_11             -0.011987  0.280185  \n",
       "TimeWeekNight_IN_VUL_11            -0.004018  0.125179  \n",
       "VULNERABLE_IN_11                   -0.019417  0.518484  \n",
       "STATE_Baja_California_Sur          -0.001975  0.027414  \n",
       "STATE_Colima                       -0.003485  0.013175  \n",
       "STATE_Guerrero                     -0.006893  0.056422  \n",
       "STATE_Hidalgo                      -0.011488  0.105358  \n",
       "STATE_Jalisco                      -0.017020  0.258447  \n",
       "STATE_Morelos                      -0.009151  0.103912  \n",
       "STATE_Nayarit                      -0.004705  0.010793  \n",
       "STATE_Oaxaca                       -0.005540  0.051564  \n",
       "STATE_Puebla                       -0.011527  0.138836  \n",
       "STATE_Sinaloa                      -0.004093  0.036188  \n",
       "STATE_Sonora                       -0.002946  0.033602  \n",
       "STATE_Tabasco                      -0.007770  0.095242  \n",
       "STATE_Tlaxcala                     -0.006837  0.018890  \n",
       "STATE_Veracruz                     -0.010359  0.159102  \n",
       "target                             -0.018073  1.000000  \n",
       "\n",
       "[88 rows x 33 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## show correlation between state and target\n",
    "\n",
    "if not 'STATE' in exclude_cols:    \n",
    "    state_cols = [col for col in corr if 'STATE' in col]\n",
    "    view = corr[state_cols + [target_col]]\n",
    "    display(view.query('target > 0.01'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.33763036341980651"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=data['EPIDEMIC_gt'].sum();b= data.shape[0]\n",
    "a*1.0/b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.30676328502415456"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=val_set['EPIDEMIC'].sum();b= val_set.shape[0]\n",
    "a*1.0/b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get metric functions and sklearn model selectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This non-commercial license of GraphLab Create for academic use is assigned to jdemonasterio@dc.uba.ar and will expire on May 06, 2018.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] graphlab.cython.cy_server: GraphLab Create v2.1 started. Logging: /tmp/graphlab_server_1497135415.log\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import *\n",
    "# from sklearn.cross_validation import *\n",
    "from sklearn.model_selection import (GridSearchCV, RandomizedSearchCV, \n",
    "                                     train_test_split, KFold, cross_val_predict, \n",
    "                                     cross_val_score, learning_curve, validation_curve\n",
    "                                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instance 1st fast model with MNB\n",
    "this is a benchmarking-only process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "from sklearn.naive_bayes import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remember that the Multinomail NB assumes no negative values\n",
    "are present in the dataset as this must be `count` data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n",
      "[CV] alpha=0.001, fit_prior=True .....................................\n",
      "[CV] alpha=0.001, fit_prior=True .....................................\n",
      "[CV] alpha=0.001, fit_prior=True .....................................\n",
      "[CV] ...... alpha=0.001, fit_prior=True, score=0.704388, total=   0.4s\n",
      "[CV] alpha=0.001, fit_prior=False ....................................\n",
      "[CV] ...... alpha=0.001, fit_prior=True, score=0.768092, total=   0.4s\n",
      "[CV] alpha=0.001, fit_prior=False ....................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 out of  24 | elapsed:    1.2s remaining:   13.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ...... alpha=0.001, fit_prior=True, score=0.768343, total=   0.4s\n",
      "[CV] alpha=0.001, fit_prior=False ....................................\n",
      "[CV] ..... alpha=0.001, fit_prior=False, score=0.700921, total=   0.4s\n",
      "[CV] alpha=0.1, fit_prior=True .......................................\n",
      "[CV] ..... alpha=0.001, fit_prior=False, score=0.768012, total=   0.4s\n",
      "[CV] alpha=0.1, fit_prior=True .......................................\n",
      "[CV] ..... alpha=0.001, fit_prior=False, score=0.768308, total=   0.4s\n",
      "[CV] alpha=0.1, fit_prior=True .......................................\n",
      "[CV] ........ alpha=0.1, fit_prior=True, score=0.704388, total=   0.4s\n",
      "[CV] alpha=0.1, fit_prior=False ......................................\n",
      "[CV] ........ alpha=0.1, fit_prior=True, score=0.768092, total=   0.4s\n",
      "[CV] alpha=0.1, fit_prior=False ......................................\n",
      "[CV] ........ alpha=0.1, fit_prior=True, score=0.768343, total=   0.5s\n",
      "[CV] alpha=0.1, fit_prior=False ......................................\n",
      "[CV] ....... alpha=0.1, fit_prior=False, score=0.700921, total=   0.4s\n",
      "[CV] alpha=10.0, fit_prior=True ......................................\n",
      "[CV] ....... alpha=0.1, fit_prior=False, score=0.768012, total=   0.4s\n",
      "[CV] alpha=10.0, fit_prior=True ......................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  11 out of  24 | elapsed:    3.4s remaining:    4.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ....... alpha=0.1, fit_prior=False, score=0.768308, total=   0.4s\n",
      "[CV] alpha=10.0, fit_prior=True ......................................\n",
      "[CV] ....... alpha=10.0, fit_prior=True, score=0.704269, total=   0.4s\n",
      "[CV] alpha=10.0, fit_prior=False .....................................\n",
      "[CV] ....... alpha=10.0, fit_prior=True, score=0.768092, total=   0.4s\n",
      "[CV] alpha=10.0, fit_prior=False .....................................\n",
      "[CV] ....... alpha=10.0, fit_prior=True, score=0.768323, total=   0.4s\n",
      "[CV] alpha=10.0, fit_prior=False .....................................\n",
      "[CV] ...... alpha=10.0, fit_prior=False, score=0.700681, total=   0.4s\n",
      "[CV] alpha=1.0, fit_prior=True .......................................\n",
      "[CV] ...... alpha=10.0, fit_prior=False, score=0.768012, total=   0.4s\n",
      "[CV] alpha=1.0, fit_prior=True .......................................\n",
      "[CV] ...... alpha=10.0, fit_prior=False, score=0.768308, total=   0.4s\n",
      "[CV] alpha=1.0, fit_prior=True .......................................\n",
      "[CV] ........ alpha=1.0, fit_prior=True, score=0.704412, total=   0.4s\n",
      "[CV] alpha=1.0, fit_prior=False ......................................\n",
      "[CV] ........ alpha=1.0, fit_prior=True, score=0.768092, total=   0.4s\n",
      "[CV] alpha=1.0, fit_prior=False ......................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  20 out of  24 | elapsed:    5.6s remaining:    1.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ........ alpha=1.0, fit_prior=True, score=0.768343, total=   0.4s\n",
      "[CV] alpha=1.0, fit_prior=False ......................................\n",
      "[CV] ....... alpha=1.0, fit_prior=False, score=0.700873, total=   0.4s\n",
      "[CV] ....... alpha=1.0, fit_prior=False, score=0.768012, total=   0.4s\n",
      "[CV] ....... alpha=1.0, fit_prior=False, score=0.768308, total=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  24 out of  24 | elapsed:    6.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid Search took 7.40813994408 seconds to run\n",
      "\n",
      " Best estimator was MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True) \n",
      "\n",
      "\n",
      " Best estimator was 0.746948151621 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/juan/mfixman/venv/local/lib/python2.7/site-packages/sklearn/model_selection/_search.py:667: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n",
      "/home/juan/mfixman/venv/local/lib/python2.7/site-packages/sklearn/model_selection/_search.py:667: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n",
      "/home/juan/mfixman/venv/local/lib/python2.7/site-packages/sklearn/model_selection/_search.py:667: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n",
      "/home/juan/mfixman/venv/local/lib/python2.7/site-packages/sklearn/model_selection/_search.py:667: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n",
      "/home/juan/mfixman/venv/local/lib/python2.7/site-packages/sklearn/model_selection/_search.py:667: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n",
      "/home/juan/mfixman/venv/local/lib/python2.7/site-packages/sklearn/model_selection/_search.py:667: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n",
      "/home/juan/mfixman/venv/local/lib/python2.7/site-packages/sklearn/model_selection/_search.py:667: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n",
      "/home/juan/mfixman/venv/local/lib/python2.7/site-packages/sklearn/model_selection/_search.py:667: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n",
      "/home/juan/mfixman/venv/local/lib/python2.7/site-packages/sklearn/model_selection/_search.py:667: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n",
      "/home/juan/mfixman/venv/local/lib/python2.7/site-packages/sklearn/model_selection/_search.py:667: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n",
      "/home/juan/mfixman/venv/local/lib/python2.7/site-packages/sklearn/model_selection/_search.py:667: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n",
      "/home/juan/mfixman/venv/local/lib/python2.7/site-packages/sklearn/model_selection/_search.py:667: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n",
      "/home/juan/mfixman/venv/local/lib/python2.7/site-packages/sklearn/model_selection/_search.py:667: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n",
      "/home/juan/mfixman/venv/local/lib/python2.7/site-packages/sklearn/model_selection/_search.py:667: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n",
      "/home/juan/mfixman/venv/local/lib/python2.7/site-packages/sklearn/model_selection/_search.py:667: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n",
      "/home/juan/mfixman/venv/local/lib/python2.7/site-packages/sklearn/model_selection/_search.py:667: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n",
      "/home/juan/mfixman/venv/local/lib/python2.7/site-packages/sklearn/model_selection/_search.py:667: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n",
      "/home/juan/mfixman/venv/local/lib/python2.7/site-packages/sklearn/model_selection/_search.py:667: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.86      0.85      0.86      9114\n",
      "       True       0.21      0.22      0.21      1644\n",
      "\n",
      "avg / total       0.76      0.76      0.76     10758\n",
      "\n",
      "CPU times: user 6.43 s, sys: 628 ms, total: 7.06 s\n",
      "Wall time: 7.73 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "start_time = time.time()\n",
    "param_grid = {\n",
    "    'alpha':[\n",
    "        1e-3,\n",
    "        1e-1,\n",
    "        1e1,\n",
    "        1e0\n",
    "            ], \n",
    "    'fit_prior': [\n",
    "        True,\n",
    "        False\n",
    "                ],\n",
    "             }\n",
    "\n",
    "mnb  = MultinomialNB( )\n",
    "\n",
    "clf = GridSearchCV(mnb, param_grid, scoring='f1_weighted', fit_params=None, n_jobs=-1, iid=True, refit=True, \n",
    "verbose=3, pre_dispatch='2*n_jobs', error_score='raise')\n",
    "\n",
    "clf2 = MultinomialNB( )\n",
    "#how many parameters to randomly search for\n",
    "#n_iter_search = 45\n",
    "\n",
    "#random_search = RandomizedSearchCV(rforest, param_distributions=param_grid,\n",
    "                                 #  n_iter=n_iter_search, n_jobs =8, verbose=3)\n",
    "\n",
    "elapsed_time =  time.time() - start_time\n",
    "\n",
    "#Y = categorical(train_table_target.values, drop=True).astype(int)\n",
    "\n",
    "clf.fit(X,Y)\n",
    "\n",
    "elapsed_time =   time.time() - start_time \n",
    "\n",
    "print('Grid Search took %s seconds to run' % (elapsed_time))\n",
    "\n",
    "cv_result = pd.DataFrame(columns=['mean_score' ] + [key for key, value in clf.grid_scores_[0].parameters.items() ] )\n",
    "i=0\n",
    "for setup in clf.grid_scores_:\n",
    "    row = [clf.grid_scores_[i].mean_validation_score ] + [value for key, value in clf.grid_scores_[i].parameters.items() ]\n",
    "    cv_result.loc[i] = row\n",
    "    i+=1\n",
    "\n",
    "\n",
    "#este flag es basicamente para chequear que hayamos terminado nomas\n",
    "finished = True\n",
    "\n",
    "print('\\n Best estimator was %s \\n' % str(clf.best_estimator_))\n",
    "print('\\n Best estimator was %s \\n' % str(clf.best_score_))\n",
    "\n",
    "clf2.set_params(**clf.best_params_)\n",
    "\n",
    "clf2.fit(X,Y)\n",
    "\n",
    "\n",
    "#converted_dict = evaluation_print(clf, X_val, test_table_target.values, test_table.index.values, \n",
    "#                              test_table_target[test_table_target>0].index.values,start_date,future)\n",
    "\n",
    "print(classification_report(Y_val,clf2.predict(X_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.53569666623418843"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(Y_val,clf2.predict(X_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((94908,), 14294, {'alpha': 1.0, 'fit_prior': True})"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape, Y.sum(), clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15281650864472951"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_val.sum()*1.0/Y_val.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.53569666623418843"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(Y_val,clf2.predict(X_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.001</th>\n",
       "      <td>0.746343</td>\n",
       "      <td>0.000844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.100</th>\n",
       "      <td>0.746343</td>\n",
       "      <td>0.000844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.000</th>\n",
       "      <td>0.746339</td>\n",
       "      <td>0.000861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10.000</th>\n",
       "      <td>0.746280</td>\n",
       "      <td>0.000868</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            mean       std\n",
       "alpha                     \n",
       "0.001   0.746343  0.000844\n",
       "0.100   0.746343  0.000844\n",
       "1.000   0.746339  0.000861\n",
       "10.000  0.746280  0.000868"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fit_prior</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>0.745722</td>\n",
       "      <td>0.000038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>0.746931</td>\n",
       "      <td>0.000025</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               mean       std\n",
       "fit_prior                    \n",
       "False      0.745722  0.000038\n",
       "True       0.746931  0.000025"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for col in cv_result.columns:\n",
    "    if col != 'mean_score':\n",
    "        df = cv_result.groupby(col)['mean_score'].mean().to_frame().copy()\n",
    "        df.columns = ['mean']\n",
    "        df['std'] = cv_result.groupby(col)['mean_score'].std()\n",
    "\n",
    "        display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " 'EPIDEMIC' in X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## now graphlab models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from graphlab import random_forest_classifier, boosted_trees_classifier, logistic_classifier, decision_tree_classifier\n",
    "from graphlab.toolkits import cross_validation, model_parameter_search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get kfolds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.18 s, sys: 460 ms, total: 6.64 s\n",
      "Wall time: 4.64 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "num_folds = 10\n",
    "\n",
    "target_col = 'target'\n",
    "if graphlab_frame:   \n",
    "    X[target_col] = Y\n",
    "    X_val[target_col] = Y_val\n",
    "    kfold = cross_validation.KFold(\n",
    "    X,num_folds=num_folds)\n",
    "else:\n",
    "    X_gl= gl.SFrame(X)\n",
    "    Y_gl = gl.SArray(Y)\n",
    "    X_val_gl= gl.SFrame(X_val)\n",
    "    Y_val_gl = gl.SArray(Y_val)\n",
    "    X_gl[target_col] = Y_gl\n",
    "    X_val_gl[target_col] = Y_val_gl\n",
    "    \n",
    "    kfold = cross_validation.KFold(\n",
    "    X_gl,num_folds=num_folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'target' in X_gl.column_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandomForest \n",
    "HyperParams Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "param_grid = {\n",
    "    \"target\":target_col,\n",
    "    \n",
    "    'metric': [\n",
    "                'auc',\n",
    "#                 'log_loss',\n",
    "                 ], \n",
    "    \n",
    "    'max_iterations': [\n",
    "#                     50,\n",
    "                    100,\n",
    "                    150,\n",
    "                    200,\n",
    "                    ],\n",
    "    \n",
    "  'column_subsample': [\n",
    "                  np.sqrt(X_gl.shape[1])/X_gl.shape[1],\n",
    "                  np.log2(X_gl.shape[1])/X_gl.shape[1],\n",
    "                  0.5,\n",
    "#                   0.1,\n",
    "                  ], \n",
    "#     \"bootstrap\": [ \n",
    "#                 False,\n",
    "#                 True,\n",
    "#                     ],\n",
    "#     \"min_child_weight\": np.append(np.random.randint(3,15,3),[3]),\n",
    "    'max_depth':[\n",
    "#                  3,\n",
    "                 6,\n",
    "                 9,\n",
    "                 12,\n",
    "                ], \n",
    "   \"class_weights\": [\n",
    "#                    'balanced',\n",
    "                   None,\n",
    "                   ],\n",
    "#     \"validation_set\": X_val_gl,\n",
    "              }\n",
    "\n",
    "model_factory = random_forest_classifier.create"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] graphlab.deploy.job: Validating job.\n",
      "[INFO] graphlab.deploy.job: Creating a LocalAsync environment called 'async'.\n",
      "[INFO] graphlab.deploy.map_job: Validation complete. Job: 'Model-Parameter-Search-May-28-2017-04-13-5100000' ready for execution\n",
      "[INFO] graphlab.deploy.map_job: Job: 'Model-Parameter-Search-May-28-2017-04-13-5100000' scheduled.\n",
      "[INFO] graphlab.deploy.job: Validating job.\n",
      "[INFO] graphlab.deploy.map_job: A job with name 'Model-Parameter-Search-May-28-2017-04-13-5100000' already exists. Renaming the job to 'Model-Parameter-Search-May-28-2017-04-13-5100000-62725'.\n",
      "[INFO] graphlab.deploy.map_job: Validation complete. Job: 'Model-Parameter-Search-May-28-2017-04-13-5100000-62725' ready for execution\n",
      "[INFO] graphlab.deploy.map_job: Job: 'Model-Parameter-Search-May-28-2017-04-13-5100000-62725' scheduled.\n",
      "[INFO] graphlab.deploy.job: Validating job.\n",
      "[INFO] graphlab.deploy.map_job: Validation complete. Job: 'Model-Parameter-Search-May-28-2017-04-13-5100001' ready for execution\n",
      "[INFO] graphlab.deploy.map_job: Job: 'Model-Parameter-Search-May-28-2017-04-13-5100001' scheduled.\n",
      "[INFO] graphlab.deploy.job: Validating job.\n",
      "[INFO] graphlab.deploy.map_job: Validation complete. Job: 'Model-Parameter-Search-May-28-2017-04-13-5100002' ready for execution\n",
      "[INFO] graphlab.deploy.map_job: Job: 'Model-Parameter-Search-May-28-2017-04-13-5100002' scheduled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 36s, sys: 8.24 s, total: 1min 44s\n",
      "Wall time: 1h 7min 3s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "start_time = time.time()\n",
    "model_search = model_parameter_search.create( datasets = kfold, \n",
    "                                             #[data, val_set],\n",
    "                                             model_factory = model_factory,\n",
    "                                            model_parameters = param_grid, \n",
    "                                             perform_trial_run = True,\n",
    "                                            )\n",
    "\n",
    "search_results = model_search.get_results()\n",
    "\n",
    "all_time = time.time() - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 7.054373967647551)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(abs(all_time)/3600) ,(abs(all_time)/3600 %1)*60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\"><table frame=\"box\" rules=\"cols\">\n",
       "    <tr>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">task_name</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">status</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">start_time</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">run_time</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">exception</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">exception_message</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">exception_traceback</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">_train_test_model-0-0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Completed</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2017-05-28 04:15:38</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">142.217834949</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">_train_test_model-0-1</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Completed</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2017-05-28 04:18:00</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">147.120588064</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">_train_test_model-0-2</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Completed</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2017-05-28 04:20:28</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">143.171838999</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">_train_test_model-0-3</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Completed</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2017-05-28 04:22:51</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">142.518718958</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">_train_test_model-0-4</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Completed</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2017-05-28 04:25:13</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">144.32323885</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">_train_test_model-0-5</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Completed</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2017-05-28 04:27:38</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">143.988962889</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">_train_test_model-0-6</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Completed</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2017-05-28 04:30:02</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">148.018715143</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">_train_test_model-0-7</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Completed</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2017-05-28 04:32:30</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">145.34139204</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">_train_test_model-0-8</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Completed</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2017-05-28 04:34:55</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">143.07583499</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">_train_test_model-0-9</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Completed</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2017-05-28 04:37:19</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">138.991053104</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "    </tr>\n",
       "</table>\n",
       "<table frame=\"box\" rules=\"cols\">\n",
       "    <tr>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">job_name</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Model-Parameter-Search-Ma<br>y-28-2017-04-13-51000 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Model-Parameter-Search-Ma<br>y-28-2017-04-13-51000 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Model-Parameter-Search-Ma<br>y-28-2017-04-13-51000 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Model-Parameter-Search-Ma<br>y-28-2017-04-13-51000 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Model-Parameter-Search-Ma<br>y-28-2017-04-13-51000 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Model-Parameter-Search-Ma<br>y-28-2017-04-13-51000 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Model-Parameter-Search-Ma<br>y-28-2017-04-13-51000 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Model-Parameter-Search-Ma<br>y-28-2017-04-13-51000 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Model-Parameter-Search-Ma<br>y-28-2017-04-13-51000 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Model-Parameter-Search-Ma<br>y-28-2017-04-13-51000 ...</td>\n",
       "    </tr>\n",
       "</table>\n",
       "[35 rows x 8 columns]<br/>Note: Only the head of the SFrame is printed.<br/>You can use print_rows(num_rows=m, num_columns=n) to print more rows and columns.\n",
       "</div>"
      ],
      "text/plain": [
       "Columns:\n",
       "\ttask_name\tstr\n",
       "\tstatus\tstr\n",
       "\tstart_time\tstr\n",
       "\trun_time\tfloat\n",
       "\texception\tfloat\n",
       "\texception_message\tfloat\n",
       "\texception_traceback\tfloat\n",
       "\tjob_name\tstr\n",
       "\n",
       "Rows: 35\n",
       "\n",
       "Data:\n",
       "+-----------------------+-----------+---------------------+---------------+-----------+\n",
       "|       task_name       |   status  |      start_time     |    run_time   | exception |\n",
       "+-----------------------+-----------+---------------------+---------------+-----------+\n",
       "| _train_test_model-0-0 | Completed | 2017-05-28 04:15:38 | 142.217834949 |    None   |\n",
       "| _train_test_model-0-1 | Completed | 2017-05-28 04:18:00 | 147.120588064 |    None   |\n",
       "| _train_test_model-0-2 | Completed | 2017-05-28 04:20:28 | 143.171838999 |    None   |\n",
       "| _train_test_model-0-3 | Completed | 2017-05-28 04:22:51 | 142.518718958 |    None   |\n",
       "| _train_test_model-0-4 | Completed | 2017-05-28 04:25:13 |  144.32323885 |    None   |\n",
       "| _train_test_model-0-5 | Completed | 2017-05-28 04:27:38 | 143.988962889 |    None   |\n",
       "| _train_test_model-0-6 | Completed | 2017-05-28 04:30:02 | 148.018715143 |    None   |\n",
       "| _train_test_model-0-7 | Completed | 2017-05-28 04:32:30 |  145.34139204 |    None   |\n",
       "| _train_test_model-0-8 | Completed | 2017-05-28 04:34:55 |  143.07583499 |    None   |\n",
       "| _train_test_model-0-9 | Completed | 2017-05-28 04:37:19 | 138.991053104 |    None   |\n",
       "+-----------------------+-----------+---------------------+---------------+-----------+\n",
       "+-------------------+---------------------+-------------------------------+\n",
       "| exception_message | exception_traceback |            job_name           |\n",
       "+-------------------+---------------------+-------------------------------+\n",
       "|        None       |         None        | Model-Parameter-Search-May... |\n",
       "|        None       |         None        | Model-Parameter-Search-May... |\n",
       "|        None       |         None        | Model-Parameter-Search-May... |\n",
       "|        None       |         None        | Model-Parameter-Search-May... |\n",
       "|        None       |         None        | Model-Parameter-Search-May... |\n",
       "|        None       |         None        | Model-Parameter-Search-May... |\n",
       "|        None       |         None        | Model-Parameter-Search-May... |\n",
       "|        None       |         None        | Model-Parameter-Search-May... |\n",
       "|        None       |         None        | Model-Parameter-Search-May... |\n",
       "|        None       |         None        | Model-Parameter-Search-May... |\n",
       "+-------------------+---------------------+-------------------------------+\n",
       "[35 rows x 8 columns]\n",
       "Note: Only the head of the SFrame is printed.\n",
       "You can use print_rows(num_rows=m, num_columns=n) to print more rows and columns."
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = model_search.get_metrics()\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 14)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_results.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-----------------+----------------+\n",
      "| class_weights |       std       |      mean      |\n",
      "+---------------+-----------------+----------------+\n",
      "|      None     | 0.0159401641879 | 0.889271322173 |\n",
      "+---------------+-----------------+----------------+\n",
      "[1 rows x 3 columns]\n",
      "\n",
      "+------------------+------------------+----------------+\n",
      "| column_subsample |       std        |      mean      |\n",
      "+------------------+------------------+----------------+\n",
      "| 0.0421898618649  |       0.0        | 0.862865681399 |\n",
      "|       0.5        | 0.0127577258664  | 0.900803623544 |\n",
      "| 0.0751646028003  | 0.00549159509322 | 0.881457355654 |\n",
      "+------------------+------------------+----------------+\n",
      "[3 rows x 3 columns]\n",
      "\n",
      "+-----------+----------------+----------------+\n",
      "| max_depth |      std       |      mean      |\n",
      "+-----------+----------------+----------------+\n",
      "|     6     |      0.0       | 0.884267236348 |\n",
      "|     12    | 0.016513145653 | 0.896034414326 |\n",
      "|     9     | 0.013381018859 | 0.882068478439 |\n",
      "+-----------+----------------+----------------+\n",
      "[3 rows x 3 columns]\n",
      "\n",
      "+----------------+------------------+----------------+\n",
      "| max_iterations |       std        |      mean      |\n",
      "+----------------+------------------+----------------+\n",
      "|      200       | 0.0139737979744  | 0.89786836637  |\n",
      "|      150       | 0.00240040371231 | 0.880879114037 |\n",
      "|      100       |       0.0        | 0.862865681399 |\n",
      "+----------------+------------------+----------------+\n",
      "[3 rows x 3 columns]\n",
      "\n",
      "+--------+-----------------+----------------+\n",
      "| metric |       std       |      mean      |\n",
      "+--------+-----------------+----------------+\n",
      "|  auc   | 0.0159401641879 | 0.889271322173 |\n",
      "+--------+-----------------+----------------+\n",
      "[1 rows x 3 columns]\n",
      "\n",
      "+------------------+------------------+----------------+\n",
      "| min_child_weight |       std        |      mean      |\n",
      "+------------------+------------------+----------------+\n",
      "|        2         |       0.0        | 0.913250916392 |\n",
      "|        16        |       0.0        | 0.862865681399 |\n",
      "|        8         | 0.00119880686648 | 0.87834395648  |\n",
      "|        1         | 0.0128187286724  | 0.896103873363 |\n",
      "|        4         |       0.0        | 0.897149261049 |\n",
      "+------------------+------------------+----------------+\n",
      "[5 rows x 3 columns]\n",
      "\n",
      "+--------------------+------------------+----------------+\n",
      "| min_loss_reduction |       std        |      mean      |\n",
      "+--------------------+------------------+----------------+\n",
      "|         10         | 0.0143657631155  | 0.877231444514 |\n",
      "|         0          | 0.00834433680765 | 0.88599408139  |\n",
      "|         1          | 0.0171099202572  | 0.898568501786 |\n",
      "+--------------------+------------------+----------------+\n",
      "[3 rows x 3 columns]\n",
      "\n",
      "+---------------+------------------+----------------+\n",
      "| row_subsample |       std        |      mean      |\n",
      "+---------------+------------------+----------------+\n",
      "|      0.9      | 0.0209762076874  | 0.892265882188 |\n",
      "|      1.0      | 0.00708813094983 | 0.886276762158 |\n",
      "+---------------+------------------+----------------+\n",
      "[2 rows x 3 columns]\n",
      "\n",
      "+--------+-----------------+----------------+\n",
      "| target |       std       |      mean      |\n",
      "+--------+-----------------+----------------+\n",
      "| target | 0.0159401641879 | 0.889271322173 |\n",
      "+--------+-----------------+----------------+\n",
      "[1 rows x 3 columns]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for col in [col for col in search_results.column_names() if \\\n",
    "            not('accuracy' in col) and col!= 'model_id' and col!= 'random_seed' and col!= 'fold_id' \\\n",
    "                               and col!= 'num_folds']:\n",
    "    print(search_results.groupby(col,\n",
    "                             {'mean':gl.aggregate.MEAN('mean_training_accuracy'),\n",
    "                                'std':gl.aggregate.STD('mean_training_accuracy')}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Refit best model for feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 'currently non_endemic, that used to live in the endemic area')"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "case, case_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = model_search.get_best_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'class_weights': None,\n",
       " 'column_subsample': 0.5,\n",
       " 'max_depth': 12,\n",
       " 'max_iterations': 200,\n",
       " 'metric': 'auc',\n",
       " 'min_child_weight': 1,\n",
       " 'min_loss_reduction': 1,\n",
       " 'row_subsample': 0.9,\n",
       " 'target': 'target'}"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ## manually insert params if needed\n",
    "params = {'class_weights': None,\n",
    " 'column_subsample': 0.5,\n",
    " 'max_depth': 12,\n",
    " 'max_iterations': 200,\n",
    " 'metric': 'auc',\n",
    " 'min_child_weight': 1,\n",
    " 'min_loss_reduction': 1,\n",
    " 'row_subsample': 0.9,\n",
    " 'target': 'target'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre>Random forest classifier:</pre>"
      ],
      "text/plain": [
       "Random forest classifier:"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>--------------------------------------------------------</pre>"
      ],
      "text/plain": [
       "--------------------------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of examples          : 95180</pre>"
      ],
      "text/plain": [
       "Number of examples          : 95180"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of classes           : 2</pre>"
      ],
      "text/plain": [
       "Number of classes           : 2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of feature columns   : 176</pre>"
      ],
      "text/plain": [
       "Number of feature columns   : 176"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of unpacked features : 176</pre>"
      ],
      "text/plain": [
       "Number of unpacked features : 176"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>+-----------+--------------+--------------+----------------+</pre>"
      ],
      "text/plain": [
       "+-----------+--------------+--------------+----------------+"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| Iteration | Elapsed Time | Training-auc | Validation-auc |</pre>"
      ],
      "text/plain": [
       "| Iteration | Elapsed Time | Training-auc | Validation-auc |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>+-----------+--------------+--------------+----------------+</pre>"
      ],
      "text/plain": [
       "+-----------+--------------+--------------+----------------+"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 1         | 0.652321     | 0.887324     | 0.857103       |</pre>"
      ],
      "text/plain": [
       "| 1         | 0.652321     | 0.887324     | 0.857103       |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 2         | 1.246490     | 0.901957     | 0.867521       |</pre>"
      ],
      "text/plain": [
       "| 2         | 1.246490     | 0.901957     | 0.867521       |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 3         | 1.806583     | 0.905375     | 0.872422       |</pre>"
      ],
      "text/plain": [
       "| 3         | 1.806583     | 0.905375     | 0.872422       |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 4         | 2.413643     | 0.907046     | 0.874334       |</pre>"
      ],
      "text/plain": [
       "| 4         | 2.413643     | 0.907046     | 0.874334       |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 5         | 2.997941     | 0.907899     | 0.877066       |</pre>"
      ],
      "text/plain": [
       "| 5         | 2.997941     | 0.907899     | 0.877066       |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 6         | 3.560141     | 0.909016     | 0.877600       |</pre>"
      ],
      "text/plain": [
       "| 6         | 3.560141     | 0.909016     | 0.877600       |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 10        | 5.866732     | 0.910702     | 0.878135       |</pre>"
      ],
      "text/plain": [
       "| 10        | 5.866732     | 0.910702     | 0.878135       |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 11        | 6.437765     | 0.911047     | 0.878510       |</pre>"
      ],
      "text/plain": [
       "| 11        | 6.437765     | 0.911047     | 0.878510       |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 15        | 8.785547     | 0.910084     | 0.878787       |</pre>"
      ],
      "text/plain": [
       "| 15        | 8.785547     | 0.910084     | 0.878787       |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 20        | 11.807212    | 0.909904     | 0.878865       |</pre>"
      ],
      "text/plain": [
       "| 20        | 11.807212    | 0.909904     | 0.878865       |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 25        | 14.744240    | 0.910098     | 0.879282       |</pre>"
      ],
      "text/plain": [
       "| 25        | 14.744240    | 0.910098     | 0.879282       |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 30        | 17.685828    | 0.910600     | 0.879573       |</pre>"
      ],
      "text/plain": [
       "| 30        | 17.685828    | 0.910600     | 0.879573       |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 35        | 20.626458    | 0.910753     | 0.879844       |</pre>"
      ],
      "text/plain": [
       "| 35        | 20.626458    | 0.910753     | 0.879844       |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 40        | 23.548323    | 0.911700     | 0.880033       |</pre>"
      ],
      "text/plain": [
       "| 40        | 23.548323    | 0.911700     | 0.880033       |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 45        | 26.465986    | 0.911888     | 0.880170       |</pre>"
      ],
      "text/plain": [
       "| 45        | 26.465986    | 0.911888     | 0.880170       |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 50        | 29.398379    | 0.911304     | 0.880063       |</pre>"
      ],
      "text/plain": [
       "| 50        | 29.398379    | 0.911304     | 0.880063       |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 51        | 29.978672    | 0.911127     | 0.879940       |</pre>"
      ],
      "text/plain": [
       "| 51        | 29.978672    | 0.911127     | 0.879940       |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 55        | 32.421343    | 0.911586     | 0.880214       |</pre>"
      ],
      "text/plain": [
       "| 55        | 32.421343    | 0.911586     | 0.880214       |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 60        | 35.351890    | 0.911719     | 0.880223       |</pre>"
      ],
      "text/plain": [
       "| 60        | 35.351890    | 0.911719     | 0.880223       |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 65        | 38.301109    | 0.911431     | 0.880264       |</pre>"
      ],
      "text/plain": [
       "| 65        | 38.301109    | 0.911431     | 0.880264       |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 70        | 41.233651    | 0.911672     | 0.880431       |</pre>"
      ],
      "text/plain": [
       "| 70        | 41.233651    | 0.911672     | 0.880431       |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 75        | 44.202491    | 0.911783     | 0.880531       |</pre>"
      ],
      "text/plain": [
       "| 75        | 44.202491    | 0.911783     | 0.880531       |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 80        | 47.131820    | 0.911876     | 0.880787       |</pre>"
      ],
      "text/plain": [
       "| 80        | 47.131820    | 0.911876     | 0.880787       |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 85        | 50.115690    | 0.911692     | 0.880654       |</pre>"
      ],
      "text/plain": [
       "| 85        | 50.115690    | 0.911692     | 0.880654       |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 90        | 53.037312    | 0.911642     | 0.880638       |</pre>"
      ],
      "text/plain": [
       "| 90        | 53.037312    | 0.911642     | 0.880638       |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 95        | 55.982949    | 0.911761     | 0.880594       |</pre>"
      ],
      "text/plain": [
       "| 95        | 55.982949    | 0.911761     | 0.880594       |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 100       | 58.942501    | 0.911896     | 0.880770       |</pre>"
      ],
      "text/plain": [
       "| 100       | 58.942501    | 0.911896     | 0.880770       |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 101       | 59.543678    | 0.911917     | 0.880809       |</pre>"
      ],
      "text/plain": [
       "| 101       | 59.543678    | 0.911917     | 0.880809       |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 105       | 61.956159    | 0.912024     | 0.880812       |</pre>"
      ],
      "text/plain": [
       "| 105       | 61.956159    | 0.912024     | 0.880812       |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 110       | 64.997207    | 0.912055     | 0.880836       |</pre>"
      ],
      "text/plain": [
       "| 110       | 64.997207    | 0.912055     | 0.880836       |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 115       | 68.007296    | 0.912050     | 0.880840       |</pre>"
      ],
      "text/plain": [
       "| 115       | 68.007296    | 0.912050     | 0.880840       |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 120       | 70.928535    | 0.912091     | 0.880870       |</pre>"
      ],
      "text/plain": [
       "| 120       | 70.928535    | 0.912091     | 0.880870       |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 125       | 73.922047    | 0.912097     | 0.880861       |</pre>"
      ],
      "text/plain": [
       "| 125       | 73.922047    | 0.912097     | 0.880861       |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 130       | 76.888999    | 0.912162     | 0.880940       |</pre>"
      ],
      "text/plain": [
       "| 130       | 76.888999    | 0.912162     | 0.880940       |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 135       | 79.867156    | 0.912198     | 0.880969       |</pre>"
      ],
      "text/plain": [
       "| 135       | 79.867156    | 0.912198     | 0.880969       |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 140       | 82.805333    | 0.912126     | 0.880958       |</pre>"
      ],
      "text/plain": [
       "| 140       | 82.805333    | 0.912126     | 0.880958       |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 145       | 85.773335    | 0.912173     | 0.880983       |</pre>"
      ],
      "text/plain": [
       "| 145       | 85.773335    | 0.912173     | 0.880983       |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 150       | 88.706009    | 0.912145     | 0.880899       |</pre>"
      ],
      "text/plain": [
       "| 150       | 88.706009    | 0.912145     | 0.880899       |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 155       | 91.627645    | 0.912177     | 0.880941       |</pre>"
      ],
      "text/plain": [
       "| 155       | 91.627645    | 0.912177     | 0.880941       |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 160       | 94.561862    | 0.912095     | 0.880943       |</pre>"
      ],
      "text/plain": [
       "| 160       | 94.561862    | 0.912095     | 0.880943       |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 165       | 97.539032    | 0.912132     | 0.880898       |</pre>"
      ],
      "text/plain": [
       "| 165       | 97.539032    | 0.912132     | 0.880898       |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 170       | 100.415218   | 0.912055     | 0.880924       |</pre>"
      ],
      "text/plain": [
       "| 170       | 100.415218   | 0.912055     | 0.880924       |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 175       | 103.342166   | 0.912047     | 0.881013       |</pre>"
      ],
      "text/plain": [
       "| 175       | 103.342166   | 0.912047     | 0.881013       |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 180       | 106.324004   | 0.912119     | 0.881047       |</pre>"
      ],
      "text/plain": [
       "| 180       | 106.324004   | 0.912119     | 0.881047       |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 185       | 109.276733   | 0.912126     | 0.881056       |</pre>"
      ],
      "text/plain": [
       "| 185       | 109.276733   | 0.912126     | 0.881056       |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 190       | 112.230811   | 0.912185     | 0.881136       |</pre>"
      ],
      "text/plain": [
       "| 190       | 112.230811   | 0.912185     | 0.881136       |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 195       | 115.117248   | 0.912165     | 0.881090       |</pre>"
      ],
      "text/plain": [
       "| 195       | 115.117248   | 0.912165     | 0.881090       |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 200       | 118.090183   | 0.912192     | 0.881041       |</pre>"
      ],
      "text/plain": [
       "| 200       | 118.090183   | 0.912192     | 0.881041       |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>+-----------+--------------+--------------+----------------+</pre>"
      ],
      "text/plain": [
       "+-----------+--------------+--------------+----------------+"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9min 30s, sys: 17.7 s, total: 9min 48s\n",
      "Wall time: 2min 9s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "best_model =  random_forest_classifier.create(dataset=X_gl,\n",
    "                                             validation_set = X_val_gl,\n",
    "                                             **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\"><table frame=\"box\" rules=\"cols\">\n",
       "    <tr>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">name</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">index</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">MOBILITY_DIAMETER</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">7950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">COUNT_0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">7009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">COUNT_WEEKNIGHT_0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">6912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">MOBILITY_DIAMETER_WEEKNIG<br>HT ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">6333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">COUNT_1</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">4335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">COUNT_2</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">3925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">COUNT_WEEKNIGHT_1</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">COUNT_3</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">TimeWeekDay_OUT_08</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">TimeWeekDay_OUT_12</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2482</td>\n",
       "    </tr>\n",
       "</table>\n",
       "[20 rows x 3 columns]<br/>Note: Only the head of the SFrame is printed.<br/>You can use print_rows(num_rows=m, num_columns=n) to print more rows and columns.\n",
       "</div>"
      ],
      "text/plain": [
       "Columns:\n",
       "\tname\tstr\n",
       "\tindex\tstr\n",
       "\tcount\tint\n",
       "\n",
       "Rows: 20\n",
       "\n",
       "Data:\n",
       "+-----------------------------+-------+-------+\n",
       "|             name            | index | count |\n",
       "+-----------------------------+-------+-------+\n",
       "|      MOBILITY_DIAMETER      |  None |  7950 |\n",
       "|           COUNT_0           |  None |  7009 |\n",
       "|      COUNT_WEEKNIGHT_0      |  None |  6912 |\n",
       "| MOBILITY_DIAMETER_WEEKNIGHT |  None |  6333 |\n",
       "|           COUNT_1           |  None |  4335 |\n",
       "|           COUNT_2           |  None |  3925 |\n",
       "|      COUNT_WEEKNIGHT_1      |  None |  2844 |\n",
       "|           COUNT_3           |  None |  2687 |\n",
       "|      TimeWeekDay_OUT_08     |  None |  2509 |\n",
       "|      TimeWeekDay_OUT_12     |  None |  2482 |\n",
       "+-----------------------------+-------+-------+\n",
       "[20 rows x 3 columns]\n",
       "Note: Only the head of the SFrame is printed.\n",
       "You can use print_rows(num_rows=m, num_columns=n) to print more rows and columns."
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_feat = best_model.get_feature_importance()\n",
    "best_feat.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# filter_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MOBILITY_DIAMETER',\n",
       " 'COUNT_0',\n",
       " 'COUNT_WEEKNIGHT_0',\n",
       " 'MOBILITY_DIAMETER_WEEKNIGHT',\n",
       " 'COUNT_1',\n",
       " 'COUNT_2',\n",
       " 'COUNT_WEEKNIGHT_1',\n",
       " 'COUNT_3',\n",
       " 'TimeWeekDay_OUT_08',\n",
       " 'TimeWeekDay_OUT_12',\n",
       " 'TimeWeekDay_IN_08',\n",
       " 'COUNT_4',\n",
       " 'COUNT_5',\n",
       " 'TimeWeekDay_IN_09',\n",
       " 'TimeWeekDay_IN_12',\n",
       " 'TimeWeekDay_OUT_09',\n",
       " 'TimeWeekEnd_IN_08',\n",
       " 'TimeWeekDay_OUT_VUL_08',\n",
       " 'CallsWeekDay_OUT_08',\n",
       " 'TimeWeekEnd_OUT_08',\n",
       " 'COUNT_WEEKNIGHT_2',\n",
       " 'COUNT_7',\n",
       " 'CallsWeekDay_OUT_12',\n",
       " 'TimeWeekDay_OUT_11',\n",
       " 'COUNT_6',\n",
       " 'CallsWeekDay_IN_12',\n",
       " 'TimeWeekDay_IN_10',\n",
       " 'TimeWeekDay_OUT_10',\n",
       " 'TimeWeekDay_IN_VUL_08',\n",
       " 'COUNT_8']"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(best_feat['name'].head(30))\n",
    "#print_rows(num_rows= 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "118.09162"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.training_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.8896624070188823,\n",
       " 'auc': 0.8810393712641603,\n",
       " 'confusion_matrix': Columns:\n",
       " \ttarget_label\tint\n",
       " \tpredicted_label\tint\n",
       " \tcount\tint\n",
       " \n",
       " Rows: 4\n",
       " \n",
       " Data:\n",
       " +--------------+-----------------+-------+\n",
       " | target_label | predicted_label | count |\n",
       " +--------------+-----------------+-------+\n",
       " |      0       |        1        |  258  |\n",
       " |      1       |        0        |  899  |\n",
       " |      1       |        1        |  1139 |\n",
       " |      0       |        0        |  8190 |\n",
       " +--------------+-----------------+-------+\n",
       " [4 rows x 3 columns],\n",
       " 'f1_score': 0.6631732168850072,\n",
       " 'log_loss': 0.337038657437402,\n",
       " 'precision': 0.8153185397279885,\n",
       " 'recall': 0.5588812561334642,\n",
       " 'roc_curve': Columns:\n",
       " \tthreshold\tfloat\n",
       " \tfpr\tfloat\n",
       " \ttpr\tfloat\n",
       " \tp\tint\n",
       " \tn\tint\n",
       " \n",
       " Rows: 100001\n",
       " \n",
       " Data:\n",
       " +-----------+-----+-----+------+------+\n",
       " | threshold | fpr | tpr |  p   |  n   |\n",
       " +-----------+-----+-----+------+------+\n",
       " |    0.0    | 1.0 | 1.0 | 2038 | 8448 |\n",
       " |   1e-05   | 1.0 | 1.0 | 2038 | 8448 |\n",
       " |   2e-05   | 1.0 | 1.0 | 2038 | 8448 |\n",
       " |   3e-05   | 1.0 | 1.0 | 2038 | 8448 |\n",
       " |   4e-05   | 1.0 | 1.0 | 2038 | 8448 |\n",
       " |   5e-05   | 1.0 | 1.0 | 2038 | 8448 |\n",
       " |   6e-05   | 1.0 | 1.0 | 2038 | 8448 |\n",
       " |   7e-05   | 1.0 | 1.0 | 2038 | 8448 |\n",
       " |   8e-05   | 1.0 | 1.0 | 2038 | 8448 |\n",
       " |   9e-05   | 1.0 | 1.0 | 2038 | 8448 |\n",
       " +-----------+-----+-----+------+------+\n",
       " [100001 rows x 5 columns]\n",
       " Note: Only the head of the SFrame is printed.\n",
       " You can use print_rows(num_rows=m, num_columns=n) to print more rows and columns.}"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_error = best_model.evaluate(X_val_gl)\n",
    "\n",
    "test_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method RandomForestClassifier.get_current_options of Class                          : RandomForestClassifier\n",
       "\n",
       "Schema\n",
       "------\n",
       "Number of examples             : 95180\n",
       "Number of feature columns      : 176\n",
       "Number of unpacked features    : 176\n",
       "Number of classes              : 2\n",
       "\n",
       "Settings\n",
       "--------\n",
       "Number of trees                : 200\n",
       "Max tree depth                 : 12\n",
       "Training time (sec)            : 118.0916\n",
       "Training auc                   : 0.9122\n",
       "Validation auc                 : 0.881\n",
       ">"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.get_current_options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boosted Classifier\n",
    "### HyperParams search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Boosted Trees HyperParams\n",
    "\n",
    "# target_col = 'Y'\n",
    "\n",
    "params = {\n",
    "    'target': target_col, ## the target column string name \n",
    "    'max_iterations': [\n",
    "                      200,\n",
    "                       250,\n",
    "#                        90,\n",
    "#                        120,\n",
    "                    300,\n",
    "                      ], #The maximum number of iterations for boosting. Each iteration == extra tree.\n",
    "    'class_weights': [\n",
    "                      None, \n",
    "#                       'auto',\n",
    "    ], #Weights the examples in the training data according to the given class weights.\n",
    "#     'class_weights': [None],\n",
    "    'max_depth': [\n",
    "#         2,\n",
    "#         3,\n",
    "        4,\n",
    "#         6,\n",
    "        9,\n",
    "        15,\n",
    "        20,\n",
    "    ], #Maximum depth of a tree. Must be at least 1.\n",
    "    'step_size': [\n",
    "        1e-1,\n",
    "        0.5,\n",
    "        1e-2,\n",
    "        1,\n",
    "    ], # Step size (shrinkage) used in update to prevents overfitting\n",
    "    'min_loss_reduction': [\n",
    "#         1e-2,\n",
    "        1,\n",
    "        10,\n",
    "    ], #Minimum loss reduction required to make a further partition/split a node during the tree learning\n",
    "    'min_child_weight': [\n",
    "#         1e-2,\n",
    "        2,\n",
    "        5,\n",
    "        10,\n",
    "    ], # Controls the minimum weight of each leaf node . larger values > less overfitting\n",
    "    'row_subsample': [\n",
    "        0.5,\n",
    "        0.75,\n",
    "    ], #Subsample the ratio of the training set in each iteration of tree construction\n",
    "    \n",
    "    'column_subsample': [\n",
    "#         0.01,\n",
    "        0.1,\n",
    "        0.05,\n",
    "        0.8,\n",
    "                        ], # Subsample the ratio of the columns in each iteration of tree construction\n",
    "    #'metric': ['accuracy', 'auc', 'f1_score','recall','precision'], # Performance metric(s) that are tracked during training     \n",
    "    'metric': ['auc'],\n",
    "    'random_seed' : int(abs(hash('im not joking...'))%1e6) \n",
    "}\n",
    "\n",
    "model_factory = boosted_trees_classifier.create"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose if we want to use random forest's top features result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_cols = 30\n",
    "\n",
    "top_rf_features = False\n",
    "# top_rf_features = None\n",
    "\n",
    "if top_rf_features:\n",
    "    filter_cols = list(best_feat['name'].head(n_cols).to_numpy()) + [target_col]\n",
    "\n",
    "    X_val_gl = X_val_gl[filter_cols]\n",
    "    X_gl = X_gl[filter_cols]\n",
    "    \n",
    "    kfold = cross_validation.KFold(\n",
    "    X_gl,num_folds=num_folds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search Boosted "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] graphlab.deploy.job: Validating job.\n",
      "[INFO] graphlab.deploy.map_job: Validation complete. Job: 'Model-Parameter-Search-May-28-2017-05-23-0800000' ready for execution\n",
      "[INFO] graphlab.deploy.map_job: Job: 'Model-Parameter-Search-May-28-2017-05-23-0800000' scheduled.\n",
      "[INFO] graphlab.deploy.job: Validating job.\n",
      "[INFO] graphlab.deploy.map_job: A job with name 'Model-Parameter-Search-May-28-2017-05-23-0800000' already exists. Renaming the job to 'Model-Parameter-Search-May-28-2017-05-23-0800000-804e5'.\n",
      "[INFO] graphlab.deploy.map_job: Validation complete. Job: 'Model-Parameter-Search-May-28-2017-05-23-0800000-804e5' ready for execution\n",
      "[INFO] graphlab.deploy.map_job: Job: 'Model-Parameter-Search-May-28-2017-05-23-0800000-804e5' scheduled.\n",
      "[INFO] graphlab.deploy.job: Validating job.\n",
      "[INFO] graphlab.deploy.map_job: Validation complete. Job: 'Model-Parameter-Search-May-28-2017-05-23-0800001' ready for execution\n",
      "[INFO] graphlab.deploy.map_job: Job: 'Model-Parameter-Search-May-28-2017-05-23-0800001' scheduled.\n",
      "[INFO] graphlab.deploy.job: Validating job.\n",
      "[INFO] graphlab.deploy.map_job: Validation complete. Job: 'Model-Parameter-Search-May-28-2017-05-23-0800002' ready for execution\n",
      "[INFO] graphlab.deploy.map_job: Job: 'Model-Parameter-Search-May-28-2017-05-23-0800002' scheduled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 41.5 s, sys: 9.14 s, total: 50.6 s\n",
      "Wall time: 19min 32s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "start_time = time.time()\n",
    "model_search = model_parameter_search.create( datasets = kfold, \n",
    "                                             #[data, val_set],\n",
    "                                             model_factory = model_factory,\n",
    "                                    model_parameters = params, \n",
    "                                    perform_trial_run = True  )\n",
    "\n",
    "search_results = model_search.get_results()\n",
    "\n",
    "all_time = time.time() - start_time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 19.53582328557968)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert duration in seconds to hours and minutes\n",
    "int(abs(all_time)/3600) ,(abs(all_time)/3600 %1)*60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\"><table frame=\"box\" rules=\"cols\">\n",
       "    <tr>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">task_name</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">status</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">start_time</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">run_time</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">exception</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">exception_message</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">exception_traceback</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">_train_test_model-0-0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Completed</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2017-05-28 05:24:26</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">84.0898089409</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">_train_test_model-0-1</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Completed</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2017-05-28 05:25:50</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">86.6875948906</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">_train_test_model-0-2</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Completed</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2017-05-28 05:27:17</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">59.9590389729</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">_train_test_model-0-3</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Completed</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2017-05-28 05:28:17</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">94.800579071</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">_train_test_model-0-4</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Completed</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2017-05-28 05:29:52</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">138.167016983</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">_train_test_model-0-5</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Completed</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2017-05-28 05:32:10</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">89.2651269436</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">_train_test_model-0-6</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Completed</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2017-05-28 05:33:40</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">101.135102987</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">_train_test_model-0-7</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Completed</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2017-05-28 05:35:21</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">48.8374538422</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">_train_test_model-0-8</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Completed</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2017-05-28 05:36:10</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">62.6350979805</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">_train_test_model-0-9</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Completed</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2017-05-28 05:37:13</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">44.2389678955</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "    </tr>\n",
       "</table>\n",
       "<table frame=\"box\" rules=\"cols\">\n",
       "    <tr>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">job_name</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Model-Parameter-Search-Ma<br>y-28-2017-05-23-08000 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Model-Parameter-Search-Ma<br>y-28-2017-05-23-08000 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Model-Parameter-Search-Ma<br>y-28-2017-05-23-08000 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Model-Parameter-Search-Ma<br>y-28-2017-05-23-08000 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Model-Parameter-Search-Ma<br>y-28-2017-05-23-08000 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Model-Parameter-Search-Ma<br>y-28-2017-05-23-08000 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Model-Parameter-Search-Ma<br>y-28-2017-05-23-08000 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Model-Parameter-Search-Ma<br>y-28-2017-05-23-08000 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Model-Parameter-Search-Ma<br>y-28-2017-05-23-08000 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Model-Parameter-Search-Ma<br>y-28-2017-05-23-08000 ...</td>\n",
       "    </tr>\n",
       "</table>\n",
       "[35 rows x 8 columns]<br/>Note: Only the head of the SFrame is printed.<br/>You can use print_rows(num_rows=m, num_columns=n) to print more rows and columns.\n",
       "</div>"
      ],
      "text/plain": [
       "Columns:\n",
       "\ttask_name\tstr\n",
       "\tstatus\tstr\n",
       "\tstart_time\tstr\n",
       "\trun_time\tfloat\n",
       "\texception\tfloat\n",
       "\texception_message\tfloat\n",
       "\texception_traceback\tfloat\n",
       "\tjob_name\tstr\n",
       "\n",
       "Rows: 35\n",
       "\n",
       "Data:\n",
       "+-----------------------+-----------+---------------------+---------------+-----------+\n",
       "|       task_name       |   status  |      start_time     |    run_time   | exception |\n",
       "+-----------------------+-----------+---------------------+---------------+-----------+\n",
       "| _train_test_model-0-0 | Completed | 2017-05-28 05:24:26 | 84.0898089409 |    None   |\n",
       "| _train_test_model-0-1 | Completed | 2017-05-28 05:25:50 | 86.6875948906 |    None   |\n",
       "| _train_test_model-0-2 | Completed | 2017-05-28 05:27:17 | 59.9590389729 |    None   |\n",
       "| _train_test_model-0-3 | Completed | 2017-05-28 05:28:17 |  94.800579071 |    None   |\n",
       "| _train_test_model-0-4 | Completed | 2017-05-28 05:29:52 | 138.167016983 |    None   |\n",
       "| _train_test_model-0-5 | Completed | 2017-05-28 05:32:10 | 89.2651269436 |    None   |\n",
       "| _train_test_model-0-6 | Completed | 2017-05-28 05:33:40 | 101.135102987 |    None   |\n",
       "| _train_test_model-0-7 | Completed | 2017-05-28 05:35:21 | 48.8374538422 |    None   |\n",
       "| _train_test_model-0-8 | Completed | 2017-05-28 05:36:10 | 62.6350979805 |    None   |\n",
       "| _train_test_model-0-9 | Completed | 2017-05-28 05:37:13 | 44.2389678955 |    None   |\n",
       "+-----------------------+-----------+---------------------+---------------+-----------+\n",
       "+-------------------+---------------------+-------------------------------+\n",
       "| exception_message | exception_traceback |            job_name           |\n",
       "+-------------------+---------------------+-------------------------------+\n",
       "|        None       |         None        | Model-Parameter-Search-May... |\n",
       "|        None       |         None        | Model-Parameter-Search-May... |\n",
       "|        None       |         None        | Model-Parameter-Search-May... |\n",
       "|        None       |         None        | Model-Parameter-Search-May... |\n",
       "|        None       |         None        | Model-Parameter-Search-May... |\n",
       "|        None       |         None        | Model-Parameter-Search-May... |\n",
       "|        None       |         None        | Model-Parameter-Search-May... |\n",
       "|        None       |         None        | Model-Parameter-Search-May... |\n",
       "|        None       |         None        | Model-Parameter-Search-May... |\n",
       "|        None       |         None        | Model-Parameter-Search-May... |\n",
       "+-------------------+---------------------+-------------------------------+\n",
       "[35 rows x 8 columns]\n",
       "Note: Only the head of the SFrame is printed.\n",
       "You can use print_rows(num_rows=m, num_columns=n) to print more rows and columns."
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = model_search.get_metrics()\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# res['exception_message']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\"><table frame=\"box\" rules=\"cols\">\n",
       "    <tr>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">task_name</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">status</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">start_time</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">run_time</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">exception</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">exception_message</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">exception_traceback</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">_train_test_model-0-0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Completed</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2017-05-28 05:24:26</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">84.0898089409</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">_train_test_model-0-1</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Completed</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2017-05-28 05:25:50</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">86.6875948906</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">_train_test_model-0-2</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Completed</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2017-05-28 05:27:17</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">59.9590389729</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">_train_test_model-0-3</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Completed</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2017-05-28 05:28:17</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">94.800579071</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">_train_test_model-0-4</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Completed</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2017-05-28 05:29:52</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">138.167016983</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">_train_test_model-0-5</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Completed</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2017-05-28 05:32:10</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">89.2651269436</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">_train_test_model-0-6</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Completed</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2017-05-28 05:33:40</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">101.135102987</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">_train_test_model-0-7</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Completed</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2017-05-28 05:35:21</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">48.8374538422</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">_train_test_model-0-8</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Completed</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2017-05-28 05:36:10</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">62.6350979805</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">_train_test_model-0-9</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Completed</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2017-05-28 05:37:13</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">44.2389678955</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "    </tr>\n",
       "</table>\n",
       "<table frame=\"box\" rules=\"cols\">\n",
       "    <tr>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">job_name</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Model-Parameter-Search-Ma<br>y-28-2017-05-23-08000 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Model-Parameter-Search-Ma<br>y-28-2017-05-23-08000 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Model-Parameter-Search-Ma<br>y-28-2017-05-23-08000 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Model-Parameter-Search-Ma<br>y-28-2017-05-23-08000 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Model-Parameter-Search-Ma<br>y-28-2017-05-23-08000 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Model-Parameter-Search-Ma<br>y-28-2017-05-23-08000 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Model-Parameter-Search-Ma<br>y-28-2017-05-23-08000 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Model-Parameter-Search-Ma<br>y-28-2017-05-23-08000 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Model-Parameter-Search-Ma<br>y-28-2017-05-23-08000 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Model-Parameter-Search-Ma<br>y-28-2017-05-23-08000 ...</td>\n",
       "    </tr>\n",
       "</table>\n",
       "[35 rows x 8 columns]<br/>Note: Only the head of the SFrame is printed.<br/>You can use print_rows(num_rows=m, num_columns=n) to print more rows and columns.\n",
       "</div>"
      ],
      "text/plain": [
       "Columns:\n",
       "\ttask_name\tstr\n",
       "\tstatus\tstr\n",
       "\tstart_time\tstr\n",
       "\trun_time\tfloat\n",
       "\texception\tfloat\n",
       "\texception_message\tfloat\n",
       "\texception_traceback\tfloat\n",
       "\tjob_name\tstr\n",
       "\n",
       "Rows: 35\n",
       "\n",
       "Data:\n",
       "+-----------------------+-----------+---------------------+---------------+-----------+\n",
       "|       task_name       |   status  |      start_time     |    run_time   | exception |\n",
       "+-----------------------+-----------+---------------------+---------------+-----------+\n",
       "| _train_test_model-0-0 | Completed | 2017-05-28 05:24:26 | 84.0898089409 |    None   |\n",
       "| _train_test_model-0-1 | Completed | 2017-05-28 05:25:50 | 86.6875948906 |    None   |\n",
       "| _train_test_model-0-2 | Completed | 2017-05-28 05:27:17 | 59.9590389729 |    None   |\n",
       "| _train_test_model-0-3 | Completed | 2017-05-28 05:28:17 |  94.800579071 |    None   |\n",
       "| _train_test_model-0-4 | Completed | 2017-05-28 05:29:52 | 138.167016983 |    None   |\n",
       "| _train_test_model-0-5 | Completed | 2017-05-28 05:32:10 | 89.2651269436 |    None   |\n",
       "| _train_test_model-0-6 | Completed | 2017-05-28 05:33:40 | 101.135102987 |    None   |\n",
       "| _train_test_model-0-7 | Completed | 2017-05-28 05:35:21 | 48.8374538422 |    None   |\n",
       "| _train_test_model-0-8 | Completed | 2017-05-28 05:36:10 | 62.6350979805 |    None   |\n",
       "| _train_test_model-0-9 | Completed | 2017-05-28 05:37:13 | 44.2389678955 |    None   |\n",
       "+-----------------------+-----------+---------------------+---------------+-----------+\n",
       "+-------------------+---------------------+-------------------------------+\n",
       "| exception_message | exception_traceback |            job_name           |\n",
       "+-------------------+---------------------+-------------------------------+\n",
       "|        None       |         None        | Model-Parameter-Search-May... |\n",
       "|        None       |         None        | Model-Parameter-Search-May... |\n",
       "|        None       |         None        | Model-Parameter-Search-May... |\n",
       "|        None       |         None        | Model-Parameter-Search-May... |\n",
       "|        None       |         None        | Model-Parameter-Search-May... |\n",
       "|        None       |         None        | Model-Parameter-Search-May... |\n",
       "|        None       |         None        | Model-Parameter-Search-May... |\n",
       "|        None       |         None        | Model-Parameter-Search-May... |\n",
       "|        None       |         None        | Model-Parameter-Search-May... |\n",
       "|        None       |         None        | Model-Parameter-Search-May... |\n",
       "+-------------------+---------------------+-------------------------------+\n",
       "[35 rows x 8 columns]\n",
       "Note: Only the head of the SFrame is printed.\n",
       "You can use print_rows(num_rows=m, num_columns=n) to print more rows and columns."
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 17)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_results.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\"><table frame=\"box\" rules=\"cols\">\n",
       "    <tr>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">class_weights</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">column_subsample</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">early_stopping_rounds</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">max_depth</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">max_iterations</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">metric</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">min_child_weight</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">min_loss_reduction</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.1</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">5</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">9</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">250</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">auc</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.8</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">5</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">15</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">200</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">auc</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">5</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.8</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">5</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">15</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">200</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">auc</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">10</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.05</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">5</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">15</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">200</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">auc</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">5</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.05</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">5</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">9</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">200</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">auc</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">10</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.8</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">5</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">9</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">300</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">auc</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.1</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">5</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">15</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">300</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">auc</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.8</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">5</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">20</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">250</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">auc</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.05</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">5</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">9</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">200</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">auc</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.8</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">5</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">4</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">200</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">auc</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">10</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n",
       "    </tr>\n",
       "</table>\n",
       "<table frame=\"box\" rules=\"cols\">\n",
       "    <tr>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">random_seed</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">row_subsample</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">step_size</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">target</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">num_folds</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">fold_id</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">mean_training_accuracy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">415168</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.75</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1.0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">target</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">10</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">[8, 9, 4, 5, 6, 7, 0, 1,<br>2, 3] ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.888214143961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">415168</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.75</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.5</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">target</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">10</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">[9, 8, 1, 0, 3, 2, 5, 4,<br>7, 6] ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.916128505055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">415168</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.5</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1.0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">target</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">10</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">[1, 8, 9, 4, 5, 6, 7, 0,<br>3, 2] ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.886419882795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">415168</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.75</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1.0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">target</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">10</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">[0, 1, 5, 4, 7, 6, 2, 3,<br>9, 8] ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.886152553057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">415168</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.5</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.1</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">target</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">10</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">[1, 0, 3, 2, 5, 4, 7, 6,<br>9, 8] ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.874481100138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">415168</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.5</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1.0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">target</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">10</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">[8, 9, 1, 0, 3, 2, 5, 4,<br>7, 6] ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.888411430973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">415168</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.5</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.1</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">target</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">10</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">[3, 2, 1, 0, 5, 4, 7, 6,<br>9, 8] ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.882219653989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">415168</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.5</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.01</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">target</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">10</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">[8, 1, 0, 3, 2, 5, 4, 7,<br>9, 6] ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.91135859541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">415168</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.75</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.01</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">target</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">10</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">[3, 4, 5, 0, 1, 9, 8, 6,<br>7, 2] ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.869836100021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">415168</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.5</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.5</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">target</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">10</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">[7, 9, 8, 6, 1, 0, 3, 2,<br>5, 4] ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.889262450095</td>\n",
       "    </tr>\n",
       "</table>\n",
       "<table frame=\"box\" rules=\"cols\">\n",
       "    <tr>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">mean_validation_accuracy</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">model_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.87504727884</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">[28, 29, 24, 25, 26, 27,<br>20, 21, 22, 23] ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.878976675772</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">[19, 18, 11, 10, 13, 12,<br>15, 14, 17, 16] ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.877390208027</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">[51, 58, 59, 54, 55, 56,<br>57, 50, 53, 52] ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.876392099181</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">[60, 61, 65, 64, 67, 66,<br>62, 63, 69, 68] ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.870487497373</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">[31, 30, 33, 32, 35, 34,<br>37, 36, 39, 38] ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.877064509351</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">[88, 89, 81, 80, 83, 82,<br>85, 84, 87, 86] ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.878041605379</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">[43, 42, 41, 40, 45, 44,<br>47, 46, 49, 48] ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.883441899559</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">[8, 1, 0, 3, 2, 5, 4, 7,<br>9, 6] ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.866453036352</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">[93, 94, 95, 90, 91, 99,<br>98, 96, 97, 92] ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.882086572809</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">[77, 79, 78, 76, 71, 70,<br>73, 72, 75, 74] ...</td>\n",
       "    </tr>\n",
       "</table>\n",
       "[10 rows x 17 columns]<br/>\n",
       "</div>"
      ],
      "text/plain": [
       "Columns:\n",
       "\tclass_weights\tfloat\n",
       "\tcolumn_subsample\tfloat\n",
       "\tearly_stopping_rounds\tint\n",
       "\tmax_depth\tint\n",
       "\tmax_iterations\tint\n",
       "\tmetric\tstr\n",
       "\tmin_child_weight\tint\n",
       "\tmin_loss_reduction\tint\n",
       "\trandom_seed\tint\n",
       "\trow_subsample\tfloat\n",
       "\tstep_size\tfloat\n",
       "\ttarget\tstr\n",
       "\tnum_folds\tint\n",
       "\tfold_id\tlist\n",
       "\tmean_training_accuracy\tfloat\n",
       "\tmean_validation_accuracy\tfloat\n",
       "\tmodel_id\tlist\n",
       "\n",
       "Rows: 10\n",
       "\n",
       "Data:\n",
       "+---------------+------------------+-----------------------+-----------+----------------+\n",
       "| class_weights | column_subsample | early_stopping_rounds | max_depth | max_iterations |\n",
       "+---------------+------------------+-----------------------+-----------+----------------+\n",
       "|      None     |       0.1        |           5           |     9     |      250       |\n",
       "|      None     |       0.8        |           5           |     15    |      200       |\n",
       "|      None     |       0.8        |           5           |     15    |      200       |\n",
       "|      None     |       0.05       |           5           |     15    |      200       |\n",
       "|      None     |       0.05       |           5           |     9     |      200       |\n",
       "|      None     |       0.8        |           5           |     9     |      300       |\n",
       "|      None     |       0.1        |           5           |     15    |      300       |\n",
       "|      None     |       0.8        |           5           |     20    |      250       |\n",
       "|      None     |       0.05       |           5           |     9     |      200       |\n",
       "|      None     |       0.8        |           5           |     4     |      200       |\n",
       "+---------------+------------------+-----------------------+-----------+----------------+\n",
       "+--------+------------------+--------------------+-------------+---------------+\n",
       "| metric | min_child_weight | min_loss_reduction | random_seed | row_subsample |\n",
       "+--------+------------------+--------------------+-------------+---------------+\n",
       "|  auc   |        2         |         10         |    415168   |      0.75     |\n",
       "|  auc   |        5         |         1          |    415168   |      0.75     |\n",
       "|  auc   |        10        |         10         |    415168   |      0.5      |\n",
       "|  auc   |        5         |         10         |    415168   |      0.75     |\n",
       "|  auc   |        10        |         1          |    415168   |      0.5      |\n",
       "|  auc   |        2         |         10         |    415168   |      0.5      |\n",
       "|  auc   |        2         |         10         |    415168   |      0.5      |\n",
       "|  auc   |        2         |         1          |    415168   |      0.5      |\n",
       "|  auc   |        2         |         10         |    415168   |      0.75     |\n",
       "|  auc   |        10        |         1          |    415168   |      0.5      |\n",
       "+--------+------------------+--------------------+-------------+---------------+\n",
       "+-----------+--------+-----------+--------------------------------+\n",
       "| step_size | target | num_folds |            fold_id             |\n",
       "+-----------+--------+-----------+--------------------------------+\n",
       "|    1.0    | target |     10    | [8, 9, 4, 5, 6, 7, 0, 1, 2, 3] |\n",
       "|    0.5    | target |     10    | [9, 8, 1, 0, 3, 2, 5, 4, 7, 6] |\n",
       "|    1.0    | target |     10    | [1, 8, 9, 4, 5, 6, 7, 0, 3, 2] |\n",
       "|    1.0    | target |     10    | [0, 1, 5, 4, 7, 6, 2, 3, 9, 8] |\n",
       "|    0.1    | target |     10    | [1, 0, 3, 2, 5, 4, 7, 6, 9, 8] |\n",
       "|    1.0    | target |     10    | [8, 9, 1, 0, 3, 2, 5, 4, 7, 6] |\n",
       "|    0.1    | target |     10    | [3, 2, 1, 0, 5, 4, 7, 6, 9, 8] |\n",
       "|    0.01   | target |     10    | [8, 1, 0, 3, 2, 5, 4, 7, 9, 6] |\n",
       "|    0.01   | target |     10    | [3, 4, 5, 0, 1, 9, 8, 6, 7, 2] |\n",
       "|    0.5    | target |     10    | [7, 9, 8, 6, 1, 0, 3, 2, 5, 4] |\n",
       "+-----------+--------+-----------+--------------------------------+\n",
       "+------------------------+--------------------------+\n",
       "| mean_training_accuracy | mean_validation_accuracy |\n",
       "+------------------------+--------------------------+\n",
       "|     0.888214143961     |      0.87504727884       |\n",
       "|     0.916128505055     |      0.878976675772      |\n",
       "|     0.886419882795     |      0.877390208027      |\n",
       "|     0.886152553057     |      0.876392099181      |\n",
       "|     0.874481100138     |      0.870487497373      |\n",
       "|     0.888411430973     |      0.877064509351      |\n",
       "|     0.882219653989     |      0.878041605379      |\n",
       "|     0.91135859541      |      0.883441899559      |\n",
       "|     0.869836100021     |      0.866453036352      |\n",
       "|     0.889262450095     |      0.882086572809      |\n",
       "+------------------------+--------------------------+\n",
       "+--------------------------------+\n",
       "|            model_id            |\n",
       "+--------------------------------+\n",
       "| [28, 29, 24, 25, 26, 27, 2...  |\n",
       "| [19, 18, 11, 10, 13, 12, 1...  |\n",
       "| [51, 58, 59, 54, 55, 56, 5...  |\n",
       "| [60, 61, 65, 64, 67, 66, 6...  |\n",
       "| [31, 30, 33, 32, 35, 34, 3...  |\n",
       "| [88, 89, 81, 80, 83, 82, 8...  |\n",
       "| [43, 42, 41, 40, 45, 44, 4...  |\n",
       "| [8, 1, 0, 3, 2, 5, 4, 7, 9, 6] |\n",
       "| [93, 94, 95, 90, 91, 99, 9...  |\n",
       "| [77, 79, 78, 76, 71, 70, 7...  |\n",
       "+--------------------------------+\n",
       "[10 rows x 17 columns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-----------------+----------------+\n",
      "| class_weights |       std       |      mean      |\n",
      "+---------------+-----------------+----------------+\n",
      "|      None     | 0.0136933187101 | 0.889248441549 |\n",
      "+---------------+-----------------+----------------+\n",
      "[1 rows x 3 columns]\n",
      "\n",
      "+------------------+------------------+----------------+\n",
      "| column_subsample |       std        |      mean      |\n",
      "+------------------+------------------+----------------+\n",
      "|       0.05       | 0.00686395965271 | 0.876823251072 |\n",
      "|       0.8        | 0.0127199016447  | 0.898316172865 |\n",
      "|       0.1        | 0.00299724498611 | 0.885216898975 |\n",
      "+------------------+------------------+----------------+\n",
      "[3 rows x 3 columns]\n",
      "\n",
      "+-----------------------+-----------------+----------------+\n",
      "| early_stopping_rounds |       std       |      mean      |\n",
      "+-----------------------+-----------------+----------------+\n",
      "|           5           | 0.0136933187101 | 0.889248441549 |\n",
      "+-----------------------+-----------------+----------------+\n",
      "[1 rows x 3 columns]\n",
      "\n",
      "+-----------+-----------------+----------------+\n",
      "| max_depth |       std       |      mean      |\n",
      "+-----------+-----------------+----------------+\n",
      "|     15    | 0.0136110047333 | 0.892730148724 |\n",
      "|     20    |       0.0       | 0.91135859541  |\n",
      "|     4     |       0.0       | 0.889262450095 |\n",
      "|     9     |  0.008242651944 | 0.880235693773 |\n",
      "+-----------+-----------------+----------------+\n",
      "[4 rows x 3 columns]\n",
      "\n",
      "+----------------+------------------+----------------+\n",
      "| max_iterations |       std        |      mean      |\n",
      "+----------------+------------------+----------------+\n",
      "|      200       | 0.0147532616947  | 0.887046765193 |\n",
      "|      250       | 0.0115722257244  | 0.899786369686 |\n",
      "|      300       | 0.00309588849198 | 0.885315542481 |\n",
      "+----------------+------------------+----------------+\n",
      "[3 rows x 3 columns]\n",
      "\n",
      "+--------+-----------------+----------------+\n",
      "| metric |       std       |      mean      |\n",
      "+--------+-----------------+----------------+\n",
      "|  auc   | 0.0136933187101 | 0.889248441549 |\n",
      "+--------+-----------------+----------------+\n",
      "[1 rows x 3 columns]\n",
      "\n",
      "+------------------+------------------+----------------+\n",
      "| min_child_weight |       std        |      mean      |\n",
      "+------------------+------------------+----------------+\n",
      "|        2         | 0.0134846465009  | 0.888007984871 |\n",
      "|        10        | 0.00640401806801 | 0.883387811009 |\n",
      "|        5         | 0.0149879759987  | 0.901140529056 |\n",
      "+------------------+------------------+----------------+\n",
      "[3 rows x 3 columns]\n",
      "\n",
      "+--------------------+------------------+----------------+\n",
      "| min_loss_reduction |       std        |      mean      |\n",
      "+--------------------+------------------+----------------+\n",
      "|         10         | 0.00645804119592 | 0.883542294133 |\n",
      "|         1          | 0.0168554903617  | 0.897807662674 |\n",
      "+--------------------+------------------+----------------+\n",
      "[2 rows x 3 columns]\n",
      "\n",
      "+---------------+-----------------+----------------+\n",
      "| row_subsample |       std       |      mean      |\n",
      "+---------------+-----------------+----------------+\n",
      "|      0.5      | 0.0112781657339 | 0.888692185567 |\n",
      "|      0.75     | 0.0166376555459 | 0.890082825524 |\n",
      "+---------------+-----------------+----------------+\n",
      "[2 rows x 3 columns]\n",
      "\n",
      "+-----------+------------------+----------------+\n",
      "| step_size |       std        |      mean      |\n",
      "+-----------+------------------+----------------+\n",
      "|    0.5    | 0.0134330274801  | 0.902695477575 |\n",
      "|    0.01   | 0.0207612476944  | 0.890597347715 |\n",
      "|    0.1    | 0.00386927692559 | 0.878350377063 |\n",
      "|    1.0    | 0.00102007080396 | 0.887299502697 |\n",
      "+-----------+------------------+----------------+\n",
      "[4 rows x 3 columns]\n",
      "\n",
      "+--------+-----------------+----------------+\n",
      "| target |       std       |      mean      |\n",
      "+--------+-----------------+----------------+\n",
      "| target | 0.0136933187101 | 0.889248441549 |\n",
      "+--------+-----------------+----------------+\n",
      "[1 rows x 3 columns]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for col in [col for col in search_results.column_names() if \\\n",
    "            not('accuracy' in col) and col!= 'model_id' and col!= 'random_seed' and col!= 'fold_id' \\\n",
    "                               and col!= 'num_folds']:\n",
    "    print(search_results.groupby(col,\n",
    "                             {'mean':gl.aggregate.MEAN('mean_training_accuracy'),\n",
    "                                'std':gl.aggregate.STD('mean_training_accuracy')}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## hyperparameter results\n",
    "\n",
    "* class_weights: None, gana por afano\n",
    "* column_subsample : algo menor a 1 pero no queda claro si cuanto menos mejor\n",
    "* row_subsample : algo menor a 1 pero no queda claro si cuanto menos mejor, refinar\n",
    "* max_depth: varia mucho, refinar\n",
    "* max_iterations: tampoco queda claro si poquito o mucho es mejor, reprobar\n",
    "* metric: el f1_score es el unico que no parece variar mucho,los demas cambian demasiado\n",
    "* min_child_weight: varia mucho, reprobar con mas\n",
    "* min_loss_reduction: varia mucho, reprobar\n",
    "* step_size: mas grande parece ser mejor> 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Results\n",
    "\n",
    "* bootstrap  ???= False es 5% mejor\n",
    "* min_samples_leaf ????= mas chico es claramente mejor, pero tmb aumenta el overfitting lo cual me hace caer mucho el valor del recall en el test_set. Sin embargo es un parametro muy sensible en la precision. Resta evaluar asi el tradeoff entre la precision y el volumen de users al cual queremos llegar.\n",
    "* n_estimators ???= mas pareceria mejor, pero depende del app y hay que ver 'cuanto' mejora por app\n",
    "* citerion ???= entropy o gini no cambia. gini podria ser mejor entonces pues entropy usa logs de los valores lo cual es mas computacionalmente costoso\n",
    "* max_features ???= no afecta al score. con auto esta bien\n",
    "* max_depth ??=  mas es mejor. intentaria probar con >15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## boosted run with best params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = model_search.get_best_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'class_weights': None,\n",
       " 'column_subsample': 0.8,\n",
       " 'early_stopping_rounds': 5,\n",
       " 'max_depth': 20,\n",
       " 'max_iterations': 250,\n",
       " 'metric': 'auc',\n",
       " 'min_child_weight': 2,\n",
       " 'min_loss_reduction': 1,\n",
       " 'random_seed': 415168,\n",
       " 'row_subsample': 0.5,\n",
       " 'step_size': 0.01,\n",
       " 'target': 'target'}"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = {'class_weights': None,\n",
    " 'column_subsample': 0.8,\n",
    " 'early_stopping_rounds': 5,\n",
    " 'max_depth': 12,\n",
    " 'max_iterations': 250,\n",
    " 'metric': 'auc',\n",
    " 'min_child_weight': 2,\n",
    " 'min_loss_reduction': 1,\n",
    " 'random_seed': 415168,\n",
    " 'row_subsample': 0.5,\n",
    " 'step_size': 0.01,\n",
    " 'target': 'target'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre>Boosted trees classifier:</pre>"
      ],
      "text/plain": [
       "Boosted trees classifier:"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>--------------------------------------------------------</pre>"
      ],
      "text/plain": [
       "--------------------------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of examples          : 95180</pre>"
      ],
      "text/plain": [
       "Number of examples          : 95180"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of classes           : 2</pre>"
      ],
      "text/plain": [
       "Number of classes           : 2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of feature columns   : 176</pre>"
      ],
      "text/plain": [
       "Number of feature columns   : 176"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of unpacked features : 176</pre>"
      ],
      "text/plain": [
       "Number of unpacked features : 176"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>+-----------+--------------+--------------+----------------+</pre>"
      ],
      "text/plain": [
       "+-----------+--------------+--------------+----------------+"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| Iteration | Elapsed Time | Training-auc | Validation-auc |</pre>"
      ],
      "text/plain": [
       "| Iteration | Elapsed Time | Training-auc | Validation-auc |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>+-----------+--------------+--------------+----------------+</pre>"
      ],
      "text/plain": [
       "+-----------+--------------+--------------+----------------+"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 1         | 0.792755     | 0.870534     | 0.854229       |</pre>"
      ],
      "text/plain": [
       "| 1         | 0.792755     | 0.870534     | 0.854229       |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 2         | 1.599966     | 0.885401     | 0.866128       |</pre>"
      ],
      "text/plain": [
       "| 2         | 1.599966     | 0.885401     | 0.866128       |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 3         | 2.415011     | 0.891582     | 0.872199       |</pre>"
      ],
      "text/plain": [
       "| 3         | 2.415011     | 0.891582     | 0.872199       |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 4         | 3.172991     | 0.896710     | 0.875075       |</pre>"
      ],
      "text/plain": [
       "| 4         | 3.172991     | 0.896710     | 0.875075       |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 5         | 3.932190     | 0.898678     | 0.876098       |</pre>"
      ],
      "text/plain": [
       "| 5         | 3.932190     | 0.898678     | 0.876098       |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 6         | 4.718734     | 0.898829     | 0.875404       |</pre>"
      ],
      "text/plain": [
       "| 6         | 4.718734     | 0.898829     | 0.875404       |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 10        | 7.827187     | 0.901186     | 0.878331       |</pre>"
      ],
      "text/plain": [
       "| 10        | 7.827187     | 0.901186     | 0.878331       |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 11        | 8.619724     | 0.901667     | 0.878403       |</pre>"
      ],
      "text/plain": [
       "| 11        | 8.619724     | 0.901667     | 0.878403       |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 15        | 11.739438    | 0.904433     | 0.879636       |</pre>"
      ],
      "text/plain": [
       "| 15        | 11.739438    | 0.904433     | 0.879636       |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 20        | 15.623586    | 0.905729     | 0.880089       |</pre>"
      ],
      "text/plain": [
       "| 20        | 15.623586    | 0.905729     | 0.880089       |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 25        | 19.480804    | 0.907467     | 0.880335       |</pre>"
      ],
      "text/plain": [
       "| 25        | 19.480804    | 0.907467     | 0.880335       |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 30        | 23.432567    | 0.907983     | 0.880966       |</pre>"
      ],
      "text/plain": [
       "| 30        | 23.432567    | 0.907983     | 0.880966       |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 35        | 27.363924    | 0.908957     | 0.880943       |</pre>"
      ],
      "text/plain": [
       "| 35        | 27.363924    | 0.908957     | 0.880943       |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>+-----------+--------------+--------------+----------------+</pre>"
      ],
      "text/plain": [
       "+-----------+--------------+--------------+----------------+"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Early stop triggered. Returning the best model at iteration: 30</pre>"
      ],
      "text/plain": [
       "Early stop triggered. Returning the best model at iteration: 30"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 27s, sys: 4.76 s, total: 2min 32s\n",
      "Wall time: 30.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "best_model =  boosted_trees_classifier.create(dataset=X_gl,\n",
    "                                             validation_set = X_val_gl,\n",
    "                                             **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['COUNT_0',\n",
       " 'MOBILITY_DIAMETER_WEEKNIGHT',\n",
       " 'MOBILITY_DIAMETER',\n",
       " 'COUNT_WEEKNIGHT_0',\n",
       " 'COUNT_1',\n",
       " 'TimeWeekDay_IN_08',\n",
       " 'COUNT_2',\n",
       " 'TimeWeekDay_OUT_08',\n",
       " 'COUNT_WEEKNIGHT_1',\n",
       " 'TimeWeekDay_OUT_09',\n",
       " 'TimeWeekDay_OUT_12',\n",
       " 'TimeWeekDay_IN_09',\n",
       " 'TimeWeekDay_IN_12',\n",
       " 'TimeWeekDay_OUT_10',\n",
       " 'TimeWeekEnd_OUT_08',\n",
       " 'COUNT_3',\n",
       " 'COUNT_4',\n",
       " 'CallsWeekDay_IN_08',\n",
       " 'TimeWeekDay_OUT_11',\n",
       " 'TimeWeekDay_IN_10']"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_feat = best_model.get_feature_importance()\n",
    "best_feat = list(best_feat['name'].head(20))\n",
    "best_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>LATITUDE</th>\n",
       "      <th>LONGITUDE</th>\n",
       "      <th>CEL_ID</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STATE</th>\n",
       "      <th>EPIDEMIC</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Aguascalientes</th>\n",
       "      <th>0</th>\n",
       "      <td>21.856175</td>\n",
       "      <td>-102.352281</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Baja_California</th>\n",
       "      <th>0</th>\n",
       "      <td>32.642231</td>\n",
       "      <td>-115.408042</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Baja_California_Sur</th>\n",
       "      <th>0</th>\n",
       "      <td>24.142063</td>\n",
       "      <td>-110.294055</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Campeche</th>\n",
       "      <th>0</th>\n",
       "      <td>19.814033</td>\n",
       "      <td>-90.508705</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chiapas</th>\n",
       "      <th>0</th>\n",
       "      <td>16.620228</td>\n",
       "      <td>-93.097100</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chihuahua</th>\n",
       "      <th>0</th>\n",
       "      <td>28.694722</td>\n",
       "      <td>-106.108056</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Coahuila_de_Zaragoza</th>\n",
       "      <th>0</th>\n",
       "      <td>28.637778</td>\n",
       "      <td>-100.553056</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Colima</th>\n",
       "      <th>0</th>\n",
       "      <td>19.052920</td>\n",
       "      <td>-104.320394</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Distrito_Federal</th>\n",
       "      <th>0</th>\n",
       "      <td>19.317872</td>\n",
       "      <td>-99.137003</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Durango</th>\n",
       "      <th>0</th>\n",
       "      <td>25.553119</td>\n",
       "      <td>-103.489508</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Guanajuato</th>\n",
       "      <th>0</th>\n",
       "      <td>21.158572</td>\n",
       "      <td>-100.923861</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Guerrero</th>\n",
       "      <th>1</th>\n",
       "      <td>16.831714</td>\n",
       "      <td>-99.778656</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hidalgo</th>\n",
       "      <th>1</th>\n",
       "      <td>19.832881</td>\n",
       "      <td>-98.950172</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jalisco</th>\n",
       "      <th>1</th>\n",
       "      <td>20.581427</td>\n",
       "      <td>-103.432628</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mexico</th>\n",
       "      <th>0</th>\n",
       "      <td>19.490600</td>\n",
       "      <td>-99.271200</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Michoacan_de_Ocampo</th>\n",
       "      <th>0</th>\n",
       "      <td>19.699532</td>\n",
       "      <td>-101.211267</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Morelos</th>\n",
       "      <th>1</th>\n",
       "      <td>18.828056</td>\n",
       "      <td>-99.244444</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nayarit</th>\n",
       "      <th>0</th>\n",
       "      <td>21.055389</td>\n",
       "      <td>-105.127556</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nuevo_Leon</th>\n",
       "      <th>0</th>\n",
       "      <td>25.806569</td>\n",
       "      <td>-100.325653</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Oaxaca</th>\n",
       "      <th>1</th>\n",
       "      <td>17.071125</td>\n",
       "      <td>-96.676006</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Puebla</th>\n",
       "      <th>1</th>\n",
       "      <td>19.067444</td>\n",
       "      <td>-98.221000</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Queretaro</th>\n",
       "      <th>0</th>\n",
       "      <td>20.594503</td>\n",
       "      <td>-100.393656</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Quintana_Roo</th>\n",
       "      <th>0</th>\n",
       "      <td>21.140333</td>\n",
       "      <td>-86.864528</td>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>San_Luis_Potosi</th>\n",
       "      <th>0</th>\n",
       "      <td>22.186800</td>\n",
       "      <td>-100.945300</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sinaloa</th>\n",
       "      <th>0</th>\n",
       "      <td>23.278450</td>\n",
       "      <td>-106.448220</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sonora</th>\n",
       "      <th>0</th>\n",
       "      <td>32.444358</td>\n",
       "      <td>-114.771023</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tabasco</th>\n",
       "      <th>1</th>\n",
       "      <td>17.879241</td>\n",
       "      <td>-92.480478</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tamaulipas</th>\n",
       "      <th>0</th>\n",
       "      <td>22.415000</td>\n",
       "      <td>-97.938000</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tlaxcala</th>\n",
       "      <th>0</th>\n",
       "      <td>19.212956</td>\n",
       "      <td>-98.240853</td>\n",
       "      <td>162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Veracruz</th>\n",
       "      <th>1</th>\n",
       "      <td>17.994111</td>\n",
       "      <td>-94.566444</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Yucatan</th>\n",
       "      <th>0</th>\n",
       "      <td>21.016680</td>\n",
       "      <td>-89.607927</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Zacatecas</th>\n",
       "      <th>0</th>\n",
       "      <td>22.738691</td>\n",
       "      <td>-102.555193</td>\n",
       "      <td>131</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                LATITUDE   LONGITUDE  CEL_ID\n",
       "STATE                EPIDEMIC                               \n",
       "Aguascalientes       0         21.856175 -102.352281      37\n",
       "Baja_California      0         32.642231 -115.408042      67\n",
       "Baja_California_Sur  0         24.142063 -110.294055       1\n",
       "Campeche             0         19.814033  -90.508705      49\n",
       "Chiapas              0         16.620228  -93.097100      76\n",
       "Chihuahua            0         28.694722 -106.108056      55\n",
       "Coahuila_de_Zaragoza 0         28.637778 -100.553056     118\n",
       "Colima               0         19.052920 -104.320394      87\n",
       "Distrito_Federal     0         19.317872  -99.137003       2\n",
       "Durango              0         25.553119 -103.489508      35\n",
       "Guanajuato           0         21.158572 -100.923861      30\n",
       "Guerrero             1         16.831714  -99.778656      57\n",
       "Hidalgo              1         19.832881  -98.950172      60\n",
       "Jalisco              1         20.581427 -103.432628      10\n",
       "Mexico               0         19.490600  -99.271200       9\n",
       "Michoacan_de_Ocampo  0         19.699532 -101.211267     102\n",
       "Morelos              1         18.828056  -99.244444       6\n",
       "Nayarit              0         21.055389 -105.127556      56\n",
       "Nuevo_Leon           0         25.806569 -100.325653       8\n",
       "Oaxaca               1         17.071125  -96.676006      24\n",
       "Puebla               1         19.067444  -98.221000       5\n",
       "Queretaro            0         20.594503 -100.393656      17\n",
       "Quintana_Roo         0         21.140333  -86.864528     123\n",
       "San_Luis_Potosi      0         22.186800 -100.945300     105\n",
       "Sinaloa              0         23.278450 -106.448220      86\n",
       "Sonora               0         32.444358 -114.771023      38\n",
       "Tabasco              1         17.879241  -92.480478       3\n",
       "Tamaulipas           0         22.415000  -97.938000       4\n",
       "Tlaxcala             0         19.212956  -98.240853     162\n",
       "Veracruz             1         17.994111  -94.566444      13\n",
       "Yucatan              0         21.016680  -89.607927      12\n",
       "Zacatecas            0         22.738691 -102.555193     131"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if best feat states are epidemic or not\n",
    "antennas.groupby(['STATE','EPIDEMIC']).first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.8897577722677856,\n",
       " 'auc': 0.8809650552848158,\n",
       " 'confusion_matrix': Columns:\n",
       " \ttarget_label\tint\n",
       " \tpredicted_label\tint\n",
       " \tcount\tint\n",
       " \n",
       " Rows: 4\n",
       " \n",
       " Data:\n",
       " +--------------+-----------------+-------+\n",
       " | target_label | predicted_label | count |\n",
       " +--------------+-----------------+-------+\n",
       " |      0       |        1        |  281  |\n",
       " |      1       |        0        |  875  |\n",
       " |      1       |        1        |  1163 |\n",
       " |      0       |        0        |  8167 |\n",
       " +--------------+-----------------+-------+\n",
       " [4 rows x 3 columns],\n",
       " 'f1_score': 0.6680068925904652,\n",
       " 'log_loss': 0.5461287424860415,\n",
       " 'precision': 0.8054016620498615,\n",
       " 'recall': 0.570657507360157,\n",
       " 'roc_curve': Columns:\n",
       " \tthreshold\tfloat\n",
       " \tfpr\tfloat\n",
       " \ttpr\tfloat\n",
       " \tp\tint\n",
       " \tn\tint\n",
       " \n",
       " Rows: 100001\n",
       " \n",
       " Data:\n",
       " +-----------+-----+-----+------+------+\n",
       " | threshold | fpr | tpr |  p   |  n   |\n",
       " +-----------+-----+-----+------+------+\n",
       " |    0.0    | 1.0 | 1.0 | 2038 | 8448 |\n",
       " |   1e-05   | 1.0 | 1.0 | 2038 | 8448 |\n",
       " |   2e-05   | 1.0 | 1.0 | 2038 | 8448 |\n",
       " |   3e-05   | 1.0 | 1.0 | 2038 | 8448 |\n",
       " |   4e-05   | 1.0 | 1.0 | 2038 | 8448 |\n",
       " |   5e-05   | 1.0 | 1.0 | 2038 | 8448 |\n",
       " |   6e-05   | 1.0 | 1.0 | 2038 | 8448 |\n",
       " |   7e-05   | 1.0 | 1.0 | 2038 | 8448 |\n",
       " |   8e-05   | 1.0 | 1.0 | 2038 | 8448 |\n",
       " |   9e-05   | 1.0 | 1.0 | 2038 | 8448 |\n",
       " +-----------+-----+-----+------+------+\n",
       " [100001 rows x 5 columns]\n",
       " Note: Only the head of the SFrame is printed.\n",
       " You can use print_rows(num_rows=m, num_columns=n) to print more rows and columns.}"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_error = best_model.evaluate(X_val_gl)\n",
    "test_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method BoostedTreesClassifier.get_current_options of Class                          : BoostedTreesClassifier\n",
       "\n",
       "Schema\n",
       "------\n",
       "Number of examples             : 95180\n",
       "Number of feature columns      : 176\n",
       "Number of unpacked features    : 176\n",
       "Number of classes              : 2\n",
       "\n",
       "Settings\n",
       "--------\n",
       "Number of trees                : 30\n",
       "Max tree depth                 : 12\n",
       "Training time (sec)            : 27.3684\n",
       "Training auc                   : 0.908\n",
       "Validation auc                 : 0.881\n",
       ">"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.get_current_options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sklearn \n",
    "\n",
    "validation, bias variance, learning curves  and decision tree models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/juan/mfixman/venv/local/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/home/juan/mfixman/venv/local/lib/python2.7/site-packages/sklearn/grid_search.py:43: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import *\n",
    "from sklearn.ensemble import *\n",
    "\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import validation_curve\n",
    "\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "from sklearn.utils import *\n",
    "\n",
    "from sklearn.preprocessing import label_binarize, scale, StandardScaler, MinMaxScaler\n",
    "\n",
    "from sklearn.metrics import *\n",
    "\n",
    "from sklearn.tree import *\n",
    "\n",
    "from sklearn.grid_search import *\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# dimensionality reduction  with SVD might improve the fit\n",
    "from sklearn.decomposition import TruncatedSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## bias variance trade-off in the number of attributes\n",
    "we first used a random forest to get the best attributes in the model and now will try to overfit the validation set using too many features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'MOBILITY_DIAMETER', u'COUNT_0', u'COUNT_WEEKNIGHT_0',\n",
       "       u'MOBILITY_DIAMETER_WEEKNIGHT', u'COUNT_1', u'COUNT_2',\n",
       "       u'COUNT_WEEKNIGHT_1', u'COUNT_3', u'TimeWeekDay_OUT_08',\n",
       "       u'TimeWeekDay_OUT_12',\n",
       "       ...\n",
       "       u'STATE_Yucatan', u'STATE_Aguascalientes', u'STATE_Colima',\n",
       "       u'STATE_Baja_California_Sur', u'STATE_Sinaloa', u'STATE_Sonora',\n",
       "       u'STATE_Tamaulipas', u'STATE_Zacatecas', u'STATE_Durango',\n",
       "       u'STATE_Coahuila_de_Zaragoza'],\n",
       "      dtype='object', length=176)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_columns = best_feat['name'].to_numpy()\n",
    "\n",
    "X[best_columns].columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## scale numerical features when necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scale_cols = None\n",
    "# scale_cols = True\n",
    "if scale_cols:\n",
    "\n",
    "    # by definition any column which is outside of [-1,1]\n",
    "    scaling_cols = (X.max()) >1 | (X.min()<-1)\n",
    "\n",
    "    scaling_cols = scaling_cols[scaling_cols==True].index\n",
    "\n",
    "    scale = MinMaxScaler(copy=True)\n",
    "    \n",
    "    X[scaling_cols] = scale.fit_transform(X[scaling_cols])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## make validation curve\n",
    "with DecisionTreeClassifier to overfit and compare without cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can't have more binary splits in a tree than the data we train with\n",
    "max_tree_depth = int(np.log2(X.shape[0]))\n",
    "max_tree_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define our tree_depth range to compare in cross validation\n",
    "\n",
    "param_range = np.arange(2,17,)\n",
    "param_range\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/juan/mfixman/venv/local/lib/python2.7/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/juan/mfixman/venv/local/lib/python2.7/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 48.8 s, sys: 564 ms, total: 49.3 s\n",
      "Wall time: 1min 43s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_scores, test_scores = validation_curve(\n",
    "    DecisionTreeClassifier(\n",
    "                       # max_depth = 100,\n",
    "                      criterion='gini'\n",
    "    ),\n",
    "    X, Y, \n",
    "    param_name=\"max_depth\", \n",
    "        param_range=param_range,\n",
    "\n",
    "        cv=10, \n",
    "    scoring='f1_weighted', \n",
    "    n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### check results by standarizing scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reverse_scores_train = 1 - train_scores\n",
    "reverse_scores_test = 1 - test_scores\n",
    "\n",
    "train_scores_mean = np.mean(reverse_scores_train, axis=1)\n",
    "train_scores_std = np.std(reverse_scores_train, axis=1)\n",
    "test_scores_mean = np.mean(reverse_scores_test, axis=1)\n",
    "test_scores_std = np.std(reverse_scores_test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f7640032d10>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfYAAAGNCAYAAADjDlO+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkP8H++AyJY85aEgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7544fd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 6)) \n",
    "plt.title(\"Validation Curve with Decision Tree Classifier\")\n",
    "plt.xlabel(\"$Max Depth$ value\".format())\n",
    "plt.ylabel(\"1 - Score\")\n",
    "plt.ylim(0.0, 0.5)\n",
    "\n",
    "lw = 1\n",
    "\n",
    "plt.plot(param_range, train_scores_mean, label=\"Training score with std-dev band\",\n",
    "             color=\"navy\", lw=lw)\n",
    "\n",
    "plt.fill_between(param_range, train_scores_mean - train_scores_std,\n",
    "                 train_scores_mean + train_scores_std, alpha=0.2,\n",
    "                 color=\"blue\", lw=lw)\n",
    "\n",
    "plt.plot(param_range, test_scores_mean, label=\"Cross-validation score avg\",\n",
    "             color=\"darkorange\", lw=lw)\n",
    "\n",
    "plt.fill_between(param_range, test_scores_mean - test_scores_std,\n",
    "                 test_scores_mean + test_scores_std, alpha=0.2,\n",
    "                 color=\"red\", lw=lw)\n",
    "\n",
    "plt.legend(loc=\"best\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show the importance of cross validation and regularization using the logistic regression. \n",
    "\n",
    "try with different \n",
    "\n",
    "* cv values: (1, 3, 10 and 20)\n",
    "\n",
    "* C regularization values (L2): (1/10, 1, 10000,20000 ,etc. - high values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1.001,   2.112,   3.223,   4.334,   5.445,   6.556,   7.667,\n",
       "         8.778,   9.889,  11.   ])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  1.00000000e-05,   1.12266777e-05,   1.26038293e-05,\n",
       "          1.41499130e-05,   1.58856513e-05,   1.78343088e-05,\n",
       "          2.00220037e-05,   2.24780583e-05,   2.52353917e-05,\n",
       "          2.83309610e-05,   3.18062569e-05,   3.57078596e-05,\n",
       "          4.00880633e-05,   4.50055768e-05,   5.05263107e-05,\n",
       "          5.67242607e-05,   6.36824994e-05,   7.14942899e-05,\n",
       "          8.02643352e-05,   9.01101825e-05]),\n",
       " array([  11097.52496412,   12458.83364295,   13987.13102647,\n",
       "          15702.90124729,   17629.14118096,   19791.66867854,\n",
       "          22219.4686094 ,   24945.0813523 ,   28005.03894184,\n",
       "          31440.35471592,   35297.07302731,   39626.88638701,\n",
       "          44487.82831128,   49945.05115855,   56071.69938205,\n",
       "          62949.88990222,   70671.81273928,   79340.96665797,\n",
       "          89073.5463861 ,  100000.        ]))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # define our c range to compare\n",
    "# inv_c_range = np.logspace(-4, 100, 15)\n",
    "\n",
    "# # param_range = 1./inv_c_range\n",
    "# param_range = np.linspace(-3,0.5,30)\n",
    "# # param_range = np.ceil(param_range)\n",
    "# param_range = np.exp((param_range)*np.log(10))\n",
    "\n",
    "# low_values = np.linspace(0.001,1,10) \n",
    "# high_values = np.linspace(10000,20000,10)\n",
    "# param_range = np.concatenate([low_values,high_values])\n",
    "\n",
    "param_range = np.logspace(-5, 5, 200)\n",
    "\n",
    "\n",
    "param_range[:20],param_range[-20:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## with no cv, high and low regularization comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# make this algorithm nilpotent (copy the data from the original case's X)\n",
    "# in case we want to run this again without re-building the whole X\n",
    "X_lreg = X.copy()\n",
    "X_val_lreg = X_val.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### check if we want SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 55s, sys: 5min 16s, total: 8min 11s\n",
      "Wall time: 1min 35s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "svd_features = True\n",
    "num_features_limit = 30\n",
    "\n",
    "#note that some svd algorithms are non-deterministic and thus results will vary if random state is not specified\n",
    "svd = TruncatedSVD(\n",
    "    n_components=num_features_limit, \n",
    "    n_iter=100, \n",
    "    random_state=42 ,\n",
    "    \n",
    "                )\n",
    "if svd_features: # only for train and test\n",
    "    svd.fit(X_lreg) \n",
    "    X_lreg = pd.DataFrame(svd.transform(X_lreg), index = X_lreg.index.values)\n",
    "    X_val_lreg = pd.DataFrame(svd.transform(X_val_lreg), index = X_val_lreg.index.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((137692, 30), (137692, 185))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_lreg.shape, X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define loss function\n",
    "\n",
    "# scoring = 'f1'\n",
    "scoring = 'roc_auc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5min 28s, sys: 9min 2s, total: 14min 31s\n",
      "Wall time: 4h 46min 55s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "num_jobs = -1\n",
    "\n",
    "logreg  =  LogisticRegression(solver = 'lbfgs', \n",
    "                       max_iter = 200,\n",
    "                      warm_start=False,\n",
    "                              verbose = 0,\n",
    "                              n_jobs =-1,\n",
    "                        )\n",
    "# init fit over a range of parameters and load these into the\n",
    "# test and train scoring lists\n",
    "scores = []\n",
    "scores_val = []\n",
    "\n",
    "## get testing score fun with our defined str score\n",
    "scoring_fun = SCORERS[scoring]\n",
    "\n",
    "for param in param_range:\n",
    "\n",
    "    logreg.set_params(C=param)\n",
    "    logreg.fit(X_lreg, Y)\n",
    "    \n",
    "    # get train and \"test\" errors without CV\n",
    "    error = scoring_fun(logreg,X_lreg,Y)\n",
    "\n",
    "    scores.append(error)\n",
    "    error_val = scoring_fun(logreg,\n",
    "                            X_val_lreg,\n",
    "                            Y_val)\n",
    "    scores_val.append(error_val)\n",
    "\n",
    "# cast to numpy arrays type\n",
    "scores = np.asarray(scores)\n",
    "scores_val = np.asarray(scores_val)\n",
    "\n",
    "elapsed_time =   time.time() - start_time \n",
    "#este flag es basicamente para chequear que hayamos terminado nomas\n",
    "finished = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finished"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Param exploration Search took 17215.576601 seconds to run\n",
      "\n",
      " Best estimator had (0.5101094833795522, 0.5103664577447542) error and error_val score \n",
      "\n",
      "\n",
      " Best param was (3.5707859649004625e-05, 3.5707859649004625e-05) \n",
      "\n",
      "Our problem type id is 0 which means \"People that used to live in the endemic area\"\n"
     ]
    }
   ],
   "source": [
    "print('Param exploration Search took %s seconds to run' % (elapsed_time))\n",
    "\n",
    "max_score_index = np.nonzero(errors == errors.max())[0][0]\n",
    "\n",
    "max_val_score_index = np.nonzero(errors_val == errors_val.max())[0][0]\n",
    "\n",
    "print('\\n Best estimator had ({:.3f},{:.3f}) error and error_val score\\\n",
    "with scoring metric {} \\n'.format(\n",
    "                                 errors[max_score_index] ,\n",
    "                                 errors_val[max_val_score_index],\n",
    "                                scoring,\n",
    "                               )\n",
    "    )\n",
    "\n",
    "print('\\n Best param found with this metric was {} \\n'.format( str( (param_range[max_score_index],\n",
    "                                           param_range[max_val_score_index])\n",
    "                                           )\n",
    "                                      )\n",
    "     )\n",
    "\n",
    "print('Our problem type id is {} which means \\\"{}\\\"'.format(case,case_text.capitalize()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('\\n Best estimator was %s \\n' % str(clf.best_estimator_))\n",
    "\n",
    "print('\\n Best estimator was {:.3f} in \"{}\" metric \\n'.format( clf.best_score_,\n",
    "                                                    scoring\n",
    "                                                   )\n",
    "     )\n",
    "\n",
    "\n",
    "## get testing score fun with our defined str score\n",
    "scoring_fun = SCORERS[scoring]\n",
    "test_score = scoring_fun(clf,X_val_lreg,Y_val)\n",
    "\n",
    "print('\\nBest estimator\\'s performance with \\\n",
    "\"{}\" metric on the test set is: {:.3f}\\n'.format( scoring,\n",
    "                                                 test_score,  \n",
    "                                            )\n",
    "     )\n",
    "\n",
    "\n",
    "\n",
    "print('Param exploration Search took %s seconds to run' % (elapsed_time))\n",
    "\n",
    "print('Our problem type id is {} which means \\\"{}\\\"'.format(case,case_text.capitalize()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.7821046113967896"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get elapsed time in hours\n",
    "elapsed_time/3600, finished"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# reverse_scores_train = 1 - train_scores\n",
    "# reverse_scores_test = 1 - test_scores\n",
    "\n",
    "train_scores_mean = errors\n",
    "train_scores_std = np.std(errors)\n",
    "test_scores_mean = errors_val\n",
    "test_scores_std = np.std(errors_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((200,), (200,), (200,), ())"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(errors), param_range.shape, train_scores_mean.shape, test_scores_mean.shape, train_scores_std.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "size = param_range.shape[0]\n",
    "#i = 0.002\n",
    "#np.linspace(1+i,1,size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x117283d0>"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgYAAAGRCAYAAAAetHvGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x90ec8d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax, fig = plt.subplots(figsize=(8,6))\n",
    "plt.title(\"Validation Curve with Logistic Regression Classifier\")\n",
    "plt.xlabel(\"Regularization $C$ Param\")\n",
    "plt.ylabel(\"AUC Score\")\n",
    "# plt.ylim(0.0, 10.1)\n",
    "\n",
    "lw = 1\n",
    "\n",
    "plt.semilogx(param_range, train_scores_mean,#\n",
    "                          label=\"Training score\",\n",
    "             color=\"navy\", lw=lw)\n",
    "\n",
    "# plt.fill_between(param_range, train_scores_mean - train_scores_std,\n",
    "#                  train_scores_mean + train_scores_std, alpha=0.2,\n",
    "#                  color=\"blue\", lw=lw)\n",
    "\n",
    "plt.semilogx(param_range, test_scores_mean,#\n",
    "             label=\"score for test set\",\n",
    "             color=\"darkorange\", lw=lw)\n",
    "\n",
    "# plt.fill_between(param_range, test_scores_mean - test_scores_std,\n",
    "#                  test_scores_mean + test_scores_std, alpha=0.2,\n",
    "#                  color=\"red\", lw=lw)\n",
    "\n",
    "plt.legend(loc=\"best\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.007843137254901968"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a =0.51\n",
    "b= 0.506\n",
    "(a-b)/a\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## now add cross validation to the problem\n",
    "\n",
    "show different instances of l1 and l2 regularization (low C) vs. non-regularizing (high C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "        'penalty': [\n",
    "                    'l1',\n",
    "                    'l2',\n",
    "        ], # type of regularization function norm\n",
    "            'C': param_range, # the regularization param, the smaller the more regulareized\n",
    "            'max_iter': [\n",
    "#                         40,\n",
    "                        150,\n",
    "#                         200,\n",
    "                        ], # number of descent iterations\n",
    "    \n",
    "            \"fit_intercept\": [ \n",
    "#                         False, \n",
    "                        True,\n",
    "                            ],# fit the constante intercept\n",
    "            \n",
    "               \"class_weight\": [\n",
    "                               None,\n",
    "#                             'balanced',\n",
    "                           ],# if class ratios are as weighted averge when computing the overall loss fn\n",
    "              }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cardinality  = 1\n",
    "for key in param_grid.keys():\n",
    "    cardinality = cardinality*len(param_grid[key])\n",
    "cardinality\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# lr_no_regularization = True\n",
    "# if lr_no_regularization:\n",
    "#     param_grid['C'] = [1e5]\n",
    "#     param_grid['penalty'] = ['l2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define loss function\n",
    "\n",
    "scoring = 'f1'\n",
    "# scoring = 'roc_auc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "num_jobs = -1\n",
    "\n",
    "logreg  = LogisticRegression( )\n",
    "\n",
    "clf =GridSearchCV( logreg, \n",
    "                  param_grid, \n",
    "                  scoring=scoring, \n",
    "                  fit_params=None,\n",
    "                  n_jobs=num_jobs, \n",
    "                  iid=True, \n",
    "                  refit=True, \n",
    "                verbose=0, \n",
    "                pre_dispatch='2*n_jobs', \n",
    "                  error_score='ignore')\n",
    "\n",
    "clf2 = LogisticRegression()\n",
    "\n",
    "\n",
    "# # when cardinality of grid search is too big, we randomly search for\n",
    "# n_iter_search = 100\n",
    "\n",
    "# if n_iter_search < cardinality:\n",
    "#     clf = RandomizedSearchCV(logreg, param_distributions=param_grid,\n",
    "#                                  n_iter=n_iter_search, n_jobs = num_jobs, verbose=3,\n",
    "#                                        iid=True, refit=True, )\n",
    "\n",
    "# X = X\n",
    "# Y = Y.values\n",
    "\n",
    "logreg  = LogisticRegression( )\n",
    "clf.fit(X_lreg, Y)\n",
    "\n",
    "elapsed_time =   time.time() - start_time \n",
    "print('HyperParam Search took %s seconds to run' % (elapsed_time))\n",
    "\n",
    "\n",
    "cv_result = pd.DataFrame(columns=['mean_score' ] + [key for key, \n",
    "                            value in clf.grid_scores_[0].parameters.items() ] )\n",
    "i=0\n",
    "for setup in clf.grid_scores_:\n",
    "    row = [clf.grid_scores_[i].mean_validation_score ] + [value for key,\n",
    "                                        value in clf.grid_scores_[i].parameters.items() ]\n",
    "    cv_result.loc[i] = row\n",
    "    i+=1\n",
    "\n",
    "elapsed_time =   time.time() - start_time\n",
    "\n",
    "#este flag es basicamente para chequear que hayamos terminado nomas\n",
    "finished = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finished"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Best estimator was LogisticRegression(C=1.0000000000000001e-05, class_weight=None, dual=False,\n",
      "          fit_intercept=True, intercept_scaling=1, max_iter=150,\n",
      "          multi_class='ovr', n_jobs=1, penalty='l1', random_state=None,\n",
      "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False) \n",
      "\n",
      "\n",
      " Best estimator was 0.648 in \"f1\" metric \n",
      "\n",
      "\n",
      "Best estimator's performance with \"f1\" metric on the test set is: 0.744\n",
      "\n",
      "Param exploration Search took 1757.97230387 seconds to run\n",
      "Our problem type id is 0 which means \"People that used to live in the endemic area\"\n"
     ]
    }
   ],
   "source": [
    "print('\\n Best estimator was %s \\n' % str(clf.best_estimator_))\n",
    "\n",
    "print('\\n Best estimator was {:.3f} in \"{}\" metric \\n'.format( clf.best_score_,\n",
    "                                                    scoring\n",
    "                                                   )\n",
    "     )\n",
    "\n",
    "\n",
    "## get testing score with the score used inour function\n",
    "scoring_fun = SCORERS[scoring]\n",
    "test_score = scoring_fun(clf,X_val_lreg,Y_val)\n",
    "\n",
    "print('\\nBest estimator\\'s performance with \\\n",
    "\"{}\" metric on the test set is: {:.3f}\\n'.format( scoring,\n",
    "                                                 test_score,  \n",
    "                                            )\n",
    "     )\n",
    "\n",
    "\n",
    "\n",
    "print('Param exploration Search took %s seconds to run' % (elapsed_time))\n",
    "\n",
    "print('Our problem type id is {} which means \\\"{}\\\"'.format(case,case_text.capitalize()))\n",
    "\n",
    "#ojo que esta parte cuando poly ==True no funciona.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.48832563996315004, True)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get elapsed time in hours\n",
    "elapsed_time/3600, finished"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.74405960531614979"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## get testing score with the score used inour function\n",
    "scoring_fun = SCORERS[scoring]\n",
    "scoring_fun(clf,X_val_lreg,Y_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_cols = [\n",
    "        'penalty',\n",
    "              'C',\n",
    "]\n",
    "\n",
    "an_col = 'mean_score'\n",
    "param_col = 'C'\n",
    "#.groupby(group_cols)['mean_score'].first()\n",
    "filter_col = 'penalty'\n",
    "filter_val = 'l1'\n",
    "view = (cv_result\n",
    "        .query('{}==@filter_val'.format(filter_col))\n",
    "        [[ param_col,filter_col,an_col]]\n",
    "        .sort_values('mean_score',ascending=False)\n",
    "       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    200.000000\n",
       "mean       0.406833\n",
       "std        0.085434\n",
       "min        0.370706\n",
       "25%        0.370732\n",
       "50%        0.370787\n",
       "75%        0.375023\n",
       "max        0.648107\n",
       "Name: mean_score, dtype: float64"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "view[an_col].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0xcd8e750>"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkoAAAG3CAYAAABLx3rDAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nKAEAABgQlAAAAAwISgAAAAb/B4PruYrTr0rcAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc66ca7a590>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "# plot histogram on cross validated scores\n",
    "view[an_col].hist()\n",
    "\n",
    "sup_title_str = \"Histogram of CV training scores for different \\\n",
    "parameter values.\"\n",
    "\n",
    "plt.suptitle(\"\\n\".join(wrap(sup_title_str)),\n",
    "         y=1.03,# otherwise twiny and title will overlap\n",
    "         fontsize=18,\n",
    "            )\n",
    "\n",
    "title_str = \"Different $C$ params \\\n",
    "for a Logistic Regression Classifier\\'s with \\\n",
    "{} regularization\".format(\n",
    "    filter_val)\n",
    "\n",
    "plt.title(title_str, fontsize=10)\n",
    "\n",
    "plt.xlabel(\"$C$ Param value\".format(filter_val))\n",
    "plt.ylabel(\"CV {} Score\".format(scoring.capitalize()))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "view = view.sort_values(param_col)\n",
    "# x_vals = view[param_col]\n",
    "# y_vals = view[param_col]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x7fc682694890>"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgwAAAHRCAYAAAAGzuFjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAwMRERG59P9PglkUO7Yj7gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc66fa16a50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "N=50\n",
    "\n",
    "labels = ['Smallest {} $C$ values '.format(N), 'Biggest {} $C$ values '.format(N)]\n",
    "\n",
    "c = palette[0]\n",
    "view.head(N).set_index(param_col)[an_col].plot(\n",
    "    ax=ax,\n",
    "    kind = 'line',\n",
    "    color='b',\n",
    "#     legend=True,\n",
    "    label =labels[0],\n",
    ")\n",
    "\n",
    "# set xlabel \n",
    "# ax.set_xlabel(labels[0])\n",
    "# set series legend\n",
    "# ax.legend(loc=0)\n",
    "\n",
    "# get a new axis to plot on with new color\n",
    "ax2 = ax.twiny()\n",
    "c = palette[1]\n",
    "view.tail(N).set_index(param_col)[an_col].plot(\n",
    "    ax=ax2,\n",
    "    kind = 'line',\n",
    "    color='r',\n",
    "#     legend=True,\n",
    "    label =labels[1],\n",
    "                                               \n",
    "         )\n",
    "\n",
    "ax.set_xlabel(labels[0])\n",
    "ax2.set_xlabel(labels[1])\n",
    "\n",
    "# get all plotted line objects\n",
    "lines = ax.get_lines() + ax2.get_lines()\n",
    "# set a common legend\n",
    "ax.legend(lines, [l.get_label() for l in lines], loc='upper center')\n",
    "\n",
    "# pass those lines legends\n",
    "\n",
    "# # set series legend\n",
    "# ax2.legend(loc='best')\n",
    "\n",
    "\n",
    "title_str = \"Cross-validated Training Score \\\n",
    "for a Logistic Regression Classifier\\'s $C$ \\\n",
    "param with {} regularization\".format(\n",
    "    filter_val)\n",
    "\n",
    "plt.title(\"\\n\".join(wrap(title_str)),\n",
    "         y=1.15,# otherwise twiny and title will overlap\n",
    "         )\n",
    "\n",
    "\n",
    "plt.xlabel(\"$C$ Param\".format(filter_val))\n",
    "plt.ylabel(\"{} Score\".format(scoring.capitalize()))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fc681415c50>"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEPCAYAAABcA4N7AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc680f62f50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "view.tail(50).set_index(param_col)[an_col].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C</th>\n",
       "      <th>penalty</th>\n",
       "      <th>mean_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>108.436597</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.399861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>121.738273</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.401293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>136.671636</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.395969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>153.436841</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.389284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>172.258597</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.385560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>193.389175</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.407473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>217.111795</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.380661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>243.744415</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.380432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>273.644000</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.387889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>307.211300</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.398666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>344.896226</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.377651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>387.203878</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.404169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>434.701316</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.384196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>488.025158</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.383940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>547.890118</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.406795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>615.098579</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.380244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>690.551352</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.377829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>775.259749</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.405910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>870.359136</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.413266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>977.124154</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.385185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>1096.985798</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.391688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>1231.550603</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.406648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>1382.622174</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.395450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>1552.225357</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.405521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>1742.633386</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.377643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>1956.398344</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.409521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>2196.385372</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.377190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>2465.811076</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.391630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>2768.286630</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.405797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>3107.866188</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.387168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>3489.101213</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.383911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>3917.101491</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.378653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>4397.603609</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.380389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>4937.047853</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.411112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>5542.664521</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.408103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351</th>\n",
       "      <td>6222.570837</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.389446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353</th>\n",
       "      <td>6985.879747</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.378755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>7842.822061</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.381505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>8804.883582</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.377421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>9884.959047</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.385547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>11097.524964</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.400973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>12458.833643</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.410306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>13987.131026</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.394954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367</th>\n",
       "      <td>15702.901247</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.386756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>17629.141181</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.393072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>19791.668679</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.384939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>22219.468609</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.401353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>24945.081352</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.425352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377</th>\n",
       "      <td>28005.038942</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.390488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>31440.354716</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.407668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>35297.073027</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.418337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>39626.886387</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.380862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>44487.828311</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.389284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>49945.051159</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.389927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>56071.699382</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.376942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>62949.889902</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.405721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>70671.812739</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.386395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>79340.966658</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.385966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>89073.546386</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.398113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>100000.000000</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.395078</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 C penalty  mean_score\n",
       "281     108.436597      l2    0.399861\n",
       "283     121.738273      l2    0.401293\n",
       "285     136.671636      l2    0.395969\n",
       "287     153.436841      l2    0.389284\n",
       "289     172.258597      l2    0.385560\n",
       "291     193.389175      l2    0.407473\n",
       "293     217.111795      l2    0.380661\n",
       "295     243.744415      l2    0.380432\n",
       "297     273.644000      l2    0.387889\n",
       "299     307.211300      l2    0.398666\n",
       "301     344.896226      l2    0.377651\n",
       "303     387.203878      l2    0.404169\n",
       "305     434.701316      l2    0.384196\n",
       "307     488.025158      l2    0.383940\n",
       "309     547.890118      l2    0.406795\n",
       "311     615.098579      l2    0.380244\n",
       "313     690.551352      l2    0.377829\n",
       "315     775.259749      l2    0.405910\n",
       "317     870.359136      l2    0.413266\n",
       "319     977.124154      l2    0.385185\n",
       "321    1096.985798      l2    0.391688\n",
       "323    1231.550603      l2    0.406648\n",
       "325    1382.622174      l2    0.395450\n",
       "327    1552.225357      l2    0.405521\n",
       "329    1742.633386      l2    0.377643\n",
       "331    1956.398344      l2    0.409521\n",
       "333    2196.385372      l2    0.377190\n",
       "335    2465.811076      l2    0.391630\n",
       "337    2768.286630      l2    0.405797\n",
       "339    3107.866188      l2    0.387168\n",
       "341    3489.101213      l2    0.383911\n",
       "343    3917.101491      l2    0.378653\n",
       "345    4397.603609      l2    0.380389\n",
       "347    4937.047853      l2    0.411112\n",
       "349    5542.664521      l2    0.408103\n",
       "351    6222.570837      l2    0.389446\n",
       "353    6985.879747      l2    0.378755\n",
       "355    7842.822061      l2    0.381505\n",
       "357    8804.883582      l2    0.377421\n",
       "359    9884.959047      l2    0.385547\n",
       "361   11097.524964      l2    0.400973\n",
       "363   12458.833643      l2    0.410306\n",
       "365   13987.131026      l2    0.394954\n",
       "367   15702.901247      l2    0.386756\n",
       "369   17629.141181      l2    0.393072\n",
       "371   19791.668679      l2    0.384939\n",
       "373   22219.468609      l2    0.401353\n",
       "375   24945.081352      l2    0.425352\n",
       "377   28005.038942      l2    0.390488\n",
       "379   31440.354716      l2    0.407668\n",
       "381   35297.073027      l2    0.418337\n",
       "383   39626.886387      l2    0.380862\n",
       "385   44487.828311      l2    0.389284\n",
       "387   49945.051159      l2    0.389927\n",
       "389   56071.699382      l2    0.376942\n",
       "391   62949.889902      l2    0.405721\n",
       "393   70671.812739      l2    0.386395\n",
       "395   79340.966658      l2    0.385966\n",
       "397   89073.546386      l2    0.398113\n",
       "399  100000.000000      l2    0.395078"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "view.tail(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "view[an_col].argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# reverse_scores_train = 1 - train_scores\n",
    "# reverse_scores_test = 1 - test_scores\n",
    "\n",
    "train_scores_mean = errors\n",
    "train_scores_std = np.std(errors)\n",
    "test_scores_mean = errors_val\n",
    "test_scores_std = np.std(errors_val)\n",
    "\n",
    "np.std(errors), param_range.shape, train_scores_mean.shape, test_scores_mean.shape, train_scores_std.shape\n",
    "\n",
    "size = param_range.shape[0]\n",
    "#i = 0.002\n",
    "#np.linspace(1+i,1,size)\n",
    "\n",
    "ax, fig = plt.subplots(figsize=(8,6))\n",
    "plt.title(\"Validation Curve with Logistic Regression Classifier\")\n",
    "plt.xlabel(\"Regularization $C$ Param\")\n",
    "plt.ylabel(\"AUC Score\")\n",
    "# plt.ylim(0.0, 10.1)\n",
    "\n",
    "lw = 1\n",
    "\n",
    "plt.semilogx(param_range, train_scores_mean,#\n",
    "                          label=\"Training score\",\n",
    "             color=\"navy\", lw=lw)\n",
    "\n",
    "# plt.fill_between(param_range, train_scores_mean - train_scores_std,\n",
    "#                  train_scores_mean + train_scores_std, alpha=0.2,\n",
    "#                  color=\"blue\", lw=lw)\n",
    "\n",
    "plt.semilogx(param_range, test_scores_mean,#\n",
    "             label=\"score for test set\",\n",
    "             color=\"darkorange\", lw=lw)\n",
    "\n",
    "# plt.fill_between(param_range, test_scores_mean - test_scores_std,\n",
    "#                  test_scores_mean + test_scores_std, alpha=0.2,\n",
    "#                  color=\"red\", lw=lw)\n",
    "\n",
    "plt.legend(loc=\"best\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## now get erros along the cv procedure and plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# reverse_scores_train = 1 - train_scores\n",
    "# reverse_scores_test = 1 - test_scores\n",
    "\n",
    "train_scores_mean = errors\n",
    "train_scores_std = np.std(errors)\n",
    "test_scores_mean = errors_val\n",
    "test_scores_std = np.std(errors_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.std(errors), param_range.shape, train_scores_mean.shape, test_scores_mean.shape, train_scores_std.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "size = param_range.shape[0]\n",
    "#i = 0.002\n",
    "#np.linspace(1+i,1,size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ax, fig = plt.subplots(figsize=(8,6))\n",
    "plt.title(\"Validation Curve with Logistic Regression Classifier\")\n",
    "plt.xlabel(\"Regularization $C$ Param\")\n",
    "plt.ylabel(\"AUC Score\")\n",
    "# plt.ylim(0.0, 10.1)\n",
    "\n",
    "lw = 1\n",
    "\n",
    "plt.semilogx(param_range, train_scores_mean,#\n",
    "                          label=\"Training score\",\n",
    "             color=\"navy\", lw=lw)\n",
    "\n",
    "# plt.fill_between(param_range, train_scores_mean - train_scores_std,\n",
    "#                  train_scores_mean + train_scores_std, alpha=0.2,\n",
    "#                  color=\"blue\", lw=lw)\n",
    "\n",
    "plt.semilogx(param_range, test_scores_mean,#\n",
    "             label=\"score for test set\",\n",
    "             color=\"darkorange\", lw=lw)\n",
    "\n",
    "# plt.fill_between(param_range, test_scores_mean - test_scores_std,\n",
    "#                  test_scores_mean + test_scores_std, alpha=0.2,\n",
    "#                  color=\"red\", lw=lw)\n",
    "\n",
    "plt.legend(loc=\"best\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# REST of shit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count Featurizer on Antennas\n",
    "nos quedamos con las columnas de antennas y en graphlab aplicamos el algo de CountFeaturizer para cada categoria de\n",
    "Antenna_ID_N\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "import graphlab as gl\n",
    "from graphlab.toolkits.feature_engineering import *\n",
    "ant_cols = [col for col in X_train.columns if \"ANTENNA_ID\" in col]\n",
    "ant_sframe_fit = gl.SFrame(X_fit[ant_cols + ['y']])\n",
    "ant_sframe_train = gl.SFrame(X_train[ant_cols + ['y']])\n",
    "ant_sframe_val = gl.SFrame(X_val[ant_cols + ['y']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "countfeat = gl.feature_engineering.create(ant_sframe_fit, \n",
    "               CountFeaturizer(target='y'))\n",
    "\n",
    "# Transform the train set. This is the dataset I will train my classifier on\n",
    "transformed_ant_train = countfeat.transform(ant_sframe_train)\n",
    "transformed_ant_val = countfeat.transform(ant_sframe_val)\n",
    "\n",
    "del ant_sframe_fit,ant_sframe_train,ant_sframe_val\n",
    "\n",
    "#por alguna razon guarda los valores de probabilidad como una lista de un unico valor\n",
    "for col in [col for col in transformed_ant_train.column_names() if \"prob_\" in col]:\n",
    "    transformed_ant_train[col] = transformed_ant_train[col].apply(lambda x: x[0]) \n",
    "    transformed_ant_val[col] = transformed_ant_val[col].apply(lambda x: x[0]) \n",
    "\n",
    "#me quedo solo con los valores de probabilidad.\n",
    "transformed_ant_train = transformed_ant_train[[col for col in transformed_ant_train.column_names() if \"prob_\" in col]]\n",
    "transformed_ant_val = transformed_ant_val[[col for col in transformed_ant_train.column_names() if \"prob_\" in col]]\n",
    "\n",
    "transformed_ant_val = transformed_ant_val.to_dataframe()\n",
    "transformed_ant_train = transformed_ant_train.to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_val[ant_cols] = transformed_ant_val.values\n",
    "X_train[ant_cols] = transformed_ant_train.values\n",
    "del transformed_ant_train, transformed_ant_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validate SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_grid = [\n",
    "  { 'alpha': [1e-3,5*1e-3,1e-2], 'l1_ratio': [3*1e-2,1e-3,6*1e-4], 'n_iter': [2,3]\n",
    "  }\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 18 candidates, totalling 54 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Virtualenvs/mateo/lib/python3.4/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] n_iter=2, alpha=0.001, l1_ratio=0.03 ............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Virtualenvs/mateo/lib/python3.4/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] n_iter=2, alpha=0.001, l1_ratio=0.03 ............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Virtualenvs/mateo/lib/python3.4/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ... n_iter=2, alpha=0.001, l1_ratio=0.03, score=0.125354 -   2.5s\n",
      "[CV] n_iter=2, alpha=0.001, l1_ratio=0.03 ............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Virtualenvs/mateo/lib/python3.4/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ... n_iter=2, alpha=0.001, l1_ratio=0.03, score=0.127442 -   2.5s\n",
      "[CV] n_iter=3, alpha=0.001, l1_ratio=0.03 ............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Virtualenvs/mateo/lib/python3.4/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ... n_iter=2, alpha=0.001, l1_ratio=0.03, score=0.119463 -   2.5s\n",
      "[CV] n_iter=3, alpha=0.001, l1_ratio=0.03 ............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Virtualenvs/mateo/lib/python3.4/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ... n_iter=3, alpha=0.001, l1_ratio=0.03, score=0.132910 -   3.1s\n",
      "[CV] n_iter=3, alpha=0.001, l1_ratio=0.03 ............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Virtualenvs/mateo/lib/python3.4/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ... n_iter=3, alpha=0.001, l1_ratio=0.03, score=0.133858 -   3.1s\n",
      "[CV] n_iter=2, alpha=0.001, l1_ratio=0.001 ...........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Virtualenvs/mateo/lib/python3.4/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ... n_iter=3, alpha=0.001, l1_ratio=0.03, score=0.125862 -   3.1s\n",
      "[CV] n_iter=2, alpha=0.001, l1_ratio=0.001 ...........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Virtualenvs/mateo/lib/python3.4/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .. n_iter=2, alpha=0.001, l1_ratio=0.001, score=0.114065 -   2.5s\n",
      "[CV] n_iter=2, alpha=0.001, l1_ratio=0.001 ...........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Virtualenvs/mateo/lib/python3.4/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .. n_iter=2, alpha=0.001, l1_ratio=0.001, score=0.125576 -   2.5s\n",
      "[CV] n_iter=3, alpha=0.001, l1_ratio=0.001 ...........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Virtualenvs/mateo/lib/python3.4/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .. n_iter=2, alpha=0.001, l1_ratio=0.001, score=0.125882 -   2.8s\n",
      "[CV] n_iter=3, alpha=0.001, l1_ratio=0.001 ...........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Virtualenvs/mateo/lib/python3.4/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .. n_iter=3, alpha=0.001, l1_ratio=0.001, score=0.138072 -   3.3s\n",
      "[CV] n_iter=3, alpha=0.001, l1_ratio=0.001 ...........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Virtualenvs/mateo/lib/python3.4/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .. n_iter=3, alpha=0.001, l1_ratio=0.001, score=0.133482 -   3.1s\n",
      "[CV] n_iter=2, alpha=0.001, l1_ratio=0.0006000000000000001 ...........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Virtualenvs/mateo/lib/python3.4/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .. n_iter=3, alpha=0.001, l1_ratio=0.001, score=0.133945 -   3.2s\n",
      "[CV] n_iter=2, alpha=0.001, l1_ratio=0.0006000000000000001 ...........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Virtualenvs/mateo/lib/python3.4/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_iter=2, alpha=0.001, l1_ratio=0.0006000000000000001, score=0.124318 -   2.5s\n",
      "[CV] n_iter=2, alpha=0.001, l1_ratio=0.0006000000000000001 ...........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Virtualenvs/mateo/lib/python3.4/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_iter=2, alpha=0.001, l1_ratio=0.0006000000000000001, score=0.125224 -   2.5s\n",
      "[CV] n_iter=3, alpha=0.001, l1_ratio=0.0006000000000000001 ...........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Virtualenvs/mateo/lib/python3.4/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_iter=2, alpha=0.001, l1_ratio=0.0006000000000000001, score=0.129423 -   2.5s\n",
      "[CV] n_iter=3, alpha=0.001, l1_ratio=0.0006000000000000001 ...........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Virtualenvs/mateo/lib/python3.4/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_iter=3, alpha=0.001, l1_ratio=0.0006000000000000001, score=0.131845 -   3.1s\n",
      "[CV] n_iter=3, alpha=0.001, l1_ratio=0.0006000000000000001 ...........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Virtualenvs/mateo/lib/python3.4/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_iter=3, alpha=0.001, l1_ratio=0.0006000000000000001, score=0.135827 -   3.1s\n",
      "[CV] n_iter=2, alpha=0.005, l1_ratio=0.03 ............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Virtualenvs/mateo/lib/python3.4/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_iter=3, alpha=0.001, l1_ratio=0.0006000000000000001, score=0.128485 -   3.1s\n",
      "[CV] n_iter=2, alpha=0.005, l1_ratio=0.03 ............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Virtualenvs/mateo/lib/python3.4/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ... n_iter=2, alpha=0.005, l1_ratio=0.03, score=0.125477 -   2.4s\n",
      "[CV] n_iter=2, alpha=0.005, l1_ratio=0.03 ............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Virtualenvs/mateo/lib/python3.4/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ... n_iter=2, alpha=0.005, l1_ratio=0.03, score=0.125957 -   2.8s\n",
      "[CV] n_iter=3, alpha=0.005, l1_ratio=0.03 ............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Virtualenvs/mateo/lib/python3.4/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ... n_iter=2, alpha=0.005, l1_ratio=0.03, score=0.127511 -   2.6s\n",
      "[CV] n_iter=3, alpha=0.005, l1_ratio=0.03 ............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Virtualenvs/mateo/lib/python3.4/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ... n_iter=3, alpha=0.005, l1_ratio=0.03, score=0.127618 -   2.8s\n",
      "[CV] n_iter=3, alpha=0.005, l1_ratio=0.03 ............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Virtualenvs/mateo/lib/python3.4/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ... n_iter=3, alpha=0.005, l1_ratio=0.03, score=0.125386 -   2.8s\n",
      "[CV] n_iter=2, alpha=0.005, l1_ratio=0.001 ...........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Virtualenvs/mateo/lib/python3.4/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ... n_iter=3, alpha=0.005, l1_ratio=0.03, score=0.136983 -   3.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  24 tasks      | elapsed:   47.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] n_iter=2, alpha=0.005, l1_ratio=0.001 ...........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Virtualenvs/mateo/lib/python3.4/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .. n_iter=2, alpha=0.005, l1_ratio=0.001, score=0.120290 -   2.5s\n",
      "[CV] n_iter=2, alpha=0.005, l1_ratio=0.001 ...........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Virtualenvs/mateo/lib/python3.4/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .. n_iter=2, alpha=0.005, l1_ratio=0.001, score=0.118753 -   2.5s\n",
      "[CV] n_iter=3, alpha=0.005, l1_ratio=0.001 ...........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Virtualenvs/mateo/lib/python3.4/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .. n_iter=2, alpha=0.005, l1_ratio=0.001, score=0.127159 -   2.9s\n",
      "[CV] n_iter=3, alpha=0.005, l1_ratio=0.001 ...........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Virtualenvs/mateo/lib/python3.4/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .. n_iter=3, alpha=0.005, l1_ratio=0.001, score=0.127485 -   3.3s\n",
      "[CV] n_iter=3, alpha=0.005, l1_ratio=0.001 ...........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Virtualenvs/mateo/lib/python3.4/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .. n_iter=3, alpha=0.005, l1_ratio=0.001, score=0.139728 -   3.1s\n",
      "[CV] n_iter=2, alpha=0.005, l1_ratio=0.0006000000000000001 ...........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Virtualenvs/mateo/lib/python3.4/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .. n_iter=3, alpha=0.005, l1_ratio=0.001, score=0.130469 -   3.1s\n",
      "[CV] n_iter=2, alpha=0.005, l1_ratio=0.0006000000000000001 ...........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Virtualenvs/mateo/lib/python3.4/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_iter=2, alpha=0.005, l1_ratio=0.0006000000000000001, score=0.129161 -   2.5s\n",
      "[CV] n_iter=2, alpha=0.005, l1_ratio=0.0006000000000000001 ...........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Virtualenvs/mateo/lib/python3.4/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_iter=2, alpha=0.005, l1_ratio=0.0006000000000000001, score=0.130159 -   2.5s\n",
      "[CV] n_iter=3, alpha=0.005, l1_ratio=0.0006000000000000001 ...........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Virtualenvs/mateo/lib/python3.4/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_iter=2, alpha=0.005, l1_ratio=0.0006000000000000001, score=0.127613 -   2.5s\n",
      "[CV] n_iter=3, alpha=0.005, l1_ratio=0.0006000000000000001 ...........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Virtualenvs/mateo/lib/python3.4/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_iter=3, alpha=0.005, l1_ratio=0.0006000000000000001, score=0.132956 -   3.1s\n",
      "[CV] n_iter=3, alpha=0.005, l1_ratio=0.0006000000000000001 ...........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Virtualenvs/mateo/lib/python3.4/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_iter=3, alpha=0.005, l1_ratio=0.0006000000000000001, score=0.143005 -   3.1s\n",
      "[CV] n_iter=2, alpha=0.01, l1_ratio=0.03 .............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Virtualenvs/mateo/lib/python3.4/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_iter=3, alpha=0.005, l1_ratio=0.0006000000000000001, score=0.135926 -   3.1s\n",
      "[CV] n_iter=2, alpha=0.01, l1_ratio=0.03 .............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Virtualenvs/mateo/lib/python3.4/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .... n_iter=2, alpha=0.01, l1_ratio=0.03, score=0.128098 -   2.4s\n",
      "[CV] n_iter=2, alpha=0.01, l1_ratio=0.03 .............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Virtualenvs/mateo/lib/python3.4/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .... n_iter=2, alpha=0.01, l1_ratio=0.03, score=0.127078 -   2.7s\n",
      "[CV] n_iter=3, alpha=0.01, l1_ratio=0.03 .............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Virtualenvs/mateo/lib/python3.4/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .... n_iter=2, alpha=0.01, l1_ratio=0.03, score=0.126921 -   2.5s\n",
      "[CV] n_iter=3, alpha=0.01, l1_ratio=0.03 .............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Virtualenvs/mateo/lib/python3.4/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .... n_iter=3, alpha=0.01, l1_ratio=0.03, score=0.138152 -   3.6s\n",
      "[CV] n_iter=3, alpha=0.01, l1_ratio=0.03 .............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Virtualenvs/mateo/lib/python3.4/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .... n_iter=3, alpha=0.01, l1_ratio=0.03, score=0.106208 -   3.1s\n",
      "[CV] n_iter=2, alpha=0.01, l1_ratio=0.001 ............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Virtualenvs/mateo/lib/python3.4/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .... n_iter=3, alpha=0.01, l1_ratio=0.03, score=0.143076 -   2.8s\n",
      "[CV] n_iter=2, alpha=0.01, l1_ratio=0.001 ............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Virtualenvs/mateo/lib/python3.4/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ... n_iter=2, alpha=0.01, l1_ratio=0.001, score=0.132427 -   2.5s\n",
      "[CV] n_iter=2, alpha=0.01, l1_ratio=0.001 ............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Virtualenvs/mateo/lib/python3.4/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ... n_iter=2, alpha=0.01, l1_ratio=0.001, score=0.125901 -   2.9s\n",
      "[CV] n_iter=3, alpha=0.01, l1_ratio=0.001 ............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Virtualenvs/mateo/lib/python3.4/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ... n_iter=2, alpha=0.01, l1_ratio=0.001, score=0.128001 -   2.7s\n",
      "[CV] n_iter=3, alpha=0.01, l1_ratio=0.001 ............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Virtualenvs/mateo/lib/python3.4/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ... n_iter=3, alpha=0.01, l1_ratio=0.001, score=0.135568 -   3.1s\n",
      "[CV] n_iter=3, alpha=0.01, l1_ratio=0.001 ............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Virtualenvs/mateo/lib/python3.4/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] n_iter=2, alpha=0.01, l1_ratio=0.0006000000000000001 ............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Virtualenvs/mateo/lib/python3.4/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ... n_iter=3, alpha=0.01, l1_ratio=0.001, score=0.132579 -   4.4s\n",
      "[CV] ... n_iter=3, alpha=0.01, l1_ratio=0.001, score=0.136589 -   3.7s\n",
      "[CV] n_iter=2, alpha=0.01, l1_ratio=0.0006000000000000001 ............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Virtualenvs/mateo/lib/python3.4/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_iter=2, alpha=0.01, l1_ratio=0.0006000000000000001, score=0.124134 -   2.8s\n",
      "[CV] n_iter=2, alpha=0.01, l1_ratio=0.0006000000000000001 ............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Virtualenvs/mateo/lib/python3.4/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_iter=2, alpha=0.01, l1_ratio=0.0006000000000000001, score=0.130883 -   2.5s\n",
      "[CV] n_iter=3, alpha=0.01, l1_ratio=0.0006000000000000001 ............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Virtualenvs/mateo/lib/python3.4/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_iter=2, alpha=0.01, l1_ratio=0.0006000000000000001, score=0.122741 -   3.5s\n",
      "[CV] n_iter=3, alpha=0.01, l1_ratio=0.0006000000000000001 ............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Virtualenvs/mateo/lib/python3.4/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_iter=3, alpha=0.01, l1_ratio=0.0006000000000000001, score=0.132433 -   3.7s\n",
      "[CV] n_iter=3, alpha=0.01, l1_ratio=0.0006000000000000001 ............\n",
      "[CV]  n_iter=3, alpha=0.01, l1_ratio=0.0006000000000000001, score=0.135111 -   3.4s\n",
      "[CV]  n_iter=3, alpha=0.01, l1_ratio=0.0006000000000000001, score=0.135908 -   3.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  54 out of  54 | elapsed:  1.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.31      0.47    355992\n",
      "          1       0.06      0.99      0.11     15152\n",
      "\n",
      "avg / total       0.96      0.33      0.45    371144\n",
      "\n",
      "This cell took 108.56432461738586 seconds to run\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "param_grid = [\n",
    "  { 'alpha': [1e-3,5*1e-3,1e-2], 'l1_ratio': [3*1e-2,1e-3,6*1e-4], 'n_iter': [2,3]\n",
    "  }\n",
    "    ]\n",
    "sgd = SGDClassifier(loss='modified_huber', penalty='elasticnet', \n",
    "             fit_intercept=True,  shuffle=True, \n",
    "                    n_jobs=3,learning_rate='optimal', power_t =2, eta0 =5,\n",
    "                    class_weight='balanced', average=40)\n",
    "\n",
    "clf =GridSearchCV(sgd, param_grid, scoring='roc_auc', fit_params=None, n_jobs=4, iid=True, refit=True, \n",
    "verbose=3, pre_dispatch='2*n_jobs', error_score='raise')\n",
    "\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "\n",
    "\n",
    "predicted_proba = pd.DataFrame()\n",
    "predicted_proba['prob'] = clf.predict_proba(X_test).max(axis=1)\n",
    "predicted_proba['class'] = clf.predict(X_test)\n",
    "predicted_proba[gt] =  y_test\n",
    "predicted_proba.sort_values(by = 'prob',ascending = False, inplace = True)\n",
    "\n",
    "cut_percentages = [10,20,30,40]\n",
    "#converted = (predicted_proba['class']==1)\n",
    "#me fijo todos los users que van a convertir en el futuro\n",
    "\n",
    "\n",
    "start = 0\n",
    "mobility_dict = {}\n",
    "index_segments = []\n",
    "for i in cut_percentages:\n",
    "    cut_size = int(len(predicted_proba)*i/100.0)    \n",
    "    bool_array = (~np.ones(len(predicted_proba), dtype=bool))\n",
    "    bool_array[start: start + cut_size] = True\n",
    "    index_segments += [bool_array]\n",
    "    start = start + cut_size\n",
    "#    subtable = \n",
    "    #mobility_dict[str(i)] = predicted_proba.loc[index_segments[-1],'ref_hash']\n",
    "    \n",
    "    print(classification_report(predicted_proba.loc[index_segments[-1],gt].values,\n",
    "                            predicted_proba.loc[index_segments[-1],'class'].values ))\n",
    "    \n",
    "    \n",
    "print(classification_report(predicted_proba.loc[:,gt].values,\n",
    "                            predicted_proba.loc[:,'class'].values ))\n",
    "    \n",
    "    \n",
    "cv_result = pd.DataFrame(columns=['mean_score' ] + [key for key, value in clf.grid_scores_[0].parameters.items() ] )\n",
    "i=0\n",
    "for setup in clf.grid_scores_:\n",
    "    row = [clf.grid_scores_[i].mean_validation_score ] + [value for key, value in clf.grid_scores_[i].parameters.items() ]\n",
    "    cv_result.loc[i] = row\n",
    "    i+=1\n",
    "#este flag es basicamente para chequear que hayamos terminado nomas\n",
    "finished = True\n",
    "\n",
    "all_time =   time.time() - start_time\n",
    "\n",
    "#este flag es basicamente para chequear que hayamos terminado nomas\n",
    "finished = True\n",
    "\n",
    "print('This cell took %s seconds to run' % all_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "threshold = 0.7\n",
    "ind = predicted_proba['prob']>threshold\n",
    "print(classification_report(predicted_proba.loc[ind,'y'].values,predicted_proba.loc[ind,'class'].values ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.005, average=40, class_weight='balanced', epsilon=0.1,\n",
       "       eta0=5, fit_intercept=True, l1_ratio=0.0006000000000000001,\n",
       "       learning_rate='optimal', loss='modified_huber', n_iter=3, n_jobs=3,\n",
       "       penalty='elasticnet', power_t=2, random_state=None, shuffle=True,\n",
       "       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_iter\n",
      "2.0    0.125741\n",
      "3.0    0.132943\n",
      "Name: mean_score, dtype: float64\n",
      "n_iter\n",
      "2.0    0.002609\n",
      "3.0    0.002703\n",
      "Name: mean_score, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "coln=1\n",
    "print(cv_result.groupby(cv_result.columns[coln])['mean_score'].mean())\n",
    "print(cv_result.groupby(cv_result.columns[coln])['mean_score'].std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Results\n",
    "* l1_ratio = cuanto mas chico mejor con lo cual la perdida l2 parece ser mejor\n",
    "* alpha = 1e-3 es suficiente pues casi no afecta el score\n",
    "* power_t = muy variado, no parece haber correlacion entre el tamanyo y el avg, mean_score\n",
    "* eta0 = no afecta mucho pero parece ser que con ser >1 ya esta\n",
    "* power_t = parecen ser practicamente iguales\n",
    "* n_iter = cuanto mas iter NO mejora el score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "371161"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predicted_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validate NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 144 candidates, totalling 432 fits\n",
      "[CV] algorithm=adam, hidden_layer_sizes=(50,), activation=logistic, power_t=0.001, alpha=0.1, learning_rate=adaptive \n",
      "[CV] algorithm=adam, hidden_layer_sizes=(50,), activation=logistic, power_t=0.001, alpha=0.1, learning_rate=adaptive \n",
      "[CV] algorithm=adam, hidden_layer_sizes=(50,), activation=logistic, power_t=0.001, alpha=0.1, learning_rate=adaptive \n",
      "[CV] algorithm=adam, hidden_layer_sizes=(50,), activation=logistic, power_t=0.0005, alpha=0.1, learning_rate=adaptive \n",
      "Iteration 1, loss = 0.20405210\n",
      "Iteration 1, loss = 0.20380843\n",
      "Iteration 1, loss = 0.20378706\n",
      "Iteration 1, loss = 0.20405210\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/teo/Repositories/scikit-learn/sklearn/metrics/classification.py:1097: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  algorithm=adam, hidden_layer_sizes=(50,), activation=logistic, power_t=0.0005, alpha=0.1, learning_rate=adaptive, score=0.000000 -   1.5s\n",
      "[CV] algorithm=adam, hidden_layer_sizes=(50,), activation=logistic, power_t=0.0005, alpha=0.1, learning_rate=adaptive \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/teo/Repositories/scikit-learn/sklearn/metrics/classification.py:1097: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  algorithm=adam, hidden_layer_sizes=(50,), activation=logistic, power_t=0.001, alpha=0.1, learning_rate=adaptive, score=0.000000 -   1.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/teo/Repositories/scikit-learn/sklearn/metrics/classification.py:1097: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  algorithm=adam, hidden_layer_sizes=(50,), activation=logistic, power_t=0.001, alpha=0.1, learning_rate=adaptive, score=0.000000 -   2.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/teo/Repositories/scikit-learn/sklearn/metrics/classification.py:1097: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  algorithm=adam, hidden_layer_sizes=(50,), activation=logistic, power_t=0.001, alpha=0.1, learning_rate=adaptive, score=0.000000 -   1.9s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-35-3491f77d2a02>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     16\u001b[0m verbose=3, pre_dispatch='2*n_jobs', error_score='raise')\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[0mpredicted_proba\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/teo/Repositories/scikit-learn/sklearn/grid_search.pyc\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    809\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    810\u001b[0m         \"\"\"\n\u001b[1;32m--> 811\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    812\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    813\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/teo/Repositories/scikit-learn/sklearn/grid_search.pyc\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, y, parameter_iterable)\u001b[0m\n\u001b[0;32m    558\u001b[0m                                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_parameters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    559\u001b[0m                                     error_score=self.error_score)\n\u001b[1;32m--> 560\u001b[1;33m                 \u001b[1;32mfor\u001b[0m \u001b[0mparameters\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mparameter_iterable\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    561\u001b[0m                 for train, test in cv)\n\u001b[0;32m    562\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/teo/Repositories/scikit-learn/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    808\u001b[0m                 \u001b[1;31m# consumption.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    809\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 810\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    811\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    812\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/teo/Repositories/scikit-learn/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    755\u001b[0m                     \u001b[1;31m# a working pool as they expect.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    756\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_initialize_pool\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 757\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    758\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    759\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "X_train,X_test,y_train ,y_test = train_test_split(X,y, test_size=0.2, random_state=42)\n",
    "\n",
    "param_grid = { 'alpha': [1e-1,5*1e-2,1e-2],\n",
    "              'hidden_layer_sizes':[(50,),(15,5)],\n",
    "              'learning_rate': ['adaptive',\"invscaling\"],\n",
    "              \"algorithm\": ['adam'],'momentum': [1e-2, 1e-1, 0.5],\n",
    "  'power_t': [1e-3, 5*1e-4, 1e-5], 'activation':['logistic','relu']\n",
    " }\n",
    "\n",
    "mlp = MLPClassifier(shuffle=True, \n",
    "                 verbose=True)\n",
    "\n",
    "clf =GridSearchCV(mlp, param_grid, scoring='roc_auc', fit_params=None, n_jobs=4, iid=True, refit=True, \n",
    "verbose=3, pre_dispatch='2*n_jobs', error_score='raise')\n",
    "\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "predicted_proba = pd.DataFrame()\n",
    "predicted_proba['prob'] = clf.predict_proba(X_test).max(axis=1)\n",
    "predicted_proba['gt'] = y_test\n",
    "predicted_proba['class'] = clf.predict(X_test)\n",
    "\n",
    "threshold = 0.7\n",
    "ind = predicted_proba['prob']>threshold\n",
    "\n",
    "all_time =   time.time() - start_time\n",
    "\n",
    "print(classification_report(predicted_proba.loc[ind,'gt'].values,predicted_proba.loc[ind,'class'].values ))\n",
    "\n",
    "cv_result = pd.DataFrame(columns=['mean_score' ] + [key for key, value in clf.grid_scores_[0].parameters.items() ] )\n",
    "i=0\n",
    "for setup in clf.grid_scores_:\n",
    "    row = [clf.grid_scores_[i].mean_validation_score ] + [value for key, value in clf.grid_scores_[i].parameters.items() ]\n",
    "    cv_result.loc[i] = row\n",
    "    i+=1\n",
    "#este flag es basicamente para chequear que hayamos terminado nomas\n",
    "finished = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'clf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-2d39bdb4c6dd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'clf' is not defined"
     ]
    }
   ],
   "source": [
    "clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "alpha\n",
       "0.00     0.000007\n",
       "0.01     0.000007\n",
       "0.10     0.000007\n",
       "0.50     0.000007\n",
       "1.00     0.000007\n",
       "10.00    0.000007\n",
       "Name: mean_score, dtype: float64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compare best parameters to tune\n",
    "coln=1\n",
    "cv_result.groupby(cv_result.columns[coln])['mean_score'].mean()\n",
    "cv_result.groupby(cv_result.columns[coln])['mean_score'].std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Results\n",
    "* activation = logistic es 10% mejor\n",
    "* alpha = 1e-2 el mejor \n",
    "* power_t = cuanto mas chico mejor, 1e-3 por lo menos\n",
    "* hidden_layer_size = menos layers es mejor..?\n",
    "* power_t = parecen ser practicamente iguales\n",
    "* n_iter = cuanto mas iter NO mejora el score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bernoulli RBM features selection & Logit crossval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-127-8675e4c7d9ab>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     39\u001b[0m verbose=0, pre_dispatch='2*n_jobs', error_score='raise')\n\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[1;31m#este metodo NO tiene predicted proba, lo que hacemos es recorrer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/teo/Repositories/scikit-learn/sklearn/grid_search.pyc\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    809\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    810\u001b[0m         \"\"\"\n\u001b[1;32m--> 811\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    812\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    813\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/teo/Repositories/scikit-learn/sklearn/grid_search.pyc\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, y, parameter_iterable)\u001b[0m\n\u001b[0;32m    558\u001b[0m                                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_parameters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    559\u001b[0m                                     error_score=self.error_score)\n\u001b[1;32m--> 560\u001b[1;33m                 \u001b[1;32mfor\u001b[0m \u001b[0mparameters\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mparameter_iterable\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    561\u001b[0m                 for train, test in cv)\n\u001b[0;32m    562\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/teo/Repositories/scikit-learn/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    808\u001b[0m                 \u001b[1;31m# consumption.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    809\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 810\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    811\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    812\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/teo/Repositories/scikit-learn/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    755\u001b[0m                     \u001b[1;31m# a working pool as they expect.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    756\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_initialize_pool\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 757\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    758\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    759\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "## obs. este metodo es especial y asume que todos los valores son True/False o que \\in [0,1]\n",
    "# luego tengo que pensar en como tomar los features nuevamente.\n",
    "# tampoco 'fittea' en la forma tradicional. Sino que se le puede tomar al y como un feature mas y esta red\n",
    "# va 'modificando' todos los valores del X (minimizando la entropia) para dar un output. Luego corriendo \n",
    "# clf.gibbs(X_test) con el y_test como feature tmb, nos transforma la data para ver el output como la 'prediccion'\n",
    "# obviamente no tiene probabilidades\n",
    "\n",
    "\n",
    "#X = X_train[X_cols].values\n",
    "#y = X_train['ground_truth'].values\n",
    "\n",
    "df = X_train.drop(X_train[X_train[X_train.columns[0:3]].\\\n",
    "                                   sum(axis=1)==0].index)\n",
    "df = df[X_cols + ['ground_truth']]\n",
    "\n",
    "for col in X_train.columns[0:3]:\n",
    "    df[col] = df[col]*1.0/df[df.columns[0:3]].sum(axis=1)\n",
    "\n",
    "df[df.columns[3]] =  df[df.columns[3]]/df[df.columns[3]].max()\n",
    "df[df.columns[4]] =  df[df.columns[4]]/df[df.columns[4]].max()\n",
    "\n",
    "X = df[df.columns[:-1]].values\n",
    "y = df['ground_truth'].values\n",
    "\n",
    "\n",
    "param_grid = {'rbm__n_components': [256, 128,46,10],\n",
    "   'rbm__n_iter':[15,10,5], 'rbm__learning_rate': [1e-4,1e-3,1e-2,1e-1,5*1e-3,5*1e-2,5*1e-1],\n",
    "  'rbm__batch_size': [10e4,3*10e3, 1e3, 300],\"logistic__C\": [1.0, 10.0, 100.0] \n",
    " }\n",
    "\n",
    "rbm = BernoulliRBM(verbose=True)\n",
    "logistic = LogisticRegression()\n",
    "classifier = Pipeline([(\"rbm\", rbm), (\"logistic\", logistic)])\n",
    "\n",
    "X_train,X_test,y_train ,y_test = train_test_split(X,y, test_size=0.2, random_state=42)\n",
    "\n",
    "clf =GridSearchCV(classifier, param_grid, scoring='roc_auc', fit_params=None, n_jobs=4, iid=True, refit=True, \n",
    "verbose=3, pre_dispatch='2*n_jobs', error_score='raise')\n",
    "\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "#este metodo NO tiene predicted proba, lo que hacemos es recorrer \n",
    "#predicted_labels = rbm.gibbs(X_test)[:,-1]\n",
    "#real_labels = X_test[:,-1]\n",
    "#print(classification_report(real_labels,predicted_labels ))\n",
    "\n",
    "\n",
    "predicted_proba = pd.DataFrame()\n",
    "predicted_proba['prob'] = clf.predict_proba(X_test).max(axis=1)\n",
    "predicted_proba['gt'] = y_test\n",
    "predicted_proba['class'] = clf.predict(X_test)\n",
    "\n",
    "threshold = 0.7\n",
    "ind = predicted_proba['prob']>threshold\n",
    "print(classification_report(predicted_proba.loc[ind,'gt'].values,predicted_proba.loc[ind,'class'].values ))\n",
    "all_time =   time.time() - start_time\n",
    "\n",
    "finished = True\n",
    "\n",
    "cv_result = pd.DataFrame(columns=['mean_score' ] + [key for key, value in clf.grid_scores_[0].parameters.items() ] )\n",
    "i=0\n",
    "for setup in clf.grid_scores_:\n",
    "    row = [clf.grid_scores_[i].mean_validation_score ] + [value for key, value in clf.grid_scores_[i].parameters.items() ]\n",
    "    cv_result.loc[i] = row\n",
    "    i+=1\n",
    "    \n",
    "print('This cell took %s seconds to run' % all_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "coln=1\n",
    "print(cv_result.groupby(cv_result.columns[coln])['mean_score'].mean())\n",
    "print(cv_result.groupby(cv_result.columns[coln])['mean_score'].std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "criterion\n",
      "gini    0.802919\n",
      "Name: mean_score, dtype: float64\n",
      "criterion\n",
      "gini    0.000598\n",
      "Name: mean_score, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "coln=3\n",
    "print(cv_result.groupby(cv_result.columns[coln])['mean_score'].mean())\n",
    "print(cv_result.groupby(cv_result.columns[coln])['mean_score'].std())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CrossV SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "param_grid = [{'kernel': ['rbf'], 'gamma': list(10.0 ** np.arange(-2, 3)),\n",
    "                     'C': list(10.0 ** np.arange(0, 4))},\n",
    "                    {'kernel': ['poly'], 'C': list(10.0 ** np.arange(0, 4)), 'degree'[2,3,4]}]\n",
    "\n",
    "svc = SVC(shuffle=True, probability=True,decision_function_shape = 'ovr',\n",
    "           verbose=True, class_weight='balanced'\n",
    "          )\n",
    "\n",
    "clf =GridSearchCV(svc, param_grid, scoring='roc_auc', fit_params=None, n_jobs=4, iid=True, refit=True, \n",
    "verbose=3, pre_dispatch='2*n_jobs', error_score='raise')\n",
    "\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "predicted_proba = pd.DataFrame()\n",
    "predicted_proba['prob'] = clf.predict_proba(X_test).max(axis=1)\n",
    "predicted_proba['gt'] = y_test\n",
    "predicted_proba['class'] = clf.predict(X_test)\n",
    "\n",
    "threshold = 0.7\n",
    "ind = predicted_proba['prob']>threshold\n",
    "\n",
    "all_time =   time.time() - start_time\n",
    "\n",
    "print(classification_report(predicted_proba.loc[ind,'gt'].values,predicted_proba.loc[ind,'class'].values ))\n",
    "\n",
    "cv_result = pd.DataFrame(columns=['mean_score' ] + [key for key, value in clf.grid_scores_[0].parameters.items() ] )\n",
    "i=0\n",
    "for setup in clf.grid_scores_:\n",
    "    row = [clf.grid_scores_[i].mean_validation_score ] + [value for key, value in clf.grid_scores_[i].parameters.items() ]\n",
    "    cv_result.loc[i] = row\n",
    "    i+=1\n",
    "#este flag es basicamente para chequear que hayamos terminado nomas\n",
    "finished = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "coln=3\n",
    "print(cv_result.groupby(cv_result.columns[coln])['mean_score'].mean())\n",
    "print(cv_result.groupby(cv_result.columns[coln])['mean_score'].std())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoosting took 117.26272392272949 seconds to run\n",
      "This cell took 117.26284193992615 seconds to run\n"
     ]
    }
   ],
   "source": [
    "#tomo tiempo para saber cuanto tarda fitear el estimador\n",
    "start_time = time.time()\n",
    "\n",
    "#model = model.fit(X,y,sample_weight=W)\n",
    "\n",
    "W = np.array([10 if i == 1 or i ==2  else 1 for i in y_mini])\n",
    "gradboost.fit(X_mini,y_mini, sample_weight=W)\n",
    "\n",
    "elapsed_time =   time.time() - start_time\n",
    "print('GradientBoosting took %s seconds to run' % elapsed_time)\n",
    "\n",
    "#validated =  cross_val_score(gradboost,X,y,cv=5, scoring = \"f1_weighted\")\n",
    "\n",
    "\n",
    "all_time =   time.time() - start_time\n",
    "print('This cell took %s seconds to run' % all_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Timings\n",
    "* 5s con  10 n_estimadores, 15 max_depth y X.sample(0.2)\n",
    "* 15s con 10 n_estimadores, 15 max_depth y X.sample(0.2)\n",
    "* 47s con 10 n_estimadores, 15 max_depth y X.sample(0.4)\n",
    "* 35s con 10 n_estimadores, 15 max_depth y X.sample(0.4)\n",
    "* 117 con 20 n_estimadores, 20 max_depth y X.sample(0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    128153\n",
       "1      7064\n",
       "Name: ground_truth, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train['ground_truth'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results\n",
    "* NO escalar (normalizar, restar la media  dividir por la std, etc) los resultados pues REVIENTAN los scores.\n",
    "* bootstrap  = False es 5% mejor\n",
    "* min_samples_leaf = mas chico es claramente mejor, pero tmb aumenta el overfitting lo cual me hace caer mucho el valor del recall en el test_set. Sin embargo es un parametro muy sensible en la precision. Resta evaluar asi el tradeoff entre la precision y el volumen de users al cual queremos llegar.\n",
    "* n_estimators = aumentar mas de 30 no tendria mucho sentido\n",
    "* citerion = entropy o gini no cambia. gini podria ser mejor entonces pues entropy usa logs de los valores lo cual es mas computacionalmente costoso\n",
    "* max_features = no afecta al score. con auto esta bien\n",
    "* max_depth =  mas es mejor. intentaria probar con >15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "#con decomposicion qr tratamos de ver si existe alguna columna que sea comb linear de las demas\n",
    "linear_test = np.linalg.qr(X_train.sample(1e6))[1]\n",
    "#notar que devuelve la tabla de tamanyo N`columnas x Ncolumnas\n",
    "\n",
    "#sumo a traves de las columnas para que me de el valor absoluto sumado de c/fila\n",
    "linear_test = abs(linear_test.sum(axis=1))<1e-2\n",
    "#si hubiese alguan que sea linearcomb entonces tendria que aparecer que toda la fila es de ceros\n",
    "for i, col in enumerate(X_train.columns):\n",
    "    if linear_test[i] == True:\n",
    "        print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Todo\n",
    "* evaluate hit_rate and \n",
    "* tune adaboost, bernoulliRBM\n",
    "* xgboost\n",
    "* libffm\n",
    "* SVC muy lento.. speed up in AWS\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

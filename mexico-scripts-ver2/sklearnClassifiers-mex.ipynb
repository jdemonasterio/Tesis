{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ipynb to test different classifiers\n",
    "\n",
    "and different ML models.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A partir de las 3 tablas ya procesdas : \n",
    "* homeantennas\n",
    "* sumlinks\n",
    "* groundtruth\n",
    "\n",
    "Procedemos a utilizar los clasificadores para ver prediccion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(180000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 180 seconds\n"
     ]
    }
   ],
   "source": [
    "## seteamos los parametros del notebook\n",
    "%autosave 180\n",
    "import pandas as pd; \n",
    "import numpy as np; \n",
    "import os;\n",
    "import random;\n",
    "import time\n",
    "%matplotlib inline\n",
    "import numpy as np; import os;import random;\n",
    "import graphlab as gl\n",
    "#esto es para dibujar directo a la notebook\n",
    "gl.canvas.set_target('ipynb')\n",
    "\n",
    "#seteamos el lugar de trabajo\n",
    "HOMEDIR=os.path.expanduser('~')\n",
    "DATADIR=HOMEDIR+\"/mobility-study/mexico-scripts-ver2/datasets\"\n",
    "DATADIR2 = HOMEDIR+'/mobility-study/mexico-scripts-ver2/data'\n",
    "# os.chdir(DATADIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gtruth_0114_0715  gtruth_0215_0715  homeant  sl  sl.csv.gz\r\n"
     ]
    }
   ],
   "source": [
    "!ls $DATADIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_input_sframe(ds):\n",
    "    if ds == 'home_antenna': url = DATADIR +\"/homeant\"\n",
    "    elif ds == 'sum_links': url  = DATADIR +\"/sl\"\n",
    "    elif ds == 'gtruth_02': url  = DATADIR +\"/gtruth_0215_0715\" # can be near ground truth (previous to july 2015)\n",
    "    elif ds == 'gtruth_01': url  =  DATADIR +\"/gtruth_0114_0715\" # or can be old GT\n",
    "    else: print('type chosen is %s, type should be home_antenna, sum_links, gtruth_02 or gtruth_01' % ds)\n",
    "    return url "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92M\t/home/juan/mobility-study/mexico-scripts-ver2/datasets/gtruth_0114_0715\r\n"
     ]
    }
   ],
   "source": [
    "url = get_input_sframe('gtruth_01')\n",
    "!du -sh $url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#from unbalanced_dataset import UnderSampler, NearMiss, CondensedNearestNeighbour, OneSidedSelection,\\\n",
    "#NeighbourhoodCleaningRule, TomekLinks, ClusterCentroids, OverSampler, SMOTE,\\\n",
    "#SMOTETomek, SMOTEENN, EasyEnsemble, BalanceCascade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/juan/mfixman/venv/local/lib/python2.7/site-packages/requests/packages/urllib3/util/ssl_.py:334: SNIMissingWarning: An HTTPS request has been made, but the SNI (Subject Name Indication) extension to TLS is not available on this platform. This may cause the server to present an incorrect TLS certificate, which can cause validation failures. You can upgrade to a newer version of Python to solve this. For more information, see https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  SNIMissingWarning\n",
      "/home/juan/mfixman/venv/local/lib/python2.7/site-packages/requests/packages/urllib3/util/ssl_.py:132: InsecurePlatformWarning: A true SSLContext object is not available. This prevents urllib3 from configuring SSL appropriately and may cause certain SSL connections to fail. You can upgrade to a newer version of Python to solve this. For more information, see https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecurePlatformWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This non-commercial license of GraphLab Create for academic use is assigned to jdemonasterio@dc.uba.ar and will expire on May 06, 2018.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] graphlab.cython.cy_server: GraphLab Create v1.10.1 started. Logging: /tmp/graphlab_server_1494805233.log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 576 ms, sys: 140 ms, total: 716 ms\n",
      "Wall time: 2.09 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "sf_table = gl.load_sframe(get_input_sframe('home_antenna'))\n",
    "\n",
    "\n",
    "sl_table = gl.load_sframe(get_input_sframe('sum_links'))\n",
    "\n",
    "gt_table = gl.load_sframe(get_input_sframe('gtruth_01'))\n",
    "\n",
    "\n",
    "rename_gt = (dict([(col,col+\"_gt\") for col in gt_table.column_names() if col != 'USER']))\n",
    "\n",
    "#agrego la etiqueta \"_gt\" a las columnas del ground_truth\n",
    "gt_table.rename(rename_gt) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## simple format description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aca miramos las top 10 antenas que utilizo un usuario, ordeandas de 0 a 10 segun el uso, en numero de llamados, que el user le daba a c. antenna. _0_ Seria la antenna mas utilizada y _10_ la menos utilizada. El count es la cantidad de veces que utilizo esa antenna. \n",
    "\n",
    "Cuando aparece _WEEKNIGHT_ en el nombre de la columna, es porque cumple la condicion de que los llamados fueron hechos de noche fuera del horario [8,20] y dentro de la semana laboral.\n",
    "\n",
    "Siguiendo las definiciones del trabajo de Caro, un user es _EPIDEMIC_ siii su ANTENNA_WEEKNIGHT_0 (esta es la home_antenna) pertence a la zona epidemica.\n",
    "\n",
    "El mobility_diameter es el radio de las antennas (0 si uso una sola, etc.) utilizadas por este user. Nuevamente el modificador _WEEKNIGHT_ solo aplica para antennas utilizadas en esos horarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['USER',\n",
       " 'COUNT_0',\n",
       " 'COUNT_1',\n",
       " 'COUNT_2',\n",
       " 'COUNT_3',\n",
       " 'COUNT_4',\n",
       " 'COUNT_5',\n",
       " 'COUNT_6',\n",
       " 'COUNT_7',\n",
       " 'COUNT_8',\n",
       " 'COUNT_9',\n",
       " 'ANTENNA_ID_0',\n",
       " 'ANTENNA_ID_1',\n",
       " 'ANTENNA_ID_2',\n",
       " 'ANTENNA_ID_3',\n",
       " 'ANTENNA_ID_4',\n",
       " 'ANTENNA_ID_5',\n",
       " 'ANTENNA_ID_6',\n",
       " 'ANTENNA_ID_7',\n",
       " 'ANTENNA_ID_8',\n",
       " 'ANTENNA_ID_9',\n",
       " 'COUNT_WEEKNIGHT_0',\n",
       " 'COUNT_WEEKNIGHT_1',\n",
       " 'COUNT_WEEKNIGHT_2',\n",
       " 'COUNT_WEEKNIGHT_3',\n",
       " 'COUNT_WEEKNIGHT_4',\n",
       " 'COUNT_WEEKNIGHT_5',\n",
       " 'COUNT_WEEKNIGHT_6',\n",
       " 'COUNT_WEEKNIGHT_7',\n",
       " 'COUNT_WEEKNIGHT_8',\n",
       " 'COUNT_WEEKNIGHT_9',\n",
       " 'ANTENNA_ID_WEEKNIGHT_0',\n",
       " 'ANTENNA_ID_WEEKNIGHT_1',\n",
       " 'ANTENNA_ID_WEEKNIGHT_2',\n",
       " 'ANTENNA_ID_WEEKNIGHT_3',\n",
       " 'ANTENNA_ID_WEEKNIGHT_4',\n",
       " 'ANTENNA_ID_WEEKNIGHT_5',\n",
       " 'ANTENNA_ID_WEEKNIGHT_6',\n",
       " 'ANTENNA_ID_WEEKNIGHT_7',\n",
       " 'ANTENNA_ID_WEEKNIGHT_8',\n",
       " 'ANTENNA_ID_WEEKNIGHT_9',\n",
       " 'MOBILITY_DIAMETER',\n",
       " 'MOBILITY_DIAMETER_WEEKNIGHT']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# column names\n",
    "sf_table.column_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sum links description\n",
    "\n",
    "La tabla sum_links tiene mas atributos y con data mas rica en informacion:\n",
    "    \n",
    "Esencialmente para c/ user miramos la cantidad de llamados y el tiempo que duraron esos llamados pero segmentando con distintos modificadores. `Time` representa la duracion del llamado y Calls el conteo de llamados.\n",
    "\n",
    "Los modficadores/ segmentaciones son:\n",
    "\n",
    "* mes en el cual estamos parados (12 == diciembre, ..., 08 == agosto)\n",
    "* OUT/IN, separa por la direccion de los llamados si salientes u entrantes.\n",
    "* _VULN_ : separa los llamados que fueron realizados hacia/desde un target_user (en una llamada hay 2 usuarios, el origin o el target) viviendo en una zona epidemica. Donde la home antena de un target_user determina su vulnerabilidad segun si es zona epidemica o no.\n",
    "* Weekend, WeekDay y WeekNight son lo que suenan. Weekend el finde, Weeknight la semana pero fuera de horario laboral y Weekday en horario laboral y de lunes a viernes.\n",
    "\n",
    "Hay solo una columna que no entra enteramente en este esquema que es VULNERABLE. Esta columna hace un conteo p/c/ usuario d cuantos target_users viven en una zona epidemica. Tambien se segmenta esta columna con los modficiadores anteriores (el mes y el out/in)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['USER',\n",
       " 'TimeWeekEnd_OUT_12',\n",
       " 'CallsWeekDay_OUT_12',\n",
       " 'CallsWeekNight_OUT_12',\n",
       " 'TimeWeekDay_OUT_12',\n",
       " 'CallsWeekEnd_OUT_12',\n",
       " 'TimeWeekNight_OUT_12',\n",
       " 'TimeWeekEnd_OUT_VUL_12',\n",
       " 'CallsWeekDay_OUT_VUL_12',\n",
       " 'CallsWeekNight_OUT_VUL_12',\n",
       " 'TimeWeekDay_OUT_VUL_12',\n",
       " 'CallsWeekEnd_OUT_VUL_12',\n",
       " 'TimeWeekNight_OUT_VUL_12',\n",
       " 'VULNERABLE_OUT_12',\n",
       " 'TimeWeekEnd_IN_12',\n",
       " 'CallsWeekDay_IN_12',\n",
       " 'CallsWeekNight_IN_12',\n",
       " 'TimeWeekDay_IN_12',\n",
       " 'CallsWeekEnd_IN_12',\n",
       " 'TimeWeekNight_IN_12',\n",
       " 'TimeWeekEnd_IN_VUL_12',\n",
       " 'CallsWeekDay_IN_VUL_12',\n",
       " 'CallsWeekNight_IN_VUL_12',\n",
       " 'TimeWeekDay_IN_VUL_12',\n",
       " 'CallsWeekEnd_IN_VUL_12',\n",
       " 'TimeWeekNight_IN_VUL_12',\n",
       " 'VULNERABLE_IN_12',\n",
       " 'TimeWeekEnd_OUT_08',\n",
       " 'CallsWeekDay_OUT_08',\n",
       " 'CallsWeekNight_OUT_08',\n",
       " 'TimeWeekDay_OUT_08',\n",
       " 'CallsWeekEnd_OUT_08',\n",
       " 'TimeWeekNight_OUT_08',\n",
       " 'TimeWeekEnd_OUT_VUL_08',\n",
       " 'CallsWeekDay_OUT_VUL_08',\n",
       " 'CallsWeekNight_OUT_VUL_08',\n",
       " 'TimeWeekDay_OUT_VUL_08',\n",
       " 'CallsWeekEnd_OUT_VUL_08',\n",
       " 'TimeWeekNight_OUT_VUL_08',\n",
       " 'VULNERABLE_OUT_08',\n",
       " 'TimeWeekEnd_IN_08',\n",
       " 'CallsWeekDay_IN_08',\n",
       " 'CallsWeekNight_IN_08',\n",
       " 'TimeWeekDay_IN_08',\n",
       " 'CallsWeekEnd_IN_08',\n",
       " 'TimeWeekNight_IN_08',\n",
       " 'TimeWeekEnd_IN_VUL_08',\n",
       " 'CallsWeekDay_IN_VUL_08',\n",
       " 'CallsWeekNight_IN_VUL_08',\n",
       " 'TimeWeekDay_IN_VUL_08',\n",
       " 'CallsWeekEnd_IN_VUL_08',\n",
       " 'TimeWeekNight_IN_VUL_08',\n",
       " 'VULNERABLE_IN_08',\n",
       " 'TimeWeekEnd_OUT_09',\n",
       " 'CallsWeekDay_OUT_09',\n",
       " 'CallsWeekNight_OUT_09',\n",
       " 'TimeWeekDay_OUT_09',\n",
       " 'CallsWeekEnd_OUT_09',\n",
       " 'TimeWeekNight_OUT_09',\n",
       " 'TimeWeekEnd_OUT_VUL_09',\n",
       " 'CallsWeekDay_OUT_VUL_09',\n",
       " 'CallsWeekNight_OUT_VUL_09',\n",
       " 'TimeWeekDay_OUT_VUL_09',\n",
       " 'CallsWeekEnd_OUT_VUL_09',\n",
       " 'TimeWeekNight_OUT_VUL_09',\n",
       " 'VULNERABLE_OUT_09',\n",
       " 'TimeWeekEnd_IN_09',\n",
       " 'CallsWeekDay_IN_09',\n",
       " 'CallsWeekNight_IN_09',\n",
       " 'TimeWeekDay_IN_09',\n",
       " 'CallsWeekEnd_IN_09',\n",
       " 'TimeWeekNight_IN_09',\n",
       " 'TimeWeekEnd_IN_VUL_09',\n",
       " 'CallsWeekDay_IN_VUL_09',\n",
       " 'CallsWeekNight_IN_VUL_09',\n",
       " 'TimeWeekDay_IN_VUL_09',\n",
       " 'CallsWeekEnd_IN_VUL_09',\n",
       " 'TimeWeekNight_IN_VUL_09',\n",
       " 'VULNERABLE_IN_09',\n",
       " 'TimeWeekEnd_OUT_10',\n",
       " 'CallsWeekDay_OUT_10',\n",
       " 'CallsWeekNight_OUT_10',\n",
       " 'TimeWeekDay_OUT_10',\n",
       " 'CallsWeekEnd_OUT_10',\n",
       " 'TimeWeekNight_OUT_10',\n",
       " 'TimeWeekEnd_OUT_VUL_10',\n",
       " 'CallsWeekDay_OUT_VUL_10',\n",
       " 'CallsWeekNight_OUT_VUL_10',\n",
       " 'TimeWeekDay_OUT_VUL_10',\n",
       " 'CallsWeekEnd_OUT_VUL_10',\n",
       " 'TimeWeekNight_OUT_VUL_10',\n",
       " 'VULNERABLE_OUT_10',\n",
       " 'TimeWeekEnd_IN_10',\n",
       " 'CallsWeekDay_IN_10',\n",
       " 'CallsWeekNight_IN_10',\n",
       " 'TimeWeekDay_IN_10',\n",
       " 'CallsWeekEnd_IN_10',\n",
       " 'TimeWeekNight_IN_10',\n",
       " 'TimeWeekEnd_IN_VUL_10',\n",
       " 'CallsWeekDay_IN_VUL_10',\n",
       " 'CallsWeekNight_IN_VUL_10',\n",
       " 'TimeWeekDay_IN_VUL_10',\n",
       " 'CallsWeekEnd_IN_VUL_10',\n",
       " 'TimeWeekNight_IN_VUL_10',\n",
       " 'VULNERABLE_IN_10',\n",
       " 'TimeWeekEnd_OUT_11',\n",
       " 'CallsWeekDay_OUT_11',\n",
       " 'CallsWeekNight_OUT_11',\n",
       " 'TimeWeekDay_OUT_11',\n",
       " 'CallsWeekEnd_OUT_11',\n",
       " 'TimeWeekNight_OUT_11',\n",
       " 'TimeWeekEnd_OUT_VUL_11',\n",
       " 'CallsWeekDay_OUT_VUL_11',\n",
       " 'CallsWeekNight_OUT_VUL_11',\n",
       " 'TimeWeekDay_OUT_VUL_11',\n",
       " 'CallsWeekEnd_OUT_VUL_11',\n",
       " 'TimeWeekNight_OUT_VUL_11',\n",
       " 'VULNERABLE_OUT_11',\n",
       " 'TimeWeekEnd_IN_11',\n",
       " 'CallsWeekDay_IN_11',\n",
       " 'CallsWeekNight_IN_11',\n",
       " 'TimeWeekDay_IN_11',\n",
       " 'CallsWeekEnd_IN_11',\n",
       " 'TimeWeekNight_IN_11',\n",
       " 'TimeWeekEnd_IN_VUL_11',\n",
       " 'CallsWeekDay_IN_VUL_11',\n",
       " 'CallsWeekNight_IN_VUL_11',\n",
       " 'TimeWeekDay_IN_VUL_11',\n",
       " 'CallsWeekEnd_IN_VUL_11',\n",
       " 'TimeWeekNight_IN_VUL_11',\n",
       " 'VULNERABLE_IN_11']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# column names\n",
    "sl_table.column_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Para la\n",
    "tabla gt (ground_truth) es mas simple la explicacion. Solo se busco el antenna_ID_0 (nuevamente la antenna mas utilizada) por un user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\"><table frame=\"box\" rules=\"cols\">\n",
       "    <tr>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">USER</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">ANTENNA_ID_0_gt</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">ANTENNA_ID_WEEKNIGHT_0_gt</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">41D91B8CB8747902A80D6108D<br>548A8AF ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2898</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">24A624FC979DF41830A31C7CE<br>D65E2D2 ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">4285</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">4285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">C3FF4C9281746CAC6C09802C2<br>54BDE71 ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">4336</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">4336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">212D3A9745F13470632678443<br>11B31FF ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1200</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">544695294E816F26691C4D015<br>16ABF9B ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">195</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">FEC4BD059A42FB5283E07539C<br>1FD2CB1 ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">262</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">BDEF57DB3EF1035FF3F210B47<br>FC2A5B0 ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1557</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">4021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">3AE1DCA333E55CA87E4F53310<br>35DB600 ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">608</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2A72E07E48667A6289D93874A<br>623C152 ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2302</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">C5287E4004BE8F3A12AD489FE<br>8204056 ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2644</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">828</td>\n",
       "    </tr>\n",
       "</table>\n",
       "[10 rows x 3 columns]<br/>\n",
       "</div>"
      ],
      "text/plain": [
       "Columns:\n",
       "\tUSER\tstr\n",
       "\tANTENNA_ID_0_gt\tstr\n",
       "\tANTENNA_ID_WEEKNIGHT_0_gt\tstr\n",
       "\n",
       "Rows: 10\n",
       "\n",
       "Data:\n",
       "+-------------------------------+-----------------+---------------------------+\n",
       "|              USER             | ANTENNA_ID_0_gt | ANTENNA_ID_WEEKNIGHT_0_gt |\n",
       "+-------------------------------+-----------------+---------------------------+\n",
       "| 41D91B8CB8747902A80D6108D5... |       2898      |            2898           |\n",
       "| 24A624FC979DF41830A31C7CED... |       4285      |            4285           |\n",
       "| C3FF4C9281746CAC6C09802C25... |       4336      |            4336           |\n",
       "| 212D3A9745F134706326784431... |       1200      |            884            |\n",
       "| 544695294E816F26691C4D0151... |       195       |            195            |\n",
       "| FEC4BD059A42FB5283E07539C1... |       262       |            262            |\n",
       "| BDEF57DB3EF1035FF3F210B47F... |       1557      |            4021           |\n",
       "| 3AE1DCA333E55CA87E4F533103... |       608       |            608            |\n",
       "| 2A72E07E48667A6289D93874A6... |       2302      |            2302           |\n",
       "| C5287E4004BE8F3A12AD489FE8... |       2644      |            828            |\n",
       "+-------------------------------+-----------------+---------------------------+\n",
       "[10 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt_table.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We need antennas metadata\n",
    "to get the epidemicity of each antenna and add that info to the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /home/juan/mobility-study/mexico-scripts-ver2/data/celdas_limpio.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /home/juan/mobility-study/mexico-scripts-ver2/data/celdas_limpio.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 4415 lines in 0.059146 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 4415 lines in 0.059146 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#agregamos al gt su info de epidemicidad\n",
    "antennas_file = DATADIR2+'/celdas_limpio.csv'\n",
    "antennas = gl.SFrame.read_csv(antennas_file, \n",
    "                              delimiter= \"|\", \n",
    "                usecols=['LATITUDE','LONGITUDE','CEL_ID','STATE','EPIDEMIC'],\n",
    "                column_type_hints=[float, float, str,str, bool])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# agrego tambien data de epidemicidad al simpleformat table\n",
    "sf_table = sf_table.join(antennas['CEL_ID','EPIDEMIC','STATE'], on = {'ANTENNA_ID_WEEKNIGHT_0':'CEL_ID'},how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 21.8 s, sys: 3.15 s, total: 25 s\n",
      "Wall time: 3.07 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# enriquecemos la data de gt con info de epidemicidad\n",
    "gt_table = gt_table.join(antennas['CEL_ID','EPIDEMIC','STATE'], on = {'ANTENNA_ID_WEEKNIGHT_0_gt':'CEL_ID'},how = 'left')\n",
    "gt_table.rename({'EPIDEMIC':'EPIDEMIC_gt'});"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['USER',\n",
       " 'ANTENNA_ID_0_gt',\n",
       " 'ANTENNA_ID_WEEKNIGHT_0_gt',\n",
       " 'EPIDEMIC_gt',\n",
       " 'STATE']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt_table.column_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\"><table frame=\"box\" rules=\"cols\">\n",
       "    <tr>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">USER</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">ANTENNA_ID_0_gt</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">ANTENNA_ID_WEEKNIGHT_0_gt</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">EPIDEMIC_gt</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">STATE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">41D91B8CB8747902A80D6108D<br>548A8AF ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2898</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2898</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Oaxaca</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">24A624FC979DF41830A31C7CE<br>D65E2D2 ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">4285</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">4285</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Mexico</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">C3FF4C9281746CAC6C09802C2<br>54BDE71 ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">4336</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">4336</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Mexico</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">212D3A9745F13470632678443<br>11B31FF ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1200</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">884</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Jalisco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">544695294E816F26691C4D015<br>16ABF9B ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">195</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">195</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Chihuahua</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">FEC4BD059A42FB5283E07539C<br>1FD2CB1 ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">262</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">262</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Guanajuato</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">BDEF57DB3EF1035FF3F210B47<br>FC2A5B0 ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1557</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">4021</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Tabasco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">3AE1DCA333E55CA87E4F53310<br>35DB600 ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">608</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">608</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Mexico</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2A72E07E48667A6289D93874A<br>623C152 ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2302</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2302</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Distrito_Federal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">C5287E4004BE8F3A12AD489FE<br>8204056 ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2644</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">828</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Queretaro</td>\n",
       "    </tr>\n",
       "</table>\n",
       "[10 rows x 5 columns]<br/>\n",
       "</div>"
      ],
      "text/plain": [
       "Columns:\n",
       "\tUSER\tstr\n",
       "\tANTENNA_ID_0_gt\tstr\n",
       "\tANTENNA_ID_WEEKNIGHT_0_gt\tstr\n",
       "\tEPIDEMIC_gt\tint\n",
       "\tSTATE\tstr\n",
       "\n",
       "Rows: 10\n",
       "\n",
       "Data:\n",
       "+-------------------------------+-----------------+---------------------------+\n",
       "|              USER             | ANTENNA_ID_0_gt | ANTENNA_ID_WEEKNIGHT_0_gt |\n",
       "+-------------------------------+-----------------+---------------------------+\n",
       "| 41D91B8CB8747902A80D6108D5... |       2898      |            2898           |\n",
       "| 24A624FC979DF41830A31C7CED... |       4285      |            4285           |\n",
       "| C3FF4C9281746CAC6C09802C25... |       4336      |            4336           |\n",
       "| 212D3A9745F134706326784431... |       1200      |            884            |\n",
       "| 544695294E816F26691C4D0151... |       195       |            195            |\n",
       "| FEC4BD059A42FB5283E07539C1... |       262       |            262            |\n",
       "| BDEF57DB3EF1035FF3F210B47F... |       1557      |            4021           |\n",
       "| 3AE1DCA333E55CA87E4F533103... |       608       |            608            |\n",
       "| 2A72E07E48667A6289D93874A6... |       2302      |            2302           |\n",
       "| C5287E4004BE8F3A12AD489FE8... |       2644      |            828            |\n",
       "+-------------------------------+-----------------+---------------------------+\n",
       "+-------------+------------------+\n",
       "| EPIDEMIC_gt |      STATE       |\n",
       "+-------------+------------------+\n",
       "|      1      |      Oaxaca      |\n",
       "|      0      |      Mexico      |\n",
       "|      0      |      Mexico      |\n",
       "|      1      |     Jalisco      |\n",
       "|      0      |    Chihuahua     |\n",
       "|      0      |    Guanajuato    |\n",
       "|      1      |     Tabasco      |\n",
       "|      0      |      Mexico      |\n",
       "|      0      | Distrito_Federal |\n",
       "|      0      |    Queretaro     |\n",
       "+-------------+------------------+\n",
       "[10 rows x 5 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt_table.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample data in case we want to work\n",
    "with a smaller data sized set to test different algorithms\n",
    "\n",
    "we will do this on sf_table which is our leading DF. \n",
    "\n",
    "All other frames will be joined onto this one, thus sampling the main DF is enough to sample the final DF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sample_data = 0.2\n",
    "sample_data = None\n",
    "\n",
    "if sample_data:\n",
    "    sf_table, _ = sf_table.random_split(sample_data, seed=2015)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# create data matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1483010, 176)\n",
      "CPU times: user 5min 30s, sys: 24.2 s, total: 5min 54s\n",
      "Wall time: 2min 27s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "## integrate target to single frame\n",
    "\n",
    "data = sf_table.join(gt_table['USER','EPIDEMIC_gt'], on = 'USER', how = 'inner')\n",
    "data = data.join(sl_table, on = 'USER', how = 'inner')\n",
    "\n",
    "#no podemos tener nulls en el target asi que dropeamos\n",
    "data = data.dropna(columns = ['EPIDEMIC_gt'], how='any')\n",
    "print(data.shape)\n",
    "del sl_table, sf_table, gt_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sub_sample rows in case we want to work\n",
    "with a better balanced dataset among the two attributes `EPIDEMIC` and `EPIDEMIC_gt`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 10 µs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\"><table frame=\"box\" rules=\"cols\">\n",
       "    <tr>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">EPIDEMIC</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">EPIDEMIC_gt</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">384466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">16642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">21007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1060895</td>\n",
       "    </tr>\n",
       "</table>\n",
       "[4 rows x 3 columns]<br/>\n",
       "</div>"
      ],
      "text/plain": [
       "Columns:\n",
       "\tEPIDEMIC\tint\n",
       "\tEPIDEMIC_gt\tint\n",
       "\tcount\tint\n",
       "\n",
       "Rows: 4\n",
       "\n",
       "Data:\n",
       "+----------+-------------+---------+\n",
       "| EPIDEMIC | EPIDEMIC_gt |  count  |\n",
       "+----------+-------------+---------+\n",
       "|    1     |      1      |  384466 |\n",
       "|    1     |      0      |  16642  |\n",
       "|    0     |      1      |  21007  |\n",
       "|    0     |      0      | 1060895 |\n",
       "+----------+-------------+---------+\n",
       "[4 rows x 3 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time\n",
    "# 1st check group sizes\n",
    "\n",
    "epidemic_transition = data.groupby(['EPIDEMIC','EPIDEMIC_gt'],\n",
    "                             {'count':gl.aggregate.COUNT_DISTINCT('USER')})\n",
    "\n",
    "epidemic_transition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### note\n",
    "some users don't have current epidemicity since they haven't used their cellphones enough on weeknights to be evaluated (only at other times). We must later exclude them from analysis\n",
    "\n",
    "This check is here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\"><table frame=\"box\" rules=\"cols\">\n",
       "    <tr>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">EPIDEMIC</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">ANTENNA_ID_WEEKNIGHT_0</th>\n",
       "    </tr>\n",
       "</table>\n",
       "[0 rows x 2 columns]<br/>\n",
       "</div>"
      ],
      "text/plain": [
       "Columns:\n",
       "\tEPIDEMIC\tint\n",
       "\tANTENNA_ID_WEEKNIGHT_0\tstr\n",
       "\n",
       "Rows: 0\n",
       "\n",
       "Data:\n",
       "\t[]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col = 'EPIDEMIC'\n",
    "mask = data[col] == None\n",
    "\n",
    "res = data[mask]['EPIDEMIC','ANTENNA_ID_WEEKNIGHT_0']\n",
    "print(res.shape)\n",
    "res.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### now sub_sample big groups of users who didn't migrate i.e. which have same epidemic and epidemic_gt status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "sample_cols = ['EPIDEMIC','EPIDEMIC_gt']\n",
    "# data[sample_cols].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 10 µs\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "sub_sample_data = 0.08 # this is the percentage of users we would like to keep from the big gruops\n",
    "# sub_sample_data = None\n",
    "\n",
    "if sub_sample_data:\n",
    "    excluded_users_list = data[(data['EPIDEMIC']==  data['EPIDEMIC_gt'])]['USER'].sample(1-sub_sample_data)\n",
    "    excluded_users_list = excluded_users_list.to_numpy()\n",
    "    data = data[data['USER'].is_in(excluded_users_list)==0] # dirty trick to flip values of binary series\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\"><table frame=\"box\" rules=\"cols\">\n",
       "    <tr>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">EPIDEMIC</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">EPIDEMIC_gt</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">30702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">16642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">21007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">84659</td>\n",
       "    </tr>\n",
       "</table>\n",
       "[4 rows x 3 columns]<br/>\n",
       "</div>"
      ],
      "text/plain": [
       "Columns:\n",
       "\tEPIDEMIC\tint\n",
       "\tEPIDEMIC_gt\tint\n",
       "\tcount\tint\n",
       "\n",
       "Rows: 4\n",
       "\n",
       "Data:\n",
       "+----------+-------------+-------+\n",
       "| EPIDEMIC | EPIDEMIC_gt | count |\n",
       "+----------+-------------+-------+\n",
       "|    1     |      1      | 30702 |\n",
       "|    1     |      0      | 16642 |\n",
       "|    0     |      1      | 21007 |\n",
       "|    0     |      0      | 84659 |\n",
       "+----------+-------------+-------+\n",
       "[4 rows x 3 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check results of sub_sampling\n",
    "epidemic_transition = data.groupby(['EPIDEMIC','EPIDEMIC_gt'],\n",
    "                             {'count':gl.aggregate.COUNT_DISTINCT('USER')})\n",
    "epidemic_transition\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\"><table frame=\"box\" rules=\"cols\">\n",
       "    <tr>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">EPIDEMIC</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">EPIDEMIC_gt</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">30702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">16642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">21007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">84659</td>\n",
       "    </tr>\n",
       "</table>\n",
       "[4 rows x 3 columns]<br/>\n",
       "</div>"
      ],
      "text/plain": [
       "Columns:\n",
       "\tEPIDEMIC\tint\n",
       "\tEPIDEMIC_gt\tint\n",
       "\tcount\tint\n",
       "\n",
       "Rows: 4\n",
       "\n",
       "Data:\n",
       "+----------+-------------+-------+\n",
       "| EPIDEMIC | EPIDEMIC_gt | count |\n",
       "+----------+-------------+-------+\n",
       "|    1     |      1      | 30702 |\n",
       "|    1     |      0      | 16642 |\n",
       "|    0     |      1      | 21007 |\n",
       "|    0     |      0      | 84659 |\n",
       "+----------+-------------+-------+\n",
       "[4 rows x 3 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epidemic_transition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## select our global model\n",
    "\n",
    "sometimes we wish to try different models. \n",
    "For example:\n",
    "\n",
    "* focus on migrations of currently non-vulnerable users\n",
    "* exclude certain columns that are very informative or correlated with the target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub_sample_file = '/'.join(get_input_sframe('sum_links').split('/')[:-1]) + '/data_balanced_sample.csv'\n",
    "sub_sample_file\n",
    "\n",
    "data.export_csv(sub_sample_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# res = data.shape\n",
    "# res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df_test = data.to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df_test.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# p% of set as validation and the resulting  as train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "split_perc = 0.7\n",
    "data, val_set = data.random_split(split_perc, seed=2015)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instance fast model with MNB\n",
    "#### convertimos la data en numpy, previamente limpiando las columnas de antennas ya que el clasificador no acepta strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/juan/mobility-study/scikit-learn/sklearn/cross_validation.py:43: DeprecationWarning: This module has been deprecated in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/home/juan/mobility-study/scikit-learn/sklearn/grid_search.py:43: DeprecationWarning: This module has been deprecated in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import *\n",
    "from sklearn.metrics import *\n",
    "from sklearn.cross_validation import *\n",
    "from sklearn.grid_search import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## preparamos los datasets que no pueden tomar valores negativos o categorical vars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## drop certain columns for different experiments\n",
    "\n",
    "we are going to try different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "exclude_cols = [     \n",
    "     'EPIDEMIC',\n",
    "                ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = data[[col for col in data.column_names() if col not in exclude_cols]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12.4 s, sys: 616 ms, total: 13 s\n",
      "Wall time: 5.66 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X = data[[col for col in data.column_names() if col != 'USER' and col != 'EPIDEMIC_gt' \\\n",
    "          and not('ANTENNA' in col) ]]\n",
    "\n",
    "Y = data['EPIDEMIC_gt']\n",
    "\n",
    "X_val = val_set[[col for col in data.column_names() if col != 'USER' and \\\n",
    "                 col != 'EPIDEMIC_gt' and not('ANTENNA' in col )]]\n",
    "Y_val = val_set['EPIDEMIC_gt']\n",
    "\n",
    "for col in [col for col in X.column_names() if 'COUNT' in col]:\n",
    "    X[col]= X[col].apply(lambda x :  x if x>=0 else 0)\n",
    "    X_val[col]= X_val[col].apply(lambda x :  x if x>=0 else 0)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# X.column_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 9s, sys: 15.7 s, total: 3min 25s\n",
      "Wall time: 2min 52s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X = X.to_numpy()\n",
    "Y = Y.to_numpy()\n",
    "X_val = X_val.to_numpy()\n",
    "Y_val = Y_val.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## remember no negative values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n",
      "[CV] alpha=0.001, fit_prior=True .....................................\n",
      "[CV] ............ alpha=0.001, fit_prior=True, score=0.927250 -   4.0s\n",
      "[CV] alpha=0.001, fit_prior=True .....................................\n",
      "[CV] ............ alpha=0.001, fit_prior=True, score=0.976829 -   4.0s\n",
      "[CV] alpha=0.001, fit_prior=True .....................................\n",
      "[CV] ............ alpha=0.001, fit_prior=True, score=0.918735 -   5.1s\n",
      "[CV] alpha=0.001, fit_prior=False ....................................\n",
      "[CV] ........... alpha=0.001, fit_prior=False, score=0.927126 -   5.9s\n",
      "[CV] alpha=0.001, fit_prior=False ....................................\n",
      "[CV] ........... alpha=0.001, fit_prior=False, score=0.976823 -   4.0s\n",
      "[CV] alpha=0.001, fit_prior=False ....................................\n",
      "[CV] ........... alpha=0.001, fit_prior=False, score=0.918739 -   4.0s\n",
      "[CV] alpha=0.1, fit_prior=True .......................................\n",
      "[CV] .............. alpha=0.1, fit_prior=True, score=0.927250 -   4.0s\n",
      "[CV] alpha=0.1, fit_prior=True .......................................\n",
      "[CV] .............. alpha=0.1, fit_prior=True, score=0.976829 -   4.1s\n",
      "[CV] alpha=0.1, fit_prior=True .......................................\n",
      "[CV] .............. alpha=0.1, fit_prior=True, score=0.918735 -   4.0s\n",
      "[CV] alpha=0.1, fit_prior=False ......................................\n",
      "[CV] ............. alpha=0.1, fit_prior=False, score=0.927126 -   4.0s\n",
      "[CV] alpha=0.1, fit_prior=False ......................................\n",
      "[CV] ............. alpha=0.1, fit_prior=False, score=0.976823 -   4.5s\n",
      "[CV] alpha=0.1, fit_prior=False ......................................\n",
      "[CV] ............. alpha=0.1, fit_prior=False, score=0.918739 -   4.0s\n",
      "[CV] alpha=10.0, fit_prior=True ......................................\n",
      "[CV] ............. alpha=10.0, fit_prior=True, score=0.927250 -   4.1s\n",
      "[CV] alpha=10.0, fit_prior=True ......................................\n",
      "[CV] ............. alpha=10.0, fit_prior=True, score=0.976829 -   4.0s\n",
      "[CV] alpha=10.0, fit_prior=True ......................................\n",
      "[CV] ............. alpha=10.0, fit_prior=True, score=0.918735 -   4.0s\n",
      "[CV] alpha=10.0, fit_prior=False .....................................\n",
      "[CV] ............ alpha=10.0, fit_prior=False, score=0.927126 -   4.1s\n",
      "[CV] alpha=10.0, fit_prior=False .....................................\n",
      "[CV] ............ alpha=10.0, fit_prior=False, score=0.976823 -   6.4s\n",
      "[CV] alpha=10.0, fit_prior=False .....................................\n",
      "[CV] ............ alpha=10.0, fit_prior=False, score=0.918739 -   6.3s\n",
      "[CV] alpha=1.0, fit_prior=True .......................................\n",
      "[CV] .............. alpha=1.0, fit_prior=True, score=0.927250 -   6.4s\n",
      "[CV] alpha=1.0, fit_prior=True .......................................\n",
      "[CV] .............. alpha=1.0, fit_prior=True, score=0.976829 -   4.0s\n",
      "[CV] alpha=1.0, fit_prior=True .......................................\n",
      "[CV] .............. alpha=1.0, fit_prior=True, score=0.918735 -   4.0s\n",
      "[CV] alpha=1.0, fit_prior=False ......................................\n",
      "[CV] ............. alpha=1.0, fit_prior=False, score=0.927126 -   4.0s\n",
      "[CV] alpha=1.0, fit_prior=False ......................................\n",
      "[CV] ............. alpha=1.0, fit_prior=False, score=0.976823 -   4.1s\n",
      "[CV] alpha=1.0, fit_prior=False ......................................\n",
      "[CV] ............. alpha=1.0, fit_prior=False, score=0.918739 -   6.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  24 out of  24 | elapsed:  1.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid Search took 115.099725008 seconds to run\n",
      "\n",
      " Best estimator was MultinomialNB(alpha=0.001, class_prior=None, fit_prior=True) \n",
      "\n",
      "\n",
      " Best estimator was 0.940938151577 \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      0.96      0.96    323278\n",
      "          1       0.89      0.90      0.90    122186\n",
      "\n",
      "avg / total       0.94      0.94      0.94    445464\n",
      "\n",
      "CPU times: user 4min 22s, sys: 53.6 s, total: 5min 15s\n",
      "Wall time: 3min 20s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "start_time = time.time()\n",
    "param_grid = {'alpha':[1e-3, 1e-1, 1e1,1e0], 'fit_prior': [True,False],\n",
    "             }\n",
    "\n",
    "mnb  = MultinomialNB( )\n",
    "\n",
    "clf = GridSearchCV(mnb, param_grid, scoring='f1_weighted', fit_params=None, n_jobs=-1, iid=True, refit=True, \n",
    "verbose=3, pre_dispatch='2*n_jobs', error_score='raise')\n",
    "\n",
    "clf2 = MultinomialNB( )\n",
    "#how many parameters to randomly search for\n",
    "#n_iter_search = 45\n",
    "\n",
    "#random_search = RandomizedSearchCV(rforest, param_distributions=param_grid,\n",
    "                                 #  n_iter=n_iter_search, n_jobs =8, verbose=3)\n",
    "\n",
    "elapsed_time =  time.time() - start_time\n",
    "\n",
    "#Y = categorical(train_table_target.values, drop=True).astype(int)\n",
    "\n",
    "clf.fit(X,Y)\n",
    "\n",
    "elapsed_time =   time.time() - start_time \n",
    "\n",
    "print('Grid Search took %s seconds to run' % (elapsed_time))\n",
    "\n",
    "cv_result = pd.DataFrame(columns=['mean_score' ] + [key for key, value in clf.grid_scores_[0].parameters.items() ] )\n",
    "i=0\n",
    "for setup in clf.grid_scores_:\n",
    "    row = [clf.grid_scores_[i].mean_validation_score ] + [value for key, value in clf.grid_scores_[i].parameters.items() ]\n",
    "    cv_result.loc[i] = row\n",
    "    i+=1\n",
    "\n",
    "\n",
    "#este flag es basicamente para chequear que hayamos terminado nomas\n",
    "finished = True\n",
    "\n",
    "print('\\n Best estimator was %s \\n' % str(clf.best_estimator_))\n",
    "print('\\n Best estimator was %s \\n' % str(clf.best_score_))\n",
    "\n",
    "clf2.set_params(**clf.best_params_)\n",
    "\n",
    "clf2.fit(X,Y)\n",
    "\n",
    "\n",
    "#converted_dict = evaluation_print(clf, X_val, test_table_target.values, test_table.index.values, \n",
    "#                              test_table_target[test_table_target>0].index.values,start_date,future)\n",
    "\n",
    "print(classification_report(Y_val,clf2.predict(X_val)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# agregamos la data de roc auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.93145104767684839"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(Y_val,clf2.predict(X_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit_prior\n",
      "False    0.940896\n",
      "True     0.940938\n",
      "Name: mean_score, dtype: float64\n",
      "fit_prior\n",
      "False    0.0\n",
      "True     0.0\n",
      "Name: mean_score, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "coln = 2\n",
    "print(cv_result.groupby(cv_result.columns[coln])['mean_score'].mean())\n",
    "print(cv_result.groupby(cv_result.columns[coln])['mean_score'].std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from graphlab import random_forest_classifier, boosted_trees_classifier\n",
    "from graphlab.toolkits import cross_validation, model_parameter_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_grid = {'criterion': ['gini'], 'n_estimators': [15,30,50],\n",
    "  'max_features': [\"auto\", \"log2\"], \"bootstrap\": [ False, True],\n",
    "    \"min_samples_leaf\": np.append(np.random.randint(3,15,3),[3]),'max_depth':[10,20,30], \n",
    "               \"class_weight\": ['balanced']\n",
    "              }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# armamos con Gr Boost un clasificador pero ahora el target es ver los movimientos 0 a 0 , 0 a 1, 1a 0 , 1 a 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = data['EPIDEMIC','EPIDEMIC_gt'].head(3)\n",
    "a[0] == [0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#son (00)=0, (01)=1, 10 =2, 11 =3 \n",
    "def get_new_target(row):\n",
    "    rv=-1\n",
    "    if row['EPIDEMIC'] ==0 and row['EPIDEMIC_gt'] == 0: rv=0\n",
    "    if row['EPIDEMIC'] ==0 and row['EPIDEMIC_gt'] == 1: rv=1\n",
    "    if row['EPIDEMIC'] ==1 and row['EPIDEMIC_gt'] == 0: rv=2\n",
    "    if row['EPIDEMIC'] ==1 and row['EPIDEMIC_gt'] == 1: rv=3\n",
    "    return rv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 2s, sys: 3.84 s, total: 1min 6s\n",
      "Wall time: 17.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data['Y'] =  data['EPIDEMIC','EPIDEMIC_gt'].apply(lambda row: get_new_target(row))\n",
    "val_set['Y'] =  val_set['EPIDEMIC','EPIDEMIC_gt'].apply(lambda row: get_new_target(row))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get kfolds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 27.3 s, sys: 1.4 s, total: 28.7 s\n",
      "Wall time: 27.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "num_folds = 4\n",
    "kfold = cross_validation.KFold(data[[col for col in data.column_names() \\\n",
    "                                    if not('EPIDEMIC' in col) and col !='USER']],num_folds=num_folds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boosted Classifier\n",
    "### HyperParams search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Boosted Trees HyperParams\n",
    "params = {\n",
    "    'target': 'Y', ## the target column string name \n",
    "    'max_iterations': [2,6,9,12], #The maximum number of iterations for boosting. Each iteration == extra tree.\n",
    "    #'class_weights': [None, 'auto'], #Weights the examples in the training data according to the given class weights.\n",
    "    'class_weights': [None],\n",
    "    'max_depth': [2,6,9,12], #Maximum depth of a tree. Must be at least 1.\n",
    "    'step_size': [1e-1,0.5,1,1.5], # Step size (shrinkage) used in update to prevents overfitting\n",
    "    'min_loss_reduction': [1e-2,1e-1,1,10], #Minimum loss reduction required to make a further partition/split a node during the tree learning\n",
    "    'min_child_weight': [1e-2,1e-1,1,10], # Controls the minimum weight of each leaf node . larger values > less overfitting\n",
    "    'row_subsample': [0.01,0.1,0.5], #Subsample the ratio of the training set in each iteration of tree construction\n",
    "    'column_subsample': [0.01,0.1,0.5], # Subsample the ratio of the columns in each iteration of tree construction\n",
    "    #'metric': ['accuracy', 'auc', 'f1_score','recall','precision'], # Performance metric(s) that are tracked during training     \n",
    "    'metric': ['f1_score'],\n",
    "    'random_seed' : int(abs(hash('im not joking...'))%1e6) \n",
    "}\n",
    "\n",
    "model_factory = boosted_trees_classifier.create"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Search Boosted \n",
    "# Full Throtttttttleee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2016-07-17 15:30:09,900 [INFO] graphlab.deploy.job, 22: Validating job.\n",
      "2016-07-17 15:30:09,908 [INFO] graphlab.deploy.map_job, 186: Validation complete. Job: 'Model-Parameter-Search-Jul-17-2016-15-30-0900000' ready for execution\n",
      "2016-07-17 15:30:15,037 [INFO] graphlab.deploy.map_job, 192: Job: 'Model-Parameter-Search-Jul-17-2016-15-30-0900000' scheduled.\n",
      "2016-07-17 15:31:27,791 [INFO] graphlab.deploy.job, 22: Validating job.\n",
      "2016-07-17 15:31:27,795 [INFO] graphlab.deploy.map_job, 220: A job with name 'Model-Parameter-Search-Jul-17-2016-15-30-0900000' already exists. Renaming the job to 'Model-Parameter-Search-Jul-17-2016-15-30-0900000-ed86b'.\n",
      "2016-07-17 15:31:27,804 [INFO] graphlab.deploy.map_job, 186: Validation complete. Job: 'Model-Parameter-Search-Jul-17-2016-15-30-0900000-ed86b' ready for execution\n",
      "2016-07-17 15:31:32,276 [INFO] graphlab.deploy.map_job, 192: Job: 'Model-Parameter-Search-Jul-17-2016-15-30-0900000-ed86b' scheduled.\n",
      "2016-07-17 15:31:35,289 [INFO] graphlab.deploy.job, 22: Validating job.\n",
      "2016-07-17 15:31:35,302 [INFO] graphlab.deploy.map_job, 186: Validation complete. Job: 'Model-Parameter-Search-Jul-17-2016-15-30-0900001' ready for execution\n",
      "2016-07-17 15:31:41,343 [INFO] graphlab.deploy.map_job, 192: Job: 'Model-Parameter-Search-Jul-17-2016-15-30-0900001' scheduled.\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "start_time = time.time()\n",
    "model_search = model_parameter_search.create(datasets = datasets = kfold, \n",
    "                                             #[data, val_set],\n",
    "                                             model_factory = model_factory,\n",
    "            model_parameters = params, perform_trial_run = True  )\n",
    "\n",
    "search_results = model_search.get_results()\n",
    "\n",
    "all_time = start_time - time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 15)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_results.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\"><table frame=\"box\" rules=\"cols\">\n",
       "    <tr>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">class_weights</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">column_subsample</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">max_depth</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">max_iterations</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">metric</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">min_child_weight</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">min_loss_reduction</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.1</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">12</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">6</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">f1_score</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">10.0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.1</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">6</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">12</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">f1_score</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">10.0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.5</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">6</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">9</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">f1_score</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">10.0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.1</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">12</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">9</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">f1_score</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">10.0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.01</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">f1_score</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.1</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.1</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">9</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">f1_score</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1.0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.01</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">9</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">9</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">f1_score</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.01</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.5</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">12</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">6</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">f1_score</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.01</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.01</td>\n",
       "    </tr>\n",
       "</table>\n",
       "<table frame=\"box\" rules=\"cols\">\n",
       "    <tr>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">random_seed</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">row_subsample</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">step_size</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">target</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">num_folds</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">fold_id</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">mean_training_accuracy</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">model_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">415168</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.5</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.5</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Y</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">[0]</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.94124886993</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">[14]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">415168</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.1</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1.0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Y</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">[0]</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.961610376793</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">[12]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">415168</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.01</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.1</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Y</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">[0]</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.976458875076</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">[18]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">415168</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.5</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1.0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Y</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">[0]</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.983330859547</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">[16]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">415168</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.01</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1.0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Y</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">[0]</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.721053331611</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">[0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">415168</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.01</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1.0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Y</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">[0]</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.961723142878</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">[6]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">415168</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.01</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.5</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Y</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">[0]</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.913090118414</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">[4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">415168</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.01</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.5</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Y</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">[0]</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.994986246393</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">[10]</td>\n",
       "    </tr>\n",
       "</table>\n",
       "[8 rows x 15 columns]<br/>\n",
       "</div>"
      ],
      "text/plain": [
       "Columns:\n",
       "\tclass_weights\tfloat\n",
       "\tcolumn_subsample\tfloat\n",
       "\tmax_depth\tint\n",
       "\tmax_iterations\tint\n",
       "\tmetric\tstr\n",
       "\tmin_child_weight\tfloat\n",
       "\tmin_loss_reduction\tfloat\n",
       "\trandom_seed\tint\n",
       "\trow_subsample\tfloat\n",
       "\tstep_size\tfloat\n",
       "\ttarget\tstr\n",
       "\tnum_folds\tint\n",
       "\tfold_id\tlist\n",
       "\tmean_training_accuracy\tfloat\n",
       "\tmodel_id\tlist\n",
       "\n",
       "Rows: 8\n",
       "\n",
       "Data:\n",
       "+---------------+------------------+-----------+----------------+----------+\n",
       "| class_weights | column_subsample | max_depth | max_iterations |  metric  |\n",
       "+---------------+------------------+-----------+----------------+----------+\n",
       "|      None     |       0.1        |     12    |       6        | f1_score |\n",
       "|      None     |       0.1        |     6     |       12       | f1_score |\n",
       "|      None     |       0.5        |     6     |       9        | f1_score |\n",
       "|      None     |       0.1        |     12    |       9        | f1_score |\n",
       "|      None     |       0.01       |     2     |       2        | f1_score |\n",
       "|      None     |       0.1        |     2     |       9        | f1_score |\n",
       "|      None     |       0.01       |     9     |       9        | f1_score |\n",
       "|      None     |       0.5        |     12    |       6        | f1_score |\n",
       "+---------------+------------------+-----------+----------------+----------+\n",
       "+------------------+--------------------+-------------+---------------+-----------+\n",
       "| min_child_weight | min_loss_reduction | random_seed | row_subsample | step_size |\n",
       "+------------------+--------------------+-------------+---------------+-----------+\n",
       "|       10.0       |        0.1         |    415168   |      0.5      |    0.5    |\n",
       "|       10.0       |        0.1         |    415168   |      0.1      |    1.0    |\n",
       "|       10.0       |        10.0        |    415168   |      0.01     |    0.1    |\n",
       "|       10.0       |        10.0        |    415168   |      0.5      |    1.0    |\n",
       "|       0.1        |        0.1         |    415168   |      0.01     |    1.0    |\n",
       "|       1.0        |        10.0        |    415168   |      0.01     |    1.0    |\n",
       "|       0.01       |        0.01        |    415168   |      0.01     |    0.5    |\n",
       "|       0.01       |        0.01        |    415168   |      0.01     |    0.5    |\n",
       "+------------------+--------------------+-------------+---------------+-----------+\n",
       "+--------+-----------+---------+------------------------+----------+\n",
       "| target | num_folds | fold_id | mean_training_accuracy | model_id |\n",
       "+--------+-----------+---------+------------------------+----------+\n",
       "|   Y    |     1     |   [0]   |     0.94124886993      |   [14]   |\n",
       "|   Y    |     1     |   [0]   |     0.961610376793     |   [12]   |\n",
       "|   Y    |     1     |   [0]   |     0.976458875076     |   [18]   |\n",
       "|   Y    |     1     |   [0]   |     0.983330859547     |   [16]   |\n",
       "|   Y    |     1     |   [0]   |     0.721053331611     |   [0]    |\n",
       "|   Y    |     1     |   [0]   |     0.961723142878     |   [6]    |\n",
       "|   Y    |     1     |   [0]   |     0.913090118414     |   [4]    |\n",
       "|   Y    |     1     |   [0]   |     0.994986246393     |   [10]   |\n",
       "+--------+-----------+---------+------------------------+----------+\n",
       "[8 rows x 15 columns]"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-----------------+---------------+\n",
      "| class_weights |       std       |      mean     |\n",
      "+---------------+-----------------+---------------+\n",
      "|      None     | 0.0831262575802 | 0.93168772758 |\n",
      "+---------------+-----------------+---------------+\n",
      "[1 rows x 3 columns]\n",
      "\n",
      "+------------------+------------------+----------------+\n",
      "| column_subsample |       std        |      mean      |\n",
      "+------------------+------------------+----------------+\n",
      "|       0.5        | 0.00926368565827 | 0.985722560735 |\n",
      "|       0.01       | 0.0960183934014  | 0.817071725013 |\n",
      "|       0.1        | 0.0148815451391  | 0.961978312287 |\n",
      "+------------------+------------------+----------------+\n",
      "[3 rows x 3 columns]\n",
      "\n",
      "+-----------+------------------+----------------+\n",
      "| max_depth |       std        |      mean      |\n",
      "+-----------+------------------+----------------+\n",
      "|     2     |  0.120334905633  | 0.841388237244 |\n",
      "|     6     | 0.00742424914172 | 0.969034625935 |\n",
      "|     12    | 0.0230806497161  | 0.973188658623 |\n",
      "|     9     |       0.0        | 0.913090118414 |\n",
      "+-----------+------------------+----------------+\n",
      "[4 rows x 3 columns]\n",
      "\n",
      "+----------------+-----------------+----------------+\n",
      "| max_iterations |       std       |      mean      |\n",
      "+----------------+-----------------+----------------+\n",
      "|       2        |       0.0       | 0.721053331611 |\n",
      "|       6        | 0.0268686882317 | 0.968117558161 |\n",
      "|       12       |       0.0       | 0.961610376793 |\n",
      "|       9        | 0.0274383302814 | 0.958650748979 |\n",
      "+----------------+-----------------+----------------+\n",
      "[4 rows x 3 columns]\n",
      "\n",
      "+----------+-----------------+---------------+\n",
      "|  metric  |       std       |      mean     |\n",
      "+----------+-----------------+---------------+\n",
      "| f1_score | 0.0831262575802 | 0.93168772758 |\n",
      "+----------+-----------------+---------------+\n",
      "[1 rows x 3 columns]\n",
      "\n",
      "+------------------+-----------------+----------------+\n",
      "| min_child_weight |       std       |      mean      |\n",
      "+------------------+-----------------+----------------+\n",
      "|       10.0       | 0.0161336424849 | 0.965662245337 |\n",
      "|       0.01       | 0.0409480639895 | 0.954038182403 |\n",
      "|       0.1        |       0.0       | 0.721053331611 |\n",
      "|       1.0        |       0.0       | 0.961723142878 |\n",
      "+------------------+-----------------+----------------+\n",
      "[4 rows x 3 columns]\n",
      "\n",
      "+--------------------+------------------+----------------+\n",
      "| min_loss_reduction |       std        |      mean      |\n",
      "+--------------------+------------------+----------------+\n",
      "|        10.0        | 0.00901393608496 | 0.973837625834 |\n",
      "|        0.01        | 0.0409480639895  | 0.954038182403 |\n",
      "|        0.1         |  0.108918092591  | 0.874637526111 |\n",
      "+--------------------+------------------+----------------+\n",
      "[3 rows x 3 columns]\n",
      "\n",
      "+---------------+-----------------+----------------+\n",
      "| row_subsample |       std       |      mean      |\n",
      "+---------------+-----------------+----------------+\n",
      "|      0.5      | 0.0210409948089 | 0.962289864739 |\n",
      "|      0.01     | 0.0999651748336 | 0.913462342874 |\n",
      "|      0.1      |       0.0       | 0.961610376793 |\n",
      "+---------------+-----------------+----------------+\n",
      "[3 rows x 3 columns]\n",
      "\n",
      "+-----------+-----------------+----------------+\n",
      "| step_size |       std       |      mean      |\n",
      "+-----------+-----------------+----------------+\n",
      "|    0.5    | 0.0339731866396 | 0.949775078246 |\n",
      "|    0.1    |       0.0       | 0.976458875076 |\n",
      "|    1.0    |  0.107679454055 | 0.906929427707 |\n",
      "+-----------+-----------------+----------------+\n",
      "[3 rows x 3 columns]\n",
      "\n",
      "+--------+-----------------+---------------+\n",
      "| target |       std       |      mean     |\n",
      "+--------+-----------------+---------------+\n",
      "|   Y    | 0.0831262575802 | 0.93168772758 |\n",
      "+--------+-----------------+---------------+\n",
      "[1 rows x 3 columns]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for col in [col for col in search_results.column_names() if \\\n",
    "            not('accuracy' in col) and col!= 'model_id' and col!= 'random_seed' and col!= 'fold_id' \\\n",
    "                               and col!= 'num_folds']:\n",
    "    print(search_results.groupby(col,\n",
    "                             {'mean':gl.aggregate.MEAN('mean_training_accuracy'),\n",
    "                                'std':gl.aggregate.STD('mean_training_accuracy')}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## hyperparameter results\n",
    "\n",
    "* class_weights: None, gana por afano\n",
    "* column_subsample : algo menor a 1 pero no queda claro si cuanto menos mejor\n",
    "* row_subsample : algo menor a 1 pero no queda claro si cuanto menos mejor, refinar\n",
    "* max_depth: varia mucho, refinar\n",
    "* max_iterations: tampoco queda claro si poquito o mucho es mejor, reprobar\n",
    "* metric: el f1_score es el unico que no parece variar mucho,los demas cambian demasiado\n",
    "* min_child_weight: varia mucho, reprobar con mas\n",
    "* min_loss_reduction: varia mucho, reprobar\n",
    "* step_size: mas grande parece ser mejor> 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gl Random Forest HyperParam Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OJO ACA EL TARGET CAMBIO!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['USER',\n",
       " 'TimeWeekEnd_OUT_12',\n",
       " 'CallsWeekDay_OUT_12',\n",
       " 'CallsWeekNight_OUT_12',\n",
       " 'TimeWeekDay_OUT_12',\n",
       " 'CallsWeekEnd_OUT_12',\n",
       " 'TimeWeekNight_OUT_12',\n",
       " 'TimeWeekEnd_OUT_VUL_12',\n",
       " 'CallsWeekDay_OUT_VUL_12',\n",
       " 'CallsWeekNight_OUT_VUL_12',\n",
       " 'TimeWeekDay_OUT_VUL_12',\n",
       " 'CallsWeekEnd_OUT_VUL_12',\n",
       " 'TimeWeekNight_OUT_VUL_12',\n",
       " 'VULNERABLE_OUT_12',\n",
       " 'TimeWeekEnd_IN_12',\n",
       " 'CallsWeekDay_IN_12',\n",
       " 'CallsWeekNight_IN_12',\n",
       " 'TimeWeekDay_IN_12',\n",
       " 'CallsWeekEnd_IN_12',\n",
       " 'TimeWeekNight_IN_12',\n",
       " 'TimeWeekEnd_IN_VUL_12',\n",
       " 'CallsWeekDay_IN_VUL_12',\n",
       " 'CallsWeekNight_IN_VUL_12',\n",
       " 'TimeWeekDay_IN_VUL_12',\n",
       " 'CallsWeekEnd_IN_VUL_12',\n",
       " 'TimeWeekNight_IN_VUL_12',\n",
       " 'VULNERABLE_IN_12',\n",
       " 'TimeWeekEnd_OUT_08',\n",
       " 'CallsWeekDay_OUT_08',\n",
       " 'CallsWeekNight_OUT_08',\n",
       " 'TimeWeekDay_OUT_08',\n",
       " 'CallsWeekEnd_OUT_08',\n",
       " 'TimeWeekNight_OUT_08',\n",
       " 'TimeWeekEnd_OUT_VUL_08',\n",
       " 'CallsWeekDay_OUT_VUL_08',\n",
       " 'CallsWeekNight_OUT_VUL_08',\n",
       " 'TimeWeekDay_OUT_VUL_08',\n",
       " 'CallsWeekEnd_OUT_VUL_08',\n",
       " 'TimeWeekNight_OUT_VUL_08',\n",
       " 'VULNERABLE_OUT_08',\n",
       " 'TimeWeekEnd_IN_08',\n",
       " 'CallsWeekDay_IN_08',\n",
       " 'CallsWeekNight_IN_08',\n",
       " 'TimeWeekDay_IN_08',\n",
       " 'CallsWeekEnd_IN_08',\n",
       " 'TimeWeekNight_IN_08',\n",
       " 'TimeWeekEnd_IN_VUL_08',\n",
       " 'CallsWeekDay_IN_VUL_08',\n",
       " 'CallsWeekNight_IN_VUL_08',\n",
       " 'TimeWeekDay_IN_VUL_08',\n",
       " 'CallsWeekEnd_IN_VUL_08',\n",
       " 'TimeWeekNight_IN_VUL_08',\n",
       " 'VULNERABLE_IN_08',\n",
       " 'TimeWeekEnd_OUT_09',\n",
       " 'CallsWeekDay_OUT_09',\n",
       " 'CallsWeekNight_OUT_09',\n",
       " 'TimeWeekDay_OUT_09',\n",
       " 'CallsWeekEnd_OUT_09',\n",
       " 'TimeWeekNight_OUT_09',\n",
       " 'TimeWeekEnd_OUT_VUL_09',\n",
       " 'CallsWeekDay_OUT_VUL_09',\n",
       " 'CallsWeekNight_OUT_VUL_09',\n",
       " 'TimeWeekDay_OUT_VUL_09',\n",
       " 'CallsWeekEnd_OUT_VUL_09',\n",
       " 'TimeWeekNight_OUT_VUL_09',\n",
       " 'VULNERABLE_OUT_09',\n",
       " 'TimeWeekEnd_IN_09',\n",
       " 'CallsWeekDay_IN_09',\n",
       " 'CallsWeekNight_IN_09',\n",
       " 'TimeWeekDay_IN_09',\n",
       " 'CallsWeekEnd_IN_09',\n",
       " 'TimeWeekNight_IN_09',\n",
       " 'TimeWeekEnd_IN_VUL_09',\n",
       " 'CallsWeekDay_IN_VUL_09',\n",
       " 'CallsWeekNight_IN_VUL_09',\n",
       " 'TimeWeekDay_IN_VUL_09',\n",
       " 'CallsWeekEnd_IN_VUL_09',\n",
       " 'TimeWeekNight_IN_VUL_09',\n",
       " 'VULNERABLE_IN_09',\n",
       " 'TimeWeekEnd_OUT_10',\n",
       " 'CallsWeekDay_OUT_10',\n",
       " 'CallsWeekNight_OUT_10',\n",
       " 'TimeWeekDay_OUT_10',\n",
       " 'CallsWeekEnd_OUT_10',\n",
       " 'TimeWeekNight_OUT_10',\n",
       " 'TimeWeekEnd_OUT_VUL_10',\n",
       " 'CallsWeekDay_OUT_VUL_10',\n",
       " 'CallsWeekNight_OUT_VUL_10',\n",
       " 'TimeWeekDay_OUT_VUL_10',\n",
       " 'CallsWeekEnd_OUT_VUL_10',\n",
       " 'TimeWeekNight_OUT_VUL_10',\n",
       " 'VULNERABLE_OUT_10',\n",
       " 'TimeWeekEnd_IN_10',\n",
       " 'CallsWeekDay_IN_10',\n",
       " 'CallsWeekNight_IN_10',\n",
       " 'TimeWeekDay_IN_10',\n",
       " 'CallsWeekEnd_IN_10',\n",
       " 'TimeWeekNight_IN_10',\n",
       " 'TimeWeekEnd_IN_VUL_10',\n",
       " 'CallsWeekDay_IN_VUL_10',\n",
       " 'CallsWeekNight_IN_VUL_10',\n",
       " 'TimeWeekDay_IN_VUL_10',\n",
       " 'CallsWeekEnd_IN_VUL_10',\n",
       " 'TimeWeekNight_IN_VUL_10',\n",
       " 'VULNERABLE_IN_10',\n",
       " 'TimeWeekEnd_OUT_11',\n",
       " 'CallsWeekDay_OUT_11',\n",
       " 'CallsWeekNight_OUT_11',\n",
       " 'TimeWeekDay_OUT_11',\n",
       " 'CallsWeekEnd_OUT_11',\n",
       " 'TimeWeekNight_OUT_11',\n",
       " 'TimeWeekEnd_OUT_VUL_11',\n",
       " 'CallsWeekDay_OUT_VUL_11',\n",
       " 'CallsWeekNight_OUT_VUL_11',\n",
       " 'TimeWeekDay_OUT_VUL_11',\n",
       " 'CallsWeekEnd_OUT_VUL_11',\n",
       " 'TimeWeekNight_OUT_VUL_11',\n",
       " 'VULNERABLE_OUT_11',\n",
       " 'TimeWeekEnd_IN_11',\n",
       " 'CallsWeekDay_IN_11',\n",
       " 'CallsWeekNight_IN_11',\n",
       " 'TimeWeekDay_IN_11',\n",
       " 'CallsWeekEnd_IN_11',\n",
       " 'TimeWeekNight_IN_11',\n",
       " 'TimeWeekEnd_IN_VUL_11',\n",
       " 'CallsWeekDay_IN_VUL_11',\n",
       " 'CallsWeekNight_IN_VUL_11',\n",
       " 'TimeWeekDay_IN_VUL_11',\n",
       " 'CallsWeekEnd_IN_VUL_11',\n",
       " 'TimeWeekNight_IN_VUL_11',\n",
       " 'VULNERABLE_IN_11',\n",
       " 'EPIDEMIC_gt',\n",
       " 'COUNT_0',\n",
       " 'COUNT_1',\n",
       " 'COUNT_2',\n",
       " 'COUNT_3',\n",
       " 'COUNT_4',\n",
       " 'COUNT_5',\n",
       " 'COUNT_6',\n",
       " 'COUNT_7',\n",
       " 'COUNT_8',\n",
       " 'COUNT_9',\n",
       " 'ANTENNA_ID_0',\n",
       " 'ANTENNA_ID_1',\n",
       " 'ANTENNA_ID_2',\n",
       " 'ANTENNA_ID_3',\n",
       " 'ANTENNA_ID_4',\n",
       " 'ANTENNA_ID_5',\n",
       " 'ANTENNA_ID_6',\n",
       " 'ANTENNA_ID_7',\n",
       " 'ANTENNA_ID_8',\n",
       " 'ANTENNA_ID_9',\n",
       " 'COUNT_WEEKNIGHT_0',\n",
       " 'COUNT_WEEKNIGHT_1',\n",
       " 'COUNT_WEEKNIGHT_2',\n",
       " 'COUNT_WEEKNIGHT_3',\n",
       " 'COUNT_WEEKNIGHT_4',\n",
       " 'COUNT_WEEKNIGHT_5',\n",
       " 'COUNT_WEEKNIGHT_6',\n",
       " 'COUNT_WEEKNIGHT_7',\n",
       " 'COUNT_WEEKNIGHT_8',\n",
       " 'COUNT_WEEKNIGHT_9',\n",
       " 'ANTENNA_ID_WEEKNIGHT_0',\n",
       " 'ANTENNA_ID_WEEKNIGHT_1',\n",
       " 'ANTENNA_ID_WEEKNIGHT_2',\n",
       " 'ANTENNA_ID_WEEKNIGHT_3',\n",
       " 'ANTENNA_ID_WEEKNIGHT_4',\n",
       " 'ANTENNA_ID_WEEKNIGHT_5',\n",
       " 'ANTENNA_ID_WEEKNIGHT_6',\n",
       " 'ANTENNA_ID_WEEKNIGHT_7',\n",
       " 'ANTENNA_ID_WEEKNIGHT_8',\n",
       " 'ANTENNA_ID_WEEKNIGHT_9',\n",
       " 'MOBILITY_DIAMETER',\n",
       " 'MOBILITY_DIAMETER_WEEKNIGHT',\n",
       " 'EPIDEMIC']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.column_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 35s, sys: 34.3 s, total: 3min 9s\n",
      "Wall time: 22.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data['Y'] =  data['EPIDEMIC_gt']\n",
    "val_set['Y'] =  val_set['EPIDEMIC_gt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 16 ms, sys: 0 ns, total: 16 ms\n",
      "Wall time: 13.4 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "num_folds = 4\n",
    "kfold = cross_validation.KFold(data[[col for col in data.column_names() if col != 'USER' and not( 'EPIDEMIC' in col ) \\\n",
    "          and not('ANTENNA' in col) ]]\n",
    ",num_folds=num_folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Random Forest HyperParams\n",
    "params = {\n",
    "    'target': 'Y', ## the target column string name \n",
    "    #'max_iterations': [2,6,9,12], #The maximum number of iterations for boosting. Each iteration == extra tree.\n",
    "    'class_weights': [None, 'auto'], #Weights the examples in the training data according to the given class weights.\n",
    "    #'class_weights': [None],\n",
    "    'max_depth': [2,6,9,12], #Maximum depth of a tree. Must be at least 1.\n",
    "    'min_loss_reduction': [1e-2,1e-1,1,10], #Minimum loss reduction required to make a further partition/split a node during the tree learning\n",
    "    'min_child_weight': [1e-2,1e-1,1,10], # Controls the minimum weight of each leaf node . larger values > less overfitting\n",
    "    'row_subsample': [0.01,0.1,0.5], #Subsample the ratio of the training set in each iteration of tree construction\n",
    "    'column_subsample': [0.01,0.1,0.5], # Subsample the ratio of the columns in each iteration of tree construction\n",
    "    #'metric': ['accuracy', 'auc', 'f1_score','recall','precision'], # Performance metric(s) that are tracked during training     \n",
    "    'metric': ['f1_score'],\n",
    "    'random_seed' : int(abs(hash('im not joking...'))%1e6) \n",
    "}\n",
    "\n",
    "model_factory = random_forest_classifier.create\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] graphlab.deploy.job: Validating job.\n",
      "[INFO] graphlab.deploy.job: Creating a LocalAsync environment called 'async'.\n",
      "[INFO] graphlab.deploy.map_job: Validation complete. Job: 'Model-Parameter-Search-Aug-21-2016-16-08-1400000' ready for execution\n",
      "[INFO] graphlab.deploy.map_job: Job: 'Model-Parameter-Search-Aug-21-2016-16-08-1400000' scheduled.\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "start_time = time.time()\n",
    "model_search = model_parameter_search.create(datasets = kfold, \n",
    "                                             #[data, val_set],\n",
    "                                             model_factory = model_factory,\n",
    "            model_parameters = params, perform_trial_run = True  )\n",
    "\n",
    "search_results = model_search.get_results()\n",
    "all_time =  time.time() -start_time\n",
    "print('fitting took %s seconds' % str(all_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('fitting took %s seconds' % str(all_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_search.get_status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_search.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "search_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#model_search.get_metrics()['exception_message']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for col in [col for col in search_results.column_names() if \\\n",
    "            not('accuracy' in col) and col!= 'model_id' and col!= 'random_seed' and col!= 'fold_id' \\\n",
    "                               and col!= 'num_folds']:\n",
    "    print(search_results.groupby(col,\n",
    "                             {'mean':gl.aggregate.MEAN('mean_validation_accuracy'),\n",
    "                                'std':gl.aggregate.STD('mean_validation_accuracy')}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Refit best model for feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = model_search.get_best_params()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROGRESS: Creating a validation set from 5 percent of training data. This may take a while.\n",
      "          You can set ``validation_set=None`` to disable validation tracking.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>WARNING: Ignore unsupported tracking metric f1_score</pre>"
      ],
      "text/plain": [
       "WARNING: Ignore unsupported tracking metric f1_score"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Random forest classifier:</pre>"
      ],
      "text/plain": [
       "Random forest classifier:"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>--------------------------------------------------------</pre>"
      ],
      "text/plain": [
       "--------------------------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of examples          : 985423</pre>"
      ],
      "text/plain": [
       "Number of examples          : 985423"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of classes           : 4</pre>"
      ],
      "text/plain": [
       "Number of classes           : 4"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of feature columns   : 172</pre>"
      ],
      "text/plain": [
       "Number of feature columns   : 172"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of unpacked features : 172</pre>"
      ],
      "text/plain": [
       "Number of unpacked features : 172"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>+-----------+--------------+</pre>"
      ],
      "text/plain": [
       "+-----------+--------------+"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| Iteration | Elapsed Time |</pre>"
      ],
      "text/plain": [
       "| Iteration | Elapsed Time |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>+-----------+--------------+</pre>"
      ],
      "text/plain": [
       "+-----------+--------------+"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 1         | 15.804339    |</pre>"
      ],
      "text/plain": [
       "| 1         | 15.804339    |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 2         | 29.118135    |</pre>"
      ],
      "text/plain": [
       "| 2         | 29.118135    |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 3         | 42.924344    |</pre>"
      ],
      "text/plain": [
       "| 3         | 42.924344    |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 4         | 55.005525    |</pre>"
      ],
      "text/plain": [
       "| 4         | 55.005525    |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 5         | 68.527383    |</pre>"
      ],
      "text/plain": [
       "| 5         | 68.527383    |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 6         | 82.395935    |</pre>"
      ],
      "text/plain": [
       "| 6         | 82.395935    |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 7         | 95.526170    |</pre>"
      ],
      "text/plain": [
       "| 7         | 95.526170    |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 8         | 108.561872   |</pre>"
      ],
      "text/plain": [
       "| 8         | 108.561872   |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 9         | 120.349770   |</pre>"
      ],
      "text/plain": [
       "| 9         | 120.349770   |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 10        | 133.015839   |</pre>"
      ],
      "text/plain": [
       "| 10        | 133.015839   |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 11        | 146.524510   |</pre>"
      ],
      "text/plain": [
       "| 11        | 146.524510   |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 12        | 158.872525   |</pre>"
      ],
      "text/plain": [
       "| 12        | 158.872525   |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 13        | 172.852501   |</pre>"
      ],
      "text/plain": [
       "| 13        | 172.852501   |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 14        | 186.321143   |</pre>"
      ],
      "text/plain": [
       "| 14        | 186.321143   |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 15        | 198.763689   |</pre>"
      ],
      "text/plain": [
       "| 15        | 198.763689   |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 16        | 211.354630   |</pre>"
      ],
      "text/plain": [
       "| 16        | 211.354630   |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 17        | 225.520137   |</pre>"
      ],
      "text/plain": [
       "| 17        | 225.520137   |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 18        | 237.817710   |</pre>"
      ],
      "text/plain": [
       "| 18        | 237.817710   |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 19        | 251.473246   |</pre>"
      ],
      "text/plain": [
       "| 19        | 251.473246   |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 20        | 264.365673   |</pre>"
      ],
      "text/plain": [
       "| 20        | 264.365673   |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 21        | 278.086903   |</pre>"
      ],
      "text/plain": [
       "| 21        | 278.086903   |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 22        | 292.090652   |</pre>"
      ],
      "text/plain": [
       "| 22        | 292.090652   |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 23        | 307.107520   |</pre>"
      ],
      "text/plain": [
       "| 23        | 307.107520   |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 24        | 320.789092   |</pre>"
      ],
      "text/plain": [
       "| 24        | 320.789092   |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 25        | 334.112336   |</pre>"
      ],
      "text/plain": [
       "| 25        | 334.112336   |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 26        | 347.792144   |</pre>"
      ],
      "text/plain": [
       "| 26        | 347.792144   |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 27        | 361.460060   |</pre>"
      ],
      "text/plain": [
       "| 27        | 361.460060   |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 28        | 374.791820   |</pre>"
      ],
      "text/plain": [
       "| 28        | 374.791820   |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 29        | 387.880683   |</pre>"
      ],
      "text/plain": [
       "| 29        | 387.880683   |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 30        | 401.879361   |</pre>"
      ],
      "text/plain": [
       "| 30        | 401.879361   |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 31        | 415.970044   |</pre>"
      ],
      "text/plain": [
       "| 31        | 415.970044   |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 32        | 429.377116   |</pre>"
      ],
      "text/plain": [
       "| 32        | 429.377116   |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 33        | 442.982983   |</pre>"
      ],
      "text/plain": [
       "| 33        | 442.982983   |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 34        | 456.833560   |</pre>"
      ],
      "text/plain": [
       "| 34        | 456.833560   |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 35        | 470.125331   |</pre>"
      ],
      "text/plain": [
       "| 35        | 470.125331   |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 36        | 484.383544   |</pre>"
      ],
      "text/plain": [
       "| 36        | 484.383544   |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 37        | 497.641781   |</pre>"
      ],
      "text/plain": [
       "| 37        | 497.641781   |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 38        | 510.748065   |</pre>"
      ],
      "text/plain": [
       "| 38        | 510.748065   |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 39        | 524.447418   |</pre>"
      ],
      "text/plain": [
       "| 39        | 524.447418   |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 40        | 537.649672   |</pre>"
      ],
      "text/plain": [
       "| 40        | 537.649672   |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 41        | 551.262162   |</pre>"
      ],
      "text/plain": [
       "| 41        | 551.262162   |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 42        | 564.856917   |</pre>"
      ],
      "text/plain": [
       "| 42        | 564.856917   |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 43        | 577.662992   |</pre>"
      ],
      "text/plain": [
       "| 43        | 577.662992   |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 44        | 590.457043   |</pre>"
      ],
      "text/plain": [
       "| 44        | 590.457043   |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 45        | 604.872139   |</pre>"
      ],
      "text/plain": [
       "| 45        | 604.872139   |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 46        | 618.541911   |</pre>"
      ],
      "text/plain": [
       "| 46        | 618.541911   |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 47        | 631.312676   |</pre>"
      ],
      "text/plain": [
       "| 47        | 631.312676   |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 48        | 645.189820   |</pre>"
      ],
      "text/plain": [
       "| 48        | 645.189820   |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 49        | 659.629693   |</pre>"
      ],
      "text/plain": [
       "| 49        | 659.629693   |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 50        | 673.709740   |</pre>"
      ],
      "text/plain": [
       "| 50        | 673.709740   |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 51        | 686.624780   |</pre>"
      ],
      "text/plain": [
       "| 51        | 686.624780   |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 52        | 700.018753   |</pre>"
      ],
      "text/plain": [
       "| 52        | 700.018753   |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 53        | 712.852126   |</pre>"
      ],
      "text/plain": [
       "| 53        | 712.852126   |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 54        | 725.772974   |</pre>"
      ],
      "text/plain": [
       "| 54        | 725.772974   |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 55        | 739.615269   |</pre>"
      ],
      "text/plain": [
       "| 55        | 739.615269   |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 56        | 752.172809   |</pre>"
      ],
      "text/plain": [
       "| 56        | 752.172809   |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 57        | 766.675121   |</pre>"
      ],
      "text/plain": [
       "| 57        | 766.675121   |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 58        | 780.697944   |</pre>"
      ],
      "text/plain": [
       "| 58        | 780.697944   |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 59        | 793.244652   |</pre>"
      ],
      "text/plain": [
       "| 59        | 793.244652   |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 60        | 806.650873   |</pre>"
      ],
      "text/plain": [
       "| 60        | 806.650873   |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 61        | 821.317556   |</pre>"
      ],
      "text/plain": [
       "| 61        | 821.317556   |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 62        | 834.970676   |</pre>"
      ],
      "text/plain": [
       "| 62        | 834.970676   |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 63        | 849.611049   |</pre>"
      ],
      "text/plain": [
       "| 63        | 849.611049   |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 64        | 862.417701   |</pre>"
      ],
      "text/plain": [
       "| 64        | 862.417701   |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 65        | 877.595408   |</pre>"
      ],
      "text/plain": [
       "| 65        | 877.595408   |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 66        | 892.148190   |</pre>"
      ],
      "text/plain": [
       "| 66        | 892.148190   |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 67        | 906.650102   |</pre>"
      ],
      "text/plain": [
       "| 67        | 906.650102   |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 68        | 920.640433   |</pre>"
      ],
      "text/plain": [
       "| 68        | 920.640433   |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 69        | 933.729070   |</pre>"
      ],
      "text/plain": [
       "| 69        | 933.729070   |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 70        | 948.115723   |</pre>"
      ],
      "text/plain": [
       "| 70        | 948.115723   |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 71        | 961.598898   |</pre>"
      ],
      "text/plain": [
       "| 71        | 961.598898   |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 72        | 975.548928   |</pre>"
      ],
      "text/plain": [
       "| 72        | 975.548928   |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 73        | 989.291447   |</pre>"
      ],
      "text/plain": [
       "| 73        | 989.291447   |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 74        | 1003.219904  |</pre>"
      ],
      "text/plain": [
       "| 74        | 1003.219904  |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 75        | 1016.428951  |</pre>"
      ],
      "text/plain": [
       "| 75        | 1016.428951  |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 76        | 1030.287595  |</pre>"
      ],
      "text/plain": [
       "| 76        | 1030.287595  |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 77        | 1045.436767  |</pre>"
      ],
      "text/plain": [
       "| 77        | 1045.436767  |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 78        | 1059.339728  |</pre>"
      ],
      "text/plain": [
       "| 78        | 1059.339728  |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 79        | 1073.496082  |</pre>"
      ],
      "text/plain": [
       "| 79        | 1073.496082  |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 80        | 1086.409107  |</pre>"
      ],
      "text/plain": [
       "| 80        | 1086.409107  |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 81        | 1099.188607  |</pre>"
      ],
      "text/plain": [
       "| 81        | 1099.188607  |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 82        | 1113.347532  |</pre>"
      ],
      "text/plain": [
       "| 82        | 1113.347532  |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 83        | 1127.294556  |</pre>"
      ],
      "text/plain": [
       "| 83        | 1127.294556  |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 84        | 1141.002714  |</pre>"
      ],
      "text/plain": [
       "| 84        | 1141.002714  |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 85        | 1154.802435  |</pre>"
      ],
      "text/plain": [
       "| 85        | 1154.802435  |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 86        | 1168.345914  |</pre>"
      ],
      "text/plain": [
       "| 86        | 1168.345914  |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 87        | 1181.940116  |</pre>"
      ],
      "text/plain": [
       "| 87        | 1181.940116  |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 88        | 1194.822101  |</pre>"
      ],
      "text/plain": [
       "| 88        | 1194.822101  |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 89        | 1209.080555  |</pre>"
      ],
      "text/plain": [
       "| 89        | 1209.080555  |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 90        | 1222.928234  |</pre>"
      ],
      "text/plain": [
       "| 90        | 1222.928234  |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 91        | 1237.935808  |</pre>"
      ],
      "text/plain": [
       "| 91        | 1237.935808  |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 92        | 1252.360457  |</pre>"
      ],
      "text/plain": [
       "| 92        | 1252.360457  |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 93        | 1266.791796  |</pre>"
      ],
      "text/plain": [
       "| 93        | 1266.791796  |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 94        | 1279.795210  |</pre>"
      ],
      "text/plain": [
       "| 94        | 1279.795210  |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 95        | 1294.519571  |</pre>"
      ],
      "text/plain": [
       "| 95        | 1294.519571  |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 96        | 1305.851979  |</pre>"
      ],
      "text/plain": [
       "| 96        | 1305.851979  |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 97        | 1319.462815  |</pre>"
      ],
      "text/plain": [
       "| 97        | 1319.462815  |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 98        | 1333.963521  |</pre>"
      ],
      "text/plain": [
       "| 98        | 1333.963521  |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 99        | 1347.875469  |</pre>"
      ],
      "text/plain": [
       "| 99        | 1347.875469  |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 100       | 1362.430618  |</pre>"
      ],
      "text/plain": [
       "| 100       | 1362.430618  |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>+-----------+--------------+</pre>"
      ],
      "text/plain": [
       "+-----------+--------------+"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "best_model =  random_forest_classifier.create(dataset=data[[col for col in data.column_names() \\\n",
    "                                    if not('EPIDEMIC' in col) and col !='USER']],\n",
    "                                             validation_set = 'auto',\n",
    "                                             **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\"><table frame=\"box\" rules=\"cols\">\n",
       "    <tr>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">name</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">index</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">COUNT_0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">MOBILITY_DIAMETER</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">MOBILITY_DIAMETER_WEEKNIG<br>HT ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">CallsWeekDay_IN_08</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">COUNT_WEEKNIGHT_0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">CallsWeekDay_OUT_08</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">COUNT_1</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">CallsWeekDay_OUT_12</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">CallsWeekDay_OUT_VUL_09</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">CallsWeekDay_IN_VUL_08</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">207</td>\n",
       "    </tr>\n",
       "</table>\n",
       "[82784 rows x 3 columns]<br/>Note: Only the head of the SFrame is printed.<br/>You can use print_rows(num_rows=m, num_columns=n) to print more rows and columns.\n",
       "</div>"
      ],
      "text/plain": [
       "Columns:\n",
       "\tname\tstr\n",
       "\tindex\tstr\n",
       "\tcount\tint\n",
       "\n",
       "Rows: 82784\n",
       "\n",
       "Data:\n",
       "+-----------------------------+-------+-------+\n",
       "|             name            | index | count |\n",
       "+-----------------------------+-------+-------+\n",
       "|           COUNT_0           |  None |  536  |\n",
       "|      MOBILITY_DIAMETER      |  None |  495  |\n",
       "| MOBILITY_DIAMETER_WEEKNIGHT |  None |  479  |\n",
       "|      CallsWeekDay_IN_08     |  None |  288  |\n",
       "|      COUNT_WEEKNIGHT_0      |  None |  283  |\n",
       "|     CallsWeekDay_OUT_08     |  None |  236  |\n",
       "|           COUNT_1           |  None |  222  |\n",
       "|     CallsWeekDay_OUT_12     |  None |  217  |\n",
       "|   CallsWeekDay_OUT_VUL_09   |  None |  211  |\n",
       "|    CallsWeekDay_IN_VUL_08   |  None |  207  |\n",
       "+-----------------------------+-------+-------+\n",
       "[82784 rows x 3 columns]\n",
       "Note: Only the head of the SFrame is printed.\n",
       "You can use print_rows(num_rows=m, num_columns=n) to print more rows and columns."
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_feat = best_model.get_feature_importance()\n",
    "best_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1362.4314"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.training_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 2s, sys: 1.51 s, total: 2min 4s\n",
      "Wall time: 24.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "test_error = best_model.evaluate(val_set[[col for col in data.column_names() \\\n",
    "                                    if not('EPIDEMIC' in col) and col !='USER']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.9317004292153799,\n",
       " 'auc': 0.8479283597887244,\n",
       " 'confusion_matrix': Columns:\n",
       " \ttarget_label\tint\n",
       " \tpredicted_label\tint\n",
       " \tcount\tint\n",
       " \n",
       " Rows: 8\n",
       " \n",
       " Data:\n",
       " +--------------+-----------------+--------+\n",
       " | target_label | predicted_label | count  |\n",
       " +--------------+-----------------+--------+\n",
       " |      2       |        3        |  2145  |\n",
       " |      1       |        3        |  2697  |\n",
       " |      1       |        0        |  3664  |\n",
       " |      3       |        3        | 103670 |\n",
       " |      3       |        0        | 12155  |\n",
       " |      2       |        0        |  2752  |\n",
       " |      0       |        3        |  7012  |\n",
       " |      0       |        0        | 311369 |\n",
       " +--------------+-----------------+--------+\n",
       " [8 rows x 3 columns],\n",
       " 'f1_score': 0.464190333713697,\n",
       " 'log_loss': 1.2443176674986582,\n",
       " 'precision': 0.9205516478410865,\n",
       " 'recall': 0.46825831776309357,\n",
       " 'roc_curve': Columns:\n",
       " \tthreshold\tfloat\n",
       " \tfpr\tfloat\n",
       " \ttpr\tfloat\n",
       " \tp\tint\n",
       " \tn\tint\n",
       " \tclass\tint\n",
       " \n",
       " Rows: 400004\n",
       " \n",
       " Data:\n",
       " +-----------+-----+-----+--------+--------+-------+\n",
       " | threshold | fpr | tpr |   p    |   n    | class |\n",
       " +-----------+-----+-----+--------+--------+-------+\n",
       " |    0.0    | 1.0 | 1.0 | 318381 | 127083 |   0   |\n",
       " |   1e-05   | 1.0 | 1.0 | 318381 | 127083 |   0   |\n",
       " |   2e-05   | 1.0 | 1.0 | 318381 | 127083 |   0   |\n",
       " |   3e-05   | 1.0 | 1.0 | 318381 | 127083 |   0   |\n",
       " |   4e-05   | 1.0 | 1.0 | 318381 | 127083 |   0   |\n",
       " |   5e-05   | 1.0 | 1.0 | 318381 | 127083 |   0   |\n",
       " |   6e-05   | 1.0 | 1.0 | 318381 | 127083 |   0   |\n",
       " |   7e-05   | 1.0 | 1.0 | 318381 | 127083 |   0   |\n",
       " |   8e-05   | 1.0 | 1.0 | 318381 | 127083 |   0   |\n",
       " |   9e-05   | 1.0 | 1.0 | 318381 | 127083 |   0   |\n",
       " +-----------+-----+-----+--------+--------+-------+\n",
       " [400004 rows x 6 columns]\n",
       " Note: Only the head of the SFrame is printed.\n",
       " You can use print_rows(num_rows=m, num_columns=n) to print more rows and columns.}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "roc_auc_score(Y_val,clf2.predict(X_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Results\n",
    "\n",
    "* bootstrap  ???= False es 5% mejor\n",
    "* min_samples_leaf ????= mas chico es claramente mejor, pero tmb aumenta el overfitting lo cual me hace caer mucho el valor del recall en el test_set. Sin embargo es un parametro muy sensible en la precision. Resta evaluar asi el tradeoff entre la precision y el volumen de users al cual queremos llegar.\n",
    "* n_estimators ???= mas pareceria mejor, pero depende del app y hay que ver 'cuanto' mejora por app\n",
    "* citerion ???= entropy o gini no cambia. gini podria ser mejor entonces pues entropy usa logs de los valores lo cual es mas computacionalmente costoso\n",
    "* max_features ???= no afecta al score. con auto esta bien\n",
    "* max_depth ??=  mas es mejor. intentaria probar con >15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# full graphlab models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROGRESS: Creating a validation set from 5 percent of training data. This may take a while.\n",
      "          You can set ``validation_set=None`` to disable validation tracking.\n",
      "\n",
      "PROGRESS: The following methods are available for this type of problem.\n",
      "PROGRESS: LogisticClassifier, SVMClassifier\n",
      "PROGRESS: The returned model will be chosen according to validation accuracy.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Logistic regression:</pre>"
      ],
      "text/plain": [
       "Logistic regression:"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>--------------------------------------------------------</pre>"
      ],
      "text/plain": [
       "--------------------------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of examples          : 985960</pre>"
      ],
      "text/plain": [
       "Number of examples          : 985960"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of classes           : 2</pre>"
      ],
      "text/plain": [
       "Number of classes           : 2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of feature columns   : 173</pre>"
      ],
      "text/plain": [
       "Number of feature columns   : 173"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of unpacked features : 173</pre>"
      ],
      "text/plain": [
       "Number of unpacked features : 173"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of coefficients    : 82760</pre>"
      ],
      "text/plain": [
       "Number of coefficients    : 82760"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Starting L-BFGS</pre>"
      ],
      "text/plain": [
       "Starting L-BFGS"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>--------------------------------------------------------</pre>"
      ],
      "text/plain": [
       "--------------------------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>+-----------+----------+-----------+--------------+-------------------+---------------------+</pre>"
      ],
      "text/plain": [
       "+-----------+----------+-----------+--------------+-------------------+---------------------+"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| Iteration | Passes   | Step size | Elapsed Time | Training-accuracy | Validation-accuracy |</pre>"
      ],
      "text/plain": [
       "| Iteration | Passes   | Step size | Elapsed Time | Training-accuracy | Validation-accuracy |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>+-----------+----------+-----------+--------------+-------------------+---------------------+</pre>"
      ],
      "text/plain": [
       "+-----------+----------+-----------+--------------+-------------------+---------------------+"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 1         | 3        | 0.000001  | 5.709029     | 0.971716          | 0.971601            |</pre>"
      ],
      "text/plain": [
       "| 1         | 3        | 0.000001  | 5.709029     | 0.971716          | 0.971601            |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 2         | 6        | 5.000000  | 12.649990    | 0.976638          | 0.975090            |</pre>"
      ],
      "text/plain": [
       "| 2         | 6        | 5.000000  | 12.649990    | 0.976638          | 0.975090            |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>+-----------+----------+-----------+--------------+-------------------+---------------------+</pre>"
      ],
      "text/plain": [
       "+-----------+----------+-----------+--------------+-------------------+---------------------+"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>TERMINATED: Terminated due to numerical difficulties.</pre>"
      ],
      "text/plain": [
       "TERMINATED: Terminated due to numerical difficulties."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>This model may not be ideal. To improve it, consider doing one of the following:\n",
       "(a) Increasing the regularization.\n",
       "(b) Standardizing the input data.\n",
       "(c) Removing highly correlated features.\n",
       "(d) Removing `inf` and `NaN` values in the training data.</pre>"
      ],
      "text/plain": [
       "This model may not be ideal. To improve it, consider doing one of the following:\n",
       "(a) Increasing the regularization.\n",
       "(b) Standardizing the input data.\n",
       "(c) Removing highly correlated features.\n",
       "(d) Removing `inf` and `NaN` values in the training data."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>SVM:</pre>"
      ],
      "text/plain": [
       "SVM:"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>--------------------------------------------------------</pre>"
      ],
      "text/plain": [
       "--------------------------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of examples          : 985960</pre>"
      ],
      "text/plain": [
       "Number of examples          : 985960"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of classes           : 2</pre>"
      ],
      "text/plain": [
       "Number of classes           : 2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of feature columns   : 173</pre>"
      ],
      "text/plain": [
       "Number of feature columns   : 173"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of unpacked features : 173</pre>"
      ],
      "text/plain": [
       "Number of unpacked features : 173"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of coefficients    : 82760</pre>"
      ],
      "text/plain": [
       "Number of coefficients    : 82760"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Starting L-BFGS</pre>"
      ],
      "text/plain": [
       "Starting L-BFGS"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>--------------------------------------------------------</pre>"
      ],
      "text/plain": [
       "--------------------------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>+-----------+----------+-----------+--------------+-------------------+---------------------+</pre>"
      ],
      "text/plain": [
       "+-----------+----------+-----------+--------------+-------------------+---------------------+"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| Iteration | Passes   | Step size | Elapsed Time | Training-accuracy | Validation-accuracy |</pre>"
      ],
      "text/plain": [
       "| Iteration | Passes   | Step size | Elapsed Time | Training-accuracy | Validation-accuracy |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>+-----------+----------+-----------+--------------+-------------------+---------------------+</pre>"
      ],
      "text/plain": [
       "+-----------+----------+-----------+--------------+-------------------+---------------------+"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 1         | 3        | 0.000001  | 5.522722     | 0.971716          | 0.971601            |</pre>"
      ],
      "text/plain": [
       "| 1         | 3        | 0.000001  | 5.522722     | 0.971716          | 0.971601            |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 2         | 7        | 21.000000 | 14.133741    | 0.972610          | 0.970399            |</pre>"
      ],
      "text/plain": [
       "| 2         | 7        | 21.000000 | 14.133741    | 0.972610          | 0.970399            |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 3         | 8        | 21.000000 | 17.156733    | 0.286318          | 0.286047            |</pre>"
      ],
      "text/plain": [
       "| 3         | 8        | 21.000000 | 17.156733    | 0.286318          | 0.286047            |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 4         | 10       | 1.000000  | 22.099915    | 0.971957          | 0.967336            |</pre>"
      ],
      "text/plain": [
       "| 4         | 10       | 1.000000  | 22.099915    | 0.971957          | 0.967336            |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 5         | 11       | 1.000000  | 25.136663    | 0.981763          | 0.977164            |</pre>"
      ],
      "text/plain": [
       "| 5         | 11       | 1.000000  | 25.136663    | 0.981763          | 0.977164            |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 6         | 12       | 1.000000  | 28.153698    | 0.982983          | 0.977300            |</pre>"
      ],
      "text/plain": [
       "| 6         | 12       | 1.000000  | 28.153698    | 0.982983          | 0.977300            |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 7         | 13       | 1.000000  | 31.172733    | 0.748879          | 0.737913            |</pre>"
      ],
      "text/plain": [
       "| 7         | 13       | 1.000000  | 31.172733    | 0.748879          | 0.737913            |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 8         | 15       | 1.000000  | 35.997210    | 0.983593          | 0.977126            |</pre>"
      ],
      "text/plain": [
       "| 8         | 15       | 1.000000  | 35.997210    | 0.983593          | 0.977126            |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 9         | 16       | 1.000000  | 39.048794    | 0.984053          | 0.976796            |</pre>"
      ],
      "text/plain": [
       "| 9         | 16       | 1.000000  | 39.048794    | 0.984053          | 0.976796            |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 10        | 17       | 1.000000  | 42.004133    | 0.589961          | 0.580371            |</pre>"
      ],
      "text/plain": [
       "| 10        | 17       | 1.000000  | 42.004133    | 0.589961          | 0.580371            |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>+-----------+----------+-----------+--------------+-------------------+---------------------+</pre>"
      ],
      "text/plain": [
       "+-----------+----------+-----------+--------------+-------------------+---------------------+"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>TERMINATED: Iteration limit reached.</pre>"
      ],
      "text/plain": [
       "TERMINATED: Iteration limit reached."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>This model may not be optimal. To improve it, consider increasing `max_iterations`.</pre>"
      ],
      "text/plain": [
       "This model may not be optimal. To improve it, consider increasing `max_iterations`."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROGRESS: Model selection based on validation accuracy:\n",
      "PROGRESS: ---------------------------------------------\n",
      "PROGRESS: LogisticClassifier              : 0.97509\n",
      "PROGRESS: SVMClassifier                   : 0.580371\n",
      "PROGRESS: ---------------------------------------------\n",
      "PROGRESS: Selecting LogisticClassifier based on validation set performance.\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Create the model\n",
    "model = gl.classifier.create(data, target = 'EPIDEMIC_gt',\n",
    "                              features = [col for col in data.column_names() if col != 'EPIDEMIC_gt' and col!= 'USER'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validamos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method LogisticClassifier.get_current_options of Class                         : LogisticClassifier\n",
       "\n",
       "Schema\n",
       "------\n",
       "Number of coefficients        : 82760\n",
       "Number of examples            : 985960\n",
       "Number of classes             : 2\n",
       "Number of feature columns     : 173\n",
       "Number of unpacked features   : 173\n",
       "\n",
       "Hyperparameters\n",
       "---------------\n",
       "L1 penalty                    : 0\n",
       "L2 penalty                    : 0.01\n",
       "\n",
       "Training Summary\n",
       "----------------\n",
       "Solver                        : lbfgs\n",
       "Solver iterations             : 2\n",
       "Solver status                 : TERMINATED: Terminated due to numerical difficulties.\n",
       "Training time (sec)           : 15.7768\n",
       "\n",
       "Settings\n",
       "--------\n",
       "Log-likelihood                : inf\n",
       "\n",
       "Highest Positive Coefficients\n",
       "-----------------------------\n",
       "ANTENNA_ID_WEEKNIGHT_7[1081]  : 89.8181\n",
       "ANTENNA_ID_WEEKNIGHT_9[3195]  : 89.8181\n",
       "ANTENNA_ID_WEEKNIGHT_8[1116]  : 88.2713\n",
       "ANTENNA_ID_WEEKNIGHT_1[99]    : 87.7119\n",
       "ANTENNA_ID_WEEKNIGHT_1[244]   : 87.1922\n",
       "\n",
       "Lowest Negative Coefficients\n",
       "----------------------------\n",
       "ANTENNA_ID_WEEKNIGHT_9[1944]  : -83.8405\n",
       "ANTENNA_ID_WEEKNIGHT_1[2723]  : -74.3549\n",
       "ANTENNA_ID_WEEKNIGHT_0[3781]  : -56.7068\n",
       "ANTENNA_ID_4[2914]            : -54.1268\n",
       "ANTENNA_ID_WEEKNIGHT_9[1716]  : -49.0394\n",
       ">"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_current_options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 24s, sys: 15.4 s, total: 2min 39s\n",
      "Wall time: 18.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "classification = model.classify(val_set)\n",
    "results = model.evaluate(val_set)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method LogisticClassifier.get_current_options of Class                         : LogisticClassifier\n",
       "\n",
       "Schema\n",
       "------\n",
       "Number of coefficients        : 1068253\n",
       "Number of examples            : 985503\n",
       "Number of classes             : 2\n",
       "Number of feature columns     : 174\n",
       "Number of unpacked features   : 174\n",
       "\n",
       "Hyperparameters\n",
       "---------------\n",
       "L1 penalty                    : 0\n",
       "L2 penalty                    : 0.01\n",
       "\n",
       "Training Summary\n",
       "----------------\n",
       "Solver                        : lbfgs\n",
       "Solver iterations             : 10\n",
       "Solver status                 : TERMINATED: Iteration limit reached.\n",
       "Training time (sec)           : 45.6194\n",
       "\n",
       "Settings\n",
       "--------\n",
       "Log-likelihood                : 279.9326\n",
       "\n",
       "Highest Positive Coefficients\n",
       "-----------------------------\n",
       "USER[AC571EA92E8F687BE672AF55FAC1EAD3]: 162.6371\n",
       "USER[6EFBFA6AC99A85C7DA609A6F9D6014F6]: 143.8373\n",
       "USER[2F5E433CAEBB38733143D0A8EB5E4EB2]: 66.9896\n",
       "USER[2321510F75A59BD796D0DBD1CBC13D9B]: 66.571\n",
       "USER[D9AC206F61422B357DBEBC95AC894CE2]: 55.8497\n",
       "\n",
       "Lowest Negative Coefficients\n",
       "----------------------------\n",
       "USER[24C21C84041B744564AB86A8E317CA58]: -76.9511\n",
       "USER[D913D8F2E16BA1CD5DB498F214B62007]: -37.5017\n",
       "USER[4D8107DAE6F2902C834EE88045FACBEF]: -32.0522\n",
       "USER[D2E794DB226863CB59CEB994F371CDEB]: -31.9837\n",
       "USER[8DFEB85635D652C5E731B6B82921AE8F]: -31.8566\n",
       ">"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_current_options"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# En particular queremos ver que tan bien nos va con los users\n",
    "\n",
    "que eran == 0 en el hoy\n",
    "\n",
    "y eran == 1 en el pasado\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de usuarios que migraron son 6361\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.3280930671278101, 'auc': 0.0, 'confusion_matrix': Columns:\n",
       " \ttarget_label\tint\n",
       " \tpredicted_label\tint\n",
       " \tcount\tint\n",
       " \n",
       " Rows: 2\n",
       " \n",
       " Data:\n",
       " +--------------+-----------------+-------+\n",
       " | target_label | predicted_label | count |\n",
       " +--------------+-----------------+-------+\n",
       " |      1       |        1        |  2087 |\n",
       " |      1       |        0        |  4274 |\n",
       " +--------------+-----------------+-------+\n",
       " [2 rows x 3 columns], 'f1_score': 0.4940814393939394, 'log_loss': 3.952783379671028, 'precision': 1.0, 'recall': 0.3280930671278101, 'roc_curve': Columns:\n",
       " \tthreshold\tfloat\n",
       " \tfpr\tfloat\n",
       " \ttpr\tfloat\n",
       " \tp\tint\n",
       " \tn\tint\n",
       " \n",
       " Rows: 100001\n",
       " \n",
       " Data:\n",
       " +-----------+-----+----------------+------+---+\n",
       " | threshold | fpr |      tpr       |  p   | n |\n",
       " +-----------+-----+----------------+------+---+\n",
       " |    0.0    | nan |      1.0       | 6361 | 0 |\n",
       " |   1e-05   | nan | 0.970444898601 | 6361 | 0 |\n",
       " |   2e-05   | nan | 0.957868259708 | 6361 | 0 |\n",
       " |   3e-05   | nan | 0.946234868731 | 6361 | 0 |\n",
       " |   4e-05   | nan | 0.937116805534 | 6361 | 0 |\n",
       " |   5e-05   | nan | 0.928313158308 | 6361 | 0 |\n",
       " |   6e-05   | nan | 0.919195095111 | 6361 | 0 |\n",
       " |   7e-05   | nan | 0.913221191637 | 6361 | 0 |\n",
       " |   8e-05   | nan | 0.906618456218 | 6361 | 0 |\n",
       " |   9e-05   | nan | 0.901902216633 | 6361 | 0 |\n",
       " +-----------+-----+----------------+------+---+\n",
       " [100001 rows x 5 columns]\n",
       " Note: Only the head of the SFrame is printed.\n",
       " You can use print_rows(num_rows=m, num_columns=n) to print more rows and columns.}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "special_val = val_set[(val_set['EPIDEMIC_gt'] == 1) & (val_set['EPIDEMIC'] == 0)]\n",
    "print('Cantidad de usuarios que migraron son %s' %special_val.shape[0])\n",
    "results = model.evaluate(special_val)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# por las dudas chequeo las correlaciones de la matriz a ver si algun feature \"ES\" el ground_truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 18s, sys: 1.66 s, total: 1min 20s\n",
      "Wall time: 1min 20s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# paso a pandas\n",
    "X = val_set.to_dataframe()\n",
    "corr_matrix = X.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], Name: EPIDEMIC_gt, dtype: float64)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chequeamos correlacion especificamente con el target/gt\n",
    "corr_cut = 0.5\n",
    "corr_matrix[(corr_matrix['EPIDEMIC_gt']>corr_cut) | corr_matrix['EPIDEMIC_gt']<-corr_cut]['EPIDEMIC_gt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(154, 154)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# notar que en la primera corrida\n",
    "el algoritmo esta hecho tomando como GT  data desde enero 2015 a julio 2015\n",
    "\n",
    "Luego la correlacion con el GT 'decae\" a medida que los meses del train_table se alejan de esta fecha (empeora en direccion a 12 que es diciembre)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8 ms, sys: 4 ms, total: 12 ms\n",
      "Wall time: 134 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#lo paso a una serie\n",
    "corr_series = abs(corr_matrix).unstack()\n",
    "#ordeno por los valores mas altos\n",
    "corr_series = corr_series.sort_values(ascending = False) \n",
    "#es obvio que la diagonal tenia correlacion ==1, asi que elimino aquellos valores que eran de la diagonal\n",
    "#tambien saco los valores que estan \"arriba\" de la diagonal, pero haciendo la comparacion entre strings\n",
    "corr_series = corr_series[(corr_series.index.get_level_values(0) != corr_series.index.get_level_values(1))\\\n",
    "                         & (corr_series.index.get_level_values(0) <= corr_series.index.get_level_values(1))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "COUNT_8            COUNT_9              0.981473\n",
       "COUNT_7            COUNT_8              0.976586\n",
       "COUNT_WEEKNIGHT_8  COUNT_WEEKNIGHT_9    0.969355\n",
       "COUNT_6            COUNT_7              0.968488\n",
       "COUNT_WEEKNIGHT_7  COUNT_WEEKNIGHT_8    0.968116\n",
       "COUNT_WEEKNIGHT_6  COUNT_WEEKNIGHT_7    0.963660\n",
       "COUNT_5            COUNT_6              0.957804\n",
       "COUNT_7            COUNT_9              0.956372\n",
       "COUNT_WEEKNIGHT_5  COUNT_WEEKNIGHT_6    0.955928\n",
       "EPIDEMIC           EPIDEMIC_gt          0.943801\n",
       "COUNT_6            COUNT_8              0.943118\n",
       "COUNT_WEEKNIGHT_7  COUNT_WEEKNIGHT_9    0.942522\n",
       "COUNT_WEEKNIGHT_4  COUNT_WEEKNIGHT_5    0.940706\n",
       "COUNT_4            COUNT_5              0.939109\n",
       "COUNT_WEEKNIGHT_6  COUNT_WEEKNIGHT_8    0.935862\n",
       "dtype: float64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_series.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A partir de aca, todo lo que esta abajo es viejo. Queda a revisar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 41.5 s, sys: 6.67 s, total: 48.1 s\n",
      "Wall time: 48.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# miramos ahora las columnas con poca varianza ie. que aportan poca info\n",
    "\n",
    "var_matrix = X_train.var()\n",
    "#imprimimos aquellas que esten por abajo de cierto percentil\n",
    "perc = 0.5\n",
    "var_matrix[var_matrix<perc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# como resultado de esto decidimos dropear las columnas, por poca varianza..\n",
    "# [ EXPOSED ]\n",
    "X_train.drop('EXPOSED',axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/juan/miniconda2/lib/python2.7/site-packages/pandas/core/generic.py:2569: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "  locs = rs.choice(axis_length, size=n, replace=replace, p=weights)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 19 s, sys: 7.15 s, total: 26.1 s\n",
      "Wall time: 9.82 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#con decomposicion qr tratamos de ver si existe alguna columna que sea comb linear de las demas\n",
    "linear_test = np.linalg.qr(X_train.sample(1e6))[1]\n",
    "#notar que devuelve la tabla de tamanyo N`columnas x Ncolumnas\n",
    "\n",
    "#sumo a traves de las columnas para que me de el valor absoluto sumado de c/fila\n",
    "linear_test = abs(linear_test.sum(axis=1))<1e-2\n",
    "#si hubiese alguan que sea linearcomb entonces tendria que aparecer que toda la fila es de ceros\n",
    "for i, col in enumerate(X_train.columns):\n",
    "    if linear_test[i] == True:\n",
    "        print(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First Simple Classification Tests\n",
    "La idea es probar tres clasificadores basicos y tener una medida de precision, recall, F1-score p/c/ estimador:\n",
    "\n",
    "* **Clasificador 1**: con la proporción de gente que vive en la zona endémica en el \"presente\", asignar la gente al azar respetando esa proporción i.e. $X \\sim Bernoulli(\\hat{p}) s.t. p$ is the mean of endemic users in the dataset\n",
    "\n",
    "* **Clasificador 2**: usando la información del \"presente\", si la persona vive en la zona endémica en el presente, predecir que va a ocurrir lo mismo en el \"pasado\" i.e. un estimador que devuelve el feature de endemicidad actual para predecir la endemicidad en el pasado.\n",
    "\n",
    "\n",
    "* **Clasificador 3**: usar 2 features del \"presente\", (i) si la persona vive en la zona endémica, (ii) cual es la proporción de sus contactos que viven en la zona endémica."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clf 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/juan/mobility-study/scikit-learn/sklearn/externals/joblib/_multiprocessing_helpers.py:29: UserWarning: [Errno 38] Function not implemented.  joblib will operate in serial mode\n",
      "  warnings.warn('%s.  joblib will operate in serial mode' % (e,))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import *\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p_hat = X_train['EPIDEMIC'].mean()\n",
    "#the output vector, i.e. the estimated epidemic users\n",
    "y_hat = stats.bernoulli.rvs(p_hat, size=len(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A priori probability of bein epidemic is 0.293362195887\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.7065    0.7061    0.7063   1413371\n",
      "          1     0.2931    0.2935    0.2933    586914\n",
      "\n",
      "avg / total     0.5852    0.5850    0.5851   2000285\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"A priori probability of bein epidemic is %s\" %p_hat)\n",
    "print(classification_report(X_train['y'], y_hat ,digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clf 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(586808, (2000285,), 586914)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train['EPIDEMIC'].sum(),X_train['EPIDEMIC'].shape , X_train['y'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1173263"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(X_train['y'] == X_train['EPIDEMIC']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    1413477\n",
       "True      586808\n",
       "Name: EPIDEMIC, dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train['EPIDEMIC'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No group keys passed!",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-48-1152f636d99e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m table = X_train.pivot_table(['EPIDEMIC', 'y'],\n\u001b[1;32m----> 2\u001b[1;33m                                    aggfunc=np.sum)\n\u001b[0m",
      "\u001b[1;32m/home/juan/miniconda2/lib/python2.7/site-packages/pandas/tools/pivot.pyc\u001b[0m in \u001b[0;36mpivot_table\u001b[1;34m(data, values, index, columns, aggfunc, fill_value, margins, dropna, margins_name)\u001b[0m\n\u001b[0;32m    118\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mto_filter\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 120\u001b[1;33m     \u001b[0mgrouped\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    121\u001b[0m     \u001b[0magged\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgrouped\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0magg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maggfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/juan/miniconda2/lib/python2.7/site-packages/pandas/core/generic.pyc\u001b[0m in \u001b[0;36mgroupby\u001b[1;34m(self, by, axis, level, as_index, sort, group_keys, squeeze)\u001b[0m\n\u001b[0;32m   3746\u001b[0m         \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_axis_number\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3747\u001b[0m         return groupby(self, by=by, axis=axis, level=level, as_index=as_index,\n\u001b[1;32m-> 3748\u001b[1;33m                        sort=sort, group_keys=group_keys, squeeze=squeeze)\n\u001b[0m\u001b[0;32m   3749\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3750\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0masfreq\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfreq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/juan/miniconda2/lib/python2.7/site-packages/pandas/core/groupby.pyc\u001b[0m in \u001b[0;36mgroupby\u001b[1;34m(obj, by, **kwds)\u001b[0m\n\u001b[0;32m   1426\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'invalid type: %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1427\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1428\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mklass\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mby\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1429\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1430\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/juan/miniconda2/lib/python2.7/site-packages/pandas/core/groupby.pyc\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, obj, keys, axis, level, grouper, exclusions, selection, as_index, sort, group_keys, squeeze)\u001b[0m\n\u001b[0;32m    343\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mgrouper\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m             grouper, exclusions, obj = _get_grouper(obj, keys, axis=axis,\n\u001b[1;32m--> 345\u001b[1;33m                                                     level=level, sort=sort)\n\u001b[0m\u001b[0;32m    346\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    347\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/juan/miniconda2/lib/python2.7/site-packages/pandas/core/groupby.pyc\u001b[0m in \u001b[0;36m_get_grouper\u001b[1;34m(obj, key, axis, level, sort)\u001b[0m\n\u001b[0;32m   2420\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2421\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgroupings\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2422\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'No group keys passed!'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2423\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2424\u001b[0m     \u001b[1;31m# create the internals grouper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: No group keys passed!"
     ]
    }
   ],
   "source": [
    "table = X_train.pivot_table(['EPIDEMIC', 'y'],\n",
    "                                   aggfunc=np.sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train.pivot_table(values=)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('bool')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train['EPIDEMIC'].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1413371\n",
       "1     586914\n",
       "Name: y, dtype: int64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train['y'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False     1.0000    1.0000    1.0000   1413477\n",
      "       True     1.0000    1.0000    1.0000    586808\n",
      "\n",
      "avg / total     1.0000    1.0000    1.0000   2000285\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_hat = X_train['EPIDEMIC'].values\n",
    "\n",
    "print(classification_report(y_target, y_hat, digits=4 ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clf 3\n",
    "adf\n",
    "\n",
    "adsf\n",
    "\n",
    "asdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('number of users who are and have been epidemic is 1171065',\n",
       " 'dataset size is 2000285')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'number of users who are and have been epidemic is %s'% (X_train['EPIDEMIC'].values == y_target).sum(), \"dataset size is %s\" % len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross, test, train splt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.46 s, sys: 544 ms, total: 2.01 s\n",
      "Wall time: 2.05 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#parto efectivamente el dataset en 3 conjunots, uno para fitear todo. otro para entrenar+transform y el ultimo\n",
    "#para transform +val\n",
    "msk = np.random.rand(len(X_train)) < 0.3333\n",
    "X_fit = X_train[msk]\n",
    "X_train =  X_train[~msk]\n",
    "msk2 = np.random.rand(len(X_train)) < 0.5\n",
    "X_val =  X_train[msk2]\n",
    "X_train =  X_train[~msk2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count Featurizer on Antennas\n",
    "nos quedamos con las columnas de antennas y en graphlab aplicamos el algo de CountFeaturizer para cada categoria de\n",
    "Antenna_ID_N\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A newer version of GraphLab Create (v1.10.1) is available! Your current version is v1.8.5.\n",
      "\n",
      "You can use pip to upgrade the graphlab-create package. For more information see https://dato.com/products/create/upgrade.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This non-commercial license of GraphLab Create is assigned to svega@dm.uba.ar and will expire on April 16, 2017. For commercial licensing options, visit https://dato.com/buy/.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2016-06-14 00:17:59,281 [INFO] graphlab.cython.cy_server, 176: GraphLab Create v1.8.5 started. Logging: /tmp/graphlab_server_1465863477.log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.21 s, sys: 1.51 s, total: 8.72 s\n",
      "Wall time: 7.14 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "## Count Featurizer on Antennas\n",
    "#nos quedamos con las columnas de antennas y pasamos todo a Graph Lab.\n",
    "import graphlab as gl\n",
    "from graphlab.toolkits.feature_engineering import *\n",
    "ant_cols = [col for col in X_train.columns if \"ANTENNA_ID\" in col]\n",
    "ant_sframe_fit = gl.SFrame(X_fit[ant_cols + ['y']])\n",
    "ant_sframe_train = gl.SFrame(X_train[ant_cols + ['y']])\n",
    "ant_sframe_val = gl.SFrame(X_val[ant_cols + ['y']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 58.6 s, sys: 8.91 s, total: 1min 7s\n",
      "Wall time: 37.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "countfeat = gl.feature_engineering.create(ant_sframe_fit, \n",
    "               CountFeaturizer(target='y'))\n",
    "\n",
    "# Transform the train set. This is the dataset I will train my classifier on\n",
    "transformed_ant_train = countfeat.transform(ant_sframe_train)\n",
    "transformed_ant_val = countfeat.transform(ant_sframe_val)\n",
    "\n",
    "del ant_sframe_fit,ant_sframe_train,ant_sframe_val\n",
    "\n",
    "#por alguna razon guarda los valores de probabilidad como una lista de un unico valor\n",
    "for col in [col for col in transformed_ant_train.column_names() if \"prob_\" in col]:\n",
    "    transformed_ant_train[col] = transformed_ant_train[col].apply(lambda x: x[0]) \n",
    "    transformed_ant_val[col] = transformed_ant_val[col].apply(lambda x: x[0]) \n",
    "\n",
    "#me quedo solo con los valores de probabilidad.\n",
    "transformed_ant_train = transformed_ant_train[[col for col in transformed_ant_train.column_names() if \"prob_\" in col]]\n",
    "transformed_ant_val = transformed_ant_val[[col for col in transformed_ant_train.column_names() if \"prob_\" in col]]\n",
    "\n",
    "transformed_ant_val = transformed_ant_val.to_dataframe()\n",
    "transformed_ant_train = transformed_ant_train.to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_val[ant_cols] = transformed_ant_val.values\n",
    "X_train[ant_cols] = transformed_ant_train.values\n",
    "del transformed_ant_train, transformed_ant_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scikit estimator fit and cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/juan/mobility-study/scikit-learn/sklearn/cross_validation.py:43: DeprecationWarning: This module has been deprecated in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/home/juan/mobility-study/scikit-learn/sklearn/grid_search.py:43: DeprecationWarning: This module has been deprecated in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import *\n",
    "#from sklearn.linear_model import *\n",
    "from sklearn.ensemble import *\n",
    "from sklearn.svm import *\n",
    "from sklearn.neural_network import *\n",
    "from sklearn.cross_validation import *\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.utils import *\n",
    "from sklearn.preprocessing import label_binarize, scale, StandardScaler\n",
    "from sklearn.metrics import *\n",
    "from sklearn.ensemble import *\n",
    "from sklearn.tree import *\n",
    "from sklearn.grid_search import *\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create new variables\n",
    "These would be more \"real\" variables i.e. variables that would be \"humanly\" explainable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'ANTENNA_ID_0', u'COUNT_0', u'ANTENNA_ID_1', u'COUNT_1',\n",
       "       u'ANTENNA_ID_2', u'COUNT_2', u'ANTENNA_ID_3', u'COUNT_3',\n",
       "       u'ANTENNA_ID_4', u'COUNT_4', u'ANTENNA_ID_5', u'COUNT_5',\n",
       "       u'ANTENNA_ID_6', u'COUNT_6', u'ANTENNA_ID_7', u'COUNT_7',\n",
       "       u'ANTENNA_ID_8', u'COUNT_8', u'ANTENNA_ID_9', u'COUNT_9',\n",
       "       u'MOBILITY_DIAMETER', u'EPIDEMIC', u'CallsWeekDaylight',\n",
       "       u'CallsWeekNight', u'CallsWeekend', u'TimeWeekDaylight',\n",
       "       u'TimeWeekNight', u'TimeWeekend', u'CallsWeekDaylight_EPI',\n",
       "       u'CallsWeekNight_EPI', u'CallsWeekend_EPI', u'TimeWeekDaylight_EPI',\n",
       "       u'TimeWeekNight_EPI', u'TimeWeekend_EPI', u'TOTAL_USERS', u'EPI_USERS',\n",
       "       u'EXP_USERS', u'y'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns\n",
    "#tenemos 38 cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create new features\n",
    "these would be \"synthetic\" variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_X_files(tables, scaled=False, poly2=False,train_size = 0.8):\n",
    "    #como input tiene que entrar la tabla sin splitea en train_test aun\n",
    "    #tiene que suceder que haya consistencia entre las columnas de c/dataframe tambien\n",
    "    \n",
    "    \n",
    "    calls_cols = [col for col in X_train.columns if \"Calls\" in col] \n",
    "    time_cols = [col for col in X_train.columns if \"Time\" in col]\n",
    "    epi_calls_cols = [col for col in X_train.columns if \"Calls\" in col and \"EPI\" in col] \n",
    "    epi_time_cols = [col for col in X_train.columns if \"Time\" in col and \"EPI\" in col]\n",
    "    antenna_cols = [col for col in X_train.columns if \"ANTENNA_\" in col]\n",
    "    count_cols = [col for col in X_train.columns if \"COUNT_\" in col]\n",
    "    condition_cols = [col for col in X_train.columns if \"EXPOSED\" == col or \"EPIDEMIC\" == col]\n",
    "    \n",
    "    categorical_cols = condition_cols\n",
    "    numerical_cols = [col for col in table.columns if col not in categorical_cols]\n",
    "\n",
    "    print(\"First dataframe is %s big\" % str(train_table.shape))\n",
    "    #print(\"Test dataframe is %s big\" % str(test_table.shape))\n",
    "    \n",
    "    X_train_categorical = train_table[categorical_cols].values\n",
    "    X_train_numeric = train_table[numeric_cols].values\n",
    "    \n",
    "    if scaled ==True :\n",
    "            min_max_scaler = MinMaxScaler().fit(X_train_count_time)\n",
    "            X_train_count_time = min_max_scaler.transform(X_train_numeric)\n",
    "    \n",
    "    #hacemos interacciones polinomiales sobre las columnas de count/time\n",
    "    if poly2 == True:\n",
    "        #pensar que hacer polynomial features es masomenos como agregar nˆ2 nuevas columnas\n",
    "        #con lo cual tenemos que tener cuidado en no reventar la memoria, ponemor las primeras 50 columnas \n",
    "        #como tope para aplicar interacciones polinomiales\n",
    "\n",
    "        poly2_transform = PolynomialFeatures(degree=2, interaction_only=False, include_bias=False)\n",
    "        max_cols = 50\n",
    "\n",
    "        if  (X_train_count_time.shape[1] <= max_cols):\n",
    "            max_cols = X_train_count_time.shape[1]\n",
    "        poly2_transform.fit(X_train_count_time[:,0:max_cols])\n",
    "\n",
    "        X_train_poly2 = poly2_transform.transform(X_train_count_time[:,0:max_cols])\n",
    "        X_train_count_time = np.concatenate( ( X_train_poly2, X_train_count_time[:,max_cols:]),axis=1) \n",
    "\n",
    "    X_train = np.concatenate( ( X_train_count_time, X_train_categorical),axis=1)\n",
    "    \n",
    "    processed_tables = [X_train]\n",
    "    \n",
    "    #aca basicamente replicamos lo anterior pero para todo el resto de las tablas y utilizando los fits que ya tenemos\n",
    "\n",
    "    for i in range(len(tables)):\n",
    "        # skip the X_train table which comes in the first postion and will behave as our special fitting table\n",
    "        if i ==0:\n",
    "            continue\n",
    "        print(i)\n",
    "        X_val_categorical = tables[i][categorical_cols].values\n",
    "        X_val_count_time = tables[i][count_time_cols].values\n",
    "\n",
    "        if scaled ==True :\n",
    "            X_val_count_time = min_max_scaler.transform(X_val_count_time)\n",
    "\n",
    "        #hacemos interacciones polinomiales sobre las columnas de count/time\n",
    "        if poly2 == True:\n",
    "            #pensar que hacer polynomial features es masomenos como agregar nˆ2 nuevas columnas\n",
    "            #con lo cual tenemos que tener cuidado en no reventar la memoria, ponemor las primeras 50 columnas \n",
    "            #como tope para aplicar interacciones polinomiales\n",
    "\n",
    "            X_val_poly2 = poly2_transform.transform(X_val_count_time[:,0:max_cols])\n",
    "            X_val_count_time = np.concatenate( ( X_val_poly2, X_val_count_time[:,max_cols:]),axis=1) \n",
    "\n",
    "        X_val = np.concatenate( ( X_val_count_time, X_val_categorical),axis=1)\n",
    "        \n",
    "        processed_tables = processed_tables + [X_val]\n",
    "    \n",
    "    for i in range(len(processed_tables)):    \n",
    "        print(\"Table {0} shape is {1}\".format( i,str(processed_tables[i].shape)))\n",
    "#        print(\"Table %s categorical shape is %s\" % str(X_val_categorical.shape))\n",
    "#        print(\"Val non-categorical shape is %s\" % str(X_val_count_time.shape))\n",
    "#        print(\"Val categorical shape is %s\" % str(X_val_categorical.shape))\n",
    "    \n",
    "    return processed_tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GradBoost model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-56-d11348c8b532>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m## seteo los generalizadores de CV\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m##genero los estimadores\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mW\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m15\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;31m#model = GradientBoostingClassifier()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'y' is not defined"
     ]
    }
   ],
   "source": [
    "## seteo los generalizadores de CV\n",
    "##genero los estimadores\n",
    "W = np.array([15 if i == 1 else 1 for i in y])\n",
    "#model = GradientBoostingClassifier()\n",
    "\n",
    "gradboost = GradientBoostingClassifier( loss = 'deviance',n_estimators=20, \n",
    "                                       max_depth = 20\n",
    "                                 )\n",
    "svc = LinearSVC(C=2.0, tol = 1e-4,\n",
    "                class_weight = 'balanced'\n",
    "               )\n",
    "\n",
    "svc2 = SVC(C=2.0, kernel = 'rbf' ,decision_function_shape='ovr',tol = 1e-5,\n",
    "                class_weight = 'balanced', max_iter = 1000\n",
    "               )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multinomial Naive Bayes - Benchmark - Cross Validation\n",
    "mnb es bastante rapido y eficiente para rapidamente resultados en problemas de clasificacion supervisada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n",
      "[CV] alpha=0, fit_prior=True .........................................\n",
      "[CV] ................ alpha=0, fit_prior=True, score=0.297282 -   2.9s\n",
      "[CV] alpha=0, fit_prior=True .........................................\n",
      "[CV] ................ alpha=0, fit_prior=True, score=0.294858 -   2.9s\n",
      "[CV] alpha=0, fit_prior=True .........................................\n",
      "[CV] ................ alpha=0, fit_prior=True, score=0.295935 -   2.9s\n",
      "[CV] alpha=0, fit_prior=False ........................................\n",
      "[CV] ............... alpha=0, fit_prior=False, score=0.297254 -   2.9s\n",
      "[CV] alpha=0, fit_prior=False ........................................\n",
      "[CV] ............... alpha=0, fit_prior=False, score=0.294880 -   2.9s\n",
      "[CV] alpha=0, fit_prior=False ........................................\n",
      "[CV] ............... alpha=0, fit_prior=False, score=0.295969 -   3.0s\n",
      "[CV] alpha=0.5, fit_prior=True .......................................\n",
      "[CV] .............. alpha=0.5, fit_prior=True, score=0.297282 -   2.9s\n",
      "[CV] alpha=0.5, fit_prior=True .......................................\n",
      "[CV] .............. alpha=0.5, fit_prior=True, score=0.294858 -   2.9s\n",
      "[CV] alpha=0.5, fit_prior=True .......................................\n",
      "[CV] .............. alpha=0.5, fit_prior=True, score=0.295935 -   2.9s\n",
      "[CV] alpha=0.5, fit_prior=False ......................................\n",
      "[CV] ............. alpha=0.5, fit_prior=False, score=0.297254 -   2.9s\n",
      "[CV] alpha=0.5, fit_prior=False ......................................\n",
      "[CV] ............. alpha=0.5, fit_prior=False, score=0.294880 -   2.9s\n",
      "[CV] alpha=0.5, fit_prior=False ......................................\n",
      "[CV] ............. alpha=0.5, fit_prior=False, score=0.295969 -   2.9s\n",
      "[CV] alpha=1.0, fit_prior=True .......................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=10)]: Done  12 tasks      | elapsed:   45.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .............. alpha=1.0, fit_prior=True, score=0.297282 -   2.9s\n",
      "[CV] alpha=1.0, fit_prior=True .......................................\n",
      "[CV] .............. alpha=1.0, fit_prior=True, score=0.294858 -   2.9s\n",
      "[CV] alpha=1.0, fit_prior=True .......................................\n",
      "[CV] .............. alpha=1.0, fit_prior=True, score=0.295935 -   2.9s\n",
      "[CV] alpha=1.0, fit_prior=False ......................................\n",
      "[CV] ............. alpha=1.0, fit_prior=False, score=0.297254 -   3.0s\n",
      "[CV] alpha=1.0, fit_prior=False ......................................\n",
      "[CV] ............. alpha=1.0, fit_prior=False, score=0.294880 -   2.9s\n",
      "[CV] alpha=1.0, fit_prior=False ......................................\n",
      "[CV] ............. alpha=1.0, fit_prior=False, score=0.295969 -   3.0s\n",
      "[CV] alpha=0.1, fit_prior=True .......................................\n",
      "[CV] .............. alpha=0.1, fit_prior=True, score=0.297282 -   3.0s\n",
      "[CV] alpha=0.1, fit_prior=True .......................................\n",
      "[CV] .............. alpha=0.1, fit_prior=True, score=0.294858 -   3.0s\n",
      "[CV] alpha=0.1, fit_prior=True .......................................\n",
      "[CV] alpha=0.1, fit_prior=False ......................................\n",
      "[CV] .............. alpha=0.1, fit_prior=True, score=0.295935 -   5.0s\n",
      "[CV] alpha=0.1, fit_prior=False ......................................\n",
      "[CV] ............. alpha=0.1, fit_prior=False, score=0.297254 -   5.1s\n",
      "[CV] alpha=0.1, fit_prior=False ......................................\n",
      "[CV] ............. alpha=0.1, fit_prior=False, score=0.294880 -   5.0s\n",
      "[CV] alpha=0.01, fit_prior=True ......................................\n",
      "[CV] ............. alpha=0.1, fit_prior=False, score=0.295969 -   5.0s\n",
      "[CV] alpha=0.01, fit_prior=True ......................................\n",
      "[CV] ............. alpha=0.01, fit_prior=True, score=0.297282 -   5.0s\n",
      "[CV] alpha=0.01, fit_prior=True ......................................\n",
      "[CV] ............. alpha=0.01, fit_prior=True, score=0.294858 -   5.0s\n",
      "[CV] alpha=0.01, fit_prior=False .....................................\n",
      "[CV] ............. alpha=0.01, fit_prior=True, score=0.295935 -   5.1s\n",
      "[CV] alpha=0.01, fit_prior=False .....................................\n",
      "[CV] ............ alpha=0.01, fit_prior=False, score=0.297254 -   5.0s\n",
      "[CV] alpha=0.01, fit_prior=False .....................................\n",
      "[CV] ............ alpha=0.01, fit_prior=False, score=0.294880 -   5.0s\n",
      "[CV] alpha=10.0, fit_prior=True ......................................\n",
      "[CV] ............ alpha=0.01, fit_prior=False, score=0.295969 -   5.1s\n",
      "[CV] alpha=10.0, fit_prior=True ......................................\n",
      "[CV] ............. alpha=10.0, fit_prior=True, score=0.297282 -   5.0s\n",
      "[CV] alpha=10.0, fit_prior=True ......................................\n",
      "[CV] ............. alpha=10.0, fit_prior=True, score=0.294858 -   5.0s\n",
      "[CV] alpha=10.0, fit_prior=False .....................................\n",
      "[CV] ............. alpha=10.0, fit_prior=True, score=0.295935 -   5.0s\n",
      "[CV] alpha=10.0, fit_prior=False .....................................\n",
      "[CV] ............ alpha=10.0, fit_prior=False, score=0.297254 -   5.0s\n",
      "[CV] alpha=10.0, fit_prior=False .....................................\n",
      "[CV] ............ alpha=10.0, fit_prior=False, score=0.294880 -   5.0s\n",
      "[CV] ............ alpha=10.0, fit_prior=False, score=0.295969 -   4.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=10)]: Done  36 out of  36 | elapsed:  2.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Search took 138.141034126 seconds to run\n",
      "Grid Search took 0.000313997268677 seconds to run\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.71      0.72      0.71     47103\n",
      "          1       0.29      0.27      0.28     19520\n",
      "\n",
      "avg / total       0.58      0.59      0.59     66623\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.71      0.72      0.71     93945\n",
      "          1       0.30      0.28      0.29     39301\n",
      "\n",
      "avg / total       0.59      0.59      0.59    133246\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.71      0.72      0.71    141314\n",
      "          1       0.29      0.28      0.28     58555\n",
      "\n",
      "avg / total       0.59      0.59      0.59    199869\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.71      1.00      0.83    188401\n",
      "          1       0.30      0.00      0.01     78091\n",
      "\n",
      "avg / total       0.59      0.71      0.59    266492\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.71      0.83      0.76    470763\n",
      "          1       0.29      0.17      0.21    195467\n",
      "\n",
      "avg / total       0.59      0.64      0.60    666230\n",
      "\n",
      "* Rates for distinct percentage groups \n",
      "\n",
      "10 %% group rate: 0.292991909701 size: 66623\n",
      "20 %% group rate: 0.294950692704 size: 133246\n",
      "30 %% group rate: 0.292966893315 size: 199869\n",
      "40 %% group rate: 0.293033186737 size: 266492\n",
      "This cell took 147.492668152 seconds to run\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "param_grid = {'alpha':[0,1.0, 1e-1,1e1], 'fit_prior': [True,False],\n",
    "             }\n",
    "estimator  = MultinomialNB( )\n",
    "\n",
    "clf =GridSearchCV(estimator, param_grid, scoring='roc_auc', fit_params=None, n_jobs=10, iid=True, refit=True, \n",
    "verbose=3, pre_dispatch='2*n_jobs', error_score='raise')\n",
    "n_iter_search =60\n",
    "\n",
    "#how many parameters to randomly search for\n",
    "n_iter_search = 45\n",
    "\n",
    "#clf = RandomizedSearchCV(estimator, param_distributions=param_grid,\n",
    "#                                   n_iter=n_iter_search, n_jobs =-1, verbose=3)\n",
    "X = X_train[X_train.columns[:-1]].values\n",
    "Y = X_train['y'].values\n",
    "\n",
    "#X = X_train_categorical\n",
    "clf.fit(X,Y)\n",
    "\n",
    "\n",
    "#random_search.fit(X_train,y_train)\n",
    "elapsed_time =  time.time() - start_time\n",
    "\n",
    "print('Random Search took %s seconds to run' % elapsed_time)\n",
    "\n",
    "\n",
    "all_time =   time.time() - start_time \n",
    "print('Grid Search took %s seconds to run' % (all_time - elapsed_time))\n",
    "\n",
    "\n",
    "X_test = X_val[X_train.columns[:-1]].values\n",
    "Y_test = X_val['y'].values\n",
    "\n",
    "predicted_proba = pd.DataFrame()\n",
    "predicted_proba['prob'] = clf.predict_proba(X_test).max(axis=1)\n",
    "predicted_proba.index = X_val.index\n",
    "predicted_proba['class'] = clf.predict(X_test)\n",
    "predicted_proba['gt'] =  Y_test\n",
    "predicted_proba.index.name = \"USER\"\n",
    "predicted_proba.sort_values(by = 'prob',ascending = False, inplace = True)\n",
    "\n",
    "cut_percentages = [10,20,30,40]\n",
    "#converted = (predicted_proba['class']==1)\n",
    "#me fijo todos los users que van a convertir en el futuro\n",
    "\n",
    "past_epidemic = X_val[X_val['y']==1].index.values\n",
    "\n",
    "start = 0\n",
    "mobility_dict = {}\n",
    "index_segments = []\n",
    "for i in cut_percentages:\n",
    "    cut_size = int(len(predicted_proba)*i/100.0)    \n",
    "    bool_array = (~np.ones(len(predicted_proba), dtype=bool))\n",
    "    bool_array[start: start + cut_size] = True\n",
    "    index_segments += [bool_array]\n",
    "    start = start + cut_size\n",
    "    #subtable = \n",
    "    mobility_dict[str(i)] = predicted_proba.loc[index_segments[-1]].index.values\n",
    "    \n",
    "    print(classification_report(predicted_proba.loc[index_segments[-1],\"gt\"].values,\n",
    "                            predicted_proba.loc[index_segments[-1],'class'].values ))\n",
    "    \n",
    "    \n",
    "print(classification_report(predicted_proba.loc[:,\"gt\"].values,\n",
    "                            predicted_proba.loc[:,'class'].values ))\n",
    "    \n",
    "    \n",
    "print(\"* Rates for distinct percentage groups \\n\")\n",
    "for i in cut_percentages:\n",
    "    subtable = mobility_dict[str(i)]\n",
    "\n",
    "    print(\"{0} %% group rate: {1} size: {2}\".format(str(i), \n",
    "                                np.in1d(subtable,past_epidemic).sum()*1.0/len(subtable),len(subtable))) \n",
    "    \n",
    "    \n",
    "cv_result = pd.DataFrame(columns=['mean_score' ] + [key for key, value in clf.grid_scores_[0].parameters.items() ] )\n",
    "i=0\n",
    "for setup in clf.grid_scores_:\n",
    "    row = [clf.grid_scores_[i].mean_validation_score ] + [value for key, value in clf.grid_scores_[i].parameters.items() ]\n",
    "    cv_result.loc[i] = row\n",
    "    i+=1\n",
    "\n",
    "    \n",
    "    \n",
    "all_time =   time.time() - start_time\n",
    "\n",
    "#este flag es basicamente para chequear que hayamos terminado nomas\n",
    "finished = True\n",
    "\n",
    "print('This cell took %s seconds to run' % all_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha\n",
      "0.00     0.500891\n",
      "0.01     0.500891\n",
      "0.10     0.500891\n",
      "0.50     0.500891\n",
      "1.00     0.500891\n",
      "10.00    0.500911\n",
      "Name: mean_score, dtype: float64\n",
      "\n",
      " std_deviation is\n",
      "alpha\n",
      "0.00     0.000066\n",
      "0.01     0.000066\n",
      "0.10     0.000066\n",
      "0.50     0.000066\n",
      "1.00     0.000066\n",
      "10.00    0.000088\n",
      "Name: mean_score, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "coln = 1\n",
    "print(cv_result.groupby(cv_result.columns[coln])['mean_score'].mean())\n",
    "print('\\n std_deviation is')\n",
    "print(cv_result.groupby(cv_result.columns[coln])['mean_score'].std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results\n",
    "* fitting prior has better mean and almost same std\n",
    "* alpha should be only > 0. But difference between positive alphas is negligible, even on different exponential orders\n",
    "* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      0.85      0.75     43545\n",
      "          1       0.40      0.19      0.25     22464\n",
      "\n",
      "avg / total       0.58      0.63      0.58     66009\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.64      0.75      0.69     83353\n",
      "          1       0.40      0.28      0.33     48666\n",
      "\n",
      "avg / total       0.55      0.58      0.56    132019\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.63      0.67      0.65    124185\n",
      "          1       0.39      0.35      0.37     73843\n",
      "\n",
      "avg / total       0.54      0.55      0.55    198028\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.62      0.56      0.59    164393\n",
      "          1       0.38      0.44      0.41     99645\n",
      "\n",
      "avg / total       0.53      0.52      0.52    264038\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.64      0.66      0.65    415477\n",
      "          1       0.39      0.36      0.37    244618\n",
      "\n",
      "avg / total       0.54      0.55      0.55    660095\n",
      "\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'LogisticRegressionCV' object has no attribute 'grid_scores_'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-54-53e73f014a4f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m \u001b[0mcv_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'mean_score'\u001b[0m \u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrid_scores_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m]\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msetup\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrid_scores_\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'LogisticRegressionCV' object has no attribute 'grid_scores_'"
     ]
    }
   ],
   "source": [
    "\n",
    "clf =  LogisticRegressionCV(n_jobs =3, class_weight= 'balanced', scoring = 'f1',cv=3)\n",
    "\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "\n",
    "predicted_proba = pd.DataFrame()\n",
    "predicted_proba['prob'] = clf.predict_proba(X_test).max(axis=1)\n",
    "predicted_proba['class'] = clf.predict(X_test)\n",
    "predicted_proba[gt] =  y_test\n",
    "predicted_proba.sort_values(by = 'prob',ascending = False, inplace = True)\n",
    "\n",
    "cut_percentages = [10,20,30,40]\n",
    "#converted = (predicted_proba['class']==1)\n",
    "#me fijo todos los users que van a convertir en el futuro\n",
    "\n",
    "\n",
    "start = 0\n",
    "mobility_dict = {}\n",
    "index_segments = []\n",
    "for i in cut_percentages:\n",
    "    cut_size = int(len(predicted_proba)*i/100.0)    \n",
    "    bool_array = (~np.ones(len(predicted_proba), dtype=bool))\n",
    "    bool_array[start: start + cut_size] = True\n",
    "    index_segments += [bool_array]\n",
    "    start = start + cut_size\n",
    "#    subtable = \n",
    "    #mobility_dict[str(i)] = predicted_proba.loc[index_segments[-1],'ref_hash']\n",
    "    \n",
    "    print(classification_report(predicted_proba.loc[index_segments[-1],gt].values,\n",
    "                            predicted_proba.loc[index_segments[-1],'class'].values ))\n",
    "    \n",
    "    \n",
    "print(classification_report(predicted_proba.loc[:,gt].values,\n",
    "                            predicted_proba.loc[:,'class'].values ))\n",
    "    \n",
    "    \n",
    "cv_result = pd.DataFrame(columns=['mean_score' ] + [key for key, value in clf.grid_scores_[0].parameters.items() ] )\n",
    "i=0\n",
    "for setup in clf.grid_scores_:\n",
    "    row = [clf.grid_scores_[i].mean_validation_score ] + [value for key, value in clf.grid_scores_[i].parameters.items() ]\n",
    "    cv_result.loc[i] = row\n",
    "    i+=1\n",
    "#este flag es basicamente para chequear que hayamos terminado nomas\n",
    "finished = True\n",
    "\n",
    "all_time =   time.time() - start_time\n",
    "\n",
    "#este flag es basicamente para chequear que hayamos terminado nomas\n",
    "finished = True\n",
    "\n",
    "print('This cell took %s seconds to run' % all_time)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validate SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_grid = [\n",
    "  { 'alpha': [1e-3,5*1e-3,1e-2], 'l1_ratio': [3*1e-2,1e-3,6*1e-4], 'n_iter': [2,3]\n",
    "  }\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 18 candidates, totalling 54 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Virtualenvs/mateo/lib/python3.4/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] n_iter=2, alpha=0.001, l1_ratio=0.03 ............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Virtualenvs/mateo/lib/python3.4/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] n_iter=2, alpha=0.001, l1_ratio=0.03 ............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Virtualenvs/mateo/lib/python3.4/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ... n_iter=2, alpha=0.001, l1_ratio=0.03, score=0.125354 -   2.5s\n",
      "[CV] n_iter=2, alpha=0.001, l1_ratio=0.03 ............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Virtualenvs/mateo/lib/python3.4/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ... n_iter=2, alpha=0.001, l1_ratio=0.03, score=0.127442 -   2.5s\n",
      "[CV] n_iter=3, alpha=0.001, l1_ratio=0.03 ............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Virtualenvs/mateo/lib/python3.4/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ... n_iter=2, alpha=0.001, l1_ratio=0.03, score=0.119463 -   2.5s\n",
      "[CV] n_iter=3, alpha=0.001, l1_ratio=0.03 ............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Virtualenvs/mateo/lib/python3.4/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ... n_iter=3, alpha=0.001, l1_ratio=0.03, score=0.132910 -   3.1s\n",
      "[CV] n_iter=3, alpha=0.001, l1_ratio=0.03 ............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Virtualenvs/mateo/lib/python3.4/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ... n_iter=3, alpha=0.001, l1_ratio=0.03, score=0.133858 -   3.1s\n",
      "[CV] n_iter=2, alpha=0.001, l1_ratio=0.001 ...........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Virtualenvs/mateo/lib/python3.4/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ... n_iter=3, alpha=0.001, l1_ratio=0.03, score=0.125862 -   3.1s\n",
      "[CV] n_iter=2, alpha=0.001, l1_ratio=0.001 ...........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Virtualenvs/mateo/lib/python3.4/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .. n_iter=2, alpha=0.001, l1_ratio=0.001, score=0.114065 -   2.5s\n",
      "[CV] n_iter=2, alpha=0.001, l1_ratio=0.001 ...........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Virtualenvs/mateo/lib/python3.4/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .. n_iter=2, alpha=0.001, l1_ratio=0.001, score=0.125576 -   2.5s\n",
      "[CV] n_iter=3, alpha=0.001, l1_ratio=0.001 ...........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Virtualenvs/mateo/lib/python3.4/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .. n_iter=2, alpha=0.001, l1_ratio=0.001, score=0.125882 -   2.8s\n",
      "[CV] n_iter=3, alpha=0.001, l1_ratio=0.001 ...........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Virtualenvs/mateo/lib/python3.4/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .. n_iter=3, alpha=0.001, l1_ratio=0.001, score=0.138072 -   3.3s\n",
      "[CV] n_iter=3, alpha=0.001, l1_ratio=0.001 ...........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Virtualenvs/mateo/lib/python3.4/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .. n_iter=3, alpha=0.001, l1_ratio=0.001, score=0.133482 -   3.1s\n",
      "[CV] n_iter=2, alpha=0.001, l1_ratio=0.0006000000000000001 ...........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Virtualenvs/mateo/lib/python3.4/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .. n_iter=3, alpha=0.001, l1_ratio=0.001, score=0.133945 -   3.2s\n",
      "[CV] n_iter=2, alpha=0.001, l1_ratio=0.0006000000000000001 ...........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Virtualenvs/mateo/lib/python3.4/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_iter=2, alpha=0.001, l1_ratio=0.0006000000000000001, score=0.124318 -   2.5s\n",
      "[CV] n_iter=2, alpha=0.001, l1_ratio=0.0006000000000000001 ...........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Virtualenvs/mateo/lib/python3.4/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_iter=2, alpha=0.001, l1_ratio=0.0006000000000000001, score=0.125224 -   2.5s\n",
      "[CV] n_iter=3, alpha=0.001, l1_ratio=0.0006000000000000001 ...........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Virtualenvs/mateo/lib/python3.4/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_iter=2, alpha=0.001, l1_ratio=0.0006000000000000001, score=0.129423 -   2.5s\n",
      "[CV] n_iter=3, alpha=0.001, l1_ratio=0.0006000000000000001 ...........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Virtualenvs/mateo/lib/python3.4/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_iter=3, alpha=0.001, l1_ratio=0.0006000000000000001, score=0.131845 -   3.1s\n",
      "[CV] n_iter=3, alpha=0.001, l1_ratio=0.0006000000000000001 ...........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Virtualenvs/mateo/lib/python3.4/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_iter=3, alpha=0.001, l1_ratio=0.0006000000000000001, score=0.135827 -   3.1s\n",
      "[CV] n_iter=2, alpha=0.005, l1_ratio=0.03 ............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Virtualenvs/mateo/lib/python3.4/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_iter=3, alpha=0.001, l1_ratio=0.0006000000000000001, score=0.128485 -   3.1s\n",
      "[CV] n_iter=2, alpha=0.005, l1_ratio=0.03 ............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Virtualenvs/mateo/lib/python3.4/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ... n_iter=2, alpha=0.005, l1_ratio=0.03, score=0.125477 -   2.4s\n",
      "[CV] n_iter=2, alpha=0.005, l1_ratio=0.03 ............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Virtualenvs/mateo/lib/python3.4/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ... n_iter=2, alpha=0.005, l1_ratio=0.03, score=0.125957 -   2.8s\n",
      "[CV] n_iter=3, alpha=0.005, l1_ratio=0.03 ............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Virtualenvs/mateo/lib/python3.4/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ... n_iter=2, alpha=0.005, l1_ratio=0.03, score=0.127511 -   2.6s\n",
      "[CV] n_iter=3, alpha=0.005, l1_ratio=0.03 ............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Virtualenvs/mateo/lib/python3.4/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ... n_iter=3, alpha=0.005, l1_ratio=0.03, score=0.127618 -   2.8s\n",
      "[CV] n_iter=3, alpha=0.005, l1_ratio=0.03 ............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Virtualenvs/mateo/lib/python3.4/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ... n_iter=3, alpha=0.005, l1_ratio=0.03, score=0.125386 -   2.8s\n",
      "[CV] n_iter=2, alpha=0.005, l1_ratio=0.001 ...........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Virtualenvs/mateo/lib/python3.4/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ... n_iter=3, alpha=0.005, l1_ratio=0.03, score=0.136983 -   3.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  24 tasks      | elapsed:   47.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] n_iter=2, alpha=0.005, l1_ratio=0.001 ...........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Virtualenvs/mateo/lib/python3.4/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .. n_iter=2, alpha=0.005, l1_ratio=0.001, score=0.120290 -   2.5s\n",
      "[CV] n_iter=2, alpha=0.005, l1_ratio=0.001 ...........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Virtualenvs/mateo/lib/python3.4/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .. n_iter=2, alpha=0.005, l1_ratio=0.001, score=0.118753 -   2.5s\n",
      "[CV] n_iter=3, alpha=0.005, l1_ratio=0.001 ...........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Virtualenvs/mateo/lib/python3.4/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .. n_iter=2, alpha=0.005, l1_ratio=0.001, score=0.127159 -   2.9s\n",
      "[CV] n_iter=3, alpha=0.005, l1_ratio=0.001 ...........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Virtualenvs/mateo/lib/python3.4/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .. n_iter=3, alpha=0.005, l1_ratio=0.001, score=0.127485 -   3.3s\n",
      "[CV] n_iter=3, alpha=0.005, l1_ratio=0.001 ...........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Virtualenvs/mateo/lib/python3.4/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .. n_iter=3, alpha=0.005, l1_ratio=0.001, score=0.139728 -   3.1s\n",
      "[CV] n_iter=2, alpha=0.005, l1_ratio=0.0006000000000000001 ...........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Virtualenvs/mateo/lib/python3.4/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .. n_iter=3, alpha=0.005, l1_ratio=0.001, score=0.130469 -   3.1s\n",
      "[CV] n_iter=2, alpha=0.005, l1_ratio=0.0006000000000000001 ...........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Virtualenvs/mateo/lib/python3.4/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_iter=2, alpha=0.005, l1_ratio=0.0006000000000000001, score=0.129161 -   2.5s\n",
      "[CV] n_iter=2, alpha=0.005, l1_ratio=0.0006000000000000001 ...........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Virtualenvs/mateo/lib/python3.4/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_iter=2, alpha=0.005, l1_ratio=0.0006000000000000001, score=0.130159 -   2.5s\n",
      "[CV] n_iter=3, alpha=0.005, l1_ratio=0.0006000000000000001 ...........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Virtualenvs/mateo/lib/python3.4/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_iter=2, alpha=0.005, l1_ratio=0.0006000000000000001, score=0.127613 -   2.5s\n",
      "[CV] n_iter=3, alpha=0.005, l1_ratio=0.0006000000000000001 ...........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Virtualenvs/mateo/lib/python3.4/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_iter=3, alpha=0.005, l1_ratio=0.0006000000000000001, score=0.132956 -   3.1s\n",
      "[CV] n_iter=3, alpha=0.005, l1_ratio=0.0006000000000000001 ...........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Virtualenvs/mateo/lib/python3.4/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_iter=3, alpha=0.005, l1_ratio=0.0006000000000000001, score=0.143005 -   3.1s\n",
      "[CV] n_iter=2, alpha=0.01, l1_ratio=0.03 .............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Virtualenvs/mateo/lib/python3.4/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_iter=3, alpha=0.005, l1_ratio=0.0006000000000000001, score=0.135926 -   3.1s\n",
      "[CV] n_iter=2, alpha=0.01, l1_ratio=0.03 .............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Virtualenvs/mateo/lib/python3.4/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .... n_iter=2, alpha=0.01, l1_ratio=0.03, score=0.128098 -   2.4s\n",
      "[CV] n_iter=2, alpha=0.01, l1_ratio=0.03 .............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Virtualenvs/mateo/lib/python3.4/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .... n_iter=2, alpha=0.01, l1_ratio=0.03, score=0.127078 -   2.7s\n",
      "[CV] n_iter=3, alpha=0.01, l1_ratio=0.03 .............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Virtualenvs/mateo/lib/python3.4/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .... n_iter=2, alpha=0.01, l1_ratio=0.03, score=0.126921 -   2.5s\n",
      "[CV] n_iter=3, alpha=0.01, l1_ratio=0.03 .............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Virtualenvs/mateo/lib/python3.4/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .... n_iter=3, alpha=0.01, l1_ratio=0.03, score=0.138152 -   3.6s\n",
      "[CV] n_iter=3, alpha=0.01, l1_ratio=0.03 .............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Virtualenvs/mateo/lib/python3.4/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .... n_iter=3, alpha=0.01, l1_ratio=0.03, score=0.106208 -   3.1s\n",
      "[CV] n_iter=2, alpha=0.01, l1_ratio=0.001 ............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Virtualenvs/mateo/lib/python3.4/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .... n_iter=3, alpha=0.01, l1_ratio=0.03, score=0.143076 -   2.8s\n",
      "[CV] n_iter=2, alpha=0.01, l1_ratio=0.001 ............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Virtualenvs/mateo/lib/python3.4/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ... n_iter=2, alpha=0.01, l1_ratio=0.001, score=0.132427 -   2.5s\n",
      "[CV] n_iter=2, alpha=0.01, l1_ratio=0.001 ............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Virtualenvs/mateo/lib/python3.4/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ... n_iter=2, alpha=0.01, l1_ratio=0.001, score=0.125901 -   2.9s\n",
      "[CV] n_iter=3, alpha=0.01, l1_ratio=0.001 ............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Virtualenvs/mateo/lib/python3.4/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ... n_iter=2, alpha=0.01, l1_ratio=0.001, score=0.128001 -   2.7s\n",
      "[CV] n_iter=3, alpha=0.01, l1_ratio=0.001 ............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Virtualenvs/mateo/lib/python3.4/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ... n_iter=3, alpha=0.01, l1_ratio=0.001, score=0.135568 -   3.1s\n",
      "[CV] n_iter=3, alpha=0.01, l1_ratio=0.001 ............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Virtualenvs/mateo/lib/python3.4/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] n_iter=2, alpha=0.01, l1_ratio=0.0006000000000000001 ............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Virtualenvs/mateo/lib/python3.4/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ... n_iter=3, alpha=0.01, l1_ratio=0.001, score=0.132579 -   4.4s\n",
      "[CV] ... n_iter=3, alpha=0.01, l1_ratio=0.001, score=0.136589 -   3.7s\n",
      "[CV] n_iter=2, alpha=0.01, l1_ratio=0.0006000000000000001 ............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Virtualenvs/mateo/lib/python3.4/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_iter=2, alpha=0.01, l1_ratio=0.0006000000000000001, score=0.124134 -   2.8s\n",
      "[CV] n_iter=2, alpha=0.01, l1_ratio=0.0006000000000000001 ............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Virtualenvs/mateo/lib/python3.4/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_iter=2, alpha=0.01, l1_ratio=0.0006000000000000001, score=0.130883 -   2.5s\n",
      "[CV] n_iter=3, alpha=0.01, l1_ratio=0.0006000000000000001 ............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Virtualenvs/mateo/lib/python3.4/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_iter=2, alpha=0.01, l1_ratio=0.0006000000000000001, score=0.122741 -   3.5s\n",
      "[CV] n_iter=3, alpha=0.01, l1_ratio=0.0006000000000000001 ............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Virtualenvs/mateo/lib/python3.4/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_iter=3, alpha=0.01, l1_ratio=0.0006000000000000001, score=0.132433 -   3.7s\n",
      "[CV] n_iter=3, alpha=0.01, l1_ratio=0.0006000000000000001 ............\n",
      "[CV]  n_iter=3, alpha=0.01, l1_ratio=0.0006000000000000001, score=0.135111 -   3.4s\n",
      "[CV]  n_iter=3, alpha=0.01, l1_ratio=0.0006000000000000001, score=0.135908 -   3.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  54 out of  54 | elapsed:  1.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.31      0.47    355992\n",
      "          1       0.06      0.99      0.11     15152\n",
      "\n",
      "avg / total       0.96      0.33      0.45    371144\n",
      "\n",
      "This cell took 108.56432461738586 seconds to run\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "param_grid = [\n",
    "  { 'alpha': [1e-3,5*1e-3,1e-2], 'l1_ratio': [3*1e-2,1e-3,6*1e-4], 'n_iter': [2,3]\n",
    "  }\n",
    "    ]\n",
    "sgd = SGDClassifier(loss='modified_huber', penalty='elasticnet', \n",
    "             fit_intercept=True,  shuffle=True, \n",
    "                    n_jobs=3,learning_rate='optimal', power_t =2, eta0 =5,\n",
    "                    class_weight='balanced', average=40)\n",
    "\n",
    "clf =GridSearchCV(sgd, param_grid, scoring='roc_auc', fit_params=None, n_jobs=4, iid=True, refit=True, \n",
    "verbose=3, pre_dispatch='2*n_jobs', error_score='raise')\n",
    "\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "\n",
    "\n",
    "predicted_proba = pd.DataFrame()\n",
    "predicted_proba['prob'] = clf.predict_proba(X_test).max(axis=1)\n",
    "predicted_proba['class'] = clf.predict(X_test)\n",
    "predicted_proba[gt] =  y_test\n",
    "predicted_proba.sort_values(by = 'prob',ascending = False, inplace = True)\n",
    "\n",
    "cut_percentages = [10,20,30,40]\n",
    "#converted = (predicted_proba['class']==1)\n",
    "#me fijo todos los users que van a convertir en el futuro\n",
    "\n",
    "\n",
    "start = 0\n",
    "mobility_dict = {}\n",
    "index_segments = []\n",
    "for i in cut_percentages:\n",
    "    cut_size = int(len(predicted_proba)*i/100.0)    \n",
    "    bool_array = (~np.ones(len(predicted_proba), dtype=bool))\n",
    "    bool_array[start: start + cut_size] = True\n",
    "    index_segments += [bool_array]\n",
    "    start = start + cut_size\n",
    "#    subtable = \n",
    "    #mobility_dict[str(i)] = predicted_proba.loc[index_segments[-1],'ref_hash']\n",
    "    \n",
    "    print(classification_report(predicted_proba.loc[index_segments[-1],gt].values,\n",
    "                            predicted_proba.loc[index_segments[-1],'class'].values ))\n",
    "    \n",
    "    \n",
    "print(classification_report(predicted_proba.loc[:,gt].values,\n",
    "                            predicted_proba.loc[:,'class'].values ))\n",
    "    \n",
    "    \n",
    "cv_result = pd.DataFrame(columns=['mean_score' ] + [key for key, value in clf.grid_scores_[0].parameters.items() ] )\n",
    "i=0\n",
    "for setup in clf.grid_scores_:\n",
    "    row = [clf.grid_scores_[i].mean_validation_score ] + [value for key, value in clf.grid_scores_[i].parameters.items() ]\n",
    "    cv_result.loc[i] = row\n",
    "    i+=1\n",
    "#este flag es basicamente para chequear que hayamos terminado nomas\n",
    "finished = True\n",
    "\n",
    "all_time =   time.time() - start_time\n",
    "\n",
    "#este flag es basicamente para chequear que hayamos terminado nomas\n",
    "finished = True\n",
    "\n",
    "print('This cell took %s seconds to run' % all_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "threshold = 0.7\n",
    "ind = predicted_proba['prob']>threshold\n",
    "print(classification_report(predicted_proba.loc[ind,'y'].values,predicted_proba.loc[ind,'class'].values ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.005, average=40, class_weight='balanced', epsilon=0.1,\n",
       "       eta0=5, fit_intercept=True, l1_ratio=0.0006000000000000001,\n",
       "       learning_rate='optimal', loss='modified_huber', n_iter=3, n_jobs=3,\n",
       "       penalty='elasticnet', power_t=2, random_state=None, shuffle=True,\n",
       "       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_iter\n",
      "2.0    0.125741\n",
      "3.0    0.132943\n",
      "Name: mean_score, dtype: float64\n",
      "n_iter\n",
      "2.0    0.002609\n",
      "3.0    0.002703\n",
      "Name: mean_score, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "coln=1\n",
    "print(cv_result.groupby(cv_result.columns[coln])['mean_score'].mean())\n",
    "print(cv_result.groupby(cv_result.columns[coln])['mean_score'].std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Results\n",
    "* l1_ratio = cuanto mas chico mejor con lo cual la perdida l2 parece ser mejor\n",
    "* alpha = 1e-3 es suficiente pues casi no afecta el score\n",
    "* power_t = muy variado, no parece haber correlacion entre el tamanyo y el avg, mean_score\n",
    "* eta0 = no afecta mucho pero parece ser que con ser >1 ya esta\n",
    "* power_t = parecen ser practicamente iguales\n",
    "* n_iter = cuanto mas iter NO mejora el score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "371161"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predicted_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validate NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 144 candidates, totalling 432 fits\n",
      "[CV] algorithm=adam, hidden_layer_sizes=(50,), activation=logistic, power_t=0.001, alpha=0.1, learning_rate=adaptive \n",
      "[CV] algorithm=adam, hidden_layer_sizes=(50,), activation=logistic, power_t=0.001, alpha=0.1, learning_rate=adaptive \n",
      "[CV] algorithm=adam, hidden_layer_sizes=(50,), activation=logistic, power_t=0.001, alpha=0.1, learning_rate=adaptive \n",
      "[CV] algorithm=adam, hidden_layer_sizes=(50,), activation=logistic, power_t=0.0005, alpha=0.1, learning_rate=adaptive \n",
      "Iteration 1, loss = 0.20405210\n",
      "Iteration 1, loss = 0.20380843\n",
      "Iteration 1, loss = 0.20378706\n",
      "Iteration 1, loss = 0.20405210\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/teo/Repositories/scikit-learn/sklearn/metrics/classification.py:1097: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  algorithm=adam, hidden_layer_sizes=(50,), activation=logistic, power_t=0.0005, alpha=0.1, learning_rate=adaptive, score=0.000000 -   1.5s\n",
      "[CV] algorithm=adam, hidden_layer_sizes=(50,), activation=logistic, power_t=0.0005, alpha=0.1, learning_rate=adaptive \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/teo/Repositories/scikit-learn/sklearn/metrics/classification.py:1097: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  algorithm=adam, hidden_layer_sizes=(50,), activation=logistic, power_t=0.001, alpha=0.1, learning_rate=adaptive, score=0.000000 -   1.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/teo/Repositories/scikit-learn/sklearn/metrics/classification.py:1097: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  algorithm=adam, hidden_layer_sizes=(50,), activation=logistic, power_t=0.001, alpha=0.1, learning_rate=adaptive, score=0.000000 -   2.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/teo/Repositories/scikit-learn/sklearn/metrics/classification.py:1097: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  algorithm=adam, hidden_layer_sizes=(50,), activation=logistic, power_t=0.001, alpha=0.1, learning_rate=adaptive, score=0.000000 -   1.9s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-35-3491f77d2a02>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     16\u001b[0m verbose=3, pre_dispatch='2*n_jobs', error_score='raise')\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[0mpredicted_proba\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/teo/Repositories/scikit-learn/sklearn/grid_search.pyc\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    809\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    810\u001b[0m         \"\"\"\n\u001b[1;32m--> 811\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    812\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    813\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/teo/Repositories/scikit-learn/sklearn/grid_search.pyc\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, y, parameter_iterable)\u001b[0m\n\u001b[0;32m    558\u001b[0m                                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_parameters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    559\u001b[0m                                     error_score=self.error_score)\n\u001b[1;32m--> 560\u001b[1;33m                 \u001b[1;32mfor\u001b[0m \u001b[0mparameters\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mparameter_iterable\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    561\u001b[0m                 for train, test in cv)\n\u001b[0;32m    562\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/teo/Repositories/scikit-learn/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    808\u001b[0m                 \u001b[1;31m# consumption.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    809\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 810\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    811\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    812\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/teo/Repositories/scikit-learn/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    755\u001b[0m                     \u001b[1;31m# a working pool as they expect.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    756\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_initialize_pool\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 757\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    758\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    759\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "X_train,X_test,y_train ,y_test = train_test_split(X,y, test_size=0.2, random_state=42)\n",
    "\n",
    "param_grid = { 'alpha': [1e-1,5*1e-2,1e-2],\n",
    "              'hidden_layer_sizes':[(50,),(15,5)],\n",
    "              'learning_rate': ['adaptive',\"invscaling\"],\n",
    "              \"algorithm\": ['adam'],'momentum': [1e-2, 1e-1, 0.5],\n",
    "  'power_t': [1e-3, 5*1e-4, 1e-5], 'activation':['logistic','relu']\n",
    " }\n",
    "\n",
    "mlp = MLPClassifier(shuffle=True, \n",
    "                 verbose=True)\n",
    "\n",
    "clf =GridSearchCV(mlp, param_grid, scoring='roc_auc', fit_params=None, n_jobs=4, iid=True, refit=True, \n",
    "verbose=3, pre_dispatch='2*n_jobs', error_score='raise')\n",
    "\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "predicted_proba = pd.DataFrame()\n",
    "predicted_proba['prob'] = clf.predict_proba(X_test).max(axis=1)\n",
    "predicted_proba['gt'] = y_test\n",
    "predicted_proba['class'] = clf.predict(X_test)\n",
    "\n",
    "threshold = 0.7\n",
    "ind = predicted_proba['prob']>threshold\n",
    "\n",
    "all_time =   time.time() - start_time\n",
    "\n",
    "print(classification_report(predicted_proba.loc[ind,'gt'].values,predicted_proba.loc[ind,'class'].values ))\n",
    "\n",
    "cv_result = pd.DataFrame(columns=['mean_score' ] + [key for key, value in clf.grid_scores_[0].parameters.items() ] )\n",
    "i=0\n",
    "for setup in clf.grid_scores_:\n",
    "    row = [clf.grid_scores_[i].mean_validation_score ] + [value for key, value in clf.grid_scores_[i].parameters.items() ]\n",
    "    cv_result.loc[i] = row\n",
    "    i+=1\n",
    "#este flag es basicamente para chequear que hayamos terminado nomas\n",
    "finished = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'clf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-2d39bdb4c6dd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'clf' is not defined"
     ]
    }
   ],
   "source": [
    "clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "alpha\n",
       "0.00     0.000007\n",
       "0.01     0.000007\n",
       "0.10     0.000007\n",
       "0.50     0.000007\n",
       "1.00     0.000007\n",
       "10.00    0.000007\n",
       "Name: mean_score, dtype: float64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compare best parameters to tune\n",
    "coln=1\n",
    "cv_result.groupby(cv_result.columns[coln])['mean_score'].mean()\n",
    "cv_result.groupby(cv_result.columns[coln])['mean_score'].std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Results\n",
    "* activation = logistic es 10% mejor\n",
    "* alpha = 1e-2 el mejor \n",
    "* power_t = cuanto mas chico mejor, 1e-3 por lo menos\n",
    "* hidden_layer_size = menos layers es mejor..?\n",
    "* power_t = parecen ser practicamente iguales\n",
    "* n_iter = cuanto mas iter NO mejora el score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bernoulli RBM features selection & Logit crossval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-127-8675e4c7d9ab>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     39\u001b[0m verbose=0, pre_dispatch='2*n_jobs', error_score='raise')\n\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[1;31m#este metodo NO tiene predicted proba, lo que hacemos es recorrer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/teo/Repositories/scikit-learn/sklearn/grid_search.pyc\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    809\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    810\u001b[0m         \"\"\"\n\u001b[1;32m--> 811\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    812\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    813\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/teo/Repositories/scikit-learn/sklearn/grid_search.pyc\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, y, parameter_iterable)\u001b[0m\n\u001b[0;32m    558\u001b[0m                                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_parameters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    559\u001b[0m                                     error_score=self.error_score)\n\u001b[1;32m--> 560\u001b[1;33m                 \u001b[1;32mfor\u001b[0m \u001b[0mparameters\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mparameter_iterable\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    561\u001b[0m                 for train, test in cv)\n\u001b[0;32m    562\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/teo/Repositories/scikit-learn/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    808\u001b[0m                 \u001b[1;31m# consumption.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    809\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 810\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    811\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    812\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/teo/Repositories/scikit-learn/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    755\u001b[0m                     \u001b[1;31m# a working pool as they expect.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    756\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_initialize_pool\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 757\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    758\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    759\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "## obs. este metodo es especial y asume que todos los valores son True/False o que \\in [0,1]\n",
    "# luego tengo que pensar en como tomar los features nuevamente.\n",
    "# tampoco 'fittea' en la forma tradicional. Sino que se le puede tomar al y como un feature mas y esta red\n",
    "# va 'modificando' todos los valores del X (minimizando la entropia) para dar un output. Luego corriendo \n",
    "# clf.gibbs(X_test) con el y_test como feature tmb, nos transforma la data para ver el output como la 'prediccion'\n",
    "# obviamente no tiene probabilidades\n",
    "\n",
    "\n",
    "#X = X_train[X_cols].values\n",
    "#y = X_train['ground_truth'].values\n",
    "\n",
    "df = X_train.drop(X_train[X_train[X_train.columns[0:3]].\\\n",
    "                                   sum(axis=1)==0].index)\n",
    "df = df[X_cols + ['ground_truth']]\n",
    "\n",
    "for col in X_train.columns[0:3]:\n",
    "    df[col] = df[col]*1.0/df[df.columns[0:3]].sum(axis=1)\n",
    "\n",
    "df[df.columns[3]] =  df[df.columns[3]]/df[df.columns[3]].max()\n",
    "df[df.columns[4]] =  df[df.columns[4]]/df[df.columns[4]].max()\n",
    "\n",
    "X = df[df.columns[:-1]].values\n",
    "y = df['ground_truth'].values\n",
    "\n",
    "\n",
    "param_grid = {'rbm__n_components': [256, 128,46,10],\n",
    "   'rbm__n_iter':[15,10,5], 'rbm__learning_rate': [1e-4,1e-3,1e-2,1e-1,5*1e-3,5*1e-2,5*1e-1],\n",
    "  'rbm__batch_size': [10e4,3*10e3, 1e3, 300],\"logistic__C\": [1.0, 10.0, 100.0] \n",
    " }\n",
    "\n",
    "rbm = BernoulliRBM(verbose=True)\n",
    "logistic = LogisticRegression()\n",
    "classifier = Pipeline([(\"rbm\", rbm), (\"logistic\", logistic)])\n",
    "\n",
    "X_train,X_test,y_train ,y_test = train_test_split(X,y, test_size=0.2, random_state=42)\n",
    "\n",
    "clf =GridSearchCV(classifier, param_grid, scoring='roc_auc', fit_params=None, n_jobs=4, iid=True, refit=True, \n",
    "verbose=3, pre_dispatch='2*n_jobs', error_score='raise')\n",
    "\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "#este metodo NO tiene predicted proba, lo que hacemos es recorrer \n",
    "#predicted_labels = rbm.gibbs(X_test)[:,-1]\n",
    "#real_labels = X_test[:,-1]\n",
    "#print(classification_report(real_labels,predicted_labels ))\n",
    "\n",
    "\n",
    "predicted_proba = pd.DataFrame()\n",
    "predicted_proba['prob'] = clf.predict_proba(X_test).max(axis=1)\n",
    "predicted_proba['gt'] = y_test\n",
    "predicted_proba['class'] = clf.predict(X_test)\n",
    "\n",
    "threshold = 0.7\n",
    "ind = predicted_proba['prob']>threshold\n",
    "print(classification_report(predicted_proba.loc[ind,'gt'].values,predicted_proba.loc[ind,'class'].values ))\n",
    "all_time =   time.time() - start_time\n",
    "\n",
    "finished = True\n",
    "\n",
    "cv_result = pd.DataFrame(columns=['mean_score' ] + [key for key, value in clf.grid_scores_[0].parameters.items() ] )\n",
    "i=0\n",
    "for setup in clf.grid_scores_:\n",
    "    row = [clf.grid_scores_[i].mean_validation_score ] + [value for key, value in clf.grid_scores_[i].parameters.items() ]\n",
    "    cv_result.loc[i] = row\n",
    "    i+=1\n",
    "    \n",
    "print('This cell took %s seconds to run' % all_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "coln=1\n",
    "print(cv_result.groupby(cv_result.columns[coln])['mean_score'].mean())\n",
    "print(cv_result.groupby(cv_result.columns[coln])['mean_score'].std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## ADaboost CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-41-b1ab4c054abd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[0mada_est\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mAdaBoostClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m \u001b[0mada_gs_cv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mada_est\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mada_param_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mada_gs_cv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mada_gs_cv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\n'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/teo/Repositories/scikit-learn/sklearn/grid_search.pyc\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    809\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    810\u001b[0m         \"\"\"\n\u001b[1;32m--> 811\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    812\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    813\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/teo/Repositories/scikit-learn/sklearn/grid_search.pyc\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, y, parameter_iterable)\u001b[0m\n\u001b[0;32m    558\u001b[0m                                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_parameters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    559\u001b[0m                                     error_score=self.error_score)\n\u001b[1;32m--> 560\u001b[1;33m                 \u001b[1;32mfor\u001b[0m \u001b[0mparameters\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mparameter_iterable\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    561\u001b[0m                 for train, test in cv)\n\u001b[0;32m    562\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/teo/Repositories/scikit-learn/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    798\u001b[0m             \u001b[1;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    799\u001b[0m             \u001b[1;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 800\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    801\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    802\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/teo/Repositories/scikit-learn/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    656\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    657\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 658\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    659\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    660\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/teo/Repositories/scikit-learn/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    564\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    565\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pool\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 566\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateComputeBatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    567\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    568\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_dispatched_batches\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/teo/Repositories/scikit-learn/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    178\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    179\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 180\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    181\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    182\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/teo/Repositories/scikit-learn/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/teo/Repositories/scikit-learn/sklearn/cross_validation.pyc\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, error_score)\u001b[0m\n\u001b[0;32m   1551\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1552\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1553\u001b[1;33m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1554\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1555\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/teo/Repositories/scikit-learn/sklearn/ensemble/weight_boosting.pyc\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    403\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    404\u001b[0m         \u001b[1;31m# Fit\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 405\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mAdaBoostClassifier\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    406\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    407\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_validate_estimator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/teo/Repositories/scikit-learn/sklearn/ensemble/weight_boosting.pyc\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    138\u001b[0m                 \u001b[0miboost\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m                 \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 140\u001b[1;33m                 sample_weight)\n\u001b[0m\u001b[0;32m    141\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    142\u001b[0m             \u001b[1;31m# Early termination\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/teo/Repositories/scikit-learn/sklearn/ensemble/weight_boosting.pyc\u001b[0m in \u001b[0;36m_boost\u001b[1;34m(self, iboost, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    460\u001b[0m         \"\"\"\n\u001b[0;32m    461\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0malgorithm\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'SAMME.R'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 462\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_boost_real\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miboost\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    463\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    464\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# elif self.algorithm == \"SAMME\":\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/teo/Repositories/scikit-learn/sklearn/ensemble/weight_boosting.pyc\u001b[0m in \u001b[0;36m_boost_real\u001b[1;34m(self, iboost, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    474\u001b[0m             \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    475\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 476\u001b[1;33m         \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    477\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    478\u001b[0m         \u001b[0my_predict_proba\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/teo/Repositories/scikit-learn/sklearn/tree/tree.pyc\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    366\u001b[0m                                            max_leaf_nodes)\n\u001b[0;32m    367\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 368\u001b[1;33m         \u001b[0mbuilder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    369\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    370\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "rf_param_grid = {'n_estimators': [10, 30, 100, 300, 1000]}\n",
    "boost_param_grid = {'n_estimators': [10, 30, 100, 300, 1000],\n",
    "                      'max_depth': [2, 3, 4, 5],\n",
    "                      'min_samples_leaf': [1, 2, 3]}\n",
    "ada_param_grid = {'n_estimators': [10, 30, 100, 300, 1000],\n",
    "                   'learning_rate': [0.1, 0.3, 1.0, 3.0]}\n",
    "\n",
    "X_train,X_test,y_train ,y_test = train_test_split(X,y, test_size=0.2, random_state=42)\n",
    "#rf_est = RandomForestClassifier()\n",
    "#rf_gs_cv = GridSearchCV(rf_est, rf_param_grid).fit(X_train, Y_train)\n",
    "#print(rf_gs_cv.best_score_, rf_gs_cv.best_params_)\n",
    "print('\\n')\n",
    " \n",
    "#boost_est = GradientBoostingClassifier()\n",
    "#boost_gs_cv = GridSearchCV(boost_est, boost_param_grid).fit(X_train, y_train)\n",
    "#print(boost_gs_cv.best_score_, boost_gs_cv.best_params_)\n",
    "print('\\n')\n",
    " \n",
    "ada_est = AdaBoostClassifier()\n",
    "ada_gs_cv = GridSearchCV(ada_est, ada_param_grid).fit(X_train, y_train)\n",
    "print(ada_gs_cv.best_score_, ada_gs_cv.best_params_)\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 42 candidates, totalling 126 fits\n",
      "[CV] n_estimators=200, learning_rate=0.0001 ..........................\n",
      "[CV] n_estimators=200, learning_rate=0.0001 ..........................\n",
      "[CV] n_estimators=200, learning_rate=0.0001 ..........................\n",
      "[CV] n_estimators=600, learning_rate=0.0001 ..........................\n",
      "[CV] n_estimators=600, learning_rate=0.0001 ..........................\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-42-05e56bcecea4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     11\u001b[0m verbose=3, pre_dispatch='2*n_jobs', error_score='raise')\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[0mpredicted_proba\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/teo/Repositories/scikit-learn/sklearn/grid_search.pyc\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    809\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    810\u001b[0m         \"\"\"\n\u001b[1;32m--> 811\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    812\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    813\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/teo/Repositories/scikit-learn/sklearn/grid_search.pyc\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, y, parameter_iterable)\u001b[0m\n\u001b[0;32m    558\u001b[0m                                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_parameters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    559\u001b[0m                                     error_score=self.error_score)\n\u001b[1;32m--> 560\u001b[1;33m                 \u001b[1;32mfor\u001b[0m \u001b[0mparameters\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mparameter_iterable\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    561\u001b[0m                 for train, test in cv)\n\u001b[0;32m    562\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/teo/Repositories/scikit-learn/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    808\u001b[0m                 \u001b[1;31m# consumption.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    809\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 810\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    811\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    812\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/teo/Repositories/scikit-learn/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    755\u001b[0m                     \u001b[1;31m# a working pool as they expect.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    756\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_initialize_pool\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 757\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    758\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    759\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "\n",
    "param_grid = {'n_estimators': [200,600,60,45,30,15],\n",
    " 'learning_rate': [1e-4,1e-3,1e-2,1e-1,5*1e-3,5*1e-2,5*1e-1]\n",
    " }\n",
    "\n",
    "aboost = AdaBoostClassifier(algorithm='SAMME.R')\n",
    "\n",
    "clf =GridSearchCV(aboost, param_grid, scoring='roc_auc', fit_params=None, n_jobs=4, iid=True, refit=True, \n",
    "verbose=3, pre_dispatch='2*n_jobs', error_score='raise')\n",
    "\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "predicted_proba = pd.DataFrame()\n",
    "predicted_proba['prob'] = clf.predict_proba(X_test).max(axis=1)\n",
    "predicted_proba['gt'] = y_test\n",
    "predicted_proba['class'] = clf.predict(X_test)\n",
    "\n",
    "threshold = 0.7\n",
    "ind = predicted_proba['prob']>threshold\n",
    "print(classification_report(predicted_proba.loc[ind,'gt'].values,predicted_proba.loc[ind,'class'].values ))\n",
    "all_time =   time.time() - start_time\n",
    "\n",
    "print('This cell took %s seconds to run' % all_time)\n",
    "\n",
    "finished = True\n",
    "#este flag es basicamente para chequear \n",
    "\n",
    "cv_result = pd.DataFrame(columns=['mean_score' ] + [key for key, value in clf.grid_scores_[0].parameters.items() ] )\n",
    "i=0\n",
    "for setup in clf.grid_scores_:\n",
    "    row = [clf.grid_scores_[i].mean_validation_score ] + [value for key, value in clf.grid_scores_[i].parameters.items() ]\n",
    "    cv_result.loc[i] = row\n",
    "    i+=1\n",
    "\n",
    "finished = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "criterion\n",
      "gini    0.802919\n",
      "Name: mean_score, dtype: float64\n",
      "criterion\n",
      "gini    0.000598\n",
      "Name: mean_score, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "coln=3\n",
    "print(cv_result.groupby(cv_result.columns[coln])['mean_score'].mean())\n",
    "print(cv_result.groupby(cv_result.columns[coln])['mean_score'].std())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CrossV SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "param_grid = [{'kernel': ['rbf'], 'gamma': list(10.0 ** np.arange(-2, 3)),\n",
    "                     'C': list(10.0 ** np.arange(0, 4))},\n",
    "                    {'kernel': ['poly'], 'C': list(10.0 ** np.arange(0, 4)), 'degree'[2,3,4]}]\n",
    "\n",
    "svc = SVC(shuffle=True, probability=True,decision_function_shape = 'ovr',\n",
    "           verbose=True, class_weight='balanced'\n",
    "          )\n",
    "\n",
    "clf =GridSearchCV(svc, param_grid, scoring='roc_auc', fit_params=None, n_jobs=4, iid=True, refit=True, \n",
    "verbose=3, pre_dispatch='2*n_jobs', error_score='raise')\n",
    "\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "predicted_proba = pd.DataFrame()\n",
    "predicted_proba['prob'] = clf.predict_proba(X_test).max(axis=1)\n",
    "predicted_proba['gt'] = y_test\n",
    "predicted_proba['class'] = clf.predict(X_test)\n",
    "\n",
    "threshold = 0.7\n",
    "ind = predicted_proba['prob']>threshold\n",
    "\n",
    "all_time =   time.time() - start_time\n",
    "\n",
    "print(classification_report(predicted_proba.loc[ind,'gt'].values,predicted_proba.loc[ind,'class'].values ))\n",
    "\n",
    "cv_result = pd.DataFrame(columns=['mean_score' ] + [key for key, value in clf.grid_scores_[0].parameters.items() ] )\n",
    "i=0\n",
    "for setup in clf.grid_scores_:\n",
    "    row = [clf.grid_scores_[i].mean_validation_score ] + [value for key, value in clf.grid_scores_[i].parameters.items() ]\n",
    "    cv_result.loc[i] = row\n",
    "    i+=1\n",
    "#este flag es basicamente para chequear que hayamos terminado nomas\n",
    "finished = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "coln=3\n",
    "print(cv_result.groupby(cv_result.columns[coln])['mean_score'].mean())\n",
    "print(cv_result.groupby(cv_result.columns[coln])['mean_score'].std())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoosting took 117.26272392272949 seconds to run\n",
      "This cell took 117.26284193992615 seconds to run\n"
     ]
    }
   ],
   "source": [
    "#tomo tiempo para saber cuanto tarda fitear el estimador\n",
    "start_time = time.time()\n",
    "\n",
    "#model = model.fit(X,y,sample_weight=W)\n",
    "\n",
    "W = np.array([10 if i == 1 or i ==2  else 1 for i in y_mini])\n",
    "gradboost.fit(X_mini,y_mini, sample_weight=W)\n",
    "\n",
    "elapsed_time =   time.time() - start_time\n",
    "print('GradientBoosting took %s seconds to run' % elapsed_time)\n",
    "\n",
    "#validated =  cross_val_score(gradboost,X,y,cv=5, scoring = \"f1_weighted\")\n",
    "\n",
    "\n",
    "all_time =   time.time() - start_time\n",
    "print('This cell took %s seconds to run' % all_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Timings\n",
    "* 5s con  10 n_estimadores, 15 max_depth y X.sample(0.2)\n",
    "* 15s con 10 n_estimadores, 15 max_depth y X.sample(0.2)\n",
    "* 47s con 10 n_estimadores, 15 max_depth y X.sample(0.4)\n",
    "* 35s con 10 n_estimadores, 15 max_depth y X.sample(0.4)\n",
    "* 117 con 20 n_estimadores, 20 max_depth y X.sample(0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    128153\n",
       "1      7064\n",
       "Name: ground_truth, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train['ground_truth'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validate - Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_grid = {'criterion': ['gini'], 'n_estimators': [15,30,50],\n",
    "  'max_features': [\"auto\", \"log2\"], \"bootstrap\": [ False, True],\n",
    "    \"min_samples_leaf\": np.append(np.random.randint(3,15,3),[3]),'max_depth':[10,20,30], \n",
    "               \"class_weight\": ['balanced']\n",
    "              }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "[CV] bootstrap=False, min_samples_leaf=6, n_estimators=25, criterion=gini, max_features=auto, max_depth=15, class_weight=balanced \n",
      "[CV] bootstrap=False, min_samples_leaf=6, n_estimators=25, criterion=gini, max_features=auto, max_depth=15, class_weight=balanced \n",
      "[CV] bootstrap=False, min_samples_leaf=6, n_estimators=25, criterion=gini, max_features=auto, max_depth=15, class_weight=balanced \n",
      "[CV] bootstrap=False, min_samples_leaf=12, n_estimators=25, criterion=gini, max_features=auto, max_depth=15, class_weight=balanced \n",
      "[CV] bootstrap=False, min_samples_leaf=12, n_estimators=25, criterion=gini, max_features=auto, max_depth=15, class_weight=balanced \n",
      "[CV] bootstrap=False, min_samples_leaf=12, n_estimators=25, criterion=gini, max_features=auto, max_depth=15, class_weight=balanced \n",
      "[CV] bootstrap=False, min_samples_leaf=6, n_estimators=25, criterion=gini, max_features=auto, max_depth=25, class_weight=balanced \n",
      "[CV] bootstrap=False, min_samples_leaf=6, n_estimators=25, criterion=gini, max_features=auto, max_depth=25, class_weight=balanced \n",
      "[CV]  bootstrap=False, min_samples_leaf=6, n_estimators=25, criterion=gini, max_features=auto, max_depth=15, class_weight=balanced, score=0.499320 - 4.0min\n",
      "[CV] bootstrap=False, min_samples_leaf=6, n_estimators=25, criterion=gini, max_features=auto, max_depth=25, class_weight=balanced \n",
      "[CV]  bootstrap=False, min_samples_leaf=6, n_estimators=25, criterion=gini, max_features=auto, max_depth=15, class_weight=balanced, score=0.501824 - 4.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done  13 out of  12 | elapsed:  4.2min remaining:  -19.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] bootstrap=False, min_samples_leaf=12, n_estimators=25, criterion=gini, max_features=auto, max_depth=25, class_weight=balanced \n",
      "[CV]  bootstrap=False, min_samples_leaf=6, n_estimators=25, criterion=gini, max_features=auto, max_depth=15, class_weight=balanced, score=0.500056 - 4.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done  13 out of  12 | elapsed:  4.3min remaining:  -19.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] bootstrap=False, min_samples_leaf=12, n_estimators=25, criterion=gini, max_features=auto, max_depth=25, class_weight=balanced \n",
      "[CV]  bootstrap=False, min_samples_leaf=12, n_estimators=25, criterion=gini, max_features=auto, max_depth=15, class_weight=balanced, score=0.498584 - 4.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done  13 out of  12 | elapsed:  4.4min remaining:  -20.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] bootstrap=False, min_samples_leaf=12, n_estimators=25, criterion=gini, max_features=auto, max_depth=25, class_weight=balanced \n",
      "[CV]  bootstrap=False, min_samples_leaf=12, n_estimators=25, criterion=gini, max_features=auto, max_depth=15, class_weight=balanced, score=0.500978 - 4.4min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done  13 out of  12 | elapsed:  4.7min remaining:  -21.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  bootstrap=False, min_samples_leaf=12, n_estimators=25, criterion=gini, max_features=auto, max_depth=15, class_weight=balanced, score=0.500560 - 4.4min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done  13 out of  12 | elapsed:  4.8min remaining:  -22.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  bootstrap=False, min_samples_leaf=6, n_estimators=25, criterion=gini, max_features=auto, max_depth=25, class_weight=balanced, score=0.499370 - 5.8min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done  13 out of  12 | elapsed:  6.3min remaining:  -29.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  bootstrap=False, min_samples_leaf=6, n_estimators=25, criterion=gini, max_features=auto, max_depth=25, class_weight=balanced, score=0.499699 - 6.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done  13 out of  12 | elapsed:  6.8min remaining:  -31.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  bootstrap=False, min_samples_leaf=12, n_estimators=25, criterion=gini, max_features=auto, max_depth=25, class_weight=balanced, score=0.502255 - 5.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done  13 out of  12 | elapsed:  9.5min remaining:  -43.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  bootstrap=False, min_samples_leaf=6, n_estimators=25, criterion=gini, max_features=auto, max_depth=25, class_weight=balanced, score=0.499331 - 5.4min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done  13 out of  12 | elapsed:  9.7min remaining:  -44.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  bootstrap=False, min_samples_leaf=12, n_estimators=25, criterion=gini, max_features=auto, max_depth=25, class_weight=balanced, score=0.500189 - 5.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done  13 out of  12 | elapsed:  9.7min remaining:  -44.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  bootstrap=False, min_samples_leaf=12, n_estimators=25, criterion=gini, max_features=auto, max_depth=25, class_weight=balanced, score=0.499681 - 5.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done  13 out of  12 | elapsed:  9.8min remaining:  -45.1s\n",
      "[Parallel(n_jobs=8)]: Done  12 out of  12 | elapsed:  9.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Search took 1023.46121788 seconds to run\n",
      "Grid Search took 0.000302076339722 seconds to run\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.71      0.92      0.80     47125\n",
      "          1       0.29      0.08      0.13     19498\n",
      "\n",
      "avg / total       0.58      0.67      0.60     66623\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.71      0.77      0.74     94223\n",
      "          1       0.29      0.23      0.26     39023\n",
      "\n",
      "avg / total       0.59      0.61      0.60    133246\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.71      0.66      0.68    141157\n",
      "          1       0.30      0.35      0.32     58712\n",
      "\n",
      "avg / total       0.59      0.57      0.57    199869\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.71      0.57      0.63    188258\n",
      "          1       0.29      0.43      0.35     78234\n",
      "\n",
      "avg / total       0.59      0.53      0.55    266492\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.71      0.67      0.69    470763\n",
      "          1       0.29      0.33      0.31    195467\n",
      "\n",
      "avg / total       0.59      0.57      0.58    666230\n",
      "\n",
      "* Rates for distinct percentage groups \n",
      "\n",
      "10 %% group rate: 0.292661693409 size: 66623\n",
      "20 %% group rate: 0.292864326134 size: 133246\n",
      "30 %% group rate: 0.293752407827 size: 199869\n",
      "40 %% group rate: 0.293569788211 size: 266492\n",
      "This cell took 1046.18349791 seconds to run\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "param_grid = {'criterion': ['gini'], 'n_estimators': [25],\n",
    "  'max_features': [\"auto\"], \"bootstrap\": [ False],\n",
    "    \"min_samples_leaf\":[6,12],'max_depth':[15,25], \n",
    "               \"class_weight\": ['balanced']\n",
    "              }\n",
    "rforest  = RandomForestClassifier( )\n",
    "\n",
    "clf =GridSearchCV(rforest, param_grid, scoring='roc_auc', fit_params=None, n_jobs=8, iid=True, refit=True, \n",
    "verbose=3, pre_dispatch='2*n_jobs', error_score='raise')\n",
    "\n",
    "clf2 = RandomForestClassifier()\n",
    "\n",
    "X = X_train[X_train.columns[:-1]].values\n",
    "Y = X_train['y'].values\n",
    "\n",
    "#X = X_train_categorical\n",
    "clf.fit(X,Y)\n",
    "\n",
    "\n",
    "#random_search.fit(X_train,y_train)\n",
    "elapsed_time =  time.time() - start_time\n",
    "\n",
    "print('Random Search took %s seconds to run' % elapsed_time)\n",
    "\n",
    "\n",
    "all_time =   time.time() - start_time \n",
    "print('Grid Search took %s seconds to run' % (all_time - elapsed_time))\n",
    "\n",
    "\n",
    "X_test = X_val[X_train.columns[:-1]].values\n",
    "Y_test = X_val['y'].values\n",
    "\n",
    "predicted_proba = pd.DataFrame()\n",
    "predicted_proba['prob'] = clf.predict_proba(X_test).max(axis=1)\n",
    "predicted_proba.index = X_val.index\n",
    "predicted_proba['class'] = clf.predict(X_test)\n",
    "predicted_proba['gt'] =  Y_test\n",
    "predicted_proba.index.name = \"USER\"\n",
    "predicted_proba.sort_values(by = 'prob',ascending = False, inplace = True)\n",
    "\n",
    "cut_percentages = [10,20,30,40]\n",
    "#converted = (predicted_proba['class']==1)\n",
    "#me fijo todos los users que van a convertir en el futuro\n",
    "\n",
    "past_epidemic = X_val[X_val['y']==1].index.values\n",
    "\n",
    "start = 0\n",
    "mobility_dict = {}\n",
    "index_segments = []\n",
    "for i in cut_percentages:\n",
    "    cut_size = int(len(predicted_proba)*i/100.0)    \n",
    "    bool_array = (~np.ones(len(predicted_proba), dtype=bool))\n",
    "    bool_array[start: start + cut_size] = True\n",
    "    index_segments += [bool_array]\n",
    "    start = start + cut_size\n",
    "    #subtable = \n",
    "    mobility_dict[str(i)] = predicted_proba.loc[index_segments[-1]].index.values\n",
    "    \n",
    "    print(classification_report(predicted_proba.loc[index_segments[-1],\"gt\"].values,\n",
    "                            predicted_proba.loc[index_segments[-1],'class'].values ))\n",
    "    \n",
    "    \n",
    "print(classification_report(predicted_proba.loc[:,\"gt\"].values,\n",
    "                            predicted_proba.loc[:,'class'].values ))\n",
    "    \n",
    "    \n",
    "print(\"* Rates for distinct percentage groups \\n\")\n",
    "for i in cut_percentages:\n",
    "    subtable = mobility_dict[str(i)]\n",
    "\n",
    "    print(\"{0} %% group rate: {1} size: {2}\".format(str(i), \n",
    "                                np.in1d(subtable,past_epidemic).sum()*1.0/len(subtable),len(subtable))) \n",
    "    \n",
    "\n",
    "clf2.set_params(n_jobs = 6,**clf.best_params_)\n",
    "clf2.fit(X,Y)\n",
    "    \n",
    "cv_result = pd.DataFrame(columns=['mean_score' ] + [key for key, value in clf.grid_scores_[0].parameters.items() ] )\n",
    "i=0\n",
    "for setup in clf.grid_scores_:\n",
    "    row = [clf.grid_scores_[i].mean_validation_score ] + [value for key, value in clf.grid_scores_[i].parameters.items() ]\n",
    "    cv_result.loc[i] = row\n",
    "    i+=1\n",
    "\n",
    "    \n",
    "    \n",
    "all_time =   time.time() - start_time\n",
    "\n",
    "#este flag es basicamente para chequear que hayamos terminado nomas\n",
    "finished = True\n",
    "\n",
    "print('This cell took %s seconds to run' % all_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.70631558433771058, 0.29368441566228937)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.bincount(Y)[0]*1.0/np.bincount(Y).sum(), np.bincount(Y)[1]*1.0/np.bincount(Y).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=False, class_weight='balanced',\n",
       "            criterion='gini', max_depth=25, max_features='auto',\n",
       "            max_leaf_nodes=None, min_samples_leaf=12, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=25, n_jobs=6,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf2 = RandomForestClassifier()\n",
    "clf2.set_params(n_jobs = 6,**clf.best_params_)\n",
    "clf2.fit(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#OJO esta parte con poly = True no funciona.\n",
    "feature_importance = pd.DataFrame(clf2.feature_importances_,columns=['prob'])\n",
    "feature_importance = feature_importance.sort_values(by = 'prob',ascending=False)\n",
    "selected_features = X_train.columns[feature_importance.index]\n",
    "\n",
    "#guardo los labels como estan en las tablas (con numeros y no palabras)\n",
    "feature_importance['labels'] = selected_features.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prob</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.047771</td>\n",
       "      <td>ANTENNA_ID_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.047296</td>\n",
       "      <td>ANTENNA_ID_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.046120</td>\n",
       "      <td>ANTENNA_ID_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.045383</td>\n",
       "      <td>ANTENNA_ID_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.045289</td>\n",
       "      <td>MOBILITY_DIAMETER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.043635</td>\n",
       "      <td>ANTENNA_ID_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.040790</td>\n",
       "      <td>ANTENNA_ID_5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.040621</td>\n",
       "      <td>TimeWeekDaylight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.040533</td>\n",
       "      <td>ANTENNA_ID_6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.038278</td>\n",
       "      <td>ANTENNA_ID_7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.038017</td>\n",
       "      <td>TimeWeekend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.037330</td>\n",
       "      <td>TimeWeekNight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.036551</td>\n",
       "      <td>ANTENNA_ID_8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.035400</td>\n",
       "      <td>ANTENNA_ID_9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.033911</td>\n",
       "      <td>COUNT_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.028475</td>\n",
       "      <td>COUNT_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.027249</td>\n",
       "      <td>CallsWeekDaylight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.025336</td>\n",
       "      <td>COUNT_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.024330</td>\n",
       "      <td>TimeWeekDaylight_EPI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.024236</td>\n",
       "      <td>CallsWeekend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.023595</td>\n",
       "      <td>CallsWeekNight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.023021</td>\n",
       "      <td>COUNT_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.022360</td>\n",
       "      <td>TimeWeekend_EPI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.021073</td>\n",
       "      <td>COUNT_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.020677</td>\n",
       "      <td>TimeWeekNight_EPI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.016019</td>\n",
       "      <td>COUNT_5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.015685</td>\n",
       "      <td>TOTAL_USERS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.015399</td>\n",
       "      <td>CallsWeekDaylight_EPI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.014447</td>\n",
       "      <td>COUNT_6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.013324</td>\n",
       "      <td>COUNT_7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.012807</td>\n",
       "      <td>CallsWeekend_EPI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.012719</td>\n",
       "      <td>COUNT_8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.012291</td>\n",
       "      <td>COUNT_9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.012157</td>\n",
       "      <td>CallsWeekNight_EPI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.008414</td>\n",
       "      <td>EPI_USERS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.005324</td>\n",
       "      <td>EXP_USERS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.004137</td>\n",
       "      <td>EPIDEMIC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        prob                 labels\n",
       "2   0.047771           ANTENNA_ID_1\n",
       "0   0.047296           ANTENNA_ID_0\n",
       "6   0.046120           ANTENNA_ID_3\n",
       "4   0.045383           ANTENNA_ID_2\n",
       "20  0.045289      MOBILITY_DIAMETER\n",
       "8   0.043635           ANTENNA_ID_4\n",
       "10  0.040790           ANTENNA_ID_5\n",
       "25  0.040621       TimeWeekDaylight\n",
       "12  0.040533           ANTENNA_ID_6\n",
       "14  0.038278           ANTENNA_ID_7\n",
       "27  0.038017            TimeWeekend\n",
       "26  0.037330          TimeWeekNight\n",
       "16  0.036551           ANTENNA_ID_8\n",
       "18  0.035400           ANTENNA_ID_9\n",
       "1   0.033911                COUNT_0\n",
       "3   0.028475                COUNT_1\n",
       "22  0.027249      CallsWeekDaylight\n",
       "5   0.025336                COUNT_2\n",
       "31  0.024330   TimeWeekDaylight_EPI\n",
       "24  0.024236           CallsWeekend\n",
       "23  0.023595         CallsWeekNight\n",
       "7   0.023021                COUNT_3\n",
       "33  0.022360        TimeWeekend_EPI\n",
       "9   0.021073                COUNT_4\n",
       "32  0.020677      TimeWeekNight_EPI\n",
       "11  0.016019                COUNT_5\n",
       "34  0.015685            TOTAL_USERS\n",
       "28  0.015399  CallsWeekDaylight_EPI\n",
       "13  0.014447                COUNT_6\n",
       "15  0.013324                COUNT_7\n",
       "30  0.012807       CallsWeekend_EPI\n",
       "17  0.012719                COUNT_8\n",
       "19  0.012291                COUNT_9\n",
       "29  0.012157     CallsWeekNight_EPI\n",
       "35  0.008414              EPI_USERS\n",
       "36  0.005324              EXP_USERS\n",
       "21  0.004137               EPIDEMIC"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1600644, 38), (1600644,))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape,y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1600644, 38)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(RandomForestClassifier(bootstrap=False, class_weight='balanced',\n",
       "             criterion='gini', max_depth=15, max_features='auto',\n",
       "             max_leaf_nodes=None, min_samples_leaf=4, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, n_estimators=35, n_jobs=1,\n",
       "             oob_score=False, random_state=None, verbose=0,\n",
       "             warm_start=False), 0.54557839409818476)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_estimator_, clf.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = classification_report(predicted_proba.loc[ind,'y'].values,predicted_proba.loc[ind,'class'].values )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_estimators\n",
      "20.0    0.537925\n",
      "35.0    0.541880\n",
      "Name: mean_score, dtype: float64\n",
      "n_estimators\n",
      "20.0    0.00539\n",
      "35.0    0.00419\n",
      "Name: mean_score, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "coln = 3\n",
    "print(cv_result.groupby(cv_result.columns[coln])['mean_score'].mean())\n",
    "print(cv_result.groupby(cv_result.columns[coln])['mean_score'].std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results\n",
    "* NO escalar (normalizar, restar la media  dividir por la std, etc) los resultados pues REVIENTAN los scores.\n",
    "* bootstrap  = False es 5% mejor\n",
    "* min_samples_leaf = mas chico es claramente mejor, pero tmb aumenta el overfitting lo cual me hace caer mucho el valor del recall en el test_set. Sin embargo es un parametro muy sensible en la precision. Resta evaluar asi el tradeoff entre la precision y el volumen de users al cual queremos llegar.\n",
    "* n_estimators = aumentar mas de 30 no tendria mucho sentido\n",
    "* citerion = entropy o gini no cambia. gini podria ser mejor entonces pues entropy usa logs de los valores lo cual es mas computacionalmente costoso\n",
    "* max_features = no afecta al score. con auto esta bien\n",
    "* max_depth =  mas es mejor. intentaria probar con >15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validate ExtraTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Virtualenvs/mateo/lib/python3.4/site-packages/sklearn/metrics/classification.py:1117: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00     26720\n",
      "          1       0.25      1.00      0.40      8738\n",
      "\n",
      "avg / total       0.06      0.25      0.10     35458\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.43      0.60     66920\n",
      "          1       0.07      0.76      0.14      3996\n",
      "\n",
      "avg / total       0.92      0.45      0.57     70916\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      0.99    105255\n",
      "          1       0.00      0.00      0.00      1119\n",
      "\n",
      "avg / total       0.98      0.99      0.98    106374\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      1.00      0.99    139582\n",
      "          1       0.00      0.00      0.00      2250\n",
      "\n",
      "avg / total       0.97      0.98      0.98    141832\n",
      "\n",
      "Rates for dafiti app 189 \n",
      "10 %% group rate: 0.10429240227875233 size: 35458\n",
      "20 %% group rate: 0.024479666083817474 size: 70916\n",
      "30 %% group rate: 0.009494801361234888 size: 106374\n",
      "40 %% group rate: 0.014101190140447854 size: 141832\n"
     ]
    }
   ],
   "source": [
    "predicted_proba = pd.DataFrame()\n",
    "predicted_proba['prob'] = clf.predict_proba(X_train)[:,1]\n",
    "predicted_proba['class'] = clf.predict(X_train)\n",
    "predicted_proba['ref_hash'] =  train_table.index.values\n",
    "predicted_proba['y'] =  y_train\n",
    "predicted_proba.sort_values(by = 'prob',ascending = False, inplace = True)\n",
    "\n",
    "cut_percentages = [10,20,30,40]\n",
    "#converted = (predicted_proba['class']==1)\n",
    "#me fijo todos los users que van a convertir en el futuro\n",
    "past_epidemic = test_table[test_table['y']>0]['ref_hash'].values\n",
    "\n",
    "\n",
    "start = 0\n",
    "mobility_dict = {}\n",
    "index_segments = []\n",
    "for i in cut_percentages:\n",
    "    cut_size = int(len(predicted_proba)*i/100.0)    \n",
    "    bool_array = (~np.ones(len(predicted_proba), dtype=bool))\n",
    "    bool_array[start: start + cut_size] = True\n",
    "    index_segments += [bool_array]\n",
    "    start = start + cut_size\n",
    "#    subtable = \n",
    "    mobility_dict[str(i)] = predicted_proba.loc[index_segments[-1],'ref_hash']\n",
    "    \n",
    "    print(classification_report(predicted_proba.loc[index_segments[-1],'y'].values,\n",
    "                            predicted_proba.loc[index_segments[-1],'class'].values ))\n",
    "    \n",
    "print(\"Rates for %s app %s \" % (appid_name[application_id], application_id))   \n",
    "for i in cut_percentages:\n",
    "    subtable = mobility_dict[str(i)]\n",
    "    \n",
    "    print(\"{0} %% group rate: {1} size: {2}\".format(str(i), subtable.isin(past_epidemic).sum()*1.0/len(subtable), \n",
    "                                       len(subtable))) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha\n",
      "0.00     0.000000\n",
      "0.01     0.242260\n",
      "0.10     0.242266\n",
      "0.50     0.242220\n",
      "1.00     0.242200\n",
      "10.00    0.241269\n",
      "Name: mean_score, dtype: float64\n",
      "alpha\n",
      "0.00     0.000000\n",
      "0.01     0.017568\n",
      "0.10     0.017598\n",
      "0.50     0.017578\n",
      "1.00     0.017570\n",
      "10.00    0.017780\n",
      "Name: mean_score, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "coln = 2\n",
    "print(cv_result.groupby(cv_result.columns[coln])['mean_score'].mean())\n",
    "print(cv_result.groupby(cv_result.columns[coln])['mean_score'].std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross validate MNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.85      0.91     70323\n",
      "          1       0.12      0.73      0.20      1932\n",
      "\n",
      "avg / total       0.97      0.84      0.89     72255\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.85      0.91     70323\n",
      "          1       0.12      0.73      0.20      1932\n",
      "\n",
      "avg / total       0.97      0.84      0.89     72255\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.85      0.91     70323\n",
      "          1       0.12      0.73      0.20      1932\n",
      "\n",
      "avg / total       0.97      0.84      0.89     72255\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.85      0.91     70323\n",
      "          1       0.12      0.73      0.20      1932\n",
      "\n",
      "avg / total       0.97      0.84      0.89     72255\n",
      "\n",
      "This cell took 1.06442093849 seconds to run\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# pero tenemos que transformar a y en un vector canonico indicando en 1 en la posicion correspondiente a su categoria\n",
    "#y =  label_binarize(X_train['ground_truth'].values.astype(int),\n",
    "#                    classes=list(set(X_train['ground_truth'].values.astype(int))))\n",
    "\n",
    "perc = 0.3\n",
    "mini_ind = np.random.choice(X_train.shape[0],int(perc*X_train.shape[0]),replace=False)\n",
    "#X_mini =  X[mini_ind,:]\n",
    "#y_mini = y[mini_ind]\n",
    "\n",
    "\n",
    "clf = MultinomialNB(\n",
    "        )\n",
    "\n",
    "clf2 = MultinomialNB()\n",
    "\n",
    "validated = []\n",
    "# Only take the first fold.\n",
    "n_folds = 4\n",
    "for i in range(n_folds):\n",
    "    # Break up the dataset into non-overlapping training (75%) and testing\n",
    "    # (25%) sets.\n",
    "    skf = StratifiedKFold(y_train, n_folds=n_folds)\n",
    "    train_index, test_index = next(iter(skf))\n",
    "\n",
    "    X_traincv = X_train[train_index]\n",
    "    y_traincv = y_train[train_index]\n",
    "\n",
    "    n_classes = len(np.unique(y_traincv))\n",
    "\n",
    "    clf.fit(X_traincv,y_traincv)\n",
    "    predictions = clf.predict(X_traincv)\n",
    "        \n",
    "    expected = y_traincv\n",
    "\n",
    "    print(classification_report(expected, predictions))\n",
    "\n",
    "\n",
    "predicted_proba = pd.DataFrame()\n",
    "predicted_proba['prob'] = clf.predict_proba(X_test).max(axis=1)\n",
    "predicted_proba['y'] = y_test\n",
    "predicted_proba['class'] = clf.predict(X_test)\n",
    "\n",
    "clf2.set_params(n_jobs = 6,**clf.best_params_)\n",
    "clf2.fit(X,Y)\n",
    "\n",
    "\n",
    "#este flag es basicamente para chequear que hayamos terminado nomas\n",
    "finished = True\n",
    "\n",
    "all_time =   time.time() - start_time\n",
    "print('This cell took %s seconds to run' % all_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.87      0.93    185744\n",
      "          1       0.15      0.73      0.26      5906\n",
      "\n",
      "avg / total       0.96      0.87      0.91    191650\n",
      "\n"
     ]
    }
   ],
   "source": [
    "threshold = 0.99\n",
    "ind = predicted_proba['prob']>threshold\n",
    "print(classification_report(predicted_proba.loc[ind,'y'].values,predicted_proba.loc[ind,'class'].values ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC took 362.8217749595642 seconds to run\n",
      "This cell took 362.8219118118286 seconds to run\n"
     ]
    }
   ],
   "source": [
    "#tomo tiempo para saber cuanto tarda fitear el estimador\n",
    "start_time = time.time()\n",
    "\n",
    "svc2.fit(X_mini,y_mini)\n",
    "elapsed_time =   time.time() - start_time\n",
    "print('SVC took %s seconds to run' % elapsed_time)\n",
    "\n",
    "all_time =   time.time() - start_time\n",
    "print('This cell took %s seconds to run' % all_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Timings\n",
    "* 40k samples : 360s\n",
    "* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logit took 1073.0756621360779 seconds to run\n"
     ]
    }
   ],
   "source": [
    "start_time =  time.time()\n",
    "lr.fit(X_train,y_train)\n",
    "elapsed_time =   time.time() - start_time\n",
    "print('Logit took %s seconds to run' % elapsed_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logit took 89.15975689888 seconds to run\n",
      "Linear SVC took 804.7178750038147 seconds to run"
     ]
    }
   ],
   "source": [
    "#tomo tiempo para saber cuanto tarda fitear el estimador\n",
    "start_time = time.time()\n",
    "\n",
    "lr.fit(X_train,y_train)\n",
    "elapsed_time =   time.time() - start_time\n",
    "print('Logit took %s seconds to run' % elapsed_time)\n",
    "\n",
    "svc.fit(X_train,y_train)\n",
    "elapsed_time =   time.time() - start_time\n",
    "print('Linear SVC took %s seconds to run' % elapsed_time)\n",
    "\n",
    "all_time =   time.time() - start_time\n",
    "print('This cell took %s seconds to run' % all_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y.value_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Todo\n",
    "* evaluate hit_rate and \n",
    "* tune adaboost, bernoulliRBM\n",
    "* xgboost\n",
    "* libffm\n",
    "* SVC muy lento.. speed up in AWS\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

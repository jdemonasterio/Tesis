{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/juan/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/_multiprocessing_helpers.py:29: UserWarning: [Errno 38] Function not implemented.  joblib will operate in serial mode\n",
      "  warnings.warn('%s.  joblib will operate in serial mode' % (e,))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import random;\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import cluster\n",
    "from sklearn.neighbors import kneighbors_graph\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "np.random.seed(2015)\n",
    "#rootdir=\"/Users/jampper/Repositories/analytics/UserAnalytics\"\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "input_file= 'tables/test.txt.gz' #% (directory,contract_type,directory)\n",
    "\n",
    "def get_output_file(input_file,hash_map=False,night_filter=False,week_end=False):\n",
    "    output = input_file.replace(\".txt.gz\",\"\")\n",
    "    if week_end == True:\n",
    "        output = output + \"_wkend\"\n",
    "    if night_filter == True:\n",
    "        output = output + \"_ngtfilter\"\n",
    "    if hash_map == True:\n",
    "        output = output + \"_usr_hash_map\"\n",
    "    return output + \"_output.txt.gz\"\n",
    "\n",
    "output_file = get_output_file(input_file)\n",
    "\n",
    "selected_attributes = pd.read_csv(\n",
    "            \"DevicesTesting.csv.gz\",\n",
    "            engine = 'c',\n",
    "#            chunksize = 5*10**5,\n",
    "#            iterator =True,\n",
    "            sep = ',',\n",
    "            skipinitialspace=True,\n",
    "#            skiprows=2,\n",
    "            #skipfooter =1,\n",
    "#            header = 0,\n",
    "            index_col=0,\n",
    "            compression = \"gzip\",    \n",
    "#            names = ['user_id','event_id','lead_event'],\n",
    "#            converters =  {'lead_event':strip},\n",
    "#            na_values=na_val,\n",
    "            #usecols = ['Target', 'AntennaID','TimeStamp']\n",
    "            #dtype = {'event_id':np.uint16}\n",
    "            )\n",
    "\n",
    "\n",
    "\n",
    "def get_user_hash_map(table):\n",
    "    if isinstance(table, str):\n",
    "        pd.read_csv(\n",
    "            table,\n",
    "            engine = 'c',\n",
    "#            chunksize = 5*10**5,\n",
    "#            iterator =True,\n",
    "            sep = ',',\n",
    "            skipinitialspace=True,\n",
    "#            skiprows=2,\n",
    "            #skipfooter =1,#la ultima fila en la ultima columna viene vacia por el LEAD de SQL, la descarto\n",
    "#            header = 0,\n",
    "            index_col=0,\n",
    "#            names = ['user_id','event_id','lead_event'],\n",
    "#            converters =  {'lead_event':strip},\n",
    "#            na_values=na_val,\n",
    "            #usecols = ['Target', 'AntennaID','TimeStamp']\n",
    "            #dtype = {'event_id':np.uint16}\n",
    "            )\n",
    "    \n",
    "    #convertimos el indice de la tabla de selected attributes a una mapa para que sea mas facil\n",
    "    vals = range(1, len(table)+1 ) #con +1 porque me gusta pensar que los datos son positivos y los NAn==-1\n",
    "    user_hash_range_map = dict(zip(table.index.values, vals))\n",
    "    user_hash_range_map = pd.DataFrame.from_dict(user_hash_range_map,orient='index',dtype=np.uint32)\n",
    "    user_hash_range_map.columns=['int_map']\n",
    "    user_hash_range_map.index.name = 'user_hash'\n",
    "    user_hash_range_map.sort_values(by='int_map',inplace=True)\n",
    "    user_hash_range_map = user_hash_range_map['int_map']\n",
    "\n",
    "    #paso a diccionario y mapeo el indice\n",
    "    user_hash_range_dict = user_hash_range_map.to_dict()\n",
    "    \n",
    "    return user_hash_range_dict\n",
    "\n",
    "\n",
    "user_hash_range_dict=get_user_hash_map(selected_attributes)\n",
    "selected_attributes.index = pd.Series({x: user_hash_range_dict[x] for x in selected_attributes.index})\n",
    "\n",
    "X = selected_attributes\n",
    "\n",
    "X.shape,\n",
    "if (X.shape[0]*X.shape[1]) > 12*10**6:\n",
    "    print(\"Warning, total # of cells is %d\" %(X.shape[0]*X.shape[1]))\n",
    "\n",
    "pca = PCA(n_components=0.9).fit(X)\n",
    "reduced_data = PCA(n_components=0.9).fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaling Data \n",
      " elapsed time is: 0.000143051147461\n",
      "connectivity matrix for structured Ward \n",
      " current time is: 0.0389719009399\n",
      "make connectivity symmetric \n",
      " elapsed time is: 279.512846947\n",
      "create clustering estimators \n",
      " elapsed time is: 279.570747852\n"
     ]
    }
   ],
   "source": [
    "i_dataset =0\n",
    "start_time = time.time()\n",
    "def elapsed_time(start_time):\n",
    "    return time.time() - start_time\n",
    "print('Scaling Data \\n elapsed time is: %s' % elapsed_time(start_time) )\n",
    "X = StandardScaler().fit_transform(X)\n",
    "\n",
    "# estimate bandwidth for mean shift\n",
    "#print('estimate bandwidth for mean shift \\n current time is: %s' % elapsed_time(start_time) )\n",
    "#bandwidth = cluster.estimate_bandwidth(X, quantile=0.3)\n",
    "\n",
    "# connectivity matrix for structured Ward\n",
    "print('connectivity matrix for structured Ward \\n current time is: %s' % elapsed_time(start_time) )\n",
    "connectivity = kneighbors_graph(X, n_neighbors=10, include_self=False)\n",
    "\n",
    "print('make connectivity symmetric \\n elapsed time is: %s' % elapsed_time(start_time) )\n",
    "# make connectivity symmetric\n",
    "connectivity = 0.5 * (connectivity + connectivity.T)\n",
    "\n",
    "print('create clustering estimators \\n elapsed time is: %s' % elapsed_time(start_time) )\n",
    "# create clustering estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1455933803.004858"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f81ea37c910>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "# create clustering estimators\n",
    "\n",
    "#ms = cluster.MeanShift(bandwidth=bandwidth, bin_seeding=True)\n",
    "\n",
    "kmeans = cluster.KMeans(n_clusters=4)\n",
    "ward = cluster.AgglomerativeClustering(n_clusters=4, linkage='ward',\n",
    "                                       connectivity=connectivity)\n",
    "spectral = cluster.SpectralClustering(n_clusters=4,\n",
    "                                      eigen_solver='arpack',\n",
    "                                      affinity=\"nearest_neighbors\")\n",
    "dbscan = cluster.DBSCAN(eps=.2)\n",
    "affinity_propagation = cluster.AffinityPropagation(damping=.6,\n",
    "                                                   max_iter=100,verbose=1)\n",
    "\n",
    "average_linkage = cluster.AgglomerativeClustering(\n",
    "    linkage=\"average\", affinity=\"cityblock\", n_clusters=4,\n",
    "    connectivity=connectivity)\n",
    "\n",
    "birch = cluster.Birch(n_clusters=4)\n",
    "#clustering_algorithms = [\n",
    "#    ward, affinity_propagation, spectral, kmeans, average_linkage,\n",
    "#    dbscan, birch] #+ [ms]\n",
    "\n",
    "#clustering_names = [\n",
    "#    'Ward','AffinityPropagation', \n",
    "#    'SpectralClustering', 'KMeans',  'AgglomerativeClustering',\n",
    "#    'DBSCAN', 'Birch']  #+ ['MeanShift']\n",
    "\n",
    "plt.figure(figsize=(len(clustering_names) * 2 + 3, 9.5))\n",
    "plt.subplots_adjust(left=.02, right=.98, bottom=.001, top=.96, wspace=.05,\n",
    "                    hspace=.01)\n",
    "plot_num = 1\n",
    "\n",
    "time.time()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clustering_algorithms = [ward]\n",
    "clustering_names = [\n",
    "    'Ward']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm iterator fitting \n",
      " elapsed time is: 1896.51348186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/juan/anaconda2/lib/python2.7/site-packages/sklearn/cluster/hierarchical.py:205: UserWarning: the number of connected components of the connectivity matrix is 502 > 1. Completing it to avoid stopping the tree early.\n",
      "  connectivity, n_components = _fix_connectivity(X, connectivity)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-6aa9d53f89ae>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;31m# predict cluster memberships\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mt0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0malgorithm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0mt1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Testing clustering model %s \\n elapsed time is: %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0melapsed_time\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstart_time\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/juan/anaconda2/lib/python2.7/site-packages/sklearn/cluster/hierarchical.pyc\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    754\u001b[0m                                        \u001b[0mn_components\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_components\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    755\u001b[0m                                        \u001b[0mn_clusters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_clusters\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 756\u001b[1;33m                                        **kwargs)\n\u001b[0m\u001b[0;32m    757\u001b[0m         \u001b[1;31m# Cut the tree\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    758\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcompute_full_tree\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/juan/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/memory.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    279\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    280\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 281\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    282\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    283\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcall_and_shelve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/juan/anaconda2/lib/python2.7/site-packages/sklearn/cluster/hierarchical.pyc\u001b[0m in \u001b[0;36mward_tree\u001b[1;34m(X, connectivity, n_components, n_clusters, return_distance)\u001b[0m\n\u001b[0;32m    203\u001b[0m             \u001b[1;34m\"matrix and will be removed in 0.18\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    204\u001b[0m             DeprecationWarning)\n\u001b[1;32m--> 205\u001b[1;33m     \u001b[0mconnectivity\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_components\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_fix_connectivity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconnectivity\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    206\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mn_clusters\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[0mn_nodes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mn_samples\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/juan/anaconda2/lib/python2.7/site-packages/sklearn/cluster/hierarchical.pyc\u001b[0m in \u001b[0;36m_fix_connectivity\u001b[1;34m(X, connectivity, n_components, affinity)\u001b[0m\n\u001b[0;32m     75\u001b[0m                 \u001b[0mXj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx_j\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m                 \u001b[0mD\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpairwise_distances\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mXj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maffinity\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 77\u001b[1;33m                 \u001b[0mii\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mjj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mD\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mD\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     78\u001b[0m                 \u001b[0mii\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mii\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m                 \u001b[0mjj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjj\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print('Algorithm iterator fitting \\n elapsed time is: %s' % elapsed_time(start_time) )\n",
    "for name, algorithm in zip(clustering_names, clustering_algorithms):\n",
    "    # predict cluster memberships\n",
    "    t0 = time.time()\n",
    "    algorithm.fit(X)\n",
    "    t1 = time.time()\n",
    "    print('Testing clustering model %s \\n elapsed time is: %s' % (name, elapsed_time(start_time)) )\n",
    "    if hasattr(algorithm, 'labels_'):\n",
    "        y_pred = algorithm.labels_.astype(np.int)\n",
    "        selected_attributes['pred_%s'%name] = y_pred\n",
    "    else:\n",
    "        y_pred = algorithm.predict(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
